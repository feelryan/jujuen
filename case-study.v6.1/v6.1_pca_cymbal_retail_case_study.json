[
  {
    "no": "1",
    "level": "hard",
    "keywords": "Migration, Cloud SQL, Database Migration Service, Compatibility",
    "question": [
      {
        "t": "Cymbal Retail 希望將其負責儲存產品目錄與客戶資料的舊有 Microsoft SQL Server 資料庫遷移至 Google Cloud，以支援新的生成式 AI 解決方案並降低授權成本。",
        "en": "Cymbal Retail wants to migrate its legacy Microsoft SQL Server databases, which store product catalogs and customer data, to Google Cloud to support the new Gen AI solution and reduce licensing costs.",
        "wg": [
          { "t": "遷移", "en": "migrate", "ps": "verb" },
          { "t": "授權成本", "en": "licensing costs", "ps": "noun" }
        ]
      },
      {
        "t": "目前的應用程式依賴複雜的儲存程序 (Stored Procedures) 以及與地端系統的交易複製 (Transactional Replication)，且開發團隊希望能盡量減少應用程式碼的重寫。",
        "en": "The current application relies on complex stored procedures and transactional replication with on-premises systems, and the development team wants to minimize application code rewrites.",
        "wg": [
          { "t": "儲存程序", "en": "stored procedures", "ps": "noun" },
          { "t": "重寫", "en": "rewrites", "ps": "verb" }
        ]
      },
      {
        "t": "您需要設計一個能夠提供高可用性、減少維運管理負擔，並確保與現有 T-SQL 語法相容的資料庫架構。",
        "en": "You need to design a database architecture that provides high availability, reduces operational management overhead, and ensures compatibility with existing T-SQL syntax.",
        "wg": [
          { "t": "高可用性", "en": "high availability", "ps": "noun" },
          { "t": "維運管理負擔", "en": "operational management overhead", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將資料庫遷移至 Compute Engine 上的 SQL Server Always On 可用性群組，並使用持久性磁碟 (Persistent Disk) 進行儲存。",
        "en": "(A) Migrate the databases to SQL Server Always On Availability Groups on Compute Engine using Persistent Disk for storage.",
        "wg": [
          { "t": "可用性群組", "en": "Availability Groups", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 使用 Database Migration Service (DMS) 將資料庫遷移至 Cloud SQL for SQL Server，並啟用高可用性 (HA) 配置。",
        "en": "(B) Use Database Migration Service (DMS) to migrate the databases to Cloud SQL for SQL Server and enable High Availability (HA) configuration.",
        "wg": [
          { "t": "Database Migration Service", "en": "Database Migration Service", "ps": "noun" },
          { "t": "高可用性", "en": "High Availability", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 將資料重構並遷移至 Cloud Spanner，以利用其全球強一致性與水平擴展能力來應對未來的流量增長。",
        "en": "(C) Refactor and migrate the data to Cloud Spanner to leverage its global strong consistency and horizontal scalability for future traffic growth.",
        "wg": [
          { "t": "重構", "en": "Refactor", "ps": "verb" },
          { "t": "全球強一致性", "en": "global strong consistency", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 將資料庫遷移至 Cloud SQL for PostgreSQL，並使用 Schema Conversion Tool 轉換現有的儲存程序。",
        "en": "(D) Migrate the databases to Cloud SQL for PostgreSQL and use the Schema Conversion Tool to convert existing stored procedures.",
        "wg": [
          { "t": "轉換", "en": "convert", "ps": "verb" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Cloud SQL for SQL Server 提供了全託管服務，能顯著降低維運負擔，同時保持與 T-SQL 的高度相容性，符合「減少重寫」的需求。Compute Engine (A) 需要自行管理，不符合降低維運負擔的目標；Spanner (C) 和 PostgreSQL (D) 則需要大量的程式碼重構。",
      "en": "Cloud SQL for SQL Server provides a fully managed service that significantly reduces operational overhead while maintaining high compatibility with T-SQL, meeting the 'minimize rewrite' requirement. Compute Engine (A) requires self-management; Spanner (C) and PostgreSQL (D) require significant code refactoring.",
      "wg": [
        { "t": "全託管服務", "en": "fully managed service", "ps": "noun" },
        { "t": "程式碼重構", "en": "code refactoring", "ps": "noun" }
      ]
    }
  },
  {
    "no": "2",
    "level": "hard",
    "keywords": "Hybrid Connectivity, Dedicated Interconnect, Security, Throughput",
    "question": [
      {
        "t": "Cymbal Retail 計畫利用位於地端資料中心的大量高解析度產品圖片來訓練生成式 AI 模型。",
        "en": "Cymbal Retail plans to use a large volume of high-resolution product images located in their on-premises data center to train generative AI models.",
        "wg": [
          { "t": "地端資料中心", "en": "on-premises data center", "ps": "noun" },
          { "t": "生成式 AI 模型", "en": "generative AI models", "ps": "noun" }
        ]
      },
      {
        "t": "訓練過程需要持續且高頻寬的資料傳輸至 Google Cloud 的 Vertex AI 平台，且安全政策要求所有傳輸流量必須使用 RFC 1918 私有 IP 位址，嚴禁透過公共網際網路傳輸。",
        "en": "The training process requires continuous, high-bandwidth data transfer to the Vertex AI platform on Google Cloud, and security policies mandate that all traffic must use RFC 1918 private IP addresses and is strictly prohibited from traversing the public internet.",
        "wg": [
          { "t": "高頻寬", "en": "high-bandwidth", "ps": "adjective" },
          { "t": "私有 IP 位址", "en": "private IP addresses", "ps": "noun" }
        ]
      },
      {
        "t": "您現有的地端防火牆支援 10 Gbps 的介面，且您所在的設施位於 Google 的主機託管設施 (Colocation Facility) 內。",
        "en": "Your existing on-premises firewall supports 10 Gbps interfaces, and your facility is located within a Google Colocation Facility.",
        "wg": [
          { "t": "主機託管設施", "en": "Colocation Facility", "ps": "noun" }
        ]
      },
      {
        "t": "您應該選擇哪種連線方案以滿足效能與安全需求？",
        "en": "Which connectivity option should you choose to meet performance and security requirements?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 佈建與 Google 的直接對等互連 (Direct Peering)，並配置 VPC 防火牆規則以限制流量來源。",
        "en": "(A) Provision Direct Peering with Google and configure VPC firewall rules to restrict traffic sources.",
        "wg": [
          { "t": "直接對等互連", "en": "Direct Peering", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 建立多個 Cloud VPN 通道並啟用 ECMP (等價多路徑路由) 以聚合頻寬，確保傳輸加密。",
        "en": "(B) Create multiple Cloud VPN tunnels and enable ECMP (Equal-Cost Multi-Path routing) to aggregate bandwidth and ensure transmission encryption.",
        "wg": [
          { "t": "Cloud VPN 通道", "en": "Cloud VPN tunnels", "ps": "noun" },
          { "t": "等價多路徑路由", "en": "ECMP", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 佈建合作夥伴互連 (Partner Interconnect)，透過服務供應商連接至 Google 網路。",
        "en": "(C) Provision Partner Interconnect to connect to the Google network through a service provider.",
        "wg": [
          { "t": "合作夥伴互連", "en": "Partner Interconnect", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 佈建專用互連 (Dedicated Interconnect)，直接將地端路由器連接至 Google 的邊緣網路。",
        "en": "(D) Provision Dedicated Interconnect to directly connect on-premises routers to Google's edge network.",
        "wg": [
          { "t": "專用互連", "en": "Dedicated Interconnect", "ps": "noun" },
          { "t": "邊緣網路", "en": "edge network", "ps": "noun" }
        ]
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "題目強調「位於 Google 主機託管設施內」且需要「高頻寬 (10 Gbps)」與「私有 IP (RFC 1918)」。專用互連 (Dedicated Interconnect) 是此情境下的最佳選擇，能提供最高傳輸量與最低延遲。Direct Peering (A) 不支援私有 IP；Cloud VPN (B) 透過網際網路傳輸且效能受限；Partner Interconnect (C) 適用於非託管設施場景。",
      "en": "The scenario emphasizes being in a 'Google Colocation Facility' and requiring 'high bandwidth (10 Gbps)' with 'private IP (RFC 1918)'. Dedicated Interconnect is the optimal choice for highest throughput and lowest latency. Direct Peering (A) does not support private IP; Cloud VPN (B) traverses the internet with limited performance; Partner Interconnect (C) is for non-colocation scenarios.",
      "wg": [
        { "t": "傳輸量", "en": "throughput", "ps": "noun" },
        { "t": "延遲", "en": "latency", "ps": "noun" }
      ]
    }
  },
  {
    "no": "3",
    "level": "hard",
    "keywords": "Vertex AI, Search for Retail, Discovery AI, Custom App Replacement",
    "question": [
      {
        "t": "Cymbal Retail 希望淘汰基於關聯式資料庫查詢的舊有產品搜尋功能，因為該功能無法理解客戶的自然語言請求 (例如：「適合海灘派對的紅色洋裝」)。",
        "en": "Cymbal Retail wants to retire its legacy product search functionality based on relational database queries, as it cannot understand customers' natural language requests (e.g., 'red dress for a beach party').",
        "wg": [
          { "t": "自然語言請求", "en": "natural language requests", "ps": "noun" },
          { "t": "關聯式資料庫", "en": "relational database", "ps": "noun" }
        ]
      },
      {
        "t": "新的解決方案必須能夠提供語義搜尋 (Semantic Search)、自動完成 (Autocomplete) 以及個人化推薦功能，且需盡可能減少基礎架構的維護工作。",
        "en": "The new solution must provide semantic search, autocomplete, and personalized recommendations, and must minimize infrastructure maintenance efforts.",
        "wg": [
          { "t": "語義搜尋", "en": "semantic search", "ps": "noun" },
          { "t": "基礎架構維護", "en": "infrastructure maintenance", "ps": "noun" }
        ]
      },
      {
        "t": "此外，該解決方案必須能直接整合現有的產品目錄資料，而無需進行複雜的模型訓練。",
        "en": "Additionally, the solution must be able to integrate directly with existing product catalog data without requiring complex model training.",
        "wg": [
          { "t": "模型訓練", "en": "model training", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 GKE 上部署 Elasticsearch 叢集，並使用客製化的機器學習模型來處理自然語言理解 (NLU)。",
        "en": "(A) Deploy an Elasticsearch cluster on GKE and use custom machine learning models to handle Natural Language Understanding (NLU).",
        "wg": [
          { "t": "叢集", "en": "cluster", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 使用 Vertex AI Agent Builder 中的 Vertex AI Search for Retail，並上傳產品目錄進行索引。",
        "en": "(B) Use Vertex AI Search for Retail within Vertex AI Agent Builder and upload the product catalog for indexing.",
        "wg": [
          { "t": "索引", "en": "indexing", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 將產品資料匯入 BigQuery，並使用 BigQuery ML 訓練 K-means 叢集模型來進行產品推薦。",
        "en": "(C) Import product data into BigQuery and use BigQuery ML to train a K-means clustering model for product recommendations.",
        "wg": [
          { "t": "匯入", "en": "Import", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用 Dialogflow CX 建立對話代理，並透過 Webhook 呼叫後端 SQL 資料庫以檢索產品。",
        "en": "(D) Use Dialogflow CX to build a conversational agent and call the backend SQL database via Webhook to retrieve products.",
        "wg": [
          { "t": "對話代理", "en": "conversational agent", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Vertex AI Search for Retail (前身為 Discovery AI) 是專為零售場景設計的全託管服務，開箱即用支援語義搜尋與推薦，符合「減少維護」與「無需複雜訓練」的要求。Elasticsearch (A) 維護成本極高；BigQuery ML (C) 主要用於分析而非即時搜尋；Dialogflow (D) 用於對話流程，無法解決資料庫檢索相關性不足的核心問題。",
      "en": "Vertex AI Search for Retail (formerly Discovery AI) is a fully managed service designed for retail scenarios, supporting semantic search and recommendations out-of-the-box, meeting the 'minimize maintenance' and 'no complex training' requirements. Elasticsearch (A) has high maintenance costs; BigQuery ML (C) is for analytics, not real-time search; Dialogflow (D) is for conversation flow and doesn't solve the core issue of database retrieval relevance.",
      "wg": [
        { "t": "全託管服務", "en": "fully managed service", "ps": "noun" },
        { "t": "開箱即用", "en": "out-of-the-box", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "4",
    "level": "hard",
    "keywords": "Security, HITL, IAP, Cloud Run, IAM",
    "question": [
      {
        "t": "Cymbal Retail 需要為內部員工開發一個「人機迴圈 (Human-in-the-Loop)」審查工具，用於批准或修改由生成式 AI 產生的產品屬性與圖片。",
        "en": "Cymbal Retail needs to develop a 'Human-in-the-Loop' (HITL) review tool for internal associates to approve or modify product attributes and images generated by Gen AI.",
        "wg": [
          { "t": "人機迴圈", "en": "Human-in-the-Loop", "ps": "noun" },
          { "t": "批准", "en": "approve", "ps": "verb" }
        ]
      },
      {
        "t": "該應用程式將託管於 Google Cloud 上。您必須確保只有特定的內部員工群組可以存取此工具，且無需使用 VPN。",
        "en": "The application will be hosted on Google Cloud. You must ensure that only specific internal associate groups can access this tool without using a VPN.",
        "wg": [
          { "t": "存取", "en": "access", "ps": "verb" }
        ]
      },
      {
        "t": "此外，為了符合安全合規要求，應用程式不應具有公共 IP 位址，且必須能根據流量自動擴展至零。",
        "en": "Additionally, to meet security compliance, the application should not have a public IP address and must be able to scale to zero based on traffic.",
        "wg": [
          { "t": "公共 IP 位址", "en": "public IP address", "ps": "noun" },
          { "t": "擴展至零", "en": "scale to zero", "ps": "verb" }
        ]
      },
      {
        "t": "您應該採取哪兩個步驟？(請選擇兩項)",
        "en": "Which two steps should you take? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 將應用程式容器化並部署至 Cloud Run 服務，並配置為僅允許內部流量 (Ingress: Internal and Cloud Load Balancing)。",
        "en": "(A) Containerize the application and deploy it to a Cloud Run service, configured to allow only internal traffic (Ingress: Internal and Cloud Load Balancing).",
        "wg": [
          { "t": "容器化", "en": "Containerize", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 為員工群組配置 Identity-Aware Proxy (IAP)，並將其綁定至後端服務的 HTTPS 負載平衡器。",
        "en": "(B) Configure Identity-Aware Proxy (IAP) for the associate groups and bind it to the HTTPS Load Balancer of the backend service.",
        "wg": [
          { "t": "綁定", "en": "bind", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 將應用程式部署至 Compute Engine 執行個體群組，並使用防火牆規則限制僅允許公司總部的 IP 範圍存取。",
        "en": "(C) Deploy the application to a Compute Engine instance group and use firewall rules to restrict access to only the company headquarters' IP range.",
        "wg": [
          { "t": "執行個體群組", "en": "instance group", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Functions 來託管應用程式前端，並透過 API Gateway 進行身份驗證。",
        "en": "(D) Use Cloud Functions to host the application frontend and authenticate via API Gateway.",
        "wg": [
          { "t": "身份驗證", "en": "authenticate", "ps": "verb" }
        ]
      },
      {
        "t": "(E) 為所有需要存取的員工建立 IAM Service Account，並將金鑰分發給他們以便登入應用程式。",
        "en": "(E) Create IAM Service Accounts for all associates requiring access and distribute keys to them for logging into the application.",
        "wg": [
          { "t": "分發", "en": "distribute", "ps": "verb" }
        ]
      }
    ],
    "answer": "(A), (B)",
    "why": {
      "t": "Cloud Run (A) 支援「擴展至零」且是全託管的無伺服器平台，符合維運效率需求。結合 Identity-Aware Proxy (IAP) (B) 可以在不使用 VPN 的情況下，利用現有的企業身分 (Google Workspace) 實現零信任存取控制。Compute Engine (C) 無法自動擴展至零；Cloud Functions (D) 不適合託管複雜 UI；分發 Service Account Key (E) 是嚴重的安全違規行為。",
      "en": "Cloud Run (A) supports 'scale to zero' and is a fully managed serverless platform, meeting operational efficiency needs. Combined with Identity-Aware Proxy (IAP) (B), it enables Zero Trust access control using existing corporate identities (Google Workspace) without a VPN. Compute Engine (C) cannot scale to zero automatically; Cloud Functions (D) is ill-suited for hosting complex UIs; distributing Service Account Keys (E) is a severe security violation.",
      "wg": [
        { "t": "零信任", "en": "Zero Trust", "ps": "noun" },
        { "t": "安全違規", "en": "security violation", "ps": "noun" }
      ]
    }
  },
  {
    "no": "5",
    "level": "hard",
    "keywords": "GKE, Monitoring, SRE, Cloud Operations Suite",
    "question": [
      {
        "t": "Cymbal Retail 的技術團隊正在對其 Kubernetes 環境進行現代化改造。目前的監控依賴於分散的開源工具 (Grafana, Nagios)，導致在零售高峰期難以關聯應用程式錯誤與基礎架構指標。",
        "en": "Cymbal Retail's technical team is modernizing its Kubernetes environment. Current monitoring relies on disparate open-source tools (Grafana, Nagios), making it difficult to correlate application errors with infrastructure metrics during peak retail periods.",
        "wg": [
          { "t": "關聯", "en": "correlate", "ps": "verb" },
          { "t": "分散的", "en": "disparate", "ps": "adjective" }
        ]
      },
      {
        "t": "您需要設計一個統一的可觀測性 (Observability) 解決方案，該方案需能自動探索 GKE 服務、提供與應用程式日誌的整合視圖，並盡量減少自行架設監控伺服器的維運成本。",
        "en": "You need to design a unified observability solution that automatically discovers GKE services, provides an integrated view with application logs, and minimizes the operational cost of self-hosting monitoring servers.",
        "wg": [
          { "t": "可觀測性", "en": "Observability", "ps": "noun" },
          { "t": "自動探索", "en": "automatically discovers", "ps": "verb" }
        ]
      },
      {
        "t": "您應該建議採用哪種配置？",
        "en": "Which configuration should you recommend?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在每個 GKE 節點上安裝自行管理的 Prometheus 伺服器，並使用 Sidecar 模式將日誌匯出至地端的 ELK Stack。",
        "en": "(A) Install self-managed Prometheus servers on each GKE node and use the Sidecar pattern to export logs to an on-premises ELK Stack.",
        "wg": [
          { "t": "自行管理", "en": "self-managed", "ps": "adjective" }
        ]
      },
      {
        "t": "(B) 啟用 GKE 的 Google Cloud Managed Service for Prometheus 以及 Cloud Logging，並使用 Cloud Monitoring 儀表板進行統一檢視。",
        "en": "(B) Enable Google Cloud Managed Service for Prometheus and Cloud Logging for GKE, and use Cloud Monitoring dashboards for a unified view.",
        "wg": [
          { "t": "儀表板", "en": "dashboards", "ps": "noun" },
          { "t": "統一檢視", "en": "unified view", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 設定 GKE 叢集將所有指標與日誌匯出至 BigQuery，並使用 Looker Studio 建立每小時更新的報告。",
        "en": "(C) Configure GKE clusters to export all metrics and logs to BigQuery, and use Looker Studio to create reports that update hourly.",
        "wg": [
          { "t": "匯出", "en": "export", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用 Terraform 在 Compute Engine 上部署一套全新的高可用性 Grafana 和 InfluxDB 叢集，並透過 VPC 對等互連連接 GKE。",
        "en": "(D) Use Terraform to deploy a new high-availability Grafana and InfluxDB cluster on Compute Engine, connecting to GKE via VPC Peering.",
        "wg": [
          { "t": "對等互連", "en": "Peering", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Google Cloud Managed Service for Prometheus 提供與 Cloud Monitoring 的無縫整合，能自動蒐集 GKE 指標且無需管理監控基礎架構，完美解決「資料孤島」與「維運成本」問題。選項 (A) 和 (D) 增加了自行管理的負擔；選項 (C) 的 BigQuery/Looker 組合延遲過高，不適合用於即時維運監控。",
      "en": "Google Cloud Managed Service for Prometheus offers seamless integration with Cloud Monitoring, automatically collecting GKE metrics without managing monitoring infrastructure, perfectly addressing 'data silos' and 'operational cost' issues. Options (A) and (D) increase self-management burden; Option (C)'s BigQuery/Looker combination has too high latency for real-time operational monitoring.",
      "wg": [
        { "t": "無縫整合", "en": "seamless integration", "ps": "noun" },
        { "t": "即時", "en": "real-time", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "6",
    "level": "hard",
    "keywords": "Event-driven, Cloud Storage, Eventarc, Cloud Run, Gen AI",
    "question": [
      {
        "t": "Cymbal Retail 的「目錄豐富化 (Catalog Enrichment)」專案需要處理供應商每天上傳的數千張新產品圖片。",
        "en": "Cymbal Retail's 'Catalog Enrichment' project needs to process thousands of new product images uploaded by suppliers daily.",
        "wg": [
          { "t": "目錄豐富化", "en": "Catalog Enrichment", "ps": "noun" }
        ]
      },
      {
        "t": "每當圖片上傳至 Cloud Storage Bucket 時，系統必須立即觸發一個基於 Gemini Pro Vision 的生成式 AI 流程來提取產品屬性，並將結果寫入 Firestore。",
        "en": "Whenever an image is uploaded to a Cloud Storage Bucket, the system must immediately trigger a Gemini Pro Vision-based Gen AI process to extract product attributes and write the results to Firestore.",
        "wg": [
          { "t": "觸發", "en": "trigger", "ps": "verb" },
          { "t": "提取", "en": "extract", "ps": "verb" }
        ]
      },
      {
        "t": "您需要設計一個鬆散耦合 (Loosely Coupled)、完全無伺服器 (Serverless) 且具備成本效益的架構來處理此自動化流程，並盡量減少維運負擔。",
        "en": "You need to design a loosely coupled, fully serverless, and cost-effective architecture to handle this automation process while minimizing operational overhead.",
        "wg": [
          { "t": "鬆散耦合", "en": "Loosely Coupled", "ps": "adjective" },
          { "t": "無伺服器", "en": "Serverless", "ps": "adjective" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 編寫一個長期運行的 Compute Engine 執行個體腳本，定期輪詢 (Poll) Cloud Storage Bucket 的變更，並呼叫 Vertex AI API。",
        "en": "(A) Write a script on a long-running Compute Engine instance that regularly polls the Cloud Storage Bucket for changes and calls the Vertex AI API.",
        "wg": [
          { "t": "輪詢", "en": "polls", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 設定 Cloud Storage 觸發 Pub/Sub 通知，並使用 Dataflow 串流作業來處理影像分析與資料庫寫入。",
        "en": "(B) Configure Cloud Storage to trigger Pub/Sub notifications and use a Dataflow streaming job to handle image analysis and database writes.",
        "wg": [
          { "t": "串流作業", "en": "streaming job", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Eventarc 擷取 Cloud Storage 的 `google.cloud.storage.object.v1.finalized` 事件，並將其路由至託管 Gen AI 程式碼的 Cloud Run 服務。",
        "en": "(C) Use Eventarc to capture the Cloud Storage `google.cloud.storage.object.v1.finalized` event and route it to a Cloud Run service hosting the Gen AI code.",
        "wg": [
          { "t": "路由", "en": "route", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Composer (Airflow) 安排每小時一次的批次作業，列出 Bucket 中的新檔案並依序處理。",
        "en": "(D) Use Cloud Composer (Airflow) to schedule an hourly batch job that lists new files in the bucket and processes them sequentially.",
        "wg": [
          { "t": "批次作業", "en": "batch job", "ps": "noun" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Eventarc 提供了標準化且完全託管的事件驅動機制，能將 GCS 事件直接傳遞給 Cloud Run，符合「立即觸發」、「鬆散耦合」與「無伺服器」的最佳實踐。輪詢 (A) 浪費資源且延遲高；Dataflow (B) 對於單純的事件觸發處理來說過於沈重且成本較高；Cloud Composer (D) 是批次處理，無法滿足「立即」的需求。",
      "en": "Eventarc provides a standardized and fully managed event-driven mechanism to deliver GCS events directly to Cloud Run, aligning with 'immediate trigger', 'loosely coupled', and 'serverless' best practices. Polling (A) wastes resources and has high latency; Dataflow (B) is overkill and more expensive for simple event handling; Cloud Composer (D) is batch-based and cannot meet the 'immediate' requirement.",
      "wg": [
        { "t": "事件驅動機制", "en": "event-driven mechanism", "ps": "noun" },
        { "t": "過於沈重", "en": "overkill", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "7",
    "level": "hard",
    "keywords": "Global Load Balancing, Cloud CDN, Latency, Conversational Commerce",
    "question": [
      {
        "t": "Cymbal Retail 的「對話式商務 (Conversational Commerce)」虛擬代理已整合至行動 App 中，後端部署於 `us-central1` 的 GKE 叢集。",
        "en": "Cymbal Retail's 'Conversational Commerce' virtual agent is integrated into the mobile app, with the backend deployed in a GKE cluster in `us-central1`.",
        "wg": [
          { "t": "虛擬代理", "en": "virtual agent", "ps": "noun" }
        ]
      },
      {
        "t": "來自亞洲和歐洲的客戶回報，載入虛擬代理介面 (靜態資源) 與接收產品推薦 (動態 API 回應) 時延遲極高，嚴重影響互動體驗。",
        "en": "Customers from Asia and Europe report high latency when loading the virtual agent interface (static assets) and receiving product recommendations (dynamic API responses), severely impacting the engagement experience.",
        "wg": [
          { "t": "靜態資源", "en": "static assets", "ps": "noun" },
          { "t": "互動體驗", "en": "engagement experience", "ps": "noun" }
        ]
      },
      {
        "t": "您需要在不將後端資料庫複製到多個地區的前提下，改善全球使用者的效能並確保傳輸安全 (TLS 終止)。",
        "en": "You need to improve performance for global users and ensure transmission security (TLS termination) without replicating the backend database to multiple regions.",
        "wg": [
          { "t": "複製", "en": "replicating", "ps": "verb" },
          { "t": "TLS 終止", "en": "TLS termination", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 設定 Cloud DNS 使用地理位置路由政策，將使用者導向至最近的 VPN 端點，再透過 Google 骨幹網路連線至後端。",
        "en": "(A) Configure Cloud DNS with geolocation routing policies to direct users to the nearest VPN endpoint, then connect to the backend via the Google backbone.",
        "wg": [
          { "t": "地理位置路由", "en": "geolocation routing", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 部署全球外部 HTTP(S) 負載平衡器 (Global External HTTP(S) Load Balancer)，啟用 Cloud CDN 快取靜態資源，並將後端服務指向 `us-central1` 的 GKE。",
        "en": "(B) Deploy a Global External HTTP(S) Load Balancer, enable Cloud CDN to cache static assets, and point the backend service to GKE in `us-central1`.",
        "wg": [
          { "t": "負載平衡器", "en": "Load Balancer", "ps": "noun" },
          { "t": "快取", "en": "cache", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 在亞洲和歐洲的區域建立新的 GKE 叢集，部署應用程式副本，並使用 Cloud SQL 讀取複本 (Read Replicas) 來同步資料。",
        "en": "(C) Create new GKE clusters in Asia and Europe regions, deploy application replicas, and use Cloud SQL Read Replicas to synchronize data.",
        "wg": [
          { "t": "讀取複本", "en": "Read Replicas", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 增加 `us-central1` GKE 叢集的節點數量，並升級至更高 CPU 規格的機器類型以加快處理速度。",
        "en": "(D) Increase the node count of the GKE cluster in `us-central1` and upgrade to higher CPU machine types to speed up processing.",
        "wg": [
          { "t": "機器類型", "en": "machine types", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "全球外部 HTTP(S) 負載平衡器利用 Google 的全球邊緣節點與 Anycast IP，能顯著優化動態內容的 TCP/SSL 連線終止速度，而 Cloud CDN 則解決了靜態資源的延遲問題。這是最符合「不複製資料庫」限制且能有效降低網路延遲的方案。選項 (C) 違反了題目關於不複製資料庫的限制（或至少增加了顯著複雜度）；選項 (D) 無法解決物理距離造成的網路延遲。",
      "en": "The Global External HTTP(S) Load Balancer leverages Google's global edge nodes and Anycast IP to significantly optimize TCP/SSL connection termination for dynamic content, while Cloud CDN solves static asset latency. This fits the 'no database replication' constraint and effectively reduces network latency. Option (C) violates the constraint about minimizing database replication complexity; Option (D) cannot solve network latency caused by physical distance.",
      "wg": [
        { "t": "邊緣節點", "en": "edge nodes", "ps": "noun" },
        { "t": "物理距離", "en": "physical distance", "ps": "noun" }
      ]
    }
  },
  {
    "no": "8",
    "level": "hard",
    "keywords": "Sensitive Data Protection (DLP), Compliance, Dataflow, PII",
    "question": [
      {
        "t": "Cymbal Retail 的資料法規遵循團隊發現，客戶與虛擬代理的對話日誌中包含敏感的個人識別資訊 (PII)，如信用卡號與住家地址。",
        "en": "Cymbal Retail's data compliance team discovered that chat logs between customers and virtual agents contain sensitive Personally Identifiable Information (PII), such as credit card numbers and home addresses.",
        "wg": [
          { "t": "個人識別資訊", "en": "Personally Identifiable Information", "ps": "noun" }
        ]
      },
      {
        "t": "這些日誌目前透過 Pub/Sub 串流至 BigQuery 進行分析。為了符合產業法規，您必須確保在資料寫入 BigQuery **之前**，所有 PII 都已被遮蔽 (Redacted) 或去識別化。",
        "en": "These logs are currently streamed via Pub/Sub to BigQuery for analytics. To comply with industry regulations, you must ensure that all PII is redacted or de-identified **before** the data is written to BigQuery.",
        "wg": [
          { "t": "遮蔽", "en": "Redacted", "ps": "verb" },
          { "t": "去識別化", "en": "de-identified", "ps": "verb" }
        ]
      },
      {
        "t": "您應採取哪項架構變更？",
        "en": "Which architectural change should you implement?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 實作 Cloud Function 觸發器，當資料寫入 BigQuery 後立即掃描資料表，並使用 SQL `UPDATE` 語句移除 PII。",
        "en": "(A) Implement a Cloud Function trigger to scan the table immediately after data is written to BigQuery and use SQL `UPDATE` statements to remove PII.",
        "wg": [
          { "t": "掃描", "en": "scan", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 修改前端應用程式碼，使用正則表達式 (Regex) 在客戶端發送訊息前過濾掉信用卡與地址格式。",
        "en": "(B) Modify the frontend application code to use Regular Expressions (Regex) to filter out credit card and address formats on the client side before sending messages.",
        "wg": [
          { "t": "正則表達式", "en": "Regular Expressions", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 在 Pub/Sub 與 BigQuery 之間部署 Dataflow 管道，並呼叫 Sensitive Data Protection (DLP) API 進行即時去識別化轉換。",
        "en": "(C) Deploy a Dataflow pipeline between Pub/Sub and BigQuery, calling the Sensitive Data Protection (DLP) API for real-time de-identification transformation.",
        "wg": [
          { "t": "管道", "en": "pipeline", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 在 BigQuery 資料集上設定 IAM 權限，僅允許「資料法規遵循官」檢視原始資料，其他分析師則無法存取。",
        "en": "(D) Configure IAM permissions on the BigQuery dataset to allow only 'Data Compliance Officers' to view raw data, restricting access for other analysts.",
        "wg": [
          { "t": "檢視", "en": "view", "ps": "verb" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "題目要求在資料「寫入 BigQuery 之前」處理 PII。Dataflow 結合 Sensitive Data Protection (前身為 DLP API) 是處理串流資料隱私的標準模式。選項 (A) 是「事後」處理，資料已落地，違反合規要求；選項 (B) 依賴客戶端邏輯不可靠且難以維護；選項 (D) 僅控制存取權，並未移除 PII，資料仍以明文儲存。",
      "en": "The requirement states PII must be handled 'before' writing to BigQuery. Dataflow combined with Sensitive Data Protection (formerly DLP API) is the standard pattern for streaming data privacy. Option (A) is 'post-processing', meaning data has already landed, violating compliance; Option (B) relies on client-side logic which is unreliable and hard to maintain; Option (D) only controls access but does not remove PII, leaving data stored in plain text.",
      "wg": [
        { "t": "標準模式", "en": "standard pattern", "ps": "noun" },
        { "t": "明文", "en": "plain text", "ps": "noun" }
      ]
    }
  },
  {
    "no": "9",
    "level": "hard",
    "keywords": "Software Supply Chain, Binary Authorization, Artifact Registry, Vulnerability Scanning",
    "question": [
      {
        "t": "作為技術堆疊現代化的一環，Cymbal Retail 正在建立安全的 CI/CD 管道。",
        "en": "As part of the technical stack modernization, Cymbal Retail is building a secure CI/CD pipeline.",
        "wg": [
          { "t": "技術堆疊", "en": "technical stack", "ps": "noun" }
        ]
      },
      {
        "t": "安全團隊要求所有部署到 GKE 生產環境的容器映像檔 (Container Images) 必須經過漏洞掃描，且必須由受信任的建置系統進行數位簽章。",
        "en": "The security team requires that all container images deployed to the GKE production environment must be scanned for vulnerabilities and digitally signed by a trusted build system.",
        "wg": [
          { "t": "數位簽章", "en": "digitally signed", "ps": "verb" },
          { "t": "受信任的", "en": "trusted", "ps": "adjective" }
        ]
      },
      {
        "t": "如果映像檔未經簽章或包含高風險漏洞，GKE 必須自動拒絕部署。您應該整合哪兩項 Google Cloud 服務來達成此強制執行機制？(請選擇兩項)",
        "en": "If an image is unsigned or contains high-risk vulnerabilities, GKE must automatically reject the deployment. Which two Google Cloud services should you integrate to achieve this enforcement mechanism? (Choose two)",
        "wg": [
          { "t": "拒絕", "en": "reject", "ps": "verb" },
          { "t": "強制執行機制", "en": "enforcement mechanism", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 Artifact Registry 儲存映像檔並啟用自動漏洞掃描。",
        "en": "(A) Use Artifact Registry to store images and enable automatic vulnerability scanning.",
        "wg": [
          { "t": "漏洞掃描", "en": "vulnerability scanning", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 在 GKE 叢集中啟用 Binary Authorization，並設定策略以要求特定的簽章者 (Attestors)。",
        "en": "(B) Enable Binary Authorization on the GKE cluster and configure policies to require specific Attestors.",
        "wg": [
          { "t": "簽章者", "en": "Attestors", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Armor 建立安全政策，攔截來自未授權來源的映像檔下載請求。",
        "en": "(C) Use Cloud Armor to create security policies to block image download requests from unauthorized sources.",
        "wg": [
          { "t": "攔截", "en": "block", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 設定 IAM 策略，僅授權 Cloud Build Service Account 具有 `container.clusters.update` 權限。",
        "en": "(D) Configure IAM policies to authorize only the Cloud Build Service Account with `container.clusters.update` permissions.",
        "wg": [
          { "t": "授權", "en": "authorize", "ps": "verb" }
        ]
      },
      {
        "t": "(E) 在 VPC Service Controls 中建立服務邊界，將 GKE 與 Artifact Registry 納入保護範圍。",
        "en": "(E) Create a Service Perimeter in VPC Service Controls to include GKE and Artifact Registry within the protection scope.",
        "wg": [
          { "t": "服務邊界", "en": "Service Perimeter", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A), (B)",
    "why": {
      "t": "Artifact Registry (A) 取代了 Container Registry，提供儲存與內建的漏洞掃描功能。Binary Authorization (B) 則是 Kubernetes 上的准入控制器 (Admission Controller)，能驗證映像檔是否具備合格的簽章 (Attestation)，若無則拒絕部署。兩者結合構成了完整的軟體供應鏈安全。Cloud Armor (C) 防護網路攻擊；IAM (D) 控制人員操作而非映像檔內容驗證；VPC-SC (E) 防止資料外洩，非部署控制。",
      "en": "Artifact Registry (A) replaces Container Registry, providing storage and built-in vulnerability scanning. Binary Authorization (B) acts as an Admission Controller on Kubernetes, verifying if images have valid Attestations and rejecting deployment if not. Together, they form a complete software supply chain security solution. Cloud Armor (C) protects against network attacks; IAM (D) controls user operations, not image content verification; VPC-SC (E) prevents data exfiltration, not deployment control.",
      "wg": [
        { "t": "准入控制器", "en": "Admission Controller", "ps": "noun" },
        { "t": "軟體供應鏈", "en": "software supply chain", "ps": "noun" }
      ]
    }
  },
  {
    "no": "10",
    "level": "hard",
    "keywords": "Cost Optimization, GKE, Spot VMs, Cluster Autoscaler",
    "question": [
      {
        "t": "Cymbal Retail 利用 GKE 叢集執行大規模的批次作業，以支援「屬性生成 (Attribute Generation)」功能。這些作業是無狀態 (Stateless) 的、可容忍中斷，且處理時間不固定。",
        "en": "Cymbal Retail uses GKE clusters to run large-scale batch jobs to support the 'Attribute Generation' feature. These jobs are stateless, fault-tolerant, and have variable processing times.",
        "wg": [
          { "t": "可容忍中斷", "en": "fault-tolerant", "ps": "adjective" },
          { "t": "無狀態", "en": "stateless", "ps": "adjective" }
        ]
      },
      {
        "t": "目前叢集採用固定數量的節點，導致在作業佇列為空時產生成本浪費，而在高峰期則處理緩慢。管理層要求在不影響作業最終完成的前提下，大幅降低運算成本。",
        "en": "Currently, the cluster uses a fixed number of nodes, resulting in wasted costs when the job queue is empty and slow processing during peaks. Management requires a significant reduction in compute costs without affecting the eventual completion of jobs.",
        "wg": [
          { "t": "成本浪費", "en": "wasted costs", "ps": "noun" },
          { "t": "大幅降低", "en": "significant reduction", "ps": "verb" }
        ]
      },
      {
        "t": "您應該在 GKE 節點集區 (Node Pool) 上實作哪兩項配置？(請選擇兩項)",
        "en": "Which two configurations should you implement on the GKE Node Pool? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 啟用 Cluster Autoscaler，讓節點數量能根據 Pod 的資源需求自動增加或減少。",
        "en": "(A) Enable Cluster Autoscaler to automatically increase or decrease the number of nodes based on Pod resource demands.",
        "wg": [
          { "t": "資源需求", "en": "resource demands", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 將節點集區設定為使用 Spot VMs (Spot 實例)，以利用閒置產能獲得大幅折扣。",
        "en": "(B) Configure the node pool to use Spot VMs instances to leverage idle capacity for significant discounts.",
        "wg": [
          { "t": "閒置產能", "en": "idle capacity", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 為節點集區購買 3 年期的承諾使用折扣 (Committed Use Discounts)，以鎖定最低費率。",
        "en": "(C) Purchase 3-year Committed Use Discounts (CUDs) for the node pool to lock in the lowest rates.",
        "wg": [
          { "t": "承諾使用折扣", "en": "Committed Use Discounts", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 設定 Horizontal Pod Autoscaler (HPA) 依據記憶體使用量來擴展 Pod 數量。",
        "en": "(D) Configure Horizontal Pod Autoscaler (HPA) to scale the number of Pods based on memory usage.",
        "wg": [
          { "t": "記憶體使用量", "en": "memory usage", "ps": "noun" }
        ]
      },
      {
        "t": "(E) 將節點集區遷移至 E2-standard 機器類型，因為其性價比最高。",
        "en": "(E) Migrate the node pool to E2-standard machine types as they offer the best price-performance ratio.",
        "wg": [
          { "t": "性價比", "en": "price-performance ratio", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A), (B)",
    "why": {
      "t": "針對「可容忍中斷」與「無狀態」的批次作業，Spot VMs (B) 提供最高可達 60-91% 的折扣，是降低成本的最有效手段。配合 Cluster Autoscaler (A)，系統能在佇列為空時自動縮減節點至零（或最小值），在高峰時自動擴展，從而消除閒置成本。CUDs (C) 適用於可預測的穩定負載，不適合波動大的批次作業；HPA (D) 擴展 Pod 但不直接減少節點成本；E2 (E) 的節省幅度遠不及 Spot VMs。",
      "en": "For 'fault-tolerant' and 'stateless' batch jobs, Spot VMs (B) offer discounts up to 60-91%, making them the most effective way to reduce costs. Combined with Cluster Autoscaler (A), the system can automatically scale down nodes to zero (or minimum) when the queue is empty and scale up during peaks, eliminating idle costs. CUDs (C) are for predictable stable loads, not fluctuating batch jobs; HPA (D) scales Pods but doesn't directly reduce node costs; E2 (E) savings are far less than Spot VMs.",
      "wg": [
        { "t": "折扣", "en": "discounts", "ps": "noun" },
        { "t": "消除", "en": "eliminating", "ps": "verb" }
      ]
    }
  },{
    "no": "11",
    "level": "hard",
    "keywords": "Cloud DNS, Hybrid Connectivity, Forwarding Zones, Inbound Server Policy",
    "question": [
      {
        "t": "Cymbal Retail 的混合雲架構依賴於透過專用互連 (Dedicated Interconnect) 連接的地端資料中心與 Google Cloud VPC。",
        "en": "Cymbal Retail's hybrid cloud architecture relies on Dedicated Interconnect connecting on-premises data centers with Google Cloud VPC.",
        "wg": [
          { "t": "混合雲架構", "en": "hybrid cloud architecture", "ps": "noun" },
          { "t": "專用互連", "en": "Dedicated Interconnect", "ps": "noun" }
        ]
      },
      {
        "t": "部署在 GKE 上的微服務需要透過主機名稱 (Hostname) 解析位於地端的傳統資料庫 (如 `db.onprem.local`)；同時，地端的管理工作站也需要解析 Google Cloud 上內部負載平衡器的 DNS 名稱。",
        "en": "Microservices deployed on GKE need to resolve on-premises legacy databases via hostnames (e.g., `db.onprem.local`); meanwhile, on-premises management workstations need to resolve DNS names of Internal Load Balancers on Google Cloud.",
        "wg": [
          { "t": "解析", "en": "resolve", "ps": "verb" },
          { "t": "內部負載平衡器", "en": "Internal Load Balancers", "ps": "noun" }
        ]
      },
      {
        "t": "您需要設計一個高可用且無需管理額外虛擬機器的 DNS 架構來實現此雙向解析。",
        "en": "You need to design a high-availability DNS architecture that requires no additional virtual machine management to achieve this bidirectional resolution.",
        "wg": [
          { "t": "雙向解析", "en": "bidirectional resolution", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 Google Cloud 上部署一組 BIND DNS 伺服器，並在地端 DNS 伺服器中設定條件轉送 (Conditional Forwarder) 指向這些 BIND 伺服器。",
        "en": "(A) Deploy a set of BIND DNS servers on Google Cloud and configure Conditional Forwarders in on-premises DNS servers pointing to these BIND servers.",
        "wg": [
          { "t": "條件轉送", "en": "Conditional Forwarder", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 修改 GKE 的 ConfigMap 以使用自定義的 Stub Domains 指向地端 DNS 伺服器 IP，並在地端主機檔案 (Hosts File) 中手動新增 Cloud 資源記錄。",
        "en": "(B) Modify GKE ConfigMaps to use custom Stub Domains pointing to on-premises DNS server IPs, and manually add Cloud resource records to on-premises Hosts Files.",
        "wg": [
          { "t": "主機檔案", "en": "Hosts Files", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 設定 Cloud DNS 對等互連 (Peering) 區域，將所有 VPC 網路連接至地端網路，並啟用 DNSSEC 以確保查詢安全。",
        "en": "(C) Configure Cloud DNS Peering zones to connect all VPC networks to the on-premises network and enable DNSSEC to ensure query security.",
        "wg": [
          { "t": "對等互連", "en": "Peering", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 建立 Cloud DNS 轉送區域 (Forwarding Zone) 以將地端網域查詢轉發至地端 DNS；並建立 Cloud DNS 入站伺服器政策 (Inbound Server Policy) 供地端查詢 Cloud DNS。",
        "en": "(D) Create a Cloud DNS Forwarding Zone to forward on-premises domain queries to on-premises DNS; and create a Cloud DNS Inbound Server Policy for on-premises to query Cloud DNS.",
        "wg": [
          { "t": "轉送區域", "en": "Forwarding Zone", "ps": "noun" },
          { "t": "入站伺服器政策", "en": "Inbound Server Policy", "ps": "noun" }
        ]
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud DNS 是全託管服務，符合「無需管理 VM」的要求。針對雙向解析：使用「轉送區域 (Forwarding Zone)」處理出站查詢 (Cloud -> On-prem)，並使用「入站伺服器政策 (Inbound Server Policy)」分配 IP 供地端進行入站查詢 (On-prem -> Cloud)。選項 (A) 需要管理 VM，違反題目限制；選項 (B) 的 Hosts File 方法不可擴展且難以維護；選項 (C) 的 Peering 用於 VPC 之間，而非混合雲 DNS 解析。",
      "en": "Cloud DNS is a fully managed service, meeting the 'no VM management' requirement. For bidirectional resolution: use 'Forwarding Zones' for outbound queries (Cloud -> On-prem) and 'Inbound Server Policies' to provision IPs for inbound queries (On-prem -> Cloud). Option (A) requires managing VMs, violating constraints; Option (B)'s Hosts File method is unscalable; Option (C)'s Peering is for VPC-to-VPC, not hybrid DNS resolution.",
      "wg": [
        { "t": "全託管服務", "en": "fully managed service", "ps": "noun" },
        { "t": "不可擴展", "en": "unscalable", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "12",
    "level": "hard",
    "keywords": "Organization Policy, Security, Hierarchy, Public IP",
    "question": [
      {
        "t": "為了加強安全性，Cymbal Retail 的資安長 (CISO) 發布了一項強制性指令：除了負責「公開網頁前端」的特定專案資料夾外，整個組織內的所有運算實例 (VM) 均嚴禁分配外部 IP 位址 (External IP Address)。",
        "en": "To enhance security, Cymbal Retail's CISO has issued a mandatory directive: with the exception of specific project folders responsible for 'Public Web Frontend', no compute instances (VMs) across the entire organization are allowed to be assigned External IP Addresses.",
        "wg": [
          { "t": "強制性指令", "en": "mandatory directive", "ps": "noun" },
          { "t": "外部 IP 位址", "en": "External IP Addresses", "ps": "noun" }
        ]
      },
      {
        "t": "您需要實作一個能夠主動預防違規、集中管理且易於稽核的控制機制。",
        "en": "You need to implement a control mechanism that proactively prevents violations, is centrally managed, and is easy to audit.",
        "wg": [
          { "t": "主動預防", "en": "proactively prevents", "ps": "verb" },
          { "t": "易於稽核", "en": "easy to audit", "ps": "adjective" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在組織層級設定 `compute.vmExternalIpAccess` 組織政策約束為「拒絕」，並在「公開網頁前端」資料夾層級設定該策略為「允許」。",
        "en": "(A) Configure the `compute.vmExternalIpAccess` Organization Policy constraint to 'Deny' at the Organization level, and set the policy to 'Allow' at the 'Public Web Frontend' folder level.",
        "wg": [
          { "t": "組織政策約束", "en": "Organization Policy constraint", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 建立一個 VPC 防火牆規則，拒絕所有目的地位於 0.0.0.0/0 的出口流量，並將優先級設為最高。",
        "en": "(B) Create a VPC firewall rule to deny all egress traffic to 0.0.0.0/0 and set the priority to the highest.",
        "wg": [
          { "t": "出口流量", "en": "egress traffic", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 移除所有開發人員的 `compute.instances.create` 權限，僅允許透過 CI/CD 管道部署，並在管道腳本中檢查 IP 設定。",
        "en": "(C) Remove `compute.instances.create` permissions from all developers, allow deployment only via CI/CD pipelines, and check IP configurations in pipeline scripts.",
        "wg": [
          { "t": "管道腳本", "en": "pipeline scripts", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 VPC Service Controls 建立服務邊界，將所有 Compute Engine 資源放入邊界內以阻止網際網路存取。",
        "en": "(D) Use VPC Service Controls to create a service perimeter, placing all Compute Engine resources inside the perimeter to block internet access.",
        "wg": [
          { "t": "服務邊界", "en": "service perimeter", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "組織政策 (Organization Policy) 是在資源建立時進行「預防性」控制的最佳工具。透過資源階層 (Hierarchy) 的繼承與覆寫特性 (Organization Deny -> Folder Allow)，可以精確且集中地滿足題目要求。防火牆 (B) 僅阻擋流量但不阻止 IP 分配（仍會產生費用與攻擊面）；IAM (C) 管理過於繁瑣且容易被繞過；VPC-SC (D) 主要用於防止資料外洩，而非控制公共 IP 的分配。",
      "en": "Organization Policy is the best tool for 'preventative' control at resource creation. Using hierarchy inheritance and override features (Organization Deny -> Folder Allow) meets requirements precisely and centrally. Firewall (B) blocks traffic but not IP assignment (incurring costs and attack surface); IAM (C) is cumbersome and easily bypassed; VPC-SC (D) is for data exfiltration prevention, not controlling public IP assignment.",
      "wg": [
        { "t": "預防性", "en": "preventative", "ps": "adjective" },
        { "t": "繼承", "en": "inheritance", "ps": "noun" }
      ]
    }
  },
  {
    "no": "13",
    "level": "hard",
    "keywords": "Cloud Storage, Lifecycle Management, Cost Optimization, Compliance",
    "question": [
      {
        "t": "Cymbal Retail 的影像生成專案產生了大量的原始素材。業務需求指出：這些圖片在生成後的 30 天內會被頻繁存取以進行模型微調；隨後必須保存 3 年以應對偶發的法律合規檢查（存取頻率極低）；3 年後應自動永久刪除。",
        "en": "Cymbal Retail's image generation project produces massive raw assets. Business requirements state: these images are accessed frequently for model fine-tuning within 30 days of generation; subsequently, they must be retained for 3 years for sporadic legal compliance checks (very low access frequency); and permanently deleted automatically after 3 years.",
        "wg": [
          { "t": "模型微調", "en": "model fine-tuning", "ps": "noun" },
          { "t": "永久刪除", "en": "permanently deleted", "ps": "verb" }
        ]
      },
      {
        "t": "您需要設定 Cloud Storage Bucket 以自動化此流程並將儲存成本降至最低。",
        "en": "You need to configure the Cloud Storage Bucket to automate this process and minimize storage costs.",
        "wg": [
          { "t": "自動化", "en": "automate", "ps": "verb" },
          { "t": "儲存成本", "en": "storage costs", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用 Autoclass 功能，讓 Google Cloud 自動根據存取模式將物件移動到最適當的儲存類別。",
        "en": "(A) Enable the Autoclass feature to let Google Cloud automatically move objects to the most appropriate storage class based on access patterns.",
        "wg": [
          { "t": "存取模式", "en": "access patterns", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 設定物件生命週期管理 (Object Lifecycle Management) 規則：(1) `Age > 30 days` 設為 Nearline，(2) `Age > 1095 days` 設為 Delete。",
        "en": "(B) Configure Object Lifecycle Management rules: (1) `Age > 30 days` Set to Nearline, (2) `Age > 1095 days` Set to Delete.",
        "wg": [
          { "t": "生命週期管理", "en": "Lifecycle Management", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 設定物件生命週期管理規則：(1) `Age > 30 days` 設為 Archive，(2) `Age > 1095 days` 設為 Delete。",
        "en": "(C) Configure Object Lifecycle Management rules: (1) `Age > 30 days` Set to Archive, (2) `Age > 1095 days` Set to Delete.",
        "wg": [
          { "t": "歸檔", "en": "Archive", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Scheduler 觸發 Cloud Functions，每天掃描 Bucket 並根據物件建立時間修改儲存類別。",
        "en": "(D) Use Cloud Scheduler to trigger Cloud Functions to scan the bucket daily and modify storage classes based on object creation time.",
        "wg": [
          { "t": "觸發", "en": "trigger", "ps": "verb" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "題目明確指出 30 天後「存取頻率極低」且需保存 3 年，這完全符合 **Archive** 儲存類別的使用場景（最低儲存成本，但存取費用較高，適合一年存取不到一次）。Nearline (B) 適合每月存取一次的資料，成本高於 Archive。Autoclass (A) 雖然方便，但會收取管理費，且在此特定已知模式下，手動設定規則通常更具成本效益。Cloud Functions (D) 增加了不必要的維護與執行成本。",
      "en": "The scenario explicitly states 'very low access frequency' after 30 days and 3-year retention, perfectly matching the **Archive** storage class (lowest storage cost, higher access cost, for data accessed < once a year). Nearline (B) is for monthly access and costs more than Archive. Autoclass (A) incurs management fees and rule-based configuration is usually more cost-effective for known patterns. Cloud Functions (D) adds unnecessary maintenance and execution costs.",
      "wg": [
        { "t": "成本效益", "en": "cost-effective", "ps": "adjective" },
        { "t": "儲存類別", "en": "storage class", "ps": "noun" }
      ]
    }
  },
  {
    "no": "14",
    "level": "hard",
    "keywords": "Cloud SQL, Disaster Recovery, RTO/RPO, Cross-region",
    "question": [
      {
        "t": "Cymbal Retail 的產品目錄資料庫 (Cloud SQL for PostgreSQL) 是其電子商務平台的核心。為了應對潛在的區域性災難 (Regional Failure)，業務連續性計畫 (BCP) 要求復原時間目標 (RTO) 必須小於 45 分鐘，復原點目標 (RPO) 必須小於 10 分鐘。",
        "en": "Cymbal Retail's product catalog database (Cloud SQL for PostgreSQL) is the core of its e-commerce platform. To address potential regional failures, the Business Continuity Plan (BCP) requires a Recovery Time Objective (RTO) of less than 45 minutes and a Recovery Point Objective (RPO) of less than 10 minutes.",
        "wg": [
          { "t": "區域性災難", "en": "Regional Failure", "ps": "noun" },
          { "t": "業務連續性計畫", "en": "Business Continuity Plan", "ps": "noun" }
        ]
      },
      {
        "t": "您需要設計一個符合這些嚴格指標的災難復原架構。",
        "en": "You need to design a disaster recovery architecture that meets these stringent metrics.",
        "wg": [
          { "t": "嚴格指標", "en": "stringent metrics", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用 Cloud SQL 的高可用性 (HA) 配置，這將自動在同一區域的不同區域 (Zone) 建立同步備用實例。",
        "en": "(A) Enable Cloud SQL High Availability (HA) configuration, which automatically creates a synchronous standby instance in a different zone within the same region.",
        "wg": [
          { "t": "同步備用實例", "en": "synchronous standby instance", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 在另一個地理區域建立跨地區讀取複本 (Cross-region Read Replica)，並在災難發生時將其提升 (Promote) 為主實例。",
        "en": "(B) Create a Cross-region Read Replica in another geographic region and promote it to primary instance in the event of a disaster.",
        "wg": [
          { "t": "跨地區讀取複本", "en": "Cross-region Read Replica", "ps": "noun" },
          { "t": "提升", "en": "Promote", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 設定每小時自動將資料庫匯出為 SQL 傾印檔 (Dump File) 並儲存至多地區 (Multi-region) 的 Cloud Storage Bucket。",
        "en": "(C) Configure automated hourly database exports as SQL Dump Files to a Multi-region Cloud Storage Bucket.",
        "wg": [
          { "t": "傾印檔", "en": "Dump File", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Persistent Disk 的快照排程功能，每 10 分鐘對底層磁碟進行一次多地區快照。",
        "en": "(D) Use the Persistent Disk snapshot schedule feature to take multi-region snapshots of the underlying disk every 10 minutes.",
        "wg": [
          { "t": "快照", "en": "snapshots", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Cloud SQL HA (A) 僅提供區域內 (Zonal) 的高可用性，無法防護整個區域 (Region) 的故障。跨地區讀取複本 (B) 是 Cloud SQL 針對區域級災難的標準 DR 解決方案，能滿足低 RTO/RPO 需求。選項 (C) 的每小時匯出無法滿足「RPO < 10 分鐘」的要求，且匯入恢復時間 (RTO) 會很長；選項 (D) 雖然快照可以頻繁進行，但在 Cloud SQL 託管服務中，直接操作底層磁碟快照並非標準恢復路徑，且恢復過程複雜耗時。",
      "en": "Cloud SQL HA (A) only provides intra-region (Zonal) high availability, offering no protection against full Region failures. Cross-region Read Replica (B) is the standard DR solution for Cloud SQL against regional disasters, meeting low RTO/RPO needs. Option (C)'s hourly export fails the 'RPO < 10 mins' requirement and has long restore times (RTO); Option (D)'s disk snapshots, while frequent, are not the standard restore path for managed Cloud SQL and involve complex, time-consuming recovery.",
      "wg": [
        { "t": "區域級災難", "en": "regional disasters", "ps": "noun" },
        { "t": "標準恢復路徑", "en": "standard restore path", "ps": "noun" }
      ]
    }
  },
  {
    "no": "15",
    "level": "hard",
    "keywords": "SRE, SLO, Error Budget, Release Velocity",
    "question": [
      {
        "t": "Cymbal Retail 的「產品發現 (Product Discovery)」團隊採用快速迭代開發模式，每天多次部署新功能。近期，客戶頻繁投訴搜尋結果加載緩慢且偶爾出現錯誤，導致客戶滿意度下降。",
        "en": "Cymbal Retail's 'Product Discovery' team uses a rapid iterative development model, deploying new features multiple times daily. Recently, customers have frequently complained about slow search result loading and occasional errors, leading to a drop in customer satisfaction.",
        "wg": [
          { "t": "快速迭代", "en": "rapid iterative", "ps": "adjective" },
          { "t": "客戶滿意度", "en": "customer satisfaction", "ps": "noun" }
        ]
      },
      {
        "t": "作為架構師，您希望引入網站可靠性工程 (SRE) 原則來平衡功能發布速度與系統穩定性。您應該採取哪兩項行動？(請選擇兩項)",
        "en": "As an architect, you want to introduce Site Reliability Engineering (SRE) principles to balance feature release velocity with system stability. Which two actions should you take? (Choose two)",
        "wg": [
          { "t": "平衡", "en": "balance", "ps": "verb" },
          { "t": "系統穩定性", "en": "system stability", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 定義服務水準目標 (SLOs)，例如「99.0% 的搜尋請求需在 200 毫秒內成功回應」。",
        "en": "(A) Define Service Level Objectives (SLOs), such as '99.0% of search requests must be successfully responded to within 200ms'.",
        "wg": [
          { "t": "服務水準目標", "en": "Service Level Objectives", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 要求開發團隊在每次部署前必須進行為期一週的手動回歸測試，直到錯誤率降為零。",
        "en": "(B) Require the development team to perform a one-week manual regression test before every deployment until the error rate drops to zero.",
        "wg": [
          { "t": "回歸測試", "en": "regression test", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 為所有微服務設定 CPU 使用率超過 80% 時的自動擴展警報，並自動增加節點。",
        "en": "(C) Configure autoscaling alerts for all microservices when CPU usage exceeds 80%, and automatically add nodes.",
        "wg": [
          { "t": "自動擴展", "en": "autoscaling", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 建立錯誤預算 (Error Budget) 政策：一旦監控顯示預算耗盡，將暫停所有非緊急的功能發布，轉而專注於可靠性修復。",
        "en": "(D) Establish an Error Budget policy: if monitoring shows the budget is exhausted, freeze all non-emergency feature releases and shift focus to reliability fixes.",
        "wg": [
          { "t": "錯誤預算", "en": "Error Budget", "ps": "noun" },
          { "t": "暫停", "en": "freeze", "ps": "verb" }
        ]
      },
      {
        "t": "(E) 將所有應用程式遷移至單體式架構 (Monolithic Architecture) 以減少網路延遲並簡化除錯。",
        "en": "(E) Migrate all applications to a Monolithic Architecture to reduce network latency and simplify debugging.",
        "wg": [
          { "t": "單體式架構", "en": "Monolithic Architecture", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A), (D)",
    "why": {
      "t": "這是 SRE 的核心實踐：首先定義與使用者體驗直接相關的 **SLO** (A)，然後利用 **錯誤預算** (D) 作為決策依據。當預算充足時，團隊可以冒險快速發布；當預算耗盡時，必須停止發布並修復穩定性問題。這種機制客觀地平衡了速度與風險。手動測試 (B) 嚴重阻礙速度；單純的 CPU 警報 (C) 無法反映真實使用者體驗；遷移至單體 (E) 是架構倒退，不符合現代化目標。",
      "en": "This is the core practice of SRE: first define **SLOs** (A) directly related to user experience, then use **Error Budgets** (D) as a decision-making tool. When budget is ample, the team can take risks and release fast; when exhausted, releases must stop to fix stability. This mechanism objectively balances speed and risk. Manual testing (B) severely hinders velocity; simple CPU alerts (C) don't reflect real user experience; migrating to monolith (E) is architectural regression.",
      "wg": [
        { "t": "決策依據", "en": "decision-making tool", "ps": "noun" },
        { "t": "架構倒退", "en": "architectural regression", "ps": "noun" }
      ]
    }
  },{
    "no": "16",
    "level": "hard",
    "keywords": "IAM Conditions, Least Privilege, Temporary Access, Security",
    "question": [
      {
        "t": "Cymbal Retail 聘請了一組外部審計人員來審查過去六個月的雲端帳單資料與稽核日誌 (Cloud Audit Logs)，以確保合規性。",
        "en": "Cymbal Retail has hired a team of external auditors to review cloud billing data and Cloud Audit Logs for the past six months to ensure compliance.",
        "wg": [
          { "t": "外部審計人員", "en": "external auditors", "ps": "noun" },
          { "t": "合規性", "en": "compliance", "ps": "noun" }
        ]
      },
      {
        "t": "這些審計人員擁有 Google 帳戶。根據資安政策，您必須授予他們僅為期 14 天的唯讀存取權限；一旦期限屆滿，權限必須自動撤銷，且無需管理員手動介入。",
        "en": "These auditors have Google accounts. According to security policy, you must grant them read-only access for a duration of exactly 14 days; once the period expires, access must be revoked automatically without manual administrator intervention.",
        "wg": [
          { "t": "唯讀存取權限", "en": "read-only access", "ps": "noun" },
          { "t": "自動撤銷", "en": "revoked automatically", "ps": "verb" }
        ]
      },
      {
        "t": "您應該如何設定 IAM 策略以精確滿足此需求？",
        "en": "How should you configure the IAM policy to precisely meet this requirement?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 為審計人員的帳戶新增 IAM 綁定，分配 `roles/billing.viewer` 與 `roles/logging.viewer` 角色，並新增一個基於時間的條件 (`request.time < timestamp`)。",
        "en": "(A) Add IAM bindings for the auditors' accounts, assigning `roles/billing.viewer` and `roles/logging.viewer` roles, and add a time-based condition (`request.time < timestamp`).",
        "wg": [
          { "t": "基於時間的條件", "en": "time-based condition", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 建立一個專用的 Service Account，授予所需的唯讀角色，產生 JSON 金鑰並透過安全電子郵件發送給審計人員，並在 14 天後手動刪除該金鑰。",
        "en": "(B) Create a dedicated Service Account, grant the required read-only roles, generate a JSON key, send it to auditors via secure email, and manually delete the key after 14 days.",
        "wg": [
          { "t": "金鑰", "en": "key", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Identity 建立一個名為 'Auditors' 的群組，將外部人員加入該群組，並設定 Cloud Task 在 14 天後呼叫 API 將使用者從群組中移除。",
        "en": "(C) Use Cloud Identity to create a group named 'Auditors', add external users to the group, and configure a Cloud Task to call the API to remove users from the group after 14 days.",
        "wg": [
          { "t": "群組", "en": "group", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 在 VPC Service Controls 中建立一個存取層級 (Access Level)，限制僅有特定 IP 來源的審計人員可以存取，並設定存取層級的過期時間。",
        "en": "(D) Create an Access Level in VPC Service Controls to restrict access to auditors only from specific source IPs, and configure an expiration time for the Access Level.",
        "wg": [
          { "t": "存取層級", "en": "Access Level", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "IAM 條件 (IAM Conditions) 允許在授予角色時設定到期日 (Expiry)，這是實現「自動撤銷」與「無需人工介入」的標準且最安全的方法。選項 (B) 涉及金鑰分發與手動刪除，風險高且不自動；選項 (C) 需要額外的開發 (Cloud Task) 且維護複雜；選項 (D) VPC-SC 用於網路邊界防護，不支援以這種方式設定 IAM 角色的時間過期。",
      "en": "IAM Conditions allow setting an expiry date when granting roles, which is the standard and most secure method to achieve 'automatic revocation' and 'no manual intervention'. Option (B) involves key distribution and manual deletion, which is high-risk and not automatic; Option (C) requires extra development (Cloud Task) and is complex to maintain; Option (D) VPC-SC is for network perimeter protection and does not support setting IAM role expiration in this manner.",
      "wg": [
        { "t": "標準方法", "en": "standard method", "ps": "noun" },
        { "t": "人工介入", "en": "manual intervention", "ps": "noun" }
      ]
    }
  },
  {
    "no": "17",
    "level": "hard",
    "keywords": "GKE, Scalability, Over-provisioning, Pause Pods",
    "question": [
      {
        "t": "Cymbal Retail 會定期舉辦「限時搶購 (Flash Sales)」活動，期間流量會在幾分鐘內激增 300%。目前的 GKE Cluster Autoscaler 需要數分鐘才能佈建新節點，導致早期的使用者請求因 Pod 處於 Pending 狀態而失敗。",
        "en": "Cymbal Retail regularly holds 'Flash Sales' events where traffic spikes by 300% within minutes. The current GKE Cluster Autoscaler takes several minutes to provision new nodes, causing early user requests to fail because Pods remain in a Pending state.",
        "wg": [
          { "t": "限時搶購", "en": "Flash Sales", "ps": "noun" },
          { "t": "激增", "en": "spikes", "ps": "verb" },
          { "t": "佈建", "en": "provision", "ps": "verb" }
        ]
      },
      {
        "t": "您需要設計一個優化策略，確保叢集能夠立即容納突發的 Pod 負載，而無需等待新節點啟動，同時盡量保持成本效益。",
        "en": "You need to design an optimization strategy to ensure the cluster can immediately accommodate burst Pod loads without waiting for new nodes to spin up, while remaining as cost-effective as possible.",
        "wg": [
          { "t": "立即容納", "en": "immediately accommodate", "ps": "verb" },
          { "t": "成本效益", "en": "cost-effective", "ps": "adjective" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將 Cluster Autoscaler 的設定檔改為 'Optimize-utilization'，並大幅增加 Horizontal Pod Autoscaler (HPA) 的目標 CPU 利用率。",
        "en": "(A) Change the Cluster Autoscaler profile to 'Optimize-utilization' and significantly increase the target CPU utilization of the Horizontal Pod Autoscaler (HPA).",
        "wg": [
          { "t": "利用率", "en": "utilization", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 為所有微服務配置 Vertical Pod Autoscaler (VPA)，使其在流量高峰時自動增加現有 Pod 的 CPU 與記憶體請求。",
        "en": "(B) Configure Vertical Pod Autoscaler (VPA) for all microservices to automatically increase CPU and memory requests for existing Pods during traffic peaks.",
        "wg": [
          { "t": "垂直 Pod 自動擴展", "en": "Vertical Pod Autoscaler", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 部署低優先級的「暫停 Pod (Pause Pods)」來預先佔用緩衝容量。當真實負載到達時，這些 Pod 會被驅逐 (Preempted) 以釋放空間給高優先級的應用程式 Pod。",
        "en": "(C) Deploy low-priority 'Pause Pods' to pre-occupy buffer capacity. When real load arrives, these Pods are preempted to free up space for high-priority application Pods.",
        "wg": [
          { "t": "暫停 Pod", "en": "Pause Pods", "ps": "noun" },
          { "t": "驅逐", "en": "preempted", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 在搶購活動開始前手動將節點集區的大小調整為最大預估值，並在活動結束後手動縮減。",
        "en": "(D) Manually resize the node pool to the maximum estimated value before the flash sale starts, and manually scale it down after the event ends.",
        "wg": [
          { "t": "手動調整", "en": "Manually resize", "ps": "verb" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "這被稱為「過度佈建 (Over-provisioning)」模式。透過使用低優先級的 Pause Pods 佔據空間，叢集可以維持隨時可用的備用節點。當流量激增時，Pause Pods 立即被驅逐，讓應用程式 Pod 能夠「瞬間」排程，無需等待節點啟動，完美解決冷啟動延遲問題。選項 (A) 的 'Optimize-utilization' 傾向於縮減節點，反而加劇問題；選項 (B) VPA 會重啟 Pod，不適合應對突發流量；選項 (D) 雖然有效但依賴人工操作，缺乏彈性且可能造成浪費。",
      "en": "This is known as the 'Over-provisioning' pattern. By using low-priority Pause Pods to occupy space, the cluster maintains ready-to-use standby nodes. When traffic spikes, Pause Pods are immediately preempted, allowing application Pods to be scheduled 'instantly' without waiting for node startup, perfectly solving cold start latency. Option (A)'s 'Optimize-utilization' tends to scale down nodes, worsening the issue; Option (B) VPA restarts Pods and is ill-suited for sudden bursts; Option (D) works but relies on manual operation, lacking elasticity and potentially causing waste.",
      "wg": [
        { "t": "過度佈建", "en": "Over-provisioning", "ps": "noun" },
        { "t": "冷啟動延遲", "en": "cold start latency", "ps": "noun" }
      ]
    }
  },
  {
    "no": "18",
    "level": "hard",
    "keywords": "BigQuery, JSON, Schemaless, Data Warehouse",
    "question": [
      {
        "t": "Cymbal Retail 整合了來自多個併購子公司的產品資料，這些資料原本儲存在 MongoDB 中。產品屬性結構高度變動且不一致（例如：電子產品有「電壓」，服裝有「材質」）。",
        "en": "Cymbal Retail integrates product data from multiple acquired subsidiaries, originally stored in MongoDB. The product attribute structure is highly variable and inconsistent (e.g., electronics have 'voltage', clothing has 'material').",
        "wg": [
          { "t": "高度變動", "en": "highly variable", "ps": "adjective" },
          { "t": "不一致", "en": "inconsistent", "ps": "adjective" }
        ]
      },
      {
        "t": "您需要將這些資料匯入 BigQuery 進行分析，並且希望能夠使用 SQL 直接查詢特定的巢狀屬性，同時避免因 Schema 變更而頻繁修改 ETL 管道。",
        "en": "You need to import this data into BigQuery for analysis and want to be able to query specific nested attributes directly using SQL, while avoiding frequent modifications to ETL pipelines due to schema changes.",
        "wg": [
          { "t": "巢狀屬性", "en": "nested attributes", "ps": "noun" },
          { "t": "ETL 管道", "en": "ETL pipelines", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 BigQuery 中定義一個包含數百個欄位的寬表 (Wide Table)，將所有可能的屬性預先定義為 Nullable Column。",
        "en": "(A) Define a wide table in BigQuery with hundreds of columns, pre-defining all possible attributes as Nullable Columns.",
        "wg": [
          { "t": "寬表", "en": "wide table", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 將產品屬性作為原生的 `JSON` 資料類型載入 BigQuery，並使用點符號 (Dot Notation) 存取巢狀欄位。",
        "en": "(B) Load product attributes into BigQuery as the native `JSON` data type, and use dot notation to access nested fields.",
        "wg": [
          { "t": "原生的", "en": "native", "ps": "adjective" },
          { "t": "點符號", "en": "dot notation", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Dataflow 在匯入前將所有巢狀 JSON 屬性展平 (Flatten) 為 `KEY:VALUE` 字串對，並儲存在 REPEATED RECORD 欄位中。",
        "en": "(C) Use Dataflow to flatten all nested JSON attributes into `KEY:VALUE` string pairs before import, and store them in a REPEATED RECORD field.",
        "wg": [
          { "t": "展平", "en": "flatten", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 將原始 JSON 檔案儲存在 Cloud Storage 中，並使用 BigQuery 外部資料表 (External Table) 進行查詢，不將資料載入 BigQuery 儲存。",
        "en": "(D) Store the raw JSON files in Cloud Storage and use BigQuery External Tables to query them without loading data into BigQuery storage.",
        "wg": [
          { "t": "外部資料表", "en": "External Table", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "BigQuery 的原生 JSON 資料類型是處理半結構化 (Semi-structured) 資料且 Schema 頻繁變動的最佳選擇。它允許直接儲存 JSON 物件並使用標準 SQL (如 `attributes.color`) 進行高效查詢，無需預先定義 Schema 或進行複雜的 ETL 轉換。選項 (A) 維護困難；選項 (C) 雖然可行但查詢語法複雜且不如原生 JSON 直觀高效；選項 (D) 的外部資料表效能通常低於原生儲存。",
      "en": "BigQuery's native JSON data type is the optimal choice for handling semi-structured data with frequent schema changes. It allows storing JSON objects directly and querying them efficiently using standard SQL (e.g., `attributes.color`) without pre-defining schema or complex ETL transformations. Option (A) is hard to maintain; Option (C) is viable but query syntax is complex and less intuitive/efficient than native JSON; Option (D) External Tables generally have lower performance than native storage.",
      "wg": [
        { "t": "半結構化", "en": "Semi-structured", "ps": "adjective" },
        { "t": "直觀", "en": "intuitive", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "19",
    "level": "hard",
    "keywords": "Cloud Armor, reCAPTCHA Enterprise, Security, WAF",
    "question": [
      {
        "t": "Cymbal Retail 的新網站面臨兩類主要安全威脅：針對登入頁面的自動化機器人憑證填充攻擊 (Credential Stuffing)，以及針對產品搜尋 API 的 SQL 資料隱碼攻擊 (SQL Injection)。",
        "en": "Cymbal Retail's new website faces two main security threats: automated bot credential stuffing attacks targeting the login page, and SQL Injection attacks targeting the product search API.",
        "wg": [
          { "t": "憑證填充攻擊", "en": "Credential Stuffing", "ps": "noun" },
          { "t": "SQL 資料隱碼攻擊", "en": "SQL Injection", "ps": "noun" }
        ]
      },
      {
        "t": "您需要部署一套整合式防禦方案來保護全域外部 HTTP(S) 負載平衡器後端的服務。您應該選擇哪兩項服務？(請選擇兩項)",
        "en": "You need to deploy an integrated defense solution to protect services behind the Global External HTTP(S) Load Balancer. Which two services should you choose? (Choose two)",
        "wg": [
          { "t": "整合式防禦", "en": "integrated defense", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 設定 Google Cloud Armor 安全政策，啟用預定義的 SQLi 防護規則集。",
        "en": "(A) Configure Google Cloud Armor security policies and enable the predefined SQLi protection ruleset.",
        "wg": [
          { "t": "規則集", "en": "ruleset", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 使用 Private Service Connect 將負載平衡器的 IP 位址隱藏，僅允許經過授權的 VPC 網路連線。",
        "en": "(B) Use Private Service Connect to hide the Load Balancer's IP address, allowing connections only from authorized VPC networks.",
        "wg": [
          { "t": "隱藏", "en": "hide", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 在所有 Web 伺服器 VM 上安裝第三方端點偵測與回應 (EDR) 代理程式。",
        "en": "(C) Install third-party Endpoint Detection and Response (EDR) agents on all web server VMs.",
        "wg": [
          { "t": "端點偵測與回應", "en": "Endpoint Detection and Response", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 整合 reCAPTCHA Enterprise，並建立 Cloud Armor 機器人管理 (Bot Management) 政策來攔截低信任分數的請求。",
        "en": "(D) Integrate reCAPTCHA Enterprise and create Cloud Armor Bot Management policies to block requests with low trust scores.",
        "wg": [
          { "t": "機器人管理", "en": "Bot Management", "ps": "noun" }
        ]
      },
      {
        "t": "(E) 啟用 Cloud CDN 並設定簽署 URL (Signed URLs) 以驗證所有 API 請求。",
        "en": "(E) Enable Cloud CDN and configure Signed URLs to validate all API requests.",
        "wg": [
          { "t": "簽署 URL", "en": "Signed URLs", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A), (D)",
    "why": {
      "t": "Cloud Armor (A) 作為 WAF (Web Application Firewall) 是防禦 SQL Injection 的核心工具。而針對「機器人憑證填充」，單純的 WAF 規則不足以應對，必須結合 reCAPTCHA Enterprise (D) 的行為分析與 Cloud Armor 的 Bot Management 功能，才能有效識別並攔截自動化攻擊。EDR (C) 是主機層級防護；Private Service Connect (B) 是內網連接技術；Cloud CDN (E) 主要用於快取加速。",
      "en": "Cloud Armor (A) serves as a WAF (Web Application Firewall) and is the core tool for defending against SQL Injection. For 'bot credential stuffing', simple WAF rules are insufficient; integrating reCAPTCHA Enterprise (D) for behavioral analysis with Cloud Armor's Bot Management is necessary to effectively identify and block automated attacks. EDR (C) is host-level protection; Private Service Connect (B) is for private networking; Cloud CDN (E) is primarily for cache acceleration.",
      "wg": [
        { "t": "行為分析", "en": "behavioral analysis", "ps": "noun" },
        { "t": "攔截", "en": "block", "ps": "verb" }
      ]
    }
  },
  {
    "no": "20",
    "level": "hard",
    "keywords": "Cloud KMS, CMEK, Key Rotation, Compliance",
    "question": [
      {
        "t": "Cymbal Retail 的產品目錄資料庫儲存了敏感的供應商合約資訊。根據新的法規遵循要求，所有靜態資料 (Data at Rest) 必須使用客戶管理的加密金鑰 (CMEK) 進行加密。",
        "en": "Cymbal Retail's product catalog database stores sensitive supplier contract information. According to new compliance requirements, all Data at Rest must be encrypted using Customer-Managed Encryption Keys (CMEK).",
        "wg": [
          { "t": "靜態資料", "en": "Data at Rest", "ps": "noun" },
          { "t": "客戶管理的加密金鑰", "en": "Customer-Managed Encryption Keys", "ps": "noun" }
        ]
      },
      {
        "t": "此外，加密金鑰必須每 90 天自動輪換 (Rotate) 一次。您需要為 Cloud SQL 實例設定此加密機制，並確保管理負擔降至最低。",
        "en": "Additionally, encryption keys must be automatically rotated every 90 days. You need to configure this encryption mechanism for the Cloud SQL instance while minimizing administrative overhead.",
        "wg": [
          { "t": "輪換", "en": "rotate", "ps": "verb" },
          { "t": "管理負擔", "en": "administrative overhead", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud HSM 產生金鑰，手動匯出並儲存在地端的硬體安全模組中，每 90 天重新匯入一次。",
        "en": "(A) Generate keys using Cloud HSM, manually export and store them in an on-premises Hardware Security Module, and re-import them every 90 days.",
        "wg": [
          { "t": "硬體安全模組", "en": "Hardware Security Module", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 撰寫一個 Cloud Functions 腳本，使用 Python 加密程式庫在應用程式層加密資料，然後寫入 Cloud SQL，並透過 Cloud Scheduler 觸發金鑰輪換。",
        "en": "(B) Write a Cloud Functions script to encrypt data at the application layer using a Python encryption library before writing to Cloud SQL, and trigger key rotation via Cloud Scheduler.",
        "wg": [
          { "t": "應用程式層", "en": "application layer", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 在 Cloud SQL 設定中啟用 'Customer-Supplied Encryption Keys (CSEK)'，並將原始 AES-256 金鑰上傳至實例中繼資料。",
        "en": "(C) Enable 'Customer-Supplied Encryption Keys (CSEK)' in Cloud SQL settings and upload raw AES-256 keys to instance metadata.",
        "wg": [
          { "t": "實例中繼資料", "en": "instance metadata", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 在 Cloud KMS 中建立對稱金鑰 (Symmetric Key)，設定輪換週期為 90 天，並授予 Cloud SQL Service Account `Cloud KMS CryptoKey Encrypter/Decrypter` 角色。",
        "en": "(D) Create a Symmetric Key in Cloud KMS, set the rotation period to 90 days, and grant the `Cloud KMS CryptoKey Encrypter/Decrypter` role to the Cloud SQL Service Account.",
        "wg": [
          { "t": "對稱金鑰", "en": "Symmetric Key", "ps": "noun" },
          { "t": "加密器/解密器", "en": "Encrypter/Decrypter", "ps": "noun" }
        ]
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud KMS 與 Cloud SQL 的 CMEK 整合是標準且完全託管的解決方案。透過在 Cloud KMS 中設定「自動輪換 (Automatic Rotation)」，系統會自動產生新版本的金鑰，且無需重新加密現有資料（Cloud SQL 會使用金鑰版本封裝 DEK）。這完全滿足了合規性與「最小化管理」的需求。選項 (A) 手動操作且違背雲原生原則；選項 (B) 是應用層加密，複雜且效能差；選項 (C) Cloud SQL 支援的是 CMEK (KMS) 而非 CSEK (原始金鑰上傳)。",
      "en": "Cloud KMS integration with Cloud SQL CMEK is the standard and fully managed solution. By configuring 'Automatic Rotation' in Cloud KMS, the system automatically generates new key versions without needing to re-encrypt existing data (Cloud SQL uses key wrapping for DEKs). This fully meets compliance and 'minimize management' needs. Option (A) is manual and anti-cloud-native; Option (B) is application-layer encryption, complex and poorly performing; Option (C) Cloud SQL supports CMEK (KMS), not CSEK (raw key upload).",
      "wg": [
        { "t": "雲原生", "en": "cloud-native", "ps": "adjective" },
        { "t": "封裝", "en": "wrapping", "ps": "verb" }
      ]
    }
  }
]