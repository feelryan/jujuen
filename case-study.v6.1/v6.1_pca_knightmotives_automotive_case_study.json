[
    {
      "no": "1",
      "level": "hard",
      "keywords": "Hybrid Connectivity, Partner Interconnect, RFC 1918",
      "question": [
        {
          "t": "KnightMotives 希望建立其位於偏遠鄉村地區的製造工廠與 Google Cloud 之間的高頻寬連線，以支援將遙測數據上傳至 BigQuery 進行數據變現專案。",
          "en": "KnightMotives wants to establish high-bandwidth connectivity between its manufacturing plants located in remote rural areas and Google Cloud to support uploading telemetry data to BigQuery for the Data Monetization project.",
          "wg": [
            { "t": "偏遠鄉村地區", "en": "remote rural areas", "ps": "noun" },
            { "t": "高頻寬連線", "en": "high-bandwidth connectivity", "ps": "noun" },
            { "t": "數據變現", "en": "Data Monetization", "ps": "noun" }
          ]
        },
        {
          "t": "工廠目前的網際網路連線極不穩定，且根據公司資安政策，所有傳輸流量必須使用 RFC 1918 私有 IP 位址，且不得經過公共網際網路。",
          "en": "The current internet connectivity at the plants is highly unreliable, and per corporate security policy, all transit traffic must use RFC 1918 private IP addresses and must not traverse the public internet.",
          "wg": [
            { "t": "極不穩定", "en": "highly unreliable", "ps": "adjective" },
            { "t": "私有 IP 位址", "en": "private IP addresses", "ps": "noun" },
            { "t": "公共網際網路", "en": "public internet", "ps": "noun" }
          ]
        },
        {
          "t": "經調查，Google 的網路服務提供點 (PoP) 距離工廠超過 500 公里。您需要建議一個符合服務水準協議 (SLA) 且最具成本效益的連線方案。",
          "en": "Investigations reveal that a Google Point of Presence (PoP) is over 500 kilometers away from the plants. You need to recommend a connectivity solution that meets Service Level Agreement (SLA) requirements and is the most cost-effective.",
          "wg": [
            { "t": "網路服務提供點", "en": "Point of Presence (PoP)", "ps": "noun" },
            { "t": "服務水準協議", "en": "Service Level Agreement (SLA)", "ps": "noun" },
            { "t": "成本效益", "en": "cost-effective", "ps": "adjective" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 透過現有的網際網路服務供應商 (ISP) 配置多條 Cloud VPN 通道，並啟用動態路由 (BGP) 以實現高可用性 (HA VPN)。",
          "en": "(A) Configure multiple Cloud VPN tunnels via the existing Internet Service Provider (ISP) and enable dynamic routing (BGP) to achieve High Availability (HA VPN).",
          "wg": [
            { "t": "Cloud VPN 通道", "en": "Cloud VPN tunnels", "ps": "noun" },
            { "t": "動態路由", "en": "dynamic routing", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 佈建與服務供應商合作的合作夥伴互連 (Partner Interconnect)，建立 VLAN 附件以連接至 VPC。",
          "en": "(B) Provision a Partner Interconnect with a service provider and establish VLAN attachments to connect to the VPC.",
          "wg": [
            { "t": "合作夥伴互連", "en": "Partner Interconnect", "ps": "noun" },
            { "t": "VLAN 附件", "en": "VLAN attachments", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 向當地電信商租用全新光纖線路並建置專用互連 (Dedicated Interconnect)，直接連接至最近的 Google PoP。",
          "en": "(C) Lease new fiber lines from a local carrier and build a Dedicated Interconnect connecting directly to the nearest Google PoP.",
          "wg": [
            { "t": "專用互連", "en": "Dedicated Interconnect", "ps": "noun" },
            { "t": "光纖線路", "en": "fiber lines", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 設定直接對等互連 (Direct Peering) 以交換 BGP 路由，確保流量直接進入 Google 網路而不經過公共網際網路。",
          "en": "(D) Configure Direct Peering to exchange BGP routes, ensuring traffic enters Google's network directly without traversing the public internet.",
          "wg": [
            { "t": "直接對等互連", "en": "Direct Peering", "ps": "noun" },
            { "t": "BGP 路由", "en": "BGP routes", "ps": "noun" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Partner Interconnect 是最佳解，因為工廠位於偏遠地區且遠離 Google PoP，無法經濟地建立 Dedicated Interconnect。Partner Interconnect 透過服務供應商提供 SLA 和私有 IP (RFC 1918) 連線。選項 (A) Cloud VPN 依賴不穩定的公共網際網路，不符合 SLA 需求。選項 (C) 成本過高且建設時間長。選項 (D) Direct Peering 不支援 RFC 1918 私有 IP 位址，且通常不提供 SLA。",
        "en": "Partner Interconnect is the optimal solution because the plants are in remote areas far from a Google PoP, making Dedicated Interconnect economically unviable. Partner Interconnect provides SLA and private IP (RFC 1918) connectivity through service providers. Option (A) Cloud VPN relies on unreliable public internet and does not meet SLA requirements. Option (C) is cost-prohibitive and has a long lead time. Option (D) Direct Peering does not support RFC 1918 private IP addresses and typically does not offer an SLA.",
        "wg": [
          { "t": "無法經濟地", "en": "economically unviable", "ps": "adverb" },
          { "t": "不符合", "en": "does not meet", "ps": "verb" }
        ]
      }
    },
    {
      "no": "2",
      "level": "hard",
      "keywords": "Apigee, Legacy Modernization, Monetization",
      "question": [
        {
          "t": "KnightMotives 希望利用現有的企業數據產生新的收入來源 (Data Monetization)，並改善經銷商的「接單生產」體驗。",
          "en": "KnightMotives wants to generate new revenue streams from existing corporate data (Data Monetization) and improve the dealer's \"build-to-order\" experience.",
          "wg": [
            { "t": "收入來源", "en": "revenue streams", "ps": "noun" },
            { "t": "接單生產", "en": "build-to-order", "ps": "noun" }
          ]
        },
        {
          "t": "目前的供應鏈系統運行在過時的大型主機 (Mainframe) 上，重寫程式碼風險過高且耗時。您需要設計一個架構，能夠安全地將舊有系統的功能暴露給外部合作夥伴與經銷商應用程式，同時具備流量控制與數據變現的計費能力。",
          "en": "The current supply chain system runs on an outdated mainframe, and rewriting the code is too risky and time-consuming. You need to design an architecture that securely exposes legacy system functionality to external partners and dealer applications, while providing traffic control and monetization billing capabilities.",
          "wg": [
            { "t": "大型主機", "en": "mainframe", "ps": "noun" },
            { "t": "暴露", "en": "exposes", "ps": "verb" },
            { "t": "流量控制", "en": "traffic control", "ps": "noun" },
            { "t": "計費能力", "en": "billing capabilities", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Functions 編寫包裝器 (Wrapper) 來呼叫大型主機介面，並將這些函式部署為公開的 HTTP 端點供合作夥伴使用。",
          "en": "(A) Write wrappers using Cloud Functions to call mainframe interfaces and deploy these functions as public HTTP endpoints for partner use.",
          "wg": [
            { "t": "包裝器", "en": "wrappers", "ps": "noun" },
            { "t": "公開的 HTTP 端點", "en": "public HTTP endpoints", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 將大型主機應用程式遷移至 Compute Engine 虛擬機，並設定 Cloud Billing API 來追蹤外部合作夥伴的 API 呼叫次數。",
          "en": "(B) Migrate the mainframe application to Compute Engine virtual machines and configure the Cloud Billing API to track API call counts from external partners.",
          "wg": [
            { "t": "遷移", "en": "Migrate", "ps": "verb" },
            { "t": "API 呼叫次數", "en": "API call counts", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 部署 Apigee API 管理平台作為大型主機的前端 Facade，設定開發者入口網站 (Developer Portal) 與變現政策 (Monetization Policy) 來管理與計費。",
          "en": "(C) Deploy the Apigee API Management platform as a frontend Facade for the mainframe, configuring a Developer Portal and Monetization Policy to manage and bill usage.",
          "wg": [
            { "t": "前端 Facade", "en": "frontend Facade", "ps": "noun" },
            { "t": "變現政策", "en": "Monetization Policy", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 使用 Cloud VPN 建立經銷商與大型主機之間的通道，並在大型主機防火牆上設定規則以限制存取速率。",
          "en": "(D) Use Cloud VPN to establish tunnels between dealers and the mainframe, and configure rules on the mainframe firewall to rate-limit access.",
          "wg": [
            { "t": "通道", "en": "tunnels", "ps": "noun" },
            { "t": "存取速率", "en": "rate-limit access", "ps": "verb" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "Apigee 是專為 API 管理與變現設計的企業級解決方案。它能作為舊有系統 (Legacy) 的代理 (Facade)，在不重寫後端程式碼的情況下提供現代化 API、安全性 (OAuth/API Key)、流量控制 (Quota) 以及關鍵的「數據變現」計費功能。選項 (A) 缺乏管理與變現功能。選項 (B) 的「遷移」違反了題目中「重寫風險過高」的限制。選項 (D) 僅提供網路連線，無法達成應用層的變現或細緻管理。",
        "en": "Apigee is an enterprise-grade solution designed for API management and monetization. It acts as a proxy (Facade) for legacy systems, providing modern APIs, security (OAuth/API Key), traffic control (Quota), and crucial \"data monetization\" billing features without rewriting backend code. Option (A) lacks management and monetization features. Option (B) suggests \"migration,\" violating the \"too risky to rewrite\" constraint. Option (D) only provides network connectivity and cannot achieve application-level monetization or granular management.",
        "wg": [
          { "t": "企業級解決方案", "en": "enterprise-grade solution", "ps": "noun" },
          { "t": "代理", "en": "proxy", "ps": "noun" },
          { "t": "違反", "en": "violating", "ps": "verb" }
        ]
      }
    },
    {
      "no": "3",
      "level": "hard",
      "keywords": "GDPR, Data Residency, DLP, BigQuery",
      "question": [
        {
          "t": "KnightMotives 計劃蒐集歐洲地區車輛的自動駕駛數據，其中包含可識別駕駛身分的個人資訊 (PII)。根據歐盟資料保護規範 (GDPR)，原始 PII 數據不得離開歐洲區域。",
          "en": "KnightMotives plans to collect autonomous driving data from vehicles in Europe, which contains Personally Identifiable Information (PII) of drivers. According to EU data protection regulations (GDPR), raw PII data must not leave the European region.",
          "wg": [
            { "t": "歐盟資料保護規範", "en": "EU data protection regulations (GDPR)", "ps": "noun" },
            { "t": "原始 PII 數據", "en": "raw PII data", "ps": "noun" }
          ]
        },
        {
          "t": "然而，位於美國的數據科學團隊需要存取這些數據來訓練全球通用的 AI 模型。您需要設計一個解決方案，確保合規性同時允許美國團隊使用數據進行訓練。應採取哪兩個步驟？（請選擇兩項）",
          "en": "However, the data science team based in the US needs access to this data to train globally applicable AI models. You need to design a solution that ensures compliance while allowing the US team to use the data for training. Which two steps should you take? (Choose two)",
          "wg": [
            { "t": "數據科學團隊", "en": "data science team", "ps": "noun" },
            { "t": "全球通用的", "en": "globally applicable", "ps": "adjective" },
            { "t": "合規性", "en": "compliance", "ps": "noun" }
          ]
        }
      ],
      "type": "複選題",
      "options": [
        {
          "t": "(A) 設定 BigQuery 資料集位置為 'europe-west'，並僅將原始遙測數據存儲於該資料集中。",
          "en": "(A) Configure the BigQuery dataset location to 'europe-west' and store raw telemetry data exclusively in that dataset.",
          "wg": [
            { "t": "資料集位置", "en": "dataset location", "ps": "noun" },
            { "t": "原始遙測數據", "en": "raw telemetry data", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 實施 VPC Service Controls，建立一個包含美國與歐洲專案的服務邊界 (Service Perimeter)，以允許跨區域資料複製。",
          "en": "(B) Implement VPC Service Controls to create a Service Perimeter containing both US and European projects to allow cross-region data replication.",
          "wg": [
            { "t": "服務邊界", "en": "Service Perimeter", "ps": "noun" },
            { "t": "跨區域資料複製", "en": "cross-region data replication", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Cloud Data Loss Prevention (DLP) 掃描歐洲資料集，建立一個去識別化 (De-identified) 的副本資料集，並將副本存儲於美國區域供 AI 訓練使用。",
          "en": "(C) Use Cloud Data Loss Prevention (DLP) to scan the European dataset, create a de-identified copy of the dataset, and store the copy in a US region for AI training use.",
          "wg": [
            { "t": "去識別化", "en": "De-identified", "ps": "adjective" },
            { "t": "副本", "en": "copy", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 透過 IAM 條件 (IAM Conditions) 限制美國團隊僅能在上班時間存取歐洲的原始資料集。",
          "en": "(D) Restrict the US team's access to the European raw dataset to business hours only using IAM Conditions.",
          "wg": [
            { "t": "IAM 條件", "en": "IAM Conditions", "ps": "noun" },
            { "t": "限制", "en": "Restrict", "ps": "verb" }
          ]
        },
        {
          "t": "(E) 在應用程式層級對所有數據進行客戶端加密 (Client-side Encryption)，並將金鑰儲存在歐洲的 Cloud KMS 中，授權美國團隊解密。",
          "en": "(E) Perform client-side encryption on all data at the application level, store the keys in Cloud KMS in Europe, and authorize the US team to decrypt.",
          "wg": [
            { "t": "客戶端加密", "en": "client-side encryption", "ps": "noun" },
            { "t": "解密", "en": "decrypt", "ps": "verb" }
          ]
        }
      ],
      "answer": "(A), (C)",
      "why": {
        "t": "選項 (A) 確保原始數據符合 GDPR 的資料駐留 (Data Residency) 要求，將數據限制在歐洲。選項 (C) 使用 DLP 技術移除或遮蔽 PII，使數據不再受限於 GDPR 的嚴格地理限制，從而可以合法地轉移至美國供模型訓練使用。選項 (B) 和 (D) 仍允許美國團隊存取或複製「原始」PII，違反法規。選項 (E) 雖然加密，但若美國團隊能解密讀取原始 PII，則仍視為數據跨境傳輸，可能違規。",
        "en": "Option (A) ensures the raw data meets GDPR Data Residency requirements by restricting it to Europe. Option (C) uses DLP to remove or mask PII, effectively rendering the data outside the scope of strict GDPR geographic restrictions, thus legally allowing transfer to the US for model training. Options (B) and (D) still allow the US team to access or replicate \"raw\" PII, violating regulations. Option (E), while encrypting, essentially allows cross-border data transfer if the US team can decrypt and read raw PII, which may still be a violation.",
        "wg": [
          { "t": "資料駐留", "en": "Data Residency", "ps": "noun" },
          { "t": "嚴格地理限制", "en": "strict geographic restrictions", "ps": "noun" },
          { "t": "跨境傳輸", "en": "cross-border transfer", "ps": "noun" }
        ]
      }
    },
    {
      "no": "4",
      "level": "hard",
      "keywords": "Anthos, Distributed Cloud, Hybrid, GKE",
      "question": [
        {
          "t": "KnightMotives 的車輛軟體存在嚴重的碎片化問題，混合動力車與電動車使用完全不同的程式碼庫。目標是透過容器化應用程式來統一「車內體驗」，並在所有車型上部署一致的 AI 功能。",
          "en": "KnightMotives faces severe fragmentation in vehicle software, with hybrids and EVs using completely different codebases. The goal is to unify the \"in-vehicle experience\" via containerized applications and deploy consistent AI features across all models.",
          "wg": [
            { "t": "碎片化問題", "en": "fragmentation", "ps": "noun" },
            { "t": "容器化應用程式", "en": "containerized applications", "ps": "noun" },
            { "t": "一致的 AI 功能", "en": "consistent AI features", "ps": "noun" }
          ]
        },
        {
          "t": "考慮到偏遠地區網路連線不穩，車輛必須具備在本地 (Edge) 執行 AI 推論的能力，但管理與更新必須透過 Google Cloud 集中進行。您應該採用哪種架構策略？",
          "en": "Considering unreliable network connectivity in rural areas, vehicles must have the capability to perform AI inference locally (Edge), but management and updates must be centralized via Google Cloud. Which architectural strategy should you adopt?",
          "wg": [
            { "t": "本地執行", "en": "perform locally", "ps": "verb" },
            { "t": "推論", "en": "inference", "ps": "noun" },
            { "t": "集中進行", "en": "centralized", "ps": "adjective" }
          ]
        },
        {
          "t": "注意：經銷商維修中心與車輛運算單元可視為邊緣節點。",
          "en": "Note: Dealer service centers and vehicle compute units can be considered edge nodes.",
          "wg": [
            { "t": "邊緣節點", "en": "edge nodes", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 在所有車輛與維修中心部署標準的 Linux 伺服器，使用 Compute Engine 的 startup-script 從 Cloud Storage 下載最新的 Docker 映像檔並執行。",
          "en": "(A) Deploy standard Linux servers in all vehicles and service centers, using Compute Engine startup-scripts to download and run the latest Docker images from Cloud Storage.",
          "wg": [
            { "t": "映像檔", "en": "images", "ps": "noun" },
            { "t": "執行", "en": "run", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 採用 Cloud Run for Anthos，將應用程式部署在 Google Cloud 區域中，並透過 Cloud Interconnect 強制車輛隨時保持連線以存取服務。",
          "en": "(B) Adopt Cloud Run for Anthos, deploying applications in Google Cloud regions, and mandate continuous vehicle connectivity via Cloud Interconnect to access services.",
          "wg": [
            { "t": "強制", "en": "mandate", "ps": "verb" },
            { "t": "隨時保持連線", "en": "continuous connectivity", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 TensorFlow Lite 將模型嵌入到行動應用程式中，透過 Google Play Store 更新車輛軟體，完全繞過雲端基礎設施。",
          "en": "(C) Use TensorFlow Lite to embed models into mobile applications, updating vehicle software via the Google Play Store, bypassing cloud infrastructure entirely.",
          "wg": [
            { "t": "嵌入", "en": "embed", "ps": "verb" },
            { "t": "繞過", "en": "bypassing", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 利用 Google Distributed Cloud (Anthos) 管理邊緣部署。在車輛硬體上執行 GKE，並透過 Google Cloud 控制平面統一派送配置與 AI 模型更新。",
          "en": "(D) Leverage Google Distributed Cloud (Anthos) to manage edge deployments. Run GKE on vehicle hardware and unify configuration delivery and AI model updates via the Google Cloud control plane.",
          "wg": [
            { "t": "邊緣部署", "en": "edge deployments", "ps": "noun" },
            { "t": "控制平面", "en": "control plane", "ps": "noun" },
            { "t": "派送", "en": "delivery", "ps": "noun" }
          ]
        }
      ],
      "answer": "(D)",
      "why": {
        "t": "Anthos (Google Distributed Cloud) 是解決混合雲與邊緣運算管理的最佳方案。它允許在邊緣 (車輛/經銷商) 運行容器化應用 (GKE)，即使在網路斷線時也能持續運作 (Local Execution)，一旦連線恢復即可透過單一控制平面 (Single Pane of Glass) 同步更新配置與模型。選項 (A) 維運成本極高且缺乏統一管理。選項 (B) 忽略了「網路連線不穩」的限制。選項 (C) 無法滿足複雜的車輛控制與集中管理需求。",
        "en": "Anthos (Google Distributed Cloud) is the optimal solution for managing hybrid and edge computing. It allows containerized applications (GKE) to run at the edge (vehicles/dealers), continuing operation even when disconnected (Local Execution), and syncing updates/models via a single control plane (Single Pane of Glass) once connectivity is restored. Option (A) has high operational toil and lacks unified management. Option (B) ignores the \"unreliable connectivity\" constraint. Option (C) cannot meet complex vehicle control and centralized management needs.",
        "wg": [
          { "t": "最佳方案", "en": "optimal solution", "ps": "noun" },
          { "t": "維運成本", "en": "operational toil", "ps": "noun" },
          { "t": "單一控制平面", "en": "Single Pane of Glass", "ps": "noun" }
        ]
      }
    },
    {
      "no": "5",
      "level": "hard",
      "keywords": "BeyondCorp, IAP, Zero Trust, Security",
      "question": [
        {
          "t": "經銷商目前使用不可靠的 VPN 存取 KnightMotives 的內部訂單系統。由於經銷商「沒有預算購買新設備」，且技術能力有限，您需要設計一個更安全且易於使用的存取方案。",
          "en": "Dealers currently use an unreliable VPN to access KnightMotives' internal ordering system. Since dealers have \"no budget for new equipment\" and limited technical skills, you need to design a more secure and user-friendly access solution.",
          "wg": [
            { "t": "不可靠的", "en": "unreliable", "ps": "adjective" },
            { "t": "沒有預算", "en": "no budget", "ps": "noun" },
            { "t": "易於使用的", "en": "user-friendly", "ps": "adjective" }
          ]
        },
        {
          "t": "新的解決方案必須支援單一登入 (SSO)，並能根據使用者的身分與情境 (Context) 驗證存取權限，而無需在經銷商端安裝任何代理程式 (Agentless)。",
          "en": "The new solution must support Single Sign-On (SSO) and validate access rights based on user identity and context, without installing any agents on the dealer side (Agentless).",
          "wg": [
            { "t": "單一登入", "en": "Single Sign-On (SSO)", "ps": "noun" },
            { "t": "身分與情境", "en": "identity and context", "ps": "noun" },
            { "t": "代理程式", "en": "agents", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 為每家經銷商配置 Cloud VPN，並強制所有流量通過防火牆規則進行過濾。",
          "en": "(A) Configure Cloud VPN for each dealer and mandate all traffic be filtered through firewall rules.",
          "wg": [
            { "t": "強制", "en": "mandate", "ps": "verb" },
            { "t": "過濾", "en": "filtered", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 實施 BeyondCorp Enterprise 模式，使用 Identity-Aware Proxy (IAP) 保護內部應用程式，並設定存取層級 (Access Levels) 以驗證身分。",
          "en": "(B) Implement the BeyondCorp Enterprise model, protecting internal applications using Identity-Aware Proxy (IAP) and configuring Access Levels to validate identity.",
          "wg": [
            { "t": "實施", "en": "Implement", "ps": "verb" },
            { "t": "存取層級", "en": "Access Levels", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 將訂單系統遷移至公共網際網路，並使用 Cloud Armor 設定 IP 白名單，僅允許經銷商的 IP 位址存取。",
          "en": "(C) Migrate the ordering system to the public internet and use Cloud Armor to configure an IP allowlist, permitting access only from dealer IP addresses.",
          "wg": [
            { "t": "白名單", "en": "allowlist", "ps": "noun" },
            { "t": "允許", "en": "permitting", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 要求所有經銷商安裝 Google Chrome 瀏覽器並啟用端點驗證 (Endpoint Verification) 擴充功能，配合 mTLS 憑證進行連線。",
          "en": "(D) Require all dealers to install the Google Chrome browser and enable the Endpoint Verification extension, connecting via mTLS certificates.",
          "wg": [
            { "t": "擴充功能", "en": "extension", "ps": "noun" },
            { "t": "憑證", "en": "certificates", "ps": "noun" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Identity-Aware Proxy (IAP) 是實現零信任 (Zero Trust) 存取的核心元件，符合 BeyondCorp 模型。它允許使用者透過網際網路安全地存取內部 Web 應用程式 (無需 VPN)，並整合 SSO 與 Context-Aware Access。這完全符合經銷商「無預算購買新硬體」且需要「無代理程式」體驗的需求。選項 (A) 需要 VPN 硬體或配置，違反預算限制。選項 (C) 依賴 IP 白名單，不夠安全且管理困難。選項 (D) 雖然安全，但涉及端點配置，可能對技術能力有限的經銷商造成負擔。",
        "en": "Identity-Aware Proxy (IAP) is a core component for achieving Zero Trust access, aligning with the BeyondCorp model. It allows users to securely access internal web apps via the internet (VPN-free), integrating SSO and Context-Aware Access. This perfectly fits the dealers' \"no budget for new hardware\" and \"agentless\" requirements. Option (A) requires VPN hardware/config, violating budget constraints. Option (C) relies on IP allowlisting, which is insecure and hard to manage. Option (D) involves endpoint configuration, which might burden dealers with limited technical skills.",
        "wg": [
          { "t": "零信任", "en": "Zero Trust", "ps": "noun" },
          { "t": "無代理程式", "en": "agentless", "ps": "adjective" },
          { "t": "負擔", "en": "burden", "ps": "noun" }
        ]
      }
    },
    {
      "no": "6",
      "level": "hard",
      "keywords": "CI/CD, Binary Authorization, IoT, Security",
      "question": [
        {
          "t": "KnightMotives 正在開發新一代的車載作業系統，以解決混合動力車與電動車之間的「程式碼庫碎片化」問題。由於這些更新直接影響車輛的煞車與轉向系統，安全性至關重要。",
          "en": "KnightMotives is developing a next-generation in-vehicle operating system to address the \"codebase fragmentation\" between hybrid and electric vehicles. Since these updates directly impact vehicle braking and steering systems, safety is paramount.",
          "wg": [
            { "t": "程式碼庫碎片化", "en": "codebase fragmentation", "ps": "noun" },
            { "t": "至關重要", "en": "paramount", "ps": "adjective" }
          ]
        },
        {
          "t": "您需要設計一個軟體供應鏈 (Software Supply Chain) 架構，確保只有經過授權且通過嚴格測試的容器映像檔才能被部署到車輛上，並且在發現異常時能夠立即停止更新。",
          "en": "You need to design a Software Supply Chain architecture ensuring that only authorized and rigorously tested container images are deployed to vehicles, with the ability to immediately halt updates upon detecting anomalies.",
          "wg": [
            { "t": "軟體供應鏈", "en": "Software Supply Chain", "ps": "noun" },
            { "t": "立即停止", "en": "immediately halt", "ps": "verb" }
          ]
        },
        {
          "t": "考量到「過去的數據洩露」事件，該架構必須防止惡意程式碼被注入。",
          "en": "Considering \"past data breaches,\" the architecture must prevent malicious code injection.",
          "wg": [
            { "t": "惡意程式碼", "en": "malicious code", "ps": "noun" },
            { "t": "注入", "en": "injection", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Build 建立映像檔，並將其儲存在公開的 Container Registry 中。透過 GKE 的 Rolling Update 策略逐步推送到車輛，若失敗則自動回滾。",
          "en": "(A) Use Cloud Build to create images and store them in a public Container Registry. Push incrementally to vehicles using GKE Rolling Update strategy, automatically rolling back on failure.",
          "wg": [
            { "t": "逐步推送", "en": "Push incrementally", "ps": "verb" },
            { "t": "自動回滾", "en": "automatically rolling back", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 實施 Jenkins 伺服器進行建置，並使用 SSH 金鑰簽署映像檔。在車輛端編寫 Shell Script 驗證簽章後再透過 `docker run` 執行更新。",
          "en": "(B) Implement Jenkins servers for builds and sign images using SSH keys. Write shell scripts on the vehicle side to verify signatures before executing updates via `docker run`.",
          "wg": [
            { "t": "簽署", "en": "sign", "ps": "verb" },
            { "t": "驗證簽章", "en": "verify signatures", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 在 CI/CD 流程中整合 Binary Authorization 與 Cloud Build。使用 Attestations 簽署通過 QA 測試的映像檔，並在 GKE 叢集中強制執行策略，僅允許受信任的映像檔啟動。",
          "en": "(C) Integrate Binary Authorization with Cloud Build in the CI/CD pipeline. Use Attestations to sign QA-passed images and enforce policies in GKE clusters to allow only trusted images to launch.",
          "wg": [
            { "t": "整合", "en": "Integrate", "ps": "verb" },
            { "t": "強制執行策略", "en": "enforce policies", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 利用 Spinnaker 進行藍/綠部署 (Blue/Green Deployment)。將新版本部署到新的命名空間，透過切換 DNS 記錄將流量導向新版本，若有問題則切換回舊 DNS。",
          "en": "(D) Utilize Spinnaker for Blue/Green Deployment. Deploy the new version to a new namespace and switch traffic via DNS records; revert DNS if issues arise.",
          "wg": [
            { "t": "藍/綠部署", "en": "Blue/Green Deployment", "ps": "noun" },
            { "t": "切換", "en": "switch", "ps": "verb" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "Binary Authorization 是 Google Cloud 針對軟體供應鏈安全的核心服務，能確保只有經過「認證 (Attestations)」的映像檔才能部署。這直接解決了「防止惡意程式碼注入」與「確保通過測試」的需求。選項 (A) 使用公開 Registry 極不安全且缺乏簽章機制。選項 (B) 的自定義 Shell Script 與 SSH 簽章難以大規模管理且易出錯 (Operational Toil)。選項 (D) 的 DNS 切換不適用於車輛端的嵌入式軟體更新，且無法保證映像檔本身的安全性。",
        "en": "Binary Authorization is Google Cloud's core service for software supply chain security, ensuring only \"attested\" images can be deployed. This directly addresses the needs to \"prevent malicious code injection\" and \"ensure rigorous testing.\" Option (A) uses a public registry, which is insecure and lacks signing. Option (B)'s custom shell scripts and SSH signing are hard to manage at scale and prone to error (Operational Toil). Option (D)'s DNS switching is unsuitable for embedded vehicle software updates and guarantees nothing about the image security itself.",
        "wg": [
          { "t": "核心服務", "en": "core service", "ps": "noun" },
          { "t": "難以大規模管理", "en": "hard to manage at scale", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "7",
      "level": "hard",
      "keywords": "Cloud Storage, Autoclass, Cost Optimization, Lifecycle",
      "question": [
        {
          "t": "KnightMotives 的「數據變現」策略依賴於從數百萬輛車蒐集的影像與感測器數據。這些數據量將達到 PB 級別，且存取模式極難預測：有些數據用於即時 AI 訓練 (熱資料)，有些僅用於長期合規存檔 (冷資料)，但經常會被突發的分析需求喚醒。",
          "en": "KnightMotives' \"Data Monetization\" strategy relies on video and sensor data collected from millions of vehicles. The data volume will reach petabytes, and access patterns are highly unpredictable: some data is used for real-time AI training (Hot), some for long-term compliance (Cold), but is often reactivated by sudden analytics demands.",
          "wg": [
            { "t": "極難預測", "en": "highly unpredictable", "ps": "adjective" },
            { "t": "突發的", "en": "sudden", "ps": "adjective" },
            { "t": "喚醒", "en": "reactivated", "ps": "verb" }
          ]
        },
        {
          "t": "由於「投資新技術需要財務優先順序的轉變」，您必須極大化成本效益，同時避免因頻繁存取歸檔數據而產生高額的檢索費用 (Retrieval Fees)。",
          "en": "Since \"investment in new technology requires a shift in financial priorities,\" you must maximize cost-effectiveness while avoiding high retrieval fees caused by frequent access to archived data.",
          "wg": [
            { "t": "極大化", "en": "maximize", "ps": "verb" },
            { "t": "檢索費用", "en": "retrieval fees", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 將所有數據預設存入 Nearline Storage 類別。設定生命週期規則 (Lifecycle Rule)，在 30 天後將未存取的數據移至 Archive Storage。",
          "en": "(A) Default all data to the Nearline Storage class. Configure a Lifecycle Rule to move unaccessed data to Archive Storage after 30 days.",
          "wg": [
            { "t": "生命週期規則", "en": "Lifecycle Rule", "ps": "noun" },
            { "t": "未存取的", "en": "unaccessed", "ps": "adjective" }
          ]
        },
        {
          "t": "(B) 建立 Cloud Storage Bucket 並啟用 Autoclass 功能。這將自動根據最後存取時間在 Standard、Nearline、Coldline 與 Archive 類別間移動物件，且無檢索費用。",
          "en": "(B) Create a Cloud Storage Bucket and enable the Autoclass feature. This automatically moves objects between Standard, Nearline, Coldline, and Archive classes based on last access time, with no retrieval fees.",
          "wg": [
            { "t": "啟用", "en": "enable", "ps": "verb" },
            { "t": "無檢索費用", "en": "no retrieval fees", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 BigQuery Omni 直接在車輛上查詢數據，僅將查詢結果傳回 Google Cloud，從而完全避免儲存原始的大型影像檔案。",
          "en": "(C) Use BigQuery Omni to query data directly on the vehicles, transmitting only query results back to Google Cloud, thereby avoiding storing large raw video files entirely.",
          "wg": [
            { "t": "查詢", "en": "query", "ps": "verb" },
            { "t": "完全避免", "en": "avoiding ... entirely", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 將所有數據存入 Standard Storage 以確保效能，並購買承諾使用折扣 (Committed Use Discounts) 來抵銷儲存成本。",
          "en": "(D) Store all data in Standard Storage to ensure performance, and purchase Committed Use Discounts to offset storage costs.",
          "wg": [
            { "t": "承諾使用折扣", "en": "Committed Use Discounts", "ps": "noun" },
            { "t": "抵銷", "en": "offset", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Autoclass 是針對「存取模式不可預測」的最佳解決方案。它會自動管理分層，最重要的是，Autoclass 移除了檢索費用 (Retrieval Fees) 與提早刪除費用，這對於「經常被突發需求喚醒」的場景至關重要。選項 (A) 的 Archive Storage 有高額的檢索費，若數據被重新讀取，成本會暴增。選項 (C) 不切實際，車輛不具備 BigQuery Omni 的運算環境且原始數據需要用於訓練。選項 (D) 將冷數據放在 Standard 儲存極其浪費，CUD 無法彌補儲存類別錯誤帶來的巨大價差。",
        "en": "Autoclass is the optimal solution for \"unpredictable access patterns.\" It manages tiering automatically and, crucially, removes retrieval and early deletion fees, which is vital for scenarios where data is \"often reactivated by sudden demands.\" Option (A)'s Archive Storage incurs high retrieval fees; costs would skyrocket if data is read again. Option (C) is impractical; vehicles lack the compute environment for BigQuery Omni, and raw data is needed for training. Option (D) involves extreme waste by keeping cold data in Standard storage; CUDs cannot bridge the massive price gap of incorrect storage classes.",
        "wg": [
          { "t": "最佳解決方案", "en": "optimal solution", "ps": "noun" },
          { "t": "成本暴增", "en": "costs would skyrocket", "ps": "verb" },
          { "t": "不切實際", "en": "impractical", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "8",
      "level": "hard",
      "keywords": "Cloud Armor, DDoS, Security, Load Balancing",
      "question": [
        {
          "t": "KnightMotives 正在重構其「線上訂購系統」，因為舊系統不可靠且對經銷商造成困擾。新系統將允許全球客戶在線上客製化車輛。",
          "en": "KnightMotives is refactoring its \"online ordering system\" as the old one was unreliable and caused strain for dealers. The new system will allow global customers to customize vehicles online.",
          "wg": [
            { "t": "重構", "en": "refactoring", "ps": "verb" },
            { "t": "困擾", "en": "strain", "ps": "noun" },
            { "t": "客製化", "en": "customize", "ps": "verb" }
          ]
        },
        {
          "t": "鑑於「過去的數據洩露」以及近期針對公開網站的 DDoS 攻擊增加，資安長 (CISO) 要求必須在應用層 (Layer 7) 防禦 SQL 注入 (SQLi) 與跨站腳本攻擊 (XSS)，同時還要能區分人類用戶與自動化機器人 (Bots)，以防止黃牛搶購熱門車款。",
          "en": "Given \"past data breaches\" and a recent increase in DDoS attacks on public sites, the CISO mandates Layer 7 protection against SQL injection (SQLi) and Cross-Site Scripting (XSS), while also distinguishing between human users and automated bots to prevent scalpers from snapping up popular car models.",
          "wg": [
            { "t": "資安長", "en": "CISO", "ps": "noun" },
            { "t": "黃牛", "en": "scalpers", "ps": "noun" },
            { "t": "搶購", "en": "snapping up", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 在全域外部 HTTP(S) 負載平衡器後端部署 Compute Engine，並在虛擬機上安裝 ModSecurity WAF 模組。設定防火牆規則僅允許負載平衡器的 IP 存取。",
          "en": "(A) Deploy Compute Engine behind a Global External HTTP(S) Load Balancer and install the ModSecurity WAF module on the VMs. Configure firewall rules to allow access only from the Load Balancer's IP.",
          "wg": [
            { "t": "安裝", "en": "install", "ps": "verb" },
            { "t": "防火牆規則", "en": "firewall rules", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 部署全域外部 HTTP(S) 負載平衡器，並啟用 Cloud Armor 安全政策。配置預定義的 WAF 規則以阻擋 SQLi/XSS，並整合 reCAPTCHA Enterprise 以識別並攔截機器人流量。",
          "en": "(B) Deploy a Global External HTTP(S) Load Balancer and enable Cloud Armor security policies. Configure predefined WAF rules to block SQLi/XSS and integrate reCAPTCHA Enterprise to identify and intercept bot traffic.",
          "wg": [
            { "t": "安全政策", "en": "security policies", "ps": "noun" },
            { "t": "攔截", "en": "intercept", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 使用 Cloud CDN 快取靜態內容以減緩 DDoS 攻擊，並在應用程式程式碼中實作輸入驗證邏輯來防禦 SQL 注入。使用 Google Analytics 分析異常流量。",
          "en": "(C) Use Cloud CDN to cache static content to mitigate DDoS attacks, and implement input validation logic in the application code to defend against SQL injection. Use Google Analytics to analyze anomalous traffic.",
          "wg": [
            { "t": "快取", "en": "cache", "ps": "verb" },
            { "t": "輸入驗證邏輯", "en": "input validation logic", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 實施 VPC Service Controls 建立服務邊界，將負載平衡器與後端服務納入保護範圍，確保只有來自特定地理區域 (Geo-blocking) 的流量可以進入。",
          "en": "(D) Implement VPC Service Controls to create a service perimeter, including the load balancer and backend services, ensuring only traffic from specific geographic regions (Geo-blocking) can enter.",
          "wg": [
            { "t": "服務邊界", "en": "service perimeter", "ps": "noun" },
            { "t": "納入保護範圍", "en": "including ... in protection", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Cloud Armor 是 Google Cloud 的全代管 WAF 與 DDoS 防禦服務，能直接在邊緣 (Edge) 阻擋 L7 攻擊 (SQLi/XSS)。整合 reCAPTCHA Enterprise 是區分「人類與機器人」的最佳實踐，能有效防止自動化搶購 (Scalping)。選項 (A) 需要自行管理 WAF (ModSecurity)，違背了「現代化」與減少維運的目標。選項 (C) 依賴程式碼層級防禦與 CDN，不足以應對複雜的 Bot 攻擊。選項 (D) VPC SC 用於防止資料外洩 (Exfiltration)，而非防禦外部的入站攻擊 (Ingress Attacks)。",
        "en": "Cloud Armor is Google Cloud's fully managed WAF and DDoS protection service, blocking L7 attacks (SQLi/XSS) at the edge. Integrating reCAPTCHA Enterprise is the best practice for distinguishing \"humans from bots,\" effectively preventing automated scalping. Option (A) requires self-managed WAF (ModSecurity), contradicting the goals of \"modernization\" and reducing toil. Option (C) relies on code-level defenses and CDN, which are insufficient against sophisticated bot attacks. Option (D) VPC SC is for preventing data exfiltration, not for defending against external ingress attacks.",
        "wg": [
          { "t": "全代管", "en": "fully managed", "ps": "adjective" },
          { "t": "最佳實踐", "en": "best practice", "ps": "noun" },
          { "t": "資料外洩", "en": "data exfiltration", "ps": "noun" }
        ]
      }
    },
    {
      "no": "9",
      "level": "hard",
      "keywords": "Vertex AI, Cost Management, Spot VMs, Checkpointing",
      "question": [
        {
          "t": "KnightMotives 需要為其自動駕駛車輛建立一個「強大的模擬環境」(Robust Simulation Environment)。這需要執行數萬個平行運算作業來模擬各種路況與天氣。",
          "en": "KnightMotives needs to build a \"robust simulation environment\" for its autonomous vehicles. This requires running tens of thousands of parallel computing jobs to simulate various road conditions and weather.",
          "wg": [
            { "t": "強大的模擬環境", "en": "robust simulation environment", "ps": "noun" },
            { "t": "平行運算作業", "en": "parallel computing jobs", "ps": "noun" }
          ]
        },
        {
          "t": "這些模擬作業是無狀態 (Stateless) 的，且可容忍中斷。為了達成「全球規模的財務優先順序轉變」，您必須將運算成本降至最低。您應選擇哪兩項架構決策？（請選擇兩項）",
          "en": "These simulation jobs are stateless and fault-tolerant. To achieve a \"shift in financial priorities on a global scale,\" you must minimize compute costs. Which two architectural decisions should you make? (Choose two)",
          "wg": [
            { "t": "無狀態", "en": "Stateless", "ps": "adjective" },
            { "t": "可容忍中斷", "en": "fault-tolerant", "ps": "adjective" },
            { "t": "成本降至最低", "en": "minimize compute costs", "ps": "verb" }
          ]
        }
      ],
      "type": "複選題",
      "options": [
        {
          "t": "(A) 使用 Compute Engine 的 Spot VMs (或 Preemptible VMs) 來執行模擬工作負載。",
          "en": "(A) Use Compute Engine Spot VMs (or Preemptible VMs) to run the simulation workloads.",
          "wg": [
            { "t": "模擬工作負載", "en": "simulation workloads", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 為所有虛擬機購買 3 年期的承諾使用折扣 (CUD)，以鎖定最低費率。",
          "en": "(B) Purchase 3-year Committed Use Discounts (CUD) for all virtual machines to lock in the lowest rates.",
          "wg": [
            { "t": "鎖定", "en": "lock in", "ps": "verb" },
            { "t": "最低費率", "en": "lowest rates", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Cloud Spanner 作為模擬數據的暫存資料庫，以確保全球一致性。",
          "en": "(C) Use Cloud Spanner as a temporary database for simulation data to ensure global consistency.",
          "wg": [
            { "t": "暫存資料庫", "en": "temporary database", "ps": "noun" },
            { "t": "全球一致性", "en": "global consistency", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 採用 Google Kubernetes Engine (GKE) 搭配 Cluster Autoscaler，並設定節點池使用 Spot 執行個體。",
          "en": "(D) Adopt Google Kubernetes Engine (GKE) with Cluster Autoscaler, configuring node pools to use Spot instances.",
          "wg": [
            { "t": "節點池", "en": "node pools", "ps": "noun" },
            { "t": "執行個體", "en": "instances", "ps": "noun" }
          ]
        },
        {
          "t": "(E) 使用僅包含 SSD 永久磁碟 (Persistent Disk) 的高效能機器類型，以縮短模擬時間。",
          "en": "(E) Use high-performance machine types with SSD Persistent Disks exclusively to reduce simulation time.",
          "wg": [
            { "t": "高效能", "en": "high-performance", "ps": "adjective" },
            { "t": "縮短", "en": "reduce", "ps": "verb" }
          ]
        }
      ],
      "answer": "(A), (D)",
      "why": {
        "t": "Spot VMs (A) 提供比標準 VM 低 60-91% 的價格，非常適合「無狀態且可容忍中斷」的大規模批次作業。結合 GKE 與 Autoscaler (D) 可以自動管理這些 Spot 節點的生命週期，當 Spot 被收回時自動請求新節點，大幅降低維運負擔並優化成本。選項 (B) CUD 雖然省錢，但折扣幅度不如 Spot VMs，且缺乏彈性。選項 (C) Spanner 對於暫存模擬數據來說太過昂貴且效能過剩 (Overkill)。選項 (E) 使用 SSD 與高效能機器會顯著增加成本，違反財務目標。",
        "en": "Spot VMs (A) offer 60-91% lower prices than standard VMs, making them ideal for \"stateless and fault-tolerant\" massive batch jobs. Combining this with GKE and Autoscaler (D) allows automatic lifecycle management of these Spot nodes—requesting new ones when reclaimed—significantly reducing operational toil and optimizing costs. Option (B) CUD saves money but less than Spot VMs and lacks flexibility. Option (C) Spanner is too expensive and overkill for temporary simulation data. Option (E) using SSDs and high-performance machines would significantly increase costs, violating financial goals.",
        "wg": [
          { "t": "生命週期", "en": "lifecycle", "ps": "noun" },
          { "t": "效能過剩", "en": "Overkill", "ps": "noun" },
          { "t": "違反", "en": "violating", "ps": "verb" }
        ]
      }
    },
    {
      "no": "10",
      "level": "hard",
      "keywords": "Cloud Spanner, Global Consistency, Supply Chain, Reliability",
      "question": [
        {
          "t": "KnightMotives 的「線上訂購系統」與供應鏈目前面臨數據不同步的問題，導致經銷商無法獲得即時的庫存資訊。目標是建立一個全球統一的庫存管理系統，支援高併發讀寫 (High throughput)。",
          "en": "KnightMotives' \"online ordering system\" and supply chain currently face data synchronization issues, preventing dealers from accessing real-time inventory information. The goal is to build a globally unified inventory management system supporting high throughput.",
          "wg": [
            { "t": "不同步", "en": "synchronization issues", "ps": "noun" },
            { "t": "即時的", "en": "real-time", "ps": "adjective" },
            { "t": "高併發讀寫", "en": "High throughput", "ps": "noun" }
          ]
        },
        {
          "t": "該資料庫必須具備 99.999% 的可用性，並能在美洲、歐洲與亞太地區之間提供強一致性 (Strong Consistency)，以確保不會發生超賣情況。這對於修復與經銷商的緊張關係至關重要。",
          "en": "The database must offer 99.999% availability and provide Strong Consistency across the Americas, Europe, and APAC regions to ensure no overselling occurs. This is critical for repairing strained relationships with dealers.",
          "wg": [
            { "t": "強一致性", "en": "Strong Consistency", "ps": "noun" },
            { "t": "超賣", "en": "overselling", "ps": "verb" },
            { "t": "緊張關係", "en": "strained relationships", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud SQL for PostgreSQL 並配置多個跨區域唯讀複本 (Read Replicas)。應用程式將寫入主節點，並從最近的複本讀取庫存。",
          "en": "(A) Use Cloud SQL for PostgreSQL configured with multiple cross-region Read Replicas. Applications write to the primary node and read inventory from the nearest replica.",
          "wg": [
            { "t": "唯讀複本", "en": "Read Replicas", "ps": "noun" },
            { "t": "主節點", "en": "primary node", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 部署 Cloud Bigtable，設計 Row Key 以包含地區代碼。這能提供極高的寫入吞吐量與低延遲，適合全球庫存更新。",
          "en": "(B) Deploy Cloud Bigtable, designing Row Keys to include region codes. This offers extremely high write throughput and low latency, suitable for global inventory updates.",
          "wg": [
            { "t": "寫入吞吐量", "en": "write throughput", "ps": "noun" },
            { "t": "低延遲", "en": "low latency", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用配置為多重地區 (Multi-region) 的 Cloud Spanner。這提供了全球規模的關聯式資料庫功能、水平擴展能力以及符合 ACID 的強一致性交易。",
          "en": "(C) Use Cloud Spanner configured as Multi-region. This provides global-scale relational database capabilities, horizontal scalability, and ACID-compliant strong consistency transactions.",
          "wg": [
            { "t": "關聯式資料庫", "en": "relational database", "ps": "noun" },
            { "t": "水平擴展", "en": "horizontal scalability", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 使用 Firestore 在 Datastore 模式下運作，並啟用多重地區複寫。這能提供良好的行動裝置支援與即時更新功能。",
          "en": "(D) Use Firestore running in Datastore mode enabled with multi-region replication. This offers good mobile support and real-time update capabilities.",
          "wg": [
            { "t": "多重地區複寫", "en": "multi-region replication", "ps": "noun" },
            { "t": "即時更新", "en": "real-time update", "ps": "noun" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "Cloud Spanner 是 Google Cloud 中唯一能同時提供「全球強一致性 (Global Strong Consistency)」與「99.999% 可用性」的關聯式資料庫。這對於庫存系統至關重要，因為它必須防止跨大陸的超賣問題 (需要 ACID 交易)。選項 (A) Cloud SQL 的跨區域複本是「最終一致性 (Eventual Consistency)」，讀取複本可能會讀到舊數據導致超賣。選項 (B) Bigtable 雖然吞吐量高，但不支援跨列交易 (Multi-row transactions) 且缺乏 SQL 查詢能力，不適合複雜的庫存管理。選項 (D) Firestore 雖然支援 ACID，但在全球寫入吞吐量與關聯式查詢能力上不如 Spanner。",
        "en": "Cloud Spanner is the only database in Google Cloud offering both \"Global Strong Consistency\" and \"99.999% availability\" as a relational database. This is critical for inventory systems to prevent cross-continental overselling (requiring ACID transactions). Option (A) Cloud SQL's cross-region replicas are \"eventually consistent,\" meaning reads might return stale data, leading to overselling. Option (B) Bigtable has high throughput but lacks multi-row transactions and SQL query capabilities, making it unsuitable for complex inventory management. Option (D) Firestore, while supporting ACID, falls short of Spanner in global write throughput and relational query capabilities.",
        "wg": [
          { "t": "最終一致性", "en": "Eventual Consistency", "ps": "noun" },
          { "t": "舊數據", "en": "stale data", "ps": "noun" }
        ]
      }
    },
    {
      "no": "11",
      "level": "hard",
      "keywords": "Cloud Operations, Hybrid, Observability, Prometheus",
      "question": [
        {
          "t": "KnightMotives 的 IT 團隊面臨嚴重的維運負擔，因為他們必須同時監控位於地端資料中心的舊有應用程式，以及部署在 Google Cloud GKE 上的新微服務。",
          "en": "KnightMotives' IT team faces significant operational toil as they must simultaneously monitor legacy applications in on-premises data centers and new microservices deployed on Google Cloud GKE.",
          "wg": [
            { "t": "維運負擔", "en": "operational toil", "ps": "noun" },
            { "t": "微服務", "en": "microservices", "ps": "noun" }
          ]
        },
        {
          "t": "新任技術長要求實施「單一玻璃窗」(Single Pane of Glass) 監控策略，將所有指標 (Metrics) 與日誌 (Logs) 集中到 Google Cloud Operations 中。該方案必須支援既有的 Prometheus 指標格式，且不需大幅修改現有程式碼。",
          "en": "The new CTO demands a \"Single Pane of Glass\" monitoring strategy, centralizing all metrics and logs into Google Cloud Operations. The solution must support existing Prometheus metric formats without requiring significant code changes.",
          "wg": [
            { "t": "單一玻璃窗", "en": "Single Pane of Glass", "ps": "noun" },
            { "t": "集中", "en": "centralizing", "ps": "verb" },
            { "t": "大幅修改", "en": "significant changes", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 在地端伺服器安裝 Ops Agent，並在 GKE 叢集中部署 Managed Service for Prometheus。使用 Cloud Monitoring 儀表板統一視覺化所有數據。",
          "en": "(A) Install the Ops Agent on on-premises servers and deploy Managed Service for Prometheus in GKE clusters. Use Cloud Monitoring dashboards to unify visualization of all data.",
          "wg": [
            { "t": "儀表板", "en": "dashboards", "ps": "noun" },
            { "t": "統一視覺化", "en": "unify visualization", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 設定 Cloud VPN 將地端 Prometheus 伺服器連接至 Google Cloud，並使用 Cloud Monitoring API 編寫自定義腳本將數據匯入 Stackdriver。",
          "en": "(B) Configure Cloud VPN to connect on-premises Prometheus servers to Google Cloud, and use custom scripts with the Cloud Monitoring API to import data into Stackdriver.",
          "wg": [
            { "t": "自定義腳本", "en": "custom scripts", "ps": "noun" },
            { "t": "匯入", "en": "import", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 將所有應用程式日誌導向 Fluentd，並配置 Fluentd 輸出插件將數據寫入 BigQuery。使用 Looker Studio 建立統一的監控報表。",
          "en": "(C) Direct all application logs to Fluentd and configure the Fluentd output plugin to write data to BigQuery. Use Looker Studio to build unified monitoring reports.",
          "wg": [
            { "t": "輸出插件", "en": "output plugin", "ps": "noun" },
            { "t": "監控報表", "en": "monitoring reports", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 在地端與雲端環境分別部署 Grafana 執行個體，並設定 Grafana Federation 以聚合兩個環境的指標。",
          "en": "(D) Deploy Grafana instances in both on-premises and cloud environments, and configure Grafana Federation to aggregate metrics from both environments.",
          "wg": [
            { "t": "執行個體", "en": "instances", "ps": "noun" },
            { "t": "聚合", "en": "aggregate", "ps": "verb" }
          ]
        }
      ],
      "answer": "(A)",
      "why": {
        "t": "Google Cloud Managed Service for Prometheus 是針對 Kubernetes (GKE) 監控的最佳實踐，能直接讀取 Prometheus 指標並寫入 Cloud Monitoring，無需管理儲存後端。對於地端舊系統，Ops Agent 是標準解決方案，能蒐集系統指標與日誌並傳送至雲端。這兩者的結合實現了「單一玻璃窗」且維運負擔最小。選項 (B) 需要編寫與維護自定義腳本 (Toil)。選項 (C) 僅處理日誌且 BigQuery/Looker 不是即時監控工具。選項 (D) 雖然可行但並非使用 Google Cloud Native 工具，且增加了管理多個 Grafana 的負擔。",
        "en": "Google Cloud Managed Service for Prometheus is the best practice for Kubernetes (GKE) monitoring, scraping Prometheus metrics directly into Cloud Monitoring without managing storage backends. For on-prem legacy systems, the Ops Agent is the standard solution for collecting metrics and logs. Combining these achieves a \"Single Pane of Glass\" with minimal toil. Option (B) requires writing and maintaining custom scripts (Toil). Option (C) only handles logs, and BigQuery/Looker are not real-time monitoring tools. Option (D) is viable but not Google Cloud Native and increases the burden of managing multiple Grafana instances.",
        "wg": [
          { "t": "最佳實踐", "en": "best practice", "ps": "noun" },
          { "t": "即時監控工具", "en": "real-time monitoring tools", "ps": "noun" }
        ]
      }
    },
    {
      "no": "12",
      "level": "hard",
      "keywords": "Dataflow, Pub/Sub, Streaming, IoT",
      "question": [
        {
          "t": "為了實現「數據變現」並提升車輛安全性，KnightMotives 需要建立一個即時串流分析平台。數百萬輛車將每秒發送一次遙測數據。",
          "en": "To enable \"Data Monetization\" and enhance vehicle safety, KnightMotives needs to build a real-time streaming analytics platform. Millions of vehicles will transmit telemetry data every second.",
          "wg": [
            { "t": "即時串流分析", "en": "real-time streaming analytics", "ps": "noun" },
            { "t": "遙測數據", "en": "telemetry data", "ps": "noun" }
          ]
        },
        {
          "t": "系統必須能自動處理延遲到達的數據 (Late Data)，並同時達成兩個目標：1) 將所有原始數據存入 BigQuery 供資料科學家長期分析；2) 即時偵測危險駕駛行為並通知駕駛。您應建議哪種架構？",
          "en": "The system must automatically handle Late Data and achieve two goals simultaneously: 1) Store all raw data in BigQuery for long-term analysis by data scientists; 2) Detect dangerous driving behavior in real-time and notify the driver. Which architecture should you recommend?",
          "wg": [
            { "t": "延遲到達的數據", "en": "Late Data", "ps": "noun" },
            { "t": "偵測", "en": "Detect", "ps": "verb" },
            { "t": "通知", "en": "notify", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 讓車輛將數據發送至 IoT Core (MQTT)，並設定 Cloud Function 觸發器。函式將資料寫入 BigQuery，並呼叫 Firebase Cloud Messaging 發送警報。",
          "en": "(A) Have vehicles send data to IoT Core (MQTT) and configure a Cloud Function trigger. The function writes data to BigQuery and calls Firebase Cloud Messaging to send alerts.",
          "wg": [
            { "t": "觸發器", "en": "trigger", "ps": "noun" },
            { "t": "呼叫", "en": "calls", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 使用 Pub/Sub 接收數據，並建立 Dataflow 串流作業。Dataflow 管道分為兩條分支：一條將原始數據串流寫入 BigQuery，另一條使用視窗 (Windowing) 邏輯計算駕駛行為並將警報發佈到另一個 Pub/Sub 主題。",
          "en": "(B) Use Pub/Sub to ingest data and create a Dataflow streaming job. The Dataflow pipeline splits into two branches: one streams raw data into BigQuery, and the other uses Windowing logic to calculate driving behavior and publishes alerts to another Pub/Sub topic.",
          "wg": [
            { "t": "串流作業", "en": "streaming job", "ps": "noun" },
            { "t": "分支", "en": "branches", "ps": "noun" },
            { "t": "視窗邏輯", "en": "Windowing logic", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Dataproc 上的 Spark Streaming 叢集來處理數據。將數據批次寫入 HDFS 進行存儲，並使用 Spark SQL 進行即時查詢以產生警報。",
          "en": "(C) Use a Spark Streaming cluster on Dataproc to process data. Batch write data to HDFS for storage and use Spark SQL for real-time querying to generate alerts.",
          "wg": [
            { "t": "叢集", "en": "cluster", "ps": "noun" },
            { "t": "批次", "en": "Batch", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 直接將數據寫入 Bigtable。設定 BigQuery 透過 External Table 讀取 Bigtable 數據進行分析，並開發一個 App Engine 應用程式定期掃描 Bigtable 以發送警報。",
          "en": "(D) Write data directly to Bigtable. Configure BigQuery to read Bigtable data via External Table for analysis, and develop an App Engine application to periodically scan Bigtable to send alerts.",
          "wg": [
            { "t": "定期掃描", "en": "periodically scan", "ps": "verb" },
            { "t": "外部資料表", "en": "External Table", "ps": "noun" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Dataflow 是處理大規模串流數據、Watermark 處理與延遲數據 (Late Data) 的最佳託管服務。透過單一管道的多重輸出 (Branching)，可以同時滿足「低延遲警報」(Windowing/Aggregates) 與「完整數據歸檔」(BigQuery Streaming Insert) 的需求。選項 (A) Cloud Functions 不適合高吞吐量的狀態處理 (Stateful Processing) 與複雜視窗運算。選項 (C) Dataproc 需要管理叢集 (Toil) 且不如 Dataflow Serverless 彈性。選項 (D) 使用 App Engine 定期掃描 (Polling) 會有延遲，無法滿足「即時」警報的需求。",
        "en": "Dataflow is the premier managed service for handling large-scale streaming data, watermarks, and Late Data. Through pipeline branching, it can simultaneously meet the needs for \"low-latency alerting\" (Windowing/Aggregates) and \"full data archival\" (BigQuery Streaming Insert). Option (A) Cloud Functions are ill-suited for high-throughput stateful processing and complex windowing. Option (C) Dataproc requires cluster management (Toil) and lacks Dataflow's serverless elasticity. Option (D) using App Engine for periodic scanning (Polling) introduces latency, failing the \"real-time\" requirement.",
        "wg": [
          { "t": "最佳託管服務", "en": "premier managed service", "ps": "noun" },
          { "t": "狀態處理", "en": "Stateful Processing", "ps": "noun" },
          { "t": "彈性", "en": "elasticity", "ps": "noun" }
        ]
      }
    },
    {
      "no": "13",
      "level": "hard",
      "keywords": "Org Policy, Security, Hierarchy, IAM",
      "question": [
        {
          "t": "KnightMotives 擁有多個專案團隊，包括自動駕駛研發、經銷商入口網站與企業 IT。為了加強安全性，資安團隊希望強制執行一項全域策略：除了特定的 DMZ (非軍事區) 專案外，任何專案中的虛擬機都不得分配外部公開 IP 位址 (Public IPs)。",
          "en": "KnightMotives has multiple project teams, including AV R&D, Dealer Portal, and Enterprise IT. To enhance security, the security team wants to enforce a global policy: no virtual machines in any project should be assigned external Public IPs, except for specific DMZ projects.",
          "wg": [
            { "t": "全域策略", "en": "global policy", "ps": "noun" },
            { "t": "非軍事區", "en": "DMZ", "ps": "noun" },
            { "t": "外部公開 IP 位址", "en": "external Public IPs", "ps": "noun" }
          ]
        },
        {
          "t": "您需要設計一個資源階層架構與控制機制，以最少的維護工作量達成此目標，並確保未來新增的專案也能自動繼承此限制。",
          "en": "You need to design a resource hierarchy and control mechanism to achieve this goal with minimal maintenance effort, ensuring that future projects automatically inherit this restriction.",
          "wg": [
            { "t": "資源階層架構", "en": "resource hierarchy", "ps": "noun" },
            { "t": "自動繼承", "en": "automatically inherit", "ps": "verb" },
            { "t": "限制", "en": "restriction", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 建立一個自訂 IAM 角色，移除 `compute.instances.create` 權限，並將此角色指派給組織層級的所有開發者。",
          "en": "(A) Create a custom IAM role, removing the `compute.instances.create` permission, and assign this role to all developers at the Organization level.",
          "wg": [
            { "t": "自訂 IAM 角色", "en": "custom IAM role", "ps": "noun" },
            { "t": "指派", "en": "assign", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 在組織層級設定組織政策 (Organization Policy)，啟用 `compute.vmExternalIpAccess` 限制並設定為「拒絕所有」。針對 DMZ 專案所在的資料夾，設定該政策為「允許」並列出特定的 VM 執行個體。",
          "en": "(B) Configure an Organization Policy at the Organization level, enabling the `compute.vmExternalIpAccess` constraint and setting it to \"Deny All\". For the folder containing DMZ projects, override the policy to \"Allow\" and list specific VM instances.",
          "wg": [
            { "t": "組織政策", "en": "Organization Policy", "ps": "noun" },
            { "t": "覆寫", "en": "override", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 使用 Shared VPC 架構。在 Host Project 中設定防火牆規則，拒絕所有來自外部 0.0.0.0/0 的入站流量，並強制所有 Service Project 使用此網路。",
          "en": "(C) Use a Shared VPC architecture. Configure firewall rules in the Host Project to deny all inbound traffic from external 0.0.0.0/0, and mandate all Service Projects use this network.",
          "wg": [
            { "t": "入站流量", "en": "inbound traffic", "ps": "noun" },
            { "t": "強制", "en": "mandate", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 編寫一個 Cloud Function，監聽所有資源建立的日誌 (Log Sink)。當偵測到有 VM 被建立且帶有外部 IP 時，立即呼叫 API 刪除該 VM。",
          "en": "(D) Write a Cloud Function that listens to log sinks for resource creation. When a VM creation with an external IP is detected, immediately call the API to delete that VM.",
          "wg": [
            { "t": "監聽", "en": "listens to", "ps": "verb" },
            { "t": "偵測到", "en": "detected", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "組織政策 (Organization Policy) 是控制資源配置屬性（如是否允許外部 IP）的正確工具。透過在組織層級設定「預設拒絕」，所有新專案都會自動繼承此安全設定，滿足「自動繼承」需求。針對例外 (DMZ)，可以在資料夾層級進行覆寫 (Override)。選項 (A) IAM 只能控制「誰」可以建立 VM，無法細緻控制 VM 的「屬性配置」（如是否有 IP）。選項 (C) 防火牆僅阻擋流量，無法阻止開發者「分配」IP 位址，且無法防止資料外洩 (Egress)。選項 (D) 是被動的補救措施 (Remediation)，會有時間差且增加維運複雜度，不如預防性的政策有效。",
        "en": "Organization Policy is the correct tool for controlling resource configuration properties (like allowing external IPs). By setting \"Deny All\" at the Organization level, all new projects automatically inherit this security posture, meeting the \"automatic inheritance\" requirement. Exceptions (DMZ) can be handled via folder-level overrides. Option (A) IAM only controls \"who\" can create VMs, not the \"configuration attributes\" (like having an IP). Option (C) Firewalls block traffic but don't prevent the \"assignment\" of IPs, nor do they fully stop egress. Option (D) is reactive remediation, introducing latency and complexity, and is less effective than preventive policies.",
        "wg": [
          { "t": "屬性配置", "en": "configuration attributes", "ps": "noun" },
          { "t": "補救措施", "en": "remediation", "ps": "noun" },
          { "t": "預防性的", "en": "preventive", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "14",
      "level": "hard",
      "keywords": "Secret Manager, Security, DevSecOps, IAM",
      "question": [
        {
          "t": "KnightMotives 的「現代化經銷商工具」應用程式部署在 GKE 上，需要存取多個敏感後端服務，包括資料庫與第三方 API。目前的憑證與 API 金鑰以明文形式儲存在環境變數中，這違反了安全性最佳實務。",
          "en": "KnightMotives' \"modern dealer tools\" application, deployed on GKE, needs to access multiple sensitive backend services, including databases and third-party APIs. Current credentials and API keys are stored in plaintext environment variables, violating security best practices.",
          "wg": [
            { "t": "敏感後端服務", "en": "sensitive backend services", "ps": "noun" },
            { "t": "明文形式", "en": "plaintext", "ps": "adjective" },
            { "t": "違反", "en": "violating", "ps": "verb" }
          ]
        },
        {
          "t": "您需要實施一個新的解決方案來管理這些機密資訊 (Secrets)，要求必須支援定期自動輪替 (Rotation)、版本控制，並能精確控制哪些微服務可以存取哪些金鑰。",
          "en": "You need to implement a new solution to manage these secrets, requiring support for periodic automatic rotation, versioning, and granular control over which microservices can access which keys.",
          "wg": [
            { "t": "定期自動輪替", "en": "periodic automatic rotation", "ps": "noun" },
            { "t": "版本控制", "en": "versioning", "ps": "noun" },
            { "t": "精確控制", "en": "granular control", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud KMS 加密金鑰，將加密後的字串儲存在 Kubernetes Secrets 中。應用程式啟動時使用 KMS API 解密。",
          "en": "(A) Use Cloud KMS to encrypt keys and store the encrypted strings in Kubernetes Secrets. Applications decrypt them using the KMS API at startup.",
          "wg": [
            { "t": "加密", "en": "encrypt", "ps": "verb" },
            { "t": "解密", "en": "decrypt", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 部署 Secret Manager，將所有憑證儲存為 Secrets。使用 Workload Identity 授權 GKE Pods 透過 API 存取特定的 Secret 版本。設定 Cloud Functions 來處理自動輪替邏輯。",
          "en": "(B) Deploy Secret Manager and store all credentials as Secrets. Use Workload Identity to authorize GKE Pods to access specific Secret versions via API. Configure Cloud Functions to handle automatic rotation logic.",
          "wg": [
            { "t": "授權", "en": "authorize", "ps": "verb" },
            { "t": "自動輪替邏輯", "en": "automatic rotation logic", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 將憑證儲存在私有的 Cloud Source Repositories 儲存庫中，並使用 Git-crypt 進行加密。在 CI/CD 流程中解密並注入到容器映像檔中。",
          "en": "(C) Store credentials in a private Cloud Source Repositories repo, encrypted using Git-crypt. Decrypt and inject them into container images during the CI/CD pipeline.",
          "wg": [
            { "t": "儲存庫", "en": "repo", "ps": "noun" },
            { "t": "注入", "en": "inject", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 使用 Cloud SQL 的 IAM 資料庫驗證功能取代所有密碼，並針對第三方 API 使用 Cloud Endpoints 作為代理，將金鑰硬編碼在 Endpoints 配置中。",
          "en": "(D) Use Cloud SQL IAM database authentication to replace all passwords, and use Cloud Endpoints as a proxy for third-party APIs, hardcoding keys in the Endpoints configuration.",
          "wg": [
            { "t": "驗證", "en": "authentication", "ps": "noun" },
            { "t": "硬編碼", "en": "hardcoding", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Secret Manager 是 Google Cloud 專門用於儲存、管理與存取 API 金鑰、密碼等機密資料的服務。它原生支援版本控制、細緻的 IAM 權限 (配合 Workload Identity 可精確到 Pod 層級) 以及透過整合 Cloud Functions 進行自動輪替。選項 (A) 使用 Cloud KMS 雖然安全，但 KMS 主要負責「加解密」而非「機密儲存與生命週期管理」，實作輪替會很複雜。選項 (C) 將金鑰注入映像檔是最差實踐，因為金鑰變更需要重新建置映像檔。選項 (D) 雖然 IAM DB Auth 很好，但無法解決第三方 API 金鑰的問題，且硬編碼配置同樣難以輪替。",
        "en": "Secret Manager is the dedicated Google Cloud service for storing, managing, and accessing secrets like API keys and passwords. It natively supports versioning, granular IAM permissions (down to the Pod level with Workload Identity), and automatic rotation via Cloud Functions integration. Option (A) using Cloud KMS is secure but KMS focuses on \"encryption/decryption\" rather than \"secret storage and lifecycle management,\" making rotation complex. Option (C) injecting keys into images is a worst practice, requiring image rebuilds for key changes. Option (D) while IAM DB Auth is good, it doesn't solve third-party API key issues, and hardcoding configs makes rotation difficult.",
        "wg": [
          { "t": "原生支援", "en": "natively supports", "ps": "verb" },
          { "t": "最差實踐", "en": "worst practice", "ps": "noun" },
          { "t": "生命週期管理", "en": "lifecycle management", "ps": "noun" }
        ]
      }
    },
    {
      "no": "15",
      "level": "hard",
      "keywords": "Private Google Access, Hybrid, Interconnect, Storage",
      "question": [
        {
          "t": "KnightMotives 位於農村地區的工廠已透過 Partner Interconnect 連接至 Google Cloud VPC。工廠內的伺服器需要將大量生產日誌上傳至 Cloud Storage 進行歸檔。",
          "en": "KnightMotives' manufacturing plants in rural areas are connected to Google Cloud VPC via Partner Interconnect. Servers inside the plants need to upload massive production logs to Cloud Storage for archiving.",
          "wg": [
            { "t": "生產日誌", "en": "production logs", "ps": "noun" },
            { "t": "歸檔", "en": "archiving", "ps": "noun" }
          ]
        },
        {
          "t": "由於資安政策禁止這些工廠伺服器擁有任何公開的網際網路存取權限 (No Internet Access)，且傳輸過程必須經過私有線路。您需要配置網路以允許這些地端主機存取 Cloud Storage API。應採取哪兩個步驟？（請選擇兩項）",
          "en": "Security policy prohibits these plant servers from having any public Internet access, and transmission must traverse private lines. You need to configure the network to allow these on-premises hosts to access Cloud Storage APIs. Which two steps should you take? (Choose two)",
          "wg": [
            { "t": "公開的網際網路存取權限", "en": "public Internet access", "ps": "noun" },
            { "t": "私有線路", "en": "private lines", "ps": "noun" }
          ]
        }
      ],
      "type": "複選題",
      "options": [
        {
          "t": "(A) 在 VPC 的子網路上啟用「私人 Google 存取權」(Private Google Access)。",
          "en": "(A) Enable \"Private Google Access\" on the VPC subnet.",
          "wg": [
            { "t": "子網路", "en": "subnet", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 設定地端 DNS 伺服器，將 `*.googleapis.com` 解析為 `private.googleapis.com` 的虛擬 IP (VIP) 範圍 (199.36.153.8/30)。",
          "en": "(B) Configure on-premises DNS servers to resolve `*.googleapis.com` to the Virtual IP (VIP) range of `private.googleapis.com` (199.36.153.8/30).",
          "wg": [
            { "t": "解析", "en": "resolve", "ps": "verb" },
            { "t": "虛擬 IP", "en": "Virtual IP (VIP)", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 在 Cloud Router 上設定自訂路由廣播 (Custom Route Advertisement)，將 `private.googleapis.com` 的 IP 範圍廣播至地端網路。",
          "en": "(C) Configure Custom Route Advertisement on the Cloud Router to advertise the IP range of `private.googleapis.com` to the on-premises network.",
          "wg": [
            { "t": "自訂路由廣播", "en": "Custom Route Advertisement", "ps": "noun" },
            { "t": "廣播", "en": "advertise", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 為每個工廠伺服器配置 Cloud NAT 閘道，以允許透過 NAT IP 存取 Google APIs。",
          "en": "(D) Configure a Cloud NAT gateway for each plant server to allow access to Google APIs via NAT IPs.",
          "wg": [
            { "t": "閘道", "en": "gateway", "ps": "noun" }
          ]
        },
        {
          "t": "(E) 在 VPC 中建立 VPC Service Controls 服務邊界，並將 Cloud Storage API 加入受保護的服務清單中。",
          "en": "(E) Create a VPC Service Controls perimeter in the VPC and add the Cloud Storage API to the list of protected services.",
          "wg": [
            { "t": "服務邊界", "en": "perimeter", "ps": "noun" },
            { "t": "受保護的", "en": "protected", "ps": "adjective" }
          ]
        }
      ],
      "answer": "(B), (C)",
      "why": {
        "t": "要讓地端主機 (On-Prem Hosts) 透過 Interconnect 私有連線存取 Google API，必須實施「地端主機的私人 Google 存取權」(Private Google Access for On-Premises Hosts)。這包含兩個關鍵步驟：1) DNS 設定 (B)：將 API 網域名稱解析為 Google 的私有 VIP (如 `private.googleapis.com`)；2) 路由廣播 (C)：透過 Cloud Router 將這些 VIP 的路由廣播回地端，確保流量走 Interconnect 而非網際網路。選項 (A) 僅適用於 VPC 內的 VM，不適用於地端主機。選項 (D) Cloud NAT 需要網際網路出口，違反「禁止網際網路存取」且不走私有線路。選項 (E) 是資料保護機制，非連線機制。",
        "en": "To allow On-Prem Hosts to access Google APIs via private Interconnect, you must implement \"Private Google Access for On-Premises Hosts.\" This involves two key steps: 1) DNS Configuration (B): Resolve API domains to Google's private VIPs (e.g., `private.googleapis.com`); 2) Route Advertisement (C): Advertise the routes for these VIPs back to on-prem via Cloud Router, ensuring traffic traverses the Interconnect, not the internet. Option (A) is for VMs *inside* the VPC, not on-prem hosts. Option (D) Cloud NAT requires internet egress, violating \"No Internet Access\" and private line requirements. Option (E) is a data protection mechanism, not a connectivity mechanism.",
        "wg": [
          { "t": "解析", "en": "Resolve", "ps": "verb" },
          { "t": "路由廣播", "en": "Route Advertisement", "ps": "noun" },
          { "t": "出口", "en": "egress", "ps": "noun" }
        ]
      }
    },
    {
      "no": "16",
      "level": "hard",
      "keywords": "Confidential Computing, GKE, Security, Encryption",
      "question": [
        {
          "t": "KnightMotives 的自動駕駛演算法涉及高度敏感的商業機密，且包含歐盟公民的駕駛行為數據。雖然運算負載極大，需要 Google Cloud 的彈性算力，但公司法務部門擔心雲端供應商可能會有權限存取記憶體中的明文數據。",
          "en": "KnightMotives' autonomous driving algorithms involve highly sensitive trade secrets and contain driving behavior data of EU citizens. Although the compute load is massive and requires Google Cloud's elasticity, the legal department is concerned that the cloud provider might have access to plaintext data in memory.",
          "wg": [
            { "t": "商業機密", "en": "trade secrets", "ps": "noun" },
            { "t": "彈性算力", "en": "elasticity", "ps": "noun" },
            { "t": "記憶體中", "en": "in memory", "ps": "noun" }
          ]
        },
        {
          "t": "您需要設計一個 GKE 架構來處理這些工作負載，確保即使是 Google 的系統管理員或底層 Hypervisor 也無法讀取處理中的數據。這項解決方案必須對現有容器應用程式的程式碼更動最小。",
          "en": "You need to design a GKE architecture to process these workloads, ensuring that even Google system administrators or the underlying Hypervisor cannot read the data during processing. This solution must require minimal code changes to existing container applications.",
          "wg": [
            { "t": "系統管理員", "en": "system administrators", "ps": "noun" },
            { "t": "程式碼更動最小", "en": "minimal code changes", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud HSM (硬體安全模組) 產生加密金鑰，並在應用程式層級實作全同態加密 (Fully Homomorphic Encryption, FHE) 演算法。",
          "en": "(A) Use Cloud HSM (Hardware Security Module) to generate encryption keys and implement Fully Homomorphic Encryption (FHE) algorithms at the application level.",
          "wg": [
            { "t": "全同態加密", "en": "Fully Homomorphic Encryption", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 啟用 GKE Sandbox 並使用 gVisor 作為容器執行時 (Runtime)。這將提供核心層級的隔離，防止主機核心存取容器數據。",
          "en": "(B) Enable GKE Sandbox and use gVisor as the container runtime. This provides kernel-level isolation, preventing the host kernel from accessing container data.",
          "wg": [
            { "t": "核心層級", "en": "kernel-level", "ps": "adjective" },
            { "t": "隔離", "en": "isolation", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 在應用程式中整合 Cloud EKM (外部金鑰管理器)，將根金鑰保留在地端資料中心，確保 Google 無法解密磁碟上的數據。",
          "en": "(C) Integrate Cloud EKM (External Key Manager) in the application, keeping the root keys in the on-premises data center to ensure Google cannot decrypt data on disk.",
          "wg": [
            { "t": "外部金鑰管理器", "en": "External Key Manager", "ps": "noun" },
            { "t": "根金鑰", "en": "root keys", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 啟用 GKE 的機密 GKE 節點 (Confidential GKE Nodes)。這將利用 AMD SEV 技術對記憶體中的數據進行硬體即時加密，應用程式無需修改即可運行。",
          "en": "(D) Enable Confidential GKE Nodes. This leverages AMD SEV technology to perform hardware-based real-time encryption of data in memory, allowing applications to run without modification.",
          "wg": [
            { "t": "機密 GKE 節點", "en": "Confidential GKE Nodes", "ps": "noun" },
            { "t": "硬體即時加密", "en": "hardware-based real-time encryption", "ps": "noun" }
          ]
        }
      ],
      "answer": "(D)",
      "why": {
        "t": "Confidential Computing (Confidential GKE Nodes) 是唯一能解決「記憶體中數據 (Data-in-use)」隱私問題且「不需要修改程式碼」的方案。它使用硬體技術 (如 AMD SEV) 確保記憶體內容對雲端供應商是加密的。選項 (A) 全同態加密 (FHE) 雖然理論上可行，但極度消耗效能且需要重寫應用程式數學邏輯。選項 (B) gVisor 提供的是容器間的沙箱隔離，主要防範容器逃逸，無法防止擁有物理存取權的 Hypervisor 讀取記憶體。選項 (C) Cloud EKM 保護的是「靜態數據 (Data-at-rest)」的磁碟加密金鑰，無法保護正在記憶體中運算的數據。",
        "en": "Confidential Computing (Confidential GKE Nodes) is the only solution that addresses \"Data-in-use\" privacy and requires \"no code modification.\" It uses hardware technology (like AMD SEV) to ensure memory contents remain encrypted to the cloud provider. Option (A) FHE is theoretically possible but extremely performance-intensive and requires rewriting application mathematical logic. Option (B) gVisor provides sandbox isolation between containers to prevent escape, but cannot stop a Hypervisor with physical access from reading memory. Option (C) Cloud EKM protects disk encryption keys for \"Data-at-rest,\" not data currently being processed in memory.",
        "wg": [
          { "t": "使用中數據", "en": "Data-in-use", "ps": "noun" },
          { "t": "靜態數據", "en": "Data-at-rest", "ps": "noun" },
          { "t": "容器逃逸", "en": "container escape", "ps": "noun" }
        ]
      }
    },
    {
      "no": "17",
      "level": "hard",
      "keywords": "Migration, Strangler Fig, Load Balancing, Legacy",
      "question": [
        {
          "t": "KnightMotives 的「線上訂購系統」是一個龐大的單體 (Monolithic) 應用程式，目前運行在地端。由於該系統「不可靠」且「導致經銷商關係緊張」，公司決定將其逐步遷移至 Google Kubernetes Engine (GKE) 上的微服務架構。",
          "en": "KnightMotives' \"online ordering system\" is a massive monolithic application currently running on-premises. Because the system is \"unreliable\" and \"straining dealer relationships,\" the company has decided to gradually migrate it to a microservices architecture on Google Kubernetes Engine (GKE).",
          "wg": [
            { "t": "單體", "en": "Monolithic", "ps": "adjective" },
            { "t": "逐步遷移", "en": "gradually migrate", "ps": "verb" }
          ]
        },
        {
          "t": "您希望在不中斷服務且不進行「大爆炸」(Big Bang) 切換的情況下，將流量逐個功能 (如庫存查詢、訂單提交) 轉移到新的微服務。您應採用哪種架構模式？",
          "en": "You want to shift traffic feature by feature (e.g., inventory lookup, order submission) to the new microservices without service interruption or a \"Big Bang\" switchover. Which architectural pattern should you adopt?",
          "wg": [
            { "t": "不中斷服務", "en": "without service interruption", "ps": "noun" },
            { "t": "大爆炸", "en": "Big Bang", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Database Migration Service (DMS) 設定持續複寫，將地端資料庫同步至 Cloud SQL。一旦同步完成，立即將 DNS 指向 GKE 上的新應用程式。",
          "en": "(A) Use Database Migration Service (DMS) to configure continuous replication, syncing the on-premises database to Cloud SQL. Once synced, immediately point DNS to the new application on GKE.",
          "wg": [
            { "t": "持續複寫", "en": "continuous replication", "ps": "noun" },
            { "t": "同步", "en": "synced", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 實施扼殺者無花果模式 (Strangler Fig Pattern)。部署一個全域外部應用負載平衡器 (GXLB)，根據 URL 路徑規則將特定流量路由至新的 GKE 微服務，其餘流量仍導向地端舊系統。",
          "en": "(B) Implement the Strangler Fig Pattern. Deploy a Global External Application Load Balancer (GXLB) to route specific traffic to new GKE microservices based on URL path rules, while directing the rest to the legacy on-premises system.",
          "wg": [
            { "t": "扼殺者無花果模式", "en": "Strangler Fig Pattern", "ps": "noun" },
            { "t": "路徑規則", "en": "path rules", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Traffic Director 建立服務網格 (Service Mesh)。將地端應用程式與 GKE 服務都註冊到網格中，並使用斷路器 (Circuit Breaker) 模式來管理流量轉移。",
          "en": "(C) Use Traffic Director to create a Service Mesh. Register both the on-premises application and GKE services into the mesh, and use the Circuit Breaker pattern to manage traffic shifting.",
          "wg": [
            { "t": "服務網格", "en": "Service Mesh", "ps": "noun" },
            { "t": "斷路器", "en": "Circuit Breaker", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 在 GKE 中部署 Config Connector，將地端基礎設施宣告為 Kubernetes 資源。使用 kubectl apply 逐步取代舊有的 VM 資源。",
          "en": "(D) Deploy Config Connector in GKE to declare on-premises infrastructure as Kubernetes resources. Use kubectl apply to gradually replace legacy VM resources.",
          "wg": [
            { "t": "宣告", "en": "declare", "ps": "verb" },
            { "t": "取代", "en": "replace", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "扼殺者無花果模式 (Strangler Fig Pattern) 是將單體應用程式逐步現代化為微服務的標準模式。透過在前端放置負載平衡器 (GXLB)，可以根據路徑 (如 `/api/v2/orders`) 將流量精確地切分到新舊系統，降低風險並實現平滑轉移。選項 (A) 描述的是「大爆炸」遷移，風險極高且不符合「逐步」的要求。選項 (C) 雖然 Traffic Director 支援混合雲網格，但設定複雜且主要用於服務間通訊，對於公開入口的遷移，L7 負載平衡器更直接有效。選項 (D) Config Connector 是用於管理 GCP 資源的工具，不能用來遷移應用程式邏輯。",
        "en": "The Strangler Fig Pattern is the standard pattern for gradually modernizing monolithic applications into microservices. By placing a Load Balancer (GXLB) at the frontend, traffic can be precisely split based on paths (e.g., `/api/v2/orders`) between the new and old systems, reducing risk and enabling smooth transition. Option (A) describes a \"Big Bang\" migration, which is high-risk and violates the \"gradual\" requirement. Option (C) while Traffic Director supports hybrid mesh, it's complex and primarily for east-west traffic; for public ingress migration, an L7 LB is more direct. Option (D) Config Connector is for managing GCP resources, not for migrating application logic.",
        "wg": [
          { "t": "標準模式", "en": "standard pattern", "ps": "noun" },
          { "t": "平滑轉移", "en": "smooth transition", "ps": "noun" }
        ]
      }
    },
    {
      "no": "18",
      "level": "hard",
      "keywords": "Dataplex, Data Governance, IAM, BigQuery",
      "question": [
        {
          "t": "KnightMotives 的企業數據分散在多個孤島：部分在地端大型主機，部分在 Cloud Storage (資料湖)，部分在 BigQuery (資料倉儲)。",
          "en": "KnightMotives' corporate data is scattered across silos: some on on-premises mainframes, some in Cloud Storage (Data Lake), and some in BigQuery (Data Warehouse).",
          "wg": [
            { "t": "孤島", "en": "silos", "ps": "noun" },
            { "t": "資料湖", "en": "Data Lake", "ps": "noun" },
            { "t": "資料倉儲", "en": "Data Warehouse", "ps": "noun" }
          ]
        },
        {
          "t": "為了實現「數據變現」並資助新技術，您需要建立一個統一的數據管理平台。該平台必須能跨越這些儲存系統自動探索數據 (Data Discovery)、統一設定存取權限 (Centralized IAM)，並監控數據品質。您應導入哪項服務？",
          "en": "To enable \"Data Monetization\" and finance new technologies, you need to establish a unified data management platform. The platform must allow automatic Data Discovery across these storage systems, centralized IAM configuration, and data quality monitoring. Which service should you introduce?",
          "wg": [
            { "t": "自動探索", "en": "automatic Data Discovery", "ps": "noun" },
            { "t": "統一設定存取權限", "en": "Centralized IAM configuration", "ps": "noun" },
            { "t": "數據品質", "en": "data quality", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 部署 Dataproc Metastore 作為統一的 Hive Metastore。將所有數據集註冊到 Hive 中，並使用 Apache Ranger 進行權限控制。",
          "en": "(A) Deploy Dataproc Metastore as a unified Hive Metastore. Register all datasets into Hive and use Apache Ranger for permission control.",
          "wg": [
            { "t": "註冊", "en": "Register", "ps": "verb" },
            { "t": "權限控制", "en": "permission control", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 實施 Dataplex。建立邏輯湖泊 (Lakes) 與區域 (Zones) 來組織 Cloud Storage 與 BigQuery 中的數據。設定傳播策略以統一管理 IAM 權限。",
          "en": "(B) Implement Dataplex. Create logical Lakes and Zones to organize data in Cloud Storage and BigQuery. Configure propagation policies to centrally manage IAM permissions.",
          "wg": [
            { "t": "邏輯湖泊", "en": "logical Lakes", "ps": "noun" },
            { "t": "傳播策略", "en": "propagation policies", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Data Catalog 掃描所有專案。手動為每個 Tag Template 建立 IAM 綁定，並編寫 Cloud Functions 來定期驗證數據品質。",
          "en": "(C) Use Data Catalog to scan all projects. Manually create IAM bindings for each Tag Template and write Cloud Functions to periodically validate data quality.",
          "wg": [
            { "t": "掃描", "en": "scan", "ps": "verb" },
            { "t": "手動", "en": "Manually", "ps": "adverb" }
          ]
        },
        {
          "t": "(D) 將所有數據遷移至 BigQuery Omni，利用其跨雲分析能力。在 BigQuery 中使用資料列層級安全性 (Row-level Security) 來管理存取。",
          "en": "(D) Migrate all data to BigQuery Omni to leverage its cross-cloud analytics capabilities. Use Row-level Security in BigQuery to manage access.",
          "wg": [
            { "t": "跨雲分析", "en": "cross-cloud analytics", "ps": "noun" },
            { "t": "資料列層級安全性", "en": "Row-level Security", "ps": "noun" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Dataplex 是 Google Cloud 專為「智慧資料網格 (Intelligent Data Fabric)」設計的服務，旨在打破數據孤島。它能統一管理分佈在 GCS (資料湖) 和 BigQuery (資料倉儲) 的數據，提供自動化探索、集中式安全政策 (IAM) 管理以及內建的數據品質檢查，完全符合題目需求。選項 (A) 是 Hadoop 生態系的傳統作法，維運複雜且非雲原生最佳解。選項 (C) Data Catalog 僅負責元數據標記，無法「管理」底層數據的 IAM 權限或執行品質檢查。選項 (D) BigQuery Omni 是用於跨雲分析 (AWS/Azure)，且題目重點在於治理 (Governance) 而非單純的遷移或查詢。",
        "en": "Dataplex is Google Cloud's service designed for \"Intelligent Data Fabric\" to break down data silos. It unifies management of data distributed across GCS (Data Lake) and BigQuery (Data Warehouse), offering automated discovery, centralized security policy (IAM) management, and built-in data quality checks, perfectly matching the requirements. Option (A) is a traditional approach in the Hadoop ecosystem, operationally complex and not the cloud-native best practice. Option (C) Data Catalog only handles metadata tagging and cannot \"manage\" underlying data IAM or perform quality checks. Option (D) BigQuery Omni is for cross-cloud analytics (AWS/Azure), while the focus here is governance, not just migration or querying.",
        "wg": [
          { "t": "打破數據孤島", "en": "break down data silos", "ps": "verb" },
          { "t": "內建的", "en": "built-in", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "19",
      "level": "hard",
      "keywords": "Cloud CDN, Signed URLs, Edge, OTA",
      "question": [
        {
          "t": "KnightMotives 必須向全球數百萬輛車推送大型韌體更新 (OTA Updates)，以啟用新的 AI 功能。車輛經常處於偏遠地區，連線頻寬有限且不穩定。",
          "en": "KnightMotives must push large firmware updates (OTA Updates) to millions of vehicles globally to enable new AI features. Vehicles are often in remote areas with limited and unstable connection bandwidth.",
          "wg": [
            { "t": "韌體更新", "en": "firmware updates", "ps": "noun" },
            { "t": "連線頻寬", "en": "connection bandwidth", "ps": "noun" }
          ]
        },
        {
          "t": "您需要確保這些敏感的更新檔案能以低延遲傳輸，且只能由驗證過的 KnightMotives 車輛下載，防止競爭對手獲取韌體進行逆向工程。最具成本效益且安全的架構為何？",
          "en": "You need to ensure these sensitive update files are delivered with low latency and can only be downloaded by authenticated KnightMotives vehicles, preventing competitors from obtaining the firmware for reverse engineering. What is the most cost-effective and secure architecture?",
          "wg": [
            { "t": "逆向工程", "en": "reverse engineering", "ps": "noun" },
            { "t": "最具成本效益", "en": "most cost-effective", "ps": "adjective" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 將韌體儲存在 Cloud Storage Multi-Region Bucket 中。為每輛車配置一組 IAM 服務帳戶金鑰，並使用 gsutil 工具下載。",
          "en": "(A) Store firmware in a Cloud Storage Multi-Region Bucket. Configure an IAM Service Account Key for each vehicle and use the gsutil tool to download.",
          "wg": [
            { "t": "服務帳戶金鑰", "en": "Service Account Key", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 使用 Cloud CDN 快取 Cloud Storage 中的韌體檔案。在後端實作邏輯，為每個請求產生具有短暫時效的簽署 URL (Signed URLs) 或簽署 Cookie，並讓車輛使用此 URL 下載。",
          "en": "(B) Use Cloud CDN to cache firmware files from Cloud Storage. Implement logic on the backend to generate short-lived Signed URLs or Signed Cookies for each request, and have vehicles download using this URL.",
          "wg": [
            { "t": "快取", "en": "cache", "ps": "verb" },
            { "t": "簽署 URL", "en": "Signed URLs", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 透過 Dedicated Interconnect 將更新推送至各地區的經銷商伺服器，並要求車主回到經銷商處進行實體連接更新。",
          "en": "(C) Push updates to regional dealer servers via Dedicated Interconnect, and require owners to return to dealers for a physical connection update.",
          "wg": [
            { "t": "實體連接", "en": "physical connection", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 在全球每個區域部署 Compute Engine 執行個體群組 (MIG) 作為網頁伺服器，並設定防火牆規則僅允許已註冊的車輛 IP 存取。",
          "en": "(D) Deploy Compute Engine Managed Instance Groups (MIG) in every global region as web servers, and configure firewall rules to allow access only from registered vehicle IPs.",
          "wg": [
            { "t": "執行個體群組", "en": "Managed Instance Groups (MIG)", "ps": "noun" },
            { "t": "已註冊的", "en": "registered", "ps": "adjective" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Cloud CDN 是分發大型靜態檔案 (如韌體) 的最佳解決方案，能利用 Google 的全球邊緣節點顯著降低下載延遲並節省頻寬成本。使用「簽署 URL (Signed URLs)」是控制 Cloud CDN 內容存取的標準安全模式，確保只有持有有效簽章的車輛能下載，且連結會過期，防止未經授權的散佈。選項 (A) 管理數百萬個 IAM 金鑰是不可能的 (Toil)，且 gsutil 不適合嵌入式系統。選項 (C) 違背了 OTA (空中下載) 的現代化體驗目標。選項 (D) 使用 VM 充當 CDN 成本極高，且維護 IP 白名單對於行動中的車輛是不切實際的。",
        "en": "Cloud CDN is the optimal solution for distributing large static files (like firmware), leveraging Google's global edge nodes to significantly reduce latency and bandwidth costs. Using \"Signed URLs\" is the standard security pattern for controlling access to Cloud CDN content, ensuring only vehicles with a valid signature can download, and links expire to prevent unauthorized distribution. Option (A) managing millions of IAM keys is impossible (Toil), and gsutil is unfit for embedded systems. Option (C) contradicts the goal of modern OTA experiences. Option (D) using VMs as a CDN is cost-prohibitive, and maintaining IP allowlists for moving vehicles is impractical.",
        "wg": [
          { "t": "標準安全模式", "en": "standard security pattern", "ps": "noun" },
          { "t": "不切實際的", "en": "impractical", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "20",
      "level": "hard",
      "keywords": "SRE, SLO, Error Budget, Reliability",
      "question": [
        {
          "t": "KnightMotives 的「線上訂購系統」即將上線，該系統對經銷商的業務至關重要。為了改善過去「不可靠」的聲譽，您決定採用 SRE (網站可靠性工程) 原則。",
          "en": "KnightMotives' \"online ordering system\" is about to go live and is critical to dealer operations. To improve upon the past reputation of being \"unreliable,\" you decide to adopt SRE (Site Reliability Engineering) principles.",
          "wg": [
            { "t": "至關重要", "en": "critical", "ps": "adjective" },
            { "t": "網站可靠性工程", "en": "Site Reliability Engineering", "ps": "noun" }
          ]
        },
        {
          "t": "您需要定義服務水準目標 (SLOs) 與錯誤預算 (Error Budgets) 策略，以平衡發布速度與系統穩定性。下列哪兩項行動符合 Google 的 SRE 最佳實踐？（請選擇兩項）",
          "en": "You need to define Service Level Objectives (SLOs) and Error Budget strategies to balance release velocity with system stability. Which two actions align with Google's SRE best practices? (Choose two)",
          "wg": [
            { "t": "平衡", "en": "balance", "ps": "verb" },
            { "t": "發布速度", "en": "release velocity", "ps": "noun" }
          ]
        }
      ],
      "type": "複選題",
      "options": [
        {
          "t": "(A) 設定 100% 的可用性 SLO，以向經銷商保證新系統絕對可靠，重建信任。",
          "en": "(A) Set a 100% availability SLO to assure dealers that the new system is absolutely reliable, rebuilding trust.",
          "wg": [
            { "t": "絕對可靠", "en": "absolutely reliable", "ps": "adjective" },
            { "t": "重建信任", "en": "rebuilding trust", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 選擇與使用者體驗直接相關的服務水準指標 (SLI)，例如「成功建立訂單請求的比例」或「首頁載入延遲」。",
          "en": "(B) Choose Service Level Indicators (SLIs) that are directly related to user experience, such as \"proportion of successful order creation requests\" or \"homepage load latency.\"",
          "wg": [
            { "t": "服務水準指標", "en": "Service Level Indicators (SLIs)", "ps": "noun" },
            { "t": "比例", "en": "proportion", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 當錯誤預算耗盡時，暫停非緊急的功能發布，並將工程資源轉向修復系統穩定性問題，直到預算恢復。",
          "en": "(C) When the error budget is exhausted, halt non-emergency feature releases and redirect engineering resources to fix system stability issues until the budget recovers.",
          "wg": [
            { "t": "耗盡", "en": "exhausted", "ps": "adjective" },
            { "t": "暫停", "en": "halt", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 使用 CPU 使用率與記憶體消耗作為主要的 SLI，因為它們最能反映系統的負載狀況。",
          "en": "(D) Use CPU utilization and memory consumption as primary SLIs, as they best reflect the system's load condition.",
          "wg": [
            { "t": "消耗", "en": "consumption", "ps": "noun" },
            { "t": "反映", "en": "reflect", "ps": "verb" }
          ]
        },
        {
          "t": "(E) 每當發生單一請求失敗時立即發送 PagerDuty 警報給值班工程師，以確保問題能被即時解決。",
          "en": "(E) Send a PagerDuty alert to the on-call engineer immediately whenever a single request fails, ensuring issues are resolved in real-time.",
          "wg": [
            { "t": "警報", "en": "alert", "ps": "noun" },
            { "t": "即時解決", "en": "resolved in real-time", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B), (C)",
      "why": {
        "t": "SRE 的核心原則是：1) 選擇從使用者視角出發的 SLI (B)，如成功率或延遲，而非硬體指標 (如 CPU)；2) 利用錯誤預算來決策 (C)，當預算耗盡時「凍結功能發布」，強迫團隊關注可靠性。選項 (A) 設定 100% SLO 是不切實際的，會導致創新停滯且成本無限大。選項 (D) CPU 是代理指標 (Proxy Metric)，CPU 高不代表使用者體驗差。選項 (E) 會導致「警報疲勞 (Alert Fatigue)」，應該針對「錯誤預算消耗速率 (Burn Rate)」進行警報，而非單一錯誤。",
        "en": "The core principles of SRE are: 1) Choose SLIs from the user's perspective (B), like success rate or latency, rather than hardware metrics (like CPU); 2) Use Error Budgets for decision making (C)—when the budget is exhausted, \"freeze feature releases\" and force the team to focus on reliability. Option (A) setting 100% SLO is unrealistic, causing stagnation and infinite costs. Option (D) CPU is a proxy metric; high CPU doesn't necessarily mean poor user experience. Option (E) leads to \"Alert Fatigue\"; alerts should be based on \"Error Budget Burn Rate,\" not single errors.",
        "wg": [
          { "t": "使用者視角", "en": "user's perspective", "ps": "noun" },
          { "t": "警報疲勞", "en": "Alert Fatigue", "ps": "noun" }
        ]
      }
    },
    {
      "no": "21",
      "level": "hard",
      "keywords": "Context-Aware Access, IAM Conditions, GDPR, IAP",
      "question": [
        {
          "t": "KnightMotives 的維修技術人員需要透過企業入口網站 (Dealer Portal) 存取車輛的詳細診斷數據。根據「歐盟數據保護法規 (GDPR)」，歐盟公民的敏感數據只能由「位於歐盟境內」的技術人員存取。",
          "en": "KnightMotives service technicians need to access detailed vehicle diagnostic data via the Dealer Portal. According to \"EU data protection regulations (GDPR),\" sensitive data of EU citizens can only be accessed by technicians \"physically located within the EU.\"",
          "wg": [
            { "t": "維修技術人員", "en": "service technicians", "ps": "noun" },
            { "t": "位於...境內", "en": "physically located within", "ps": "adjective" }
          ]
        },
        {
          "t": "由於技術人員經常跨國出差，您的解決方案必須根據他們「當下的地理位置」動態授予或拒絕存取權限，且不應要求他們使用 VPN。您應如何設定身分驗證與授權？",
          "en": "Since technicians frequently travel internationally, your solution must dynamically grant or deny access based on their \"current geographic location\" without requiring a VPN. How should you configure authentication and authorization?",
          "wg": [
            { "t": "動態授予", "en": "dynamically grant", "ps": "verb" },
            { "t": "當下的地理位置", "en": "current geographic location", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 為歐盟與非歐盟地區分別建立不同的 Google Group。當技術人員出差時，由人資部門手動更新其群組成員資格。",
          "en": "(A) Create separate Google Groups for EU and non-EU regions. When technicians travel, have HR manually update their group membership.",
          "wg": [
            { "t": "手動更新", "en": "manually update", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 使用 Cloud Armor 設定地理位置過濾規則 (Geo-blocking)，僅允許來自歐盟 IP 的流量存取入口網站的歐盟資料區塊。",
          "en": "(B) Use Cloud Armor to configure geographic filtering rules (Geo-blocking), allowing only traffic from EU IPs to access the EU data section of the portal.",
          "wg": [
            { "t": "地理位置過濾規則", "en": "geographic filtering rules", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 部署 Identity-Aware Proxy (IAP) 保護應用程式。設定 Access Context Manager 定義地理位置存取層級 (Access Level)，並將 IAM 條件 (IAM Conditions) 綁定至該存取層級。",
          "en": "(C) Deploy Identity-Aware Proxy (IAP) to protect the application. Configure Access Context Manager to define geographic Access Levels, and bind IAM Conditions to those levels.",
          "wg": [
            { "t": "存取層級", "en": "Access Level", "ps": "noun" },
            { "t": "綁定", "en": "bind", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 在 VPC 網路上實施防火牆規則，封鎖所有非歐盟地區的 IP 位址範圍，並要求所有技術人員安裝固定 IP 的用戶端憑證。",
          "en": "(D) Implement firewall rules on the VPC network to block all non-EU IP address ranges, and require all technicians to install client certificates with static IPs.",
          "wg": [
            { "t": "封鎖", "en": "block", "ps": "verb" },
            { "t": "用戶端憑證", "en": "client certificates", "ps": "noun" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "Context-Aware Access (透過 IAP 與 Access Context Manager) 是實現「基於位置的動態存取控制」的最佳實踐。它能在使用者登入時檢查其 IP 地理位置 (Context)，並結合 IAM 條件來決定是否授權，完全不需要 VPN 或繁瑣的防火牆管理。選項 (A) 的手動流程不可擴展且容易出錯。選項 (B) Cloud Armor 雖然能阻擋 IP，但它是在網路邊緣運作，無法精細地結合「使用者身分 (Identity)」與「存取權限 (Authorization)」。選項 (D) 管理全球 IP 清單與憑證是巨大的維運負擔。",
        "en": "Context-Aware Access (via IAP and Access Context Manager) is the best practice for \"location-based dynamic access control.\" It checks the user's IP geolocation (Context) at login and combines it with IAM conditions to authorize access, without needing a VPN or cumbersome firewall management. Option (A) manual processes are unscalable and error-prone. Option (B) Cloud Armor blocks IPs at the edge but cannot granularly combine \"User Identity\" with \"Authorization\" logic. Option (D) managing global IP lists and certificates is a massive operational toil.",
        "wg": [
          { "t": "動態存取控制", "en": "dynamic access control", "ps": "noun" },
          { "t": "繁瑣的", "en": "cumbersome", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "22",
      "level": "hard",
      "keywords": "Cloud Run, Traffic Splitting, Canary Deployment, Modernization",
      "question": [
        {
          "t": "KnightMotives 已將其「線上訂購系統」容器化並遷移至 Cloud Run。為了「提升客戶滿意度」，行銷團隊希望對新的車輛配置介面 (UI) 進行 A/B 測試。",
          "en": "KnightMotives has containerized its \"online ordering system\" and migrated it to Cloud Run. To \"improve customer satisfaction,\" the marketing team wants to conduct A/B testing on the new vehicle configuration UI.",
          "wg": [
            { "t": "線上訂購系統", "en": "online ordering system", "ps": "noun" },
            { "t": "A/B 測試", "en": "A/B testing", "ps": "noun" }
          ]
        },
        {
          "t": "您需要設定一個部署策略，將 10% 的流量導向新版本 (v2)，其餘 90% 保留在當前版本 (v1)。若 v2 發生錯誤，系統必須能立即、零停機地切換回 100% v1。您應採取哪項操作？",
          "en": "You need to configure a deployment strategy to route 10% of traffic to the new version (v2) while keeping 90% on the current version (v1). If v2 errors out, the system must revert to 100% v1 immediately with zero downtime. Which action should you take?",
          "wg": [
            { "t": "零停機", "en": "zero downtime", "ps": "noun" },
            { "t": "切換回", "en": "revert", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Run 的流量分割 (Traffic Splitting) 功能。部署 v2 版本但不立即切換標籤，接著手動設定 10% 的流量分配給 v2 修訂版 (Revision)。",
          "en": "(A) Use Cloud Run's Traffic Splitting feature. Deploy the v2 version without immediately switching tags, then manually configure a 10% traffic allocation to the v2 revision.",
          "wg": [
            { "t": "流量分割", "en": "Traffic Splitting", "ps": "noun" },
            { "t": "修訂版", "en": "Revision", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 在 HTTP 負載平衡器後端設定兩個執行個體群組 (Instance Groups)。將 v2 群組的大小設定為 v1 群組的 10%，並依賴負載平衡演算法進行分配。",
          "en": "(B) Configure two Instance Groups behind the HTTP Load Balancer. Set the size of the v2 group to 10% of the v1 group, relying on the load balancing algorithm for distribution.",
          "wg": [
            { "t": "依賴", "en": "relying on", "ps": "verb" },
            { "t": "分配", "en": "distribution", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Cloud DNS 的加權循環 (Weighted Round Robin) 策略，建立兩個 A 記錄，分別指向 v1 與 v2 的負載平衡器 IP，權重設為 90 與 10。",
          "en": "(C) Use Cloud DNS Weighted Round Robin policy. Create two A records pointing to the Load Balancer IPs of v1 and v2 respectively, with weights set to 90 and 10.",
          "wg": [
            { "t": "加權循環", "en": "Weighted Round Robin", "ps": "noun" },
            { "t": "權重", "en": "weights", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 部署 Istio 服務網格，並編寫 VirtualService 路由規則，根據 HTTP 標頭中的 User-ID 雜湊值將流量進行百分比分割。",
          "en": "(D) Deploy Istio service mesh and write VirtualService routing rules to split traffic by percentage based on the hash of the User-ID in HTTP headers.",
          "wg": [
            { "t": "路由規則", "en": "routing rules", "ps": "noun" },
            { "t": "雜湊值", "en": "hash", "ps": "noun" }
          ]
        }
      ],
      "answer": "(A)",
      "why": {
        "t": "Cloud Run 內建的流量分割 (Traffic Splitting) 是最簡單、全代管且符合現代化應用程式 (Serverless) 的金絲雀部署 (Canary Deployment) 方式。它允許精確控制百分比且回滾 (Rollback) 僅需秒級 API 呼叫，無需管理基礎設施。選項 (B) 使用 VM 與 Instance Group 大小來控制流量是非常粗糙且不精確的。選項 (C) DNS 變更有 TTL 延遲，無法滿足「立即」回滾的需求。選項 (D) 引入 Istio 會增加巨大的維運複雜度，對於僅需簡單 A/B 測試的場景是過度設計 (Over-engineering)。",
        "en": "Cloud Run's built-in Traffic Splitting is the simplest, fully managed way to perform Canary Deployment for modern (Serverless) apps. It allows precise percentage control, and rollback requires only a seconds-fast API call without managing infrastructure. Option (B) using VM instance group sizing is crude and imprecise for traffic control. Option (C) DNS changes have TTL latency, failing the \"immediate\" rollback requirement. Option (D) introducing Istio adds massive operational complexity and is over-engineering for a simple A/B test scenario.",
        "wg": [
          { "t": "金絲雀部署", "en": "Canary Deployment", "ps": "noun" },
          { "t": "過度設計", "en": "Over-engineering", "ps": "noun" }
        ]
      }
    },
    {
      "no": "23",
      "level": "hard",
      "keywords": "BigQuery ML, Upskilling, Predictive Analytics, SQL",
      "question": [
        {
          "t": "KnightMotives 的銷售團隊希望預測哪些現有客戶最有可能購買新的 BEV 車型，以進行精準行銷。所有的客戶互動數據與銷售紀錄都已存儲在 BigQuery 中。",
          "en": "KnightMotives' sales team wants to predict which existing customers are most likely to purchase new BEV models for targeted marketing. All customer interaction data and sales records are already stored in BigQuery.",
          "wg": [
            { "t": "預測", "en": "predict", "ps": "verb" },
            { "t": "精準行銷", "en": "targeted marketing", "ps": "noun" }
          ]
        },
        {
          "t": "目前的商業智慧 (BI) 團隊精通 SQL，但缺乏 Python 或 TensorFlow 的機器學習專業知識。您需要選擇一個最快能產出預測模型且學習門檻最低的解決方案，以達成「提升員工技能」的目標。",
          "en": "The current Business Intelligence (BI) team is proficient in SQL but lacks machine learning expertise in Python or TensorFlow. You need to choose a solution that yields predictive models fastest with the lowest learning curve to meet the \"employee upskilling\" objective.",
          "wg": [
            { "t": "精通", "en": "proficient in", "ps": "adjective" },
            { "t": "學習門檻", "en": "learning curve", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 將數據匯出至 Cloud Storage，使用 Dataproc 執行 PySpark MLlib 作業進行模型訓練，並聘請外部顧問協助編寫程式碼。",
          "en": "(A) Export data to Cloud Storage, run PySpark MLlib jobs on Dataproc for model training, and hire external consultants to assist with coding.",
          "wg": [
            { "t": "匯出", "en": "Export", "ps": "verb" },
            { "t": "外部顧問", "en": "external consultants", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 使用 Vertex AI Workbench 啟動 Jupyter Notebooks，讓 BI 團隊學習使用 TensorFlow Keras API 來建置神經網路模型。",
          "en": "(B) Use Vertex AI Workbench to launch Jupyter Notebooks, and have the BI team learn to use the TensorFlow Keras API to build neural network models.",
          "wg": [
            { "t": "神經網路模型", "en": "neural network models", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Dataflow 將數據轉換為 TFRecord 格式，並使用 Vertex AI Training 服務執行自訂容器化的訓練作業。",
          "en": "(C) Use Dataflow to transform data into TFRecord format and run custom containerized training jobs using Vertex AI Training service.",
          "wg": [
            { "t": "轉換", "en": "transform", "ps": "verb" },
            { "t": "自訂容器化", "en": "custom containerized", "ps": "adjective" }
          ]
        },
        {
          "t": "(D) 直接在 BigQuery 中使用 BigQuery ML (BQML)。使用標準 SQL 語法 (`CREATE MODEL`) 來訓練邏輯回歸 (Logistic Regression) 模型。",
          "en": "(D) Use BigQuery ML (BQML) directly within BigQuery. Use standard SQL syntax (`CREATE MODEL`) to train a Logistic Regression model.",
          "wg": [
            { "t": "標準 SQL 語法", "en": "standard SQL syntax", "ps": "noun" },
            { "t": "邏輯回歸", "en": "Logistic Regression", "ps": "noun" }
          ]
        }
      ],
      "answer": "(D)",
      "why": {
        "t": "BigQuery ML (BQML) 是針對 SQL 專業人員 (如 BI 分析師) 的最佳 ML 解決方案。它允許使用者直接在資料倉儲內使用 SQL 建立、訓練與部署模型，無需移動數據，也無需學習 Python 或複雜的 ML 框架。這完全符合案例中「提升現有員工技能 (Upskilling)」與「利用數據變現」的目標，且開發速度最快。選項 (A)、(B)、(C) 都需要大幅改變技術堆疊並學習新語言 (Python/Java)，學習曲線陡峭，不符合團隊現況。",
        "en": "BigQuery ML (BQML) is the ideal ML solution for SQL professionals (like BI analysts). It allows users to create, train, and deploy models directly inside the data warehouse using SQL, without moving data or learning Python/complex ML frameworks. This aligns perfectly with the case study's goals of \"upskilling existing employees\" and \"data monetization,\" offering the fastest time-to-value. Options (A), (B), and (C) all require significant tech stack changes and learning new languages (Python/Java), presenting a steep learning curve unsuitable for the current team.",
        "wg": [
          { "t": "最佳 ML 解決方案", "en": "ideal ML solution", "ps": "noun" },
          { "t": "無需移動數據", "en": "without moving data", "ps": "verb" },
          { "t": "學習曲線陡峭", "en": "steep learning curve", "ps": "noun" }
        ]
      }
    },
    {
      "no": "24",
      "level": "hard",
      "keywords": "Global Load Balancing, Multi-Region, Cloud Spanner, DR",
      "question": [
        {
          "t": "KnightMotives 的「線上訂購系統」將在全球推出，並成為主要的營收來源。該系統必須具備極高的可靠性，即使單一 Google Cloud 地區 (Region) 完全故障，也能繼續處理訂單 (RPO 接近 0，RTO < 5 分鐘)。",
          "en": "KnightMotives' \"online ordering system\" will launch globally and become a primary revenue source. The system must be highly reliable, capable of processing orders even if a single Google Cloud Region fails completely (RPO near 0, RTO < 5 minutes).",
          "wg": [
            { "t": "主要的營收來源", "en": "primary revenue source", "ps": "noun" },
            { "t": "完全故障", "en": "fails completely", "ps": "verb" }
          ]
        },
        {
          "t": "您需要設計一個主動-主動 (Active-Active) 的全球架構。應選擇哪兩項關鍵元件？（請選擇兩項）",
          "en": "You need to design an Active-Active global architecture. Which two key components should you choose? (Choose two)",
          "wg": [
            { "t": "主動-主動", "en": "Active-Active", "ps": "adjective" },
            { "t": "關鍵元件", "en": "key components", "ps": "noun" }
          ]
        }
      ],
      "type": "複選題",
      "options": [
        {
          "t": "(A) Cloud Spanner，配置為多重地區 (Multi-region) 執行個體。",
          "en": "(A) Cloud Spanner, configured as a Multi-region instance.",
          "wg": [
            { "t": "執行個體", "en": "instance", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 全域外部應用程式負載平衡器 (Global External Application Load Balancer)。",
          "en": "(B) Global External Application Load Balancer.",
          "wg": [
            { "t": "全域外部", "en": "Global External", "ps": "adjective" }
          ]
        },
        {
          "t": "(C) Cloud SQL for PostgreSQL，啟用跨區域唯讀複本 (Cross-Region Read Replicas)。",
          "en": "(C) Cloud SQL for PostgreSQL, enabled with Cross-Region Read Replicas.",
          "wg": [
            { "t": "跨區域", "en": "Cross-Region", "ps": "adjective" }
          ]
        },
        {
          "t": "(D) 區域性外部應用程式負載平衡器 (Regional External Application Load Balancer) 搭配 Cloud DNS 地理路由。",
          "en": "(D) Regional External Application Load Balancer combined with Cloud DNS Geolocation routing.",
          "wg": [
            { "t": "地理路由", "en": "Geolocation routing", "ps": "noun" }
          ]
        },
        {
          "t": "(E) Cloud Storage，使用雙區域 (Dual-region) 儲存類別來同步靜態資產。",
          "en": "(E) Cloud Storage, using Dual-region storage class to sync static assets.",
          "wg": [
            { "t": "同步", "en": "sync", "ps": "verb" },
            { "t": "靜態資產", "en": "static assets", "ps": "noun" }
          ]
        }
      ],
      "answer": "(A), (B)",
      "why": {
        "t": "為了達成全球 Active-Active 架構與地區級故障容忍：(B) 全域負載平衡器提供單一 Anycast IP，能自動將流量導向最近且健康的地區，若某地區故障會自動重新導向流量 (Failover)。(A) Cloud Spanner 是唯一支援全球同步複寫與強一致性的資料庫，能確保在地區故障時不遺失數據 (RPO=0) 且無需手動切換。選項 (C) Cloud SQL 跨區故障轉移需要手動或觸發程序，RTO 較長且通常有數據遺失風險。選項 (D) 使用 DNS 進行故障轉移會受限於 TTL，速度較慢。選項 (E) 雖然對靜態資源有用，但對於核心交易系統 (Ordering) 來說，資料庫與流量入口才是關鍵。",
        "en": "To achieve a Global Active-Active architecture with regional fault tolerance: (B) Global Load Balancer provides a single Anycast IP, automatically routing traffic to the nearest healthy region and redirecting (Failover) if a region fails. (A) Cloud Spanner is the only database supporting global synchronous replication and strong consistency, ensuring zero data loss (RPO=0) and no manual failover during outages. Option (C) Cloud SQL cross-region failover is manual/triggered, with longer RTO and potential data loss. Option (D) DNS-based failover is slow due to TTL. Option (E) is useful for static assets, but for the core transactional system (Ordering), the database and ingress are the critical components.",
        "wg": [
          { "t": "故障容忍", "en": "fault tolerance", "ps": "noun" },
          { "t": "強一致性", "en": "strong consistency", "ps": "noun" },
          { "t": "數據遺失風險", "en": "potential data loss", "ps": "noun" }
        ]
      }
    },
    {
      "no": "25",
      "level": "hard",
      "keywords": "Cost Management, Labels, Billing Export, FinOps",
      "question": [
        {
          "t": "KnightMotives 的「財務優先順序轉變」要求對雲端支出進行嚴格管控。由於 BEV、Hybrid 與 ICE 車輛專案共用同一個 GCP 組織與多個專案，財務部門難以區分各業務單位的實際成本。",
          "en": "KnightMotives' \"shift in financial priorities\" demands strict control over cloud spending. Since BEV, Hybrid, and ICE vehicle projects share the same GCP Organization and multiple projects, the finance department struggles to attribute actual costs to each business unit.",
          "wg": [
            { "t": "雲端支出", "en": "cloud spending", "ps": "noun" },
            { "t": "業務單位", "en": "business unit", "ps": "noun" }
          ]
        },
        {
          "t": "您需要設計一個解決方案，能夠自動化生成詳細的成本分攤報告，清楚顯示每個車型的開發與維運成本。您應採取哪項行動？",
          "en": "You need to design a solution that automatically generates detailed cost allocation reports, clearly showing development and operational costs for each vehicle model. Which action should you take?",
          "wg": [
            { "t": "成本分攤報告", "en": "cost allocation reports", "ps": "noun" },
            { "t": "開發與維運成本", "en": "development and operational costs", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 為每個業務單位 (BEV/Hybrid/ICE) 建立獨立的 Billing Account，並將相關專案連結至各自的帳單帳戶。",
          "en": "(A) Create separate Billing Accounts for each business unit (BEV/Hybrid/ICE) and link relevant projects to their respective billing accounts.",
          "wg": [
            { "t": "連結", "en": "link", "ps": "verb" },
            { "t": "各自的", "en": "respective", "ps": "adjective" }
          ]
        },
        {
          "t": "(B) 實施強制性的標籤策略 (Mandatory Labeling Strategy)。在資源層級套用 `vehicle-model` 標籤，啟用 Billing Export 將詳細帳單資料匯出至 BigQuery，並使用 Looker Studio 製作儀表板。",
          "en": "(B) Implement a Mandatory Labeling Strategy. Apply `vehicle-model` labels at the resource level, enable Billing Export to BigQuery, and use Looker Studio to create dashboards.",
          "wg": [
            { "t": "強制性的", "en": "Mandatory", "ps": "adjective" },
            { "t": "儀表板", "en": "dashboards", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Resource Quotas 來限制每個專案的支出上限。當達到上限時，自動觸發 Cloud Functions 停止所有資源以防止超支。",
          "en": "(C) Use Resource Quotas to cap spending for each project. When the cap is reached, automatically trigger Cloud Functions to stop all resources to prevent overspending.",
          "wg": [
            { "t": "支出上限", "en": "spending cap", "ps": "noun" },
            { "t": "超支", "en": "overspending", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 在 Google Cloud Console 的 Billing Reports 頁面中，使用專案名稱進行篩選，並手動下載 CSV 檔案每月寄送給財務部門。",
          "en": "(D) In the Google Cloud Console Billing Reports page, filter by project name, and manually download CSV files to email the finance department monthly.",
          "wg": [
            { "t": "篩選", "en": "filter", "ps": "verb" },
            { "t": "手動下載", "en": "manually download", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "標籤 (Labels) 是 GCP 中進行細粒度成本分攤 (Cost Allocation) 的標準機制。透過強制標籤 (如 `vehicle-model: bev`) 並結合 BigQuery Billing Export，可以精確地追蹤共用專案中個別資源的成本，並透過 Data Studio (Looker Studio) 實現自動化報告。選項 (A) 使用多個 Billing Account 管理複雜且會失去跨專案的大量折扣 (Volume Discounts)。選項 (C) Quota 是用於限制資源數量而非金額，且直接停機 (Stop resources) 會影響業務，不是正確的成本「報告」方式。選項 (D) 手動流程無法擴展且缺乏細節。",
        "en": "Labels are the standard mechanism in GCP for granular Cost Allocation. By using mandatory labels (e.g., `vehicle-model: bev`) combined with BigQuery Billing Export, you can precisely track costs of individual resources within shared projects and automate reporting via Data Studio (Looker Studio). Option (A) managing multiple Billing Accounts is complex and may lose Volume Discounts. Option (C) Quotas limit resource counts, not cost directly, and stopping resources impacts business; it's not a \"reporting\" solution. Option (D) manual processes do not scale and lack detail.",
        "wg": [
          { "t": "細粒度", "en": "granular", "ps": "adjective" },
          { "t": "大量折扣", "en": "Volume Discounts", "ps": "noun" }
        ]
      }
    },
    {
      "no": "26",
      "level": "hard",
      "keywords": "Transfer Appliance, Migration, Bandwidth, Hybrid",
      "question": [
        {
          "t": "KnightMotives 希望將位於偏遠工廠的 5 PB 歷史碰撞測試影片數據遷移至 Cloud Storage，以訓練更精確的自動駕駛 AI 模型。",
          "en": "KnightMotives wants to migrate 5 PB of historical crash test video data from remote factories to Cloud Storage to train more accurate autonomous driving AI models.",
          "wg": [
            { "t": "碰撞測試影片", "en": "crash test video", "ps": "noun" },
            { "t": "歷史數據", "en": "historical data", "ps": "noun" }
          ]
        },
        {
          "t": "該工廠目前的網路頻寬僅有 100 Mbps，且大部分頻寬需保留給生產線控制系統。您需要在 1 個月內完成數據遷移。應建議哪種方案？",
          "en": "The factory's current network bandwidth is only 100 Mbps, with most of it reserved for production line control systems. You need to complete the data migration within 1 month. Which solution should you recommend?",
          "wg": [
            { "t": "頻寬", "en": "bandwidth", "ps": "noun" },
            { "t": "保留", "en": "reserved", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 升級網路連線，向電信商申請 10 Gbps 的專用互連 (Dedicated Interconnect)，並使用 Storage Transfer Service 進行線上傳輸。",
          "en": "(A) Upgrade network connectivity by requesting a 10 Gbps Dedicated Interconnect from the carrier and use Storage Transfer Service for online transmission.",
          "wg": [
            { "t": "專用互連", "en": "Dedicated Interconnect", "ps": "noun" },
            { "t": "線上傳輸", "en": "online transmission", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 使用 `gsutil -m` 指令啟用多執行緒上傳，並實作頻寬限制 (Throttling) 以避免影響生產線。",
          "en": "(B) Use the `gsutil -m` command to enable multi-threaded uploads and implement bandwidth throttling to avoid impacting the production line.",
          "wg": [
            { "t": "多執行緒", "en": "multi-threaded", "ps": "adjective" },
            { "t": "頻寬限制", "en": "Throttling", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 訂購 Transfer Appliance。將數據複製到實體設備上，將其運回 Google 上傳資料，然後在雲端進行解密與驗證。",
          "en": "(C) Order Transfer Appliance. Copy data to the physical device, ship it back to Google for upload, and then decrypt and verify in the cloud.",
          "wg": [
            { "t": "實體設備", "en": "physical device", "ps": "noun" },
            { "t": "運回", "en": "ship ... back", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 在地端部署 Storage Transfer Service 代理程式，並設定排程僅在夜間非生產時段進行數據同步。",
          "en": "(D) Deploy Storage Transfer Service agents on-premises and configure schedules to sync data only during non-production hours at night.",
          "wg": [
            { "t": "代理程式", "en": "agents", "ps": "noun" },
            { "t": "非生產時段", "en": "non-production hours", "ps": "noun" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "這是一個典型的「頻寬受限且數據量巨大」的場景。5 PB 的數據在 100 Mbps 的線路下傳輸需要數年時間，完全無法滿足 1 個月的期限。即使是 Dedicated Interconnect (A)，其建設前置時間通常也超過一個月。Transfer Appliance 是唯一能在有限時間與頻寬下遷移 PB 級數據的可行方案（俗稱「卡車頻寬」）。選項 (B) 和 (D) 都受限於物理頻寬，無法按時完成。",
        "en": "This is a classic \"limited bandwidth, massive data\" scenario. Transferring 5 PB over a 100 Mbps line would take years, failing the 1-month deadline completely. Even with Dedicated Interconnect (A), the lead time for construction typically exceeds one month. Transfer Appliance is the only viable solution to migrate PB-scale data under limited time and bandwidth (often called \"Sneakernet\"). Options (B) and (D) are constrained by physical bandwidth and cannot finish on time.",
        "wg": [
          { "t": "頻寬受限", "en": "bandwidth constrained", "ps": "adjective" },
          { "t": "建設前置時間", "en": "construction lead time", "ps": "noun" }
        ]
      }
    },
    {
      "no": "27",
      "level": "hard",
      "keywords": "Vertex AI Pipelines, MLOps, Lineage, Automation",
      "question": [
        {
          "t": "KnightMotives 的 AI 團隊目前使用手動腳本在 VM 上訓練自動駕駛模型。這種方式容易出錯，且缺乏模型的可重現性 (Reproducibility) 與血緣追蹤 (Lineage)，導致難以符合安全稽核要求。",
          "en": "KnightMotives' AI team currently uses manual scripts on VMs to train autonomous driving models. This approach is error-prone and lacks model reproducibility and lineage, making it difficult to meet safety audit requirements.",
          "wg": [
            { "t": "可重現性", "en": "Reproducibility", "ps": "noun" },
            { "t": "血緣追蹤", "en": "Lineage", "ps": "noun" },
            { "t": "安全稽核", "en": "safety audit", "ps": "noun" }
          ]
        },
        {
          "t": "您需要設計一個標準化的 MLOps 流程，自動化數據準備、訓練、評估與部署步驟，並自動記錄所有元數據 (Metadata) 以供追溯。應採用哪項服務？",
          "en": "You need to design a standardized MLOps process that automates data preparation, training, evaluation, and deployment steps, while automatically recording all metadata for traceability. Which service should you adopt?",
          "wg": [
            { "t": "標準化的", "en": "standardized", "ps": "adjective" },
            { "t": "元數據", "en": "Metadata", "ps": "noun" },
            { "t": "追溯", "en": "traceability", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Composer (Airflow) 編排所有訓練任務。將模型參數寫入 Cloud Logging 以供稽核。",
          "en": "(A) Use Cloud Composer (Airflow) to orchestrate all training tasks. Write model parameters to Cloud Logging for auditing.",
          "wg": [
            { "t": "編排", "en": "orchestrate", "ps": "verb" },
            { "t": "參數", "en": "parameters", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 建立 Vertex AI Pipelines。定義 TFX 或 Kubeflow Pipelines (KFP) 元件來串接訓練步驟，利用 Vertex ML Metadata 自動追蹤模型血緣。",
          "en": "(B) Create Vertex AI Pipelines. Define TFX or Kubeflow Pipelines (KFP) components to chain training steps, leveraging Vertex ML Metadata to automatically track model lineage.",
          "wg": [
            { "t": "元件", "en": "components", "ps": "noun" },
            { "t": "串接", "en": "chain", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 使用 Cloud Functions 觸發 Vertex AI Training 作業。當作業完成時，觸發另一個 Function 將模型部署到 Endpoint。",
          "en": "(C) Use Cloud Functions to trigger Vertex AI Training jobs. When a job completes, trigger another Function to deploy the model to an Endpoint.",
          "wg": [
            { "t": "觸發", "en": "trigger", "ps": "verb" },
            { "t": "部署", "en": "deploy", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 在 Dataproc 叢集上執行 PySpark 作業進行訓練，並使用 MLflow 開源伺服器自行管理實驗追蹤。",
          "en": "(D) Run PySpark jobs on a Dataproc cluster for training, and manage experiment tracking yourself using an open-source MLflow server.",
          "wg": [
            { "t": "實驗追蹤", "en": "experiment tracking", "ps": "noun" },
            { "t": "自行管理", "en": "manage ... yourself", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Vertex AI Pipelines 是 Google Cloud 專為 MLOps 設計的全代管服務。它原生整合了 Vertex ML Metadata，能自動記錄每個步驟的輸入、輸出與參數 (Lineage)，完美解決「可重現性」與「稽核」問題。選項 (A) Composer 是通用的工作流程編排工具，缺乏針對 ML 模型的內建元數據管理。選項 (C) Cloud Functions 難以管理複雜的 DAG 依賴關係與參數傳遞。選項 (D) 自建 MLflow 增加了維運負擔 (Toil)，不符合託管服務優先的策略。",
        "en": "Vertex AI Pipelines is Google Cloud's fully managed service designed specifically for MLOps. It natively integrates with Vertex ML Metadata to automatically record inputs, outputs, and parameters for every step (Lineage), perfectly solving the \"reproducibility\" and \"auditing\" issues. Option (A) Composer is a general workflow orchestrator lacking built-in metadata management for ML models. Option (C) Cloud Functions struggle to manage complex DAG dependencies and parameter passing. Option (D) self-hosting MLflow increases operational toil, contradicting the strategy of preferring managed services.",
        "wg": [
          { "t": "全代管服務", "en": "fully managed service", "ps": "noun" },
          { "t": "依賴關係", "en": "dependencies", "ps": "noun" }
        ]
      }
    },
    {
      "no": "28",
      "level": "hard",
      "keywords": "Shared VPC, Network Administration, Separation of Duties, Host Project",
      "question": [
        {
          "t": "KnightMotives 的組織架構複雜，包含「業務團隊」、「AI 研發團隊」與「工廠維運團隊」。中央網路團隊希望集中管理所有網路資源（如子網、防火牆、VPN），但允許各團隊獨立管理自己的應用程式與虛擬機。",
          "en": "KnightMotives has a complex organizational structure, including \"Business Teams,\" \"AI R&D Teams,\" and \"Factory Ops Teams.\" The central network team wants to centrally manage all network resources (subnets, firewalls, VPNs) but allow each team to independently manage their applications and VMs.",
          "wg": [
            { "t": "中央網路團隊", "en": "central network team", "ps": "noun" },
            { "t": "集中管理", "en": "centrally manage", "ps": "verb" },
            { "t": "獨立管理", "en": "independently manage", "ps": "verb" }
          ]
        },
        {
          "t": "您應設計哪種網路拓撲來達成「職責分離」(Separation of Duties)，同時避免複雜的 VPC 對等互連 (VPC Peering) 管理？",
          "en": "Which network topology should you design to achieve \"Separation of Duties\" while avoiding complex VPC Peering management?",
          "wg": [
            { "t": "網路拓撲", "en": "network topology", "ps": "noun" },
            { "t": "職責分離", "en": "Separation of Duties", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 為每個團隊建立獨立的 VPC，並使用 VPN 閘道以 Hub-and-Spoke 模式連接到中央 VPC。",
          "en": "(A) Create separate VPCs for each team and connect them to a central VPC in a Hub-and-Spoke pattern using VPN gateways.",
          "wg": [
            { "t": "獨立的", "en": "separate", "ps": "adjective" },
            { "t": "閘道", "en": "gateways", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 實施共享 VPC (Shared VPC)。指定一個 Host Project 容納網路資源，並將各團隊的專案設定為 Service Projects，授權他們使用特定的子網路。",
          "en": "(B) Implement Shared VPC. Designate a Host Project to house network resources and configure team projects as Service Projects, authorizing them to use specific subnets.",
          "wg": [
            { "t": "共享 VPC", "en": "Shared VPC", "ps": "noun" },
            { "t": "容納", "en": "house", "ps": "verb" },
            { "t": "授權", "en": "authorizing", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 使用 VPC Network Peering 將所有團隊的 VPC 連接在一起，並在每個專案中分別設定防火牆規則。",
          "en": "(C) Use VPC Network Peering to connect all team VPCs together, and configure firewall rules separately in each project.",
          "wg": [
            { "t": "連接", "en": "connect", "ps": "verb" },
            { "t": "分別設定", "en": "configure ... separately", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 將所有團隊的資源都放在同一個大型專案中，使用 IAM 條件限制每個人只能操作特定標籤的 VM。",
          "en": "(D) Place all team resources in a single large project, using IAM conditions to restrict everyone to operating only VMs with specific tags.",
          "wg": [
            { "t": "大型專案", "en": "large project", "ps": "noun" },
            { "t": "操作", "en": "operating", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "共享 VPC (Shared VPC) 是 Google Cloud 實現「網路集中管理，服務分散部署」的標準架構。Host Project 管理員控制子網 IP 範圍、路由與防火牆，而 Service Project 管理員 (各業務團隊) 只能使用被分配的子網建立資源。這完美達成了「職責分離」。選項 (A) 和 (C) 會導致網路碎片化，且 Peering/VPN 在大規模環境下難以維護路由與防火牆一致性。選項 (D) 將所有資源放在單一專案違反了資源隔離與帳單管理的最佳實務。",
        "en": "Shared VPC is the standard Google Cloud architecture for \"centralized network management with decentralized service deployment.\" Host Project admins control subnet IP ranges, routes, and firewalls, while Service Project admins (business teams) can only create resources using assigned subnets. This perfectly achieves \"Separation of Duties.\" Options (A) and (C) lead to network fragmentation, and Peering/VPN are hard to maintain for routing/firewall consistency at scale. Option (D) putting everything in a single project violates resource isolation and billing management best practices.",
        "wg": [
          { "t": "碎片化", "en": "fragmentation", "ps": "noun" },
          { "t": "資源隔離", "en": "resource isolation", "ps": "noun" }
        ]
      }
    },
    {
      "no": "29",
      "level": "hard",
      "keywords": "Cloud IDS, Security, Compliance, Malware Detection",
      "question": [
        {
          "t": "KnightMotives 的資安團隊要求在自動駕駛研發環境中實施更嚴格的監控。由於這些環境涉及許多專用的黑盒測試設備 (Appliances)，無法在其上安裝任何監控代理程式 (Agents)。",
          "en": "KnightMotives' security team requires stricter monitoring in the autonomous driving R&D environment. Since these environments involve many proprietary black-box test appliances, no monitoring agents can be installed on them.",
          "wg": [
            { "t": "黑盒測試設備", "en": "black-box test appliances", "ps": "noun" },
            { "t": "監控代理程式", "en": "monitoring agents", "ps": "noun" }
          ]
        },
        {
          "t": "您需要偵測 VPC 內部的橫向移動 (Lateral Movement)、惡意軟體通訊以及對已知漏洞的攻擊嘗試。解決方案必須是全代管的且不影響網路效能。應選擇哪項服務？",
          "en": "You need to detect Lateral Movement within the VPC, malware communication, and exploit attempts against known vulnerabilities. The solution must be fully managed and not impact network performance. Which service should you choose?",
          "wg": [
            { "t": "橫向移動", "en": "Lateral Movement", "ps": "noun" },
            { "t": "漏洞", "en": "vulnerabilities", "ps": "noun" },
            { "t": "不影響", "en": "not impact", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 啟用 VPC Flow Logs 並將日誌匯出至 BigQuery，撰寫 SQL 查詢來分析異常流量模式。",
          "en": "(A) Enable VPC Flow Logs and export logs to BigQuery, writing SQL queries to analyze anomalous traffic patterns.",
          "wg": [
            { "t": "異常流量模式", "en": "anomalous traffic patterns", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 設定 Packet Mirroring 將流量鏡像到一組運行開源 Suricata IDS 的 Compute Engine 執行個體群組。",
          "en": "(B) Configure Packet Mirroring to mirror traffic to a Compute Engine Instance Group running open-source Suricata IDS.",
          "wg": [
            { "t": "鏡像", "en": "mirror", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 部署 Cloud IDS 端點。這是一個全代管的入侵偵測服務，利用 Palo Alto Networks 的技術進行深度封包檢測 (Deep Packet Inspection)。",
          "en": "(C) Deploy Cloud IDS endpoints. This is a fully managed intrusion detection service leveraging Palo Alto Networks technology for Deep Packet Inspection.",
          "wg": [
            { "t": "入侵偵測服務", "en": "intrusion detection service", "ps": "noun" },
            { "t": "深度封包檢測", "en": "Deep Packet Inspection", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 使用 Google Cloud Armor 的自適應保護 (Adaptive Protection) 功能來自動阻擋 L3/L4 攻擊。",
          "en": "(D) Use Google Cloud Armor's Adaptive Protection feature to automatically block L3/L4 attacks.",
          "wg": [
            { "t": "自適應保護", "en": "Adaptive Protection", "ps": "noun" },
            { "t": "阻擋", "en": "block", "ps": "verb" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "Cloud IDS 是針對「無法安裝 Agent」且需要「深度封包檢測 (DPI)」場景的最佳解決方案。它能偵測惡意軟體 (Malware)、間諜軟體 (Spyware) 與命令控制 (C2) 流量，且完全託管，不會像自行架設 IDS (選項 B) 那樣帶來巨大的維運負擔。選項 (A) VPC Flow Logs 只有「元數據 (Metadata)」(如 IP、Port)，無法看到封包內容，無法偵測 Payload 中的惡意程式。選項 (D) Cloud Armor 主要防禦入站 (Ingress) 攻擊，無法偵測 VPC 內部的橫向移動。",
        "en": "Cloud IDS is the optimal solution for scenarios where \"Agents cannot be installed\" and \"Deep Packet Inspection (DPI)\" is required. It detects malware, spyware, and C2 traffic, and is fully managed, avoiding the massive operational toil of self-hosting IDS (Option B). Option (A) VPC Flow Logs only provide \"Metadata\" (IP, Port), lacking visibility into packet contents to detect malware payloads. Option (D) Cloud Armor primarily defends against Ingress attacks and cannot detect Lateral Movement within the VPC.",
        "wg": [
          { "t": "最佳解決方案", "en": "optimal solution", "ps": "noun" },
          { "t": "封包內容", "en": "packet contents", "ps": "noun" }
        ]
      }
    },
    {
      "no": "30",
      "level": "hard",
      "keywords": "Analytics Hub, Data Monetization, BigQuery, Zero-Copy",
      "question": [
        {
          "t": "KnightMotives 希望實現「數據變現」，將去識別化後的駕駛行為統計數據出售給保險合作夥伴。您需要一個安全、低摩擦 (Low-friction) 的方式來分享這些數據。",
          "en": "KnightMotives wants to achieve \"Data Monetization\" by selling de-identified driving behavior statistics to insurance partners. You need a secure, low-friction way to share this data.",
          "wg": [
            { "t": "去識別化", "en": "de-identified", "ps": "adjective" },
            { "t": "低摩擦", "en": "low-friction", "ps": "adjective" }
          ]
        },
        {
          "t": "解決方案必須避免複製數據 (Zero-Copy) 以降低成本，並允許您管理訂閱者清單，隨時撤銷特定合作夥伴的存取權。應使用哪項 BigQuery 功能？",
          "en": "The solution must avoid copying data (Zero-Copy) to reduce costs and allow you to manage the subscriber list, revoking access for specific partners at any time. Which BigQuery feature should you use?",
          "wg": [
            { "t": "避免複製數據", "en": "avoid copying data", "ps": "verb" },
            { "t": "訂閱者", "en": "subscriber", "ps": "noun" },
            { "t": "撤銷", "en": "revoking", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 BigQuery Data Transfer Service 定期將數據匯出至合作夥伴的 Cloud Storage Bucket。",
          "en": "(A) Use BigQuery Data Transfer Service to periodically export data to partners' Cloud Storage Buckets.",
          "wg": [
            { "t": "定期", "en": "periodically", "ps": "adverb" },
            { "t": "匯出", "en": "export", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 為每個合作夥伴建立授權視圖 (Authorized Views)，並將其新增至合作夥伴的 IAM 權限中。",
          "en": "(B) Create Authorized Views for each partner and add them to the partners' IAM permissions.",
          "wg": [
            { "t": "授權視圖", "en": "Authorized Views", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Analytics Hub 建立數據交換 (Data Exchange) 與列表 (Listing)。合作夥伴訂閱該列表後，數據集會連結到他們的專案中，實現就地查詢。",
          "en": "(C) Use Analytics Hub to create a Data Exchange and Listing. Once partners subscribe to the listing, the dataset is linked to their project, enabling in-place querying.",
          "wg": [
            { "t": "數據交換", "en": "Data Exchange", "ps": "noun" },
            { "t": "就地查詢", "en": "in-place querying", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 將數據匯出為 CSV 檔案並發布到公開的 Web Server，並透過 HTTP Basic Auth 進行密碼保護。",
          "en": "(D) Export data as CSV files and publish them to a public Web Server, protected by HTTP Basic Auth.",
          "wg": [
            { "t": "發布", "en": "publish", "ps": "verb" },
            { "t": "密碼保護", "en": "password protected", "ps": "adjective" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "Analytics Hub 是 BigQuery 專為跨組織數據共享與變現設計的功能。它基於「發布者-訂閱者」模型，允許將數據集作為「列表 (Listing)」發布。訂閱者獲得的是連結資料集 (Linked Dataset)，數據保留在原處 (Zero-Copy)，發布者保有完全控制權並可隨時監控使用情況或撤銷存取。選項 (A) 和 (D) 涉及數據複製，增加了儲存成本且數據一旦發出即失去控制。選項 (B) Authorized Views 雖然不複製數據，但在管理大量外部合作夥伴 (多租戶) 時，權限管理極為繁瑣，不如 Analytics Hub 的訂閱管理機制現代化且可擴展。",
        "en": "Analytics Hub is the BigQuery feature designed specifically for cross-organization data sharing and monetization. Based on a \"Publisher-Subscriber\" model, it allows publishing datasets as \"Listings.\" Subscribers get a Linked Dataset, meaning data stays in place (Zero-Copy). The publisher retains full control and can monitor usage or revoke access anytime. Options (A) and (D) involve data copying, increasing storage costs and losing control once data is sent. Option (B) Authorized Views allow zero-copy but become operationally burdensome when managing many external partners (multi-tenancy), unlike the modern, scalable subscription management of Analytics Hub.",
        "wg": [
          { "t": "跨組織", "en": "cross-organization", "ps": "adjective" },
          { "t": "失去控制", "en": "losing control", "ps": "verb" }
        ]
      }
    },
    {
      "no": "31",
      "level": "hard",
      "keywords": "Cloud Storage, Retention Policy, Compliance, WORM",
      "question": [
        {
          "t": "KnightMotives 的法務部門根據新的監管要求，規定所有的「碰撞安全統計數據 (Crash Safety Statistics)」必須在 Cloud Storage 中保存至少 7年。",
          "en": "KnightMotives' legal department, in accordance with new regulatory requirements, mandates that all \"Crash Safety Statistics\" must be retained in Cloud Storage for at least 7 years.",
          "wg": [
            { "t": "監管要求", "en": "regulatory requirements", "ps": "noun" },
            { "t": "保存", "en": "retained", "ps": "verb" }
          ]
        },
        {
          "t": "在這段期間內，數據必須是不可變的 (Immutable)，即便是擁有最高權限的組織管理員也無法覆寫或刪除這些檔案。您應如何設定儲存桶？",
          "en": "During this period, the data must be Immutable, meaning even Organization Admins with the highest privileges cannot overwrite or delete these files. How should you configure the bucket?",
          "wg": [
            { "t": "不可變的", "en": "Immutable", "ps": "adjective" },
            { "t": "覆寫", "en": "overwrite", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 設定 IAM 策略，移除所有使用者的 `storage.objects.delete` 權限，並啟用 MFA Delete 功能。",
          "en": "(A) Configure IAM policies to remove the `storage.objects.delete` permission for all users, and enable MFA Delete.",
          "wg": [
            { "t": "移除", "en": "remove", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 設定儲存桶鎖定 (Bucket Lock) 並定義保留政策 (Retention Policy) 為 7 年，然後鎖定該政策 (Lock the policy)。",
          "en": "(B) Configure Bucket Lock and define a Retention Policy of 7 years, then Lock the policy.",
          "wg": [
            { "t": "儲存桶鎖定", "en": "Bucket Lock", "ps": "noun" },
            { "t": "保留政策", "en": "Retention Policy", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 啟用物件版本控制 (Object Versioning)，並設定生命週期規則以將非目前版本 (Non-current versions) 保留 7 年。",
          "en": "(C) Enable Object Versioning and configure Lifecycle Rules to keep Non-current versions for 7 years.",
          "wg": [
            { "t": "物件版本控制", "en": "Object Versioning", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 使用 Cloud KMS 的非對稱金鑰加密所有檔案，並將解密私鑰刪除，確保 7 年後才能透過金鑰輪替恢復存取。",
          "en": "(D) Encrypt all files using Cloud KMS asymmetric keys and delete the decryption private key, ensuring access is only restored after 7 years via key rotation.",
          "wg": [
            { "t": "非對稱金鑰", "en": "asymmetric keys", "ps": "noun" },
            { "t": "恢復存取", "en": "restored access", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Bucket Lock (基於保留政策) 是實現 WORM (Write Once, Read Many) 合規性儲存的標準功能。一旦政策被「鎖定 (Locked)」，在保留期到期前，沒有人 (包括管理員) 可以刪除物件或降低保留時間。選項 (A) IAM 權限可以被管理員隨時修改，無法防止惡意內部人員 (Insider Threat)。選項 (C) 版本控制雖然保留歷史紀錄，但管理員仍可手動刪除特定版本。選項 (D) 刪除金鑰會導致資料永久遺失 (Crypto-shredding)，而非保存資料。",
        "en": "Bucket Lock (based on Retention Policy) is the standard feature for achieving WORM (Write Once, Read Many) compliant storage. Once the policy is \"Locked,\" no one (including admins) can delete objects or reduce the retention period until it expires. Option (A) IAM permissions can be modified by admins at any time, failing to prevent Insider Threats. Option (C) Versioning keeps history, but admins can still manually delete specific versions. Option (D) deleting keys results in permanent data loss (Crypto-shredding), not data preservation.",
        "wg": [
          { "t": "合規性儲存", "en": "compliant storage", "ps": "noun" },
          { "t": "惡意內部人員", "en": "Insider Threat", "ps": "noun" }
        ]
      }
    },
    {
      "no": "32",
      "level": "hard",
      "keywords": "Private Service Connect, VPC Peering, IP Overlap, Networking",
      "question": [
        {
          "t": "KnightMotives 收購了一家專門從事「行為研究」的新創公司。該公司在自己的 Google Cloud 組織中運行一套重要的 API 服務，位於 `10.128.0.0/20` 子網。",
          "en": "KnightMotives has acquired a startup specializing in \"behavioral studies.\" This company runs a critical API service in their own Google Cloud Organization, located in the `10.128.0.0/20` subnet.",
          "wg": [
            { "t": "收購", "en": "acquired", "ps": "verb" },
            { "t": "子網", "en": "subnet", "ps": "noun" }
          ]
        },
        {
          "t": "KnightMotives 的核心生產環境 VPC 也使用了相同的 IP 範圍 (IP 重疊)。您需要建立從 KnightMotives VPC 到該 API 服務的私有連線，且不希望透過公共網際網路傳輸。應使用哪種網路解決方案？",
          "en": "KnightMotives' core production VPC uses the same IP range (IP Overlap). You need to establish private connectivity from the KnightMotives VPC to this API service without traversing the public internet. Which networking solution should you use?",
          "wg": [
            { "t": "IP 重疊", "en": "IP Overlap", "ps": "noun" },
            { "t": "私有連線", "en": "private connectivity", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 設定 VPC 網路對等互連 (VPC Network Peering)，並啟用「匯入自訂路由」選項。",
          "en": "(A) Configure VPC Network Peering and enable the \"Import custom routes\" option.",
          "wg": [
            { "t": "網路對等互連", "en": "Network Peering", "ps": "noun" },
            { "t": "匯入", "en": "Import", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 在新創公司的 VPC 中發布該服務為 Private Service Connect (PSC) 服務，並在 KnightMotives VPC 中建立 PSC 端點 (Endpoint) 進行連接。",
          "en": "(B) Publish the service as a Private Service Connect (PSC) service in the startup's VPC, and create a PSC Endpoint in the KnightMotives VPC to connect.",
          "wg": [
            { "t": "發布", "en": "Publish", "ps": "verb" },
            { "t": "端點", "en": "Endpoint", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Cloud VPN 建立兩地之間的連線，並在兩端設定 Cloud Router 使用 NAT 功能 (IP Masquerading) 來隱藏重疊的 IP。",
          "en": "(C) Establish a connection using Cloud VPN, and configure Cloud Router on both ends to use NAT (IP Masquerading) to hide the overlapping IPs.",
          "wg": [
            { "t": "隱藏", "en": "hide", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 將新創公司的應用程式遷移至 App Engine，並使用 Identity-Aware Proxy (IAP) 來控制存取。",
          "en": "(D) Migrate the startup's application to App Engine and use Identity-Aware Proxy (IAP) to control access.",
          "wg": [
            { "t": "遷移", "en": "Migrate", "ps": "verb" },
            { "t": "控制存取", "en": "control access", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Private Service Connect (PSC) 是解決「IP 重疊 (IP Overlap)」與「跨組織私有連線」的最佳方案。它允許服務生產者 (Producer) 將服務透過一個負載平衡器暴露出來，而消費者 (Consumer) 透過自己 VPC 中的一個私有 IP (Endpoint) 存取，完全無需擔心底層 IP 衝突或建立複雜的對等互連關係。選項 (A) VPC Peering 不支援重疊的 IP CIDR，會直接失敗。選項 (C) 雖然 VPN + NAT 技術上可行，但配置複雜度高 (Toil) 且效能不如 PSC。選項 (D) 遷移應用程式 (Replatforming) 成本過高且非網路層面的解決方案。",
        "en": "Private Service Connect (PSC) is the optimal solution for \"IP Overlap\" and \"cross-organization private connectivity.\" It allows the service Producer to expose a service via a Load Balancer, while the Consumer accesses it via a private IP (Endpoint) in their own VPC, completely bypassing underlying IP conflicts or complex peering relationships. Option (A) VPC Peering does not support overlapping IP CIDRs and will fail. Option (C) while VPN + NAT is technically possible, it introduces high complexity (Toil) and lower performance compared to PSC. Option (D) Replatforming the application is too costly and not a network-level solution.",
        "wg": [
          { "t": "最佳方案", "en": "optimal solution", "ps": "noun" },
          { "t": "底層 IP 衝突", "en": "underlying IP conflicts", "ps": "noun" }
        ]
      }
    },
    {
      "no": "33",
      "level": "hard",
      "keywords": "GKE Autopilot, Operational Efficiency, Security, Kubernetes",
      "question": [
        {
          "t": "KnightMotives 希望透過容器化技術「現代化」其傳統應用程式，但目前的 IT 團隊缺乏 Kubernetes 的深層管理經驗，且公司目標是「減少維運負擔」。",
          "en": "KnightMotives wants to \"modernize\" its legacy applications via containerization, but the current IT team lacks deep Kubernetes management experience, and the corporate goal is to \"reduce operational toil.\"",
          "wg": [
            { "t": "深層管理經驗", "en": "deep management experience", "ps": "noun" },
            { "t": "維運負擔", "en": "operational toil", "ps": "noun" }
          ]
        },
        {
          "t": "資安長要求所有叢集必須預設遵循 Google 的安全最佳實踐 (如遮蔽節點存取、強制執行安全政策)。您應選擇哪種運算平台？",
          "en": "The CISO requires that all clusters must adhere to Google's security best practices by default (e.g., restricted node access, enforced security policies). Which compute platform should you choose?",
          "wg": [
            { "t": "預設遵循", "en": "adhere to ... by default", "ps": "verb" },
            { "t": "遮蔽", "en": "restricted", "ps": "adjective" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) Google Kubernetes Engine (GKE) Standard 模式，並使用 Terraform 自動化節點池的升級與維護。",
          "en": "(A) Google Kubernetes Engine (GKE) Standard mode, using Terraform to automate node pool upgrades and maintenance.",
          "wg": [
            { "t": "標準模式", "en": "Standard mode", "ps": "noun" },
            { "t": "自動化", "en": "automate", "ps": "verb" }
          ]
        },
        {
          "t": "(B) Compute Engine 託管執行個體群組 (MIG)，並在 VM 上安裝 Docker Swarm 進行編排。",
          "en": "(B) Compute Engine Managed Instance Groups (MIG), installing Docker Swarm on VMs for orchestration.",
          "wg": [
            { "t": "編排", "en": "orchestration", "ps": "noun" }
          ]
        },
        {
          "t": "(C) Google Kubernetes Engine (GKE) Autopilot 模式。",
          "en": "(C) Google Kubernetes Engine (GKE) Autopilot mode.",
          "wg": [
            { "t": "Autopilot 模式", "en": "Autopilot mode", "ps": "noun" }
          ]
        },
        {
          "t": "(D) Cloud Run，並透過 Cloud Deploy 管理發布流程。",
          "en": "(D) Cloud Run, managing the release process via Cloud Deploy.",
          "wg": [
            { "t": "發布流程", "en": "release process", "ps": "noun" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "GKE Autopilot 是專為「減少維運負擔」與「預設安全」設計的 GKE 運作模式。Google 全權管理節點 (Nodes)、擴展與修補，使用者只需關注 Pod。Autopilot 預設啟用多項安全功能 (如 Workload Identity, Shielded Nodes)，禁止特權容器，完全符合資安長與團隊技能不足的需求。選項 (A) GKE Standard 需要使用者自行管理節點池與安全硬化 (Hardening)，維運負擔較高。選項 (D) Cloud Run 雖是無伺服器，但對於需要完整 K8s API 相容性的遷移場景 (Legacy App)，GKE Autopilot 通常更適合。",
        "en": "GKE Autopilot is the GKE mode of operation designed specifically for \"reducing operational toil\" and \"security by default.\" Google fully manages nodes, scaling, and patching; users only focus on Pods. Autopilot enables various security features by default (e.g., Workload Identity, Shielded Nodes) and disallows privileged containers, perfectly matching the CISO's needs and the team's skill gap. Option (A) GKE Standard requires user management of node pools and security hardening, implying higher toil. Option (D) Cloud Run is serverless, but for migration scenarios requiring full K8s API compatibility (Legacy App), GKE Autopilot is often a better fit.",
        "wg": [
          { "t": "全權管理", "en": "fully manages", "ps": "verb" },
          { "t": "安全硬化", "en": "security hardening", "ps": "noun" }
        ]
      }
    },
    {
      "no": "34",
      "level": "hard",
      "keywords": "Cloud SQL, High Availability, Maintenance, Migration",
      "question": [
        {
          "t": "KnightMotives 正將其舊有的 ERP 系統遷移至 Cloud SQL for PostgreSQL。該系統支援「經銷商折扣」計算，對可用性要求極高。",
          "en": "KnightMotives is migrating its legacy ERP system to Cloud SQL for PostgreSQL. This system supports \"dealer discount\" calculations and has extremely high availability requirements.",
          "wg": [
            { "t": "遷移", "en": "migrating", "ps": "verb" },
            { "t": "極高", "en": "extremely high", "ps": "adjective" }
          ]
        },
        {
          "t": "您需要確保資料庫能夠在發生區域性 (Zonal) 故障時自動復原，並且在定期維護更新期間將停機時間降至最低 (< 60 秒)。應如何配置 Cloud SQL？",
          "en": "You need to ensure the database can automatically recover from Zonal failures and minimize downtime (< 60 seconds) during periodic maintenance updates. How should you configure Cloud SQL?",
          "wg": [
            { "t": "區域性故障", "en": "Zonal failures", "ps": "noun" },
            { "t": "定期維護", "en": "periodic maintenance", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 建立單一區域 (Single Zone) 執行個體，並設定每 10 分鐘進行一次自動備份。故障時從備份還原。",
          "en": "(A) Create a Single Zone instance and configure automatic backups every 10 minutes. Restore from backup upon failure.",
          "wg": [
            { "t": "自動備份", "en": "automatic backups", "ps": "noun" },
            { "t": "還原", "en": "Restore", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 啟用高可用性 (High Availability, HA) 配置，並設定維護視窗 (Maintenance Window) 在業務離峰時間。這將建立一個同步的待命 (Standby) 執行個體。",
          "en": "(B) Enable High Availability (HA) configuration and set the Maintenance Window to off-peak hours. This creates a synchronous Standby instance.",
          "wg": [
            { "t": "高可用性", "en": "High Availability (HA)", "ps": "noun" },
            { "t": "待命", "en": "Standby", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 建立一個主執行個體與一個跨區域唯讀複本 (Cross-Region Read Replica)。故障時手動將唯讀複本提升為主機。",
          "en": "(C) Create a primary instance and a Cross-Region Read Replica. Manually promote the read replica to primary upon failure.",
          "wg": [
            { "t": "提升", "en": "promote", "ps": "verb" },
            { "t": "手動", "en": "Manually", "ps": "adverb" }
          ]
        },
        {
          "t": "(D) 使用 Cloud Spanner 取代 Cloud SQL，因為只有 Spanner 能提供零停機維護。",
          "en": "(D) Use Cloud Spanner instead of Cloud SQL, as only Spanner offers zero-downtime maintenance.",
          "wg": [
            { "t": "取代", "en": "instead of", "ps": "preposition" },
            { "t": "零停機", "en": "zero-downtime", "ps": "adjective" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Cloud SQL 的高可用性 (HA) 配置使用同步複寫 (Synchronous Replication) 將數據寫入另一個區域的待命實例。當發生區域故障或進行維護時，Cloud SQL 會自動故障轉移 (Failover) 至待命實例，通常在 60 秒內完成，且不遺失數據。這符合題目對「自動復原」與「最小停機時間」的要求。選項 (A) 還原備份耗時太長 (RTO 高)。選項 (C) 唯讀複本使用非同步複寫 (Asynchronous)，提升為主機可能遺失數據且需要手動介入。選項 (D) 雖然 Spanner 很強，但 ERP 系統 (PostgreSQL) 的遷移成本極高，不需要為了 HA 犧牲相容性。",
        "en": "Cloud SQL's High Availability (HA) configuration uses synchronous replication to write data to a standby instance in another zone. In the event of a zonal failure or maintenance, Cloud SQL automatically fails over to the standby, typically within 60 seconds with no data loss. This meets the requirements for \"automatic recovery\" and \"minimal downtime.\" Option (A) restoring from backup takes too long (high RTO). Option (C) Read Replicas use asynchronous replication; promotion may lose data and requires manual intervention. Option (D) while Spanner is powerful, migrating an ERP system (PostgreSQL) is too costly/complex to justify when Cloud SQL HA suffices.",
        "wg": [
          { "t": "同步複寫", "en": "Synchronous Replication", "ps": "noun" },
          { "t": "故障轉移", "en": "Failover", "ps": "noun" }
        ]
      }
    },
    {
      "no": "35",
      "level": "hard",
      "keywords": "Document AI, Workflows, Automation, Serverless",
      "question": [
        {
          "t": "KnightMotives 希望提升維修技術人員的效率。目前技術人員需手動輸入紙本維修日誌，導致數據錯誤與延遲。目標是自動化此流程：技術人員上傳掃描檔，系統自動提取結構化數據並存入資料庫。",
          "en": "KnightMotives wants to improve service technician efficiency. Currently, technicians manually enter paper service logs, leading to data errors and delays. The goal is to automate this: technicians upload scans, and the system automatically extracts structured data into a database.",
          "wg": [
            { "t": "手動輸入", "en": "manually enter", "ps": "verb" },
            { "t": "提取", "en": "extracts", "ps": "verb" },
            { "t": "結構化數據", "en": "structured data", "ps": "noun" }
          ]
        },
        {
          "t": "您需要設計一個無伺服器架構來處理此工作流程，並確保能處理複雜的審核邏輯（例如：若信心分數過低則通知人工審核）。應選擇哪組產品？",
          "en": "You need to design a serverless architecture to handle this workflow, ensuring capability to handle complex approval logic (e.g., notify human review if confidence score is low). Which combination of products should you choose?",
          "wg": [
            { "t": "無伺服器架構", "en": "serverless architecture", "ps": "noun" },
            { "t": "信心分數", "en": "confidence score", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) Cloud Storage 觸發 Cloud Functions。在函式中呼叫 Vision API 進行 OCR，並使用 `if/else` 程式碼處理邏輯。",
          "en": "(A) Cloud Storage triggers Cloud Functions. Inside the function, call Vision API for OCR and use `if/else` code for logic.",
          "wg": [
            { "t": "觸發", "en": "triggers", "ps": "verb" },
            { "t": "處理邏輯", "en": "handle logic", "ps": "verb" }
          ]
        },
        {
          "t": "(B) Cloud Storage 透過 Eventarc 觸發 Workflows。Workflows 協調 Document AI 進行表單解析 (Form Parser)，並根據信心分數決定是寫入 Firestore 還是建立人工審核任務。",
          "en": "(B) Cloud Storage triggers Workflows via Eventarc. Workflows orchestrates Document AI for Form Parser, and based on confidence scores, decides whether to write to Firestore or create a human review task.",
          "wg": [
            { "t": "協調", "en": "orchestrates", "ps": "verb" },
            { "t": "人工審核任務", "en": "human review task", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 AI Platform Data Labeling Service 建立標註任務，讓外包人員手動轉錄所有上傳的檔案。",
          "en": "(C) Use AI Platform Data Labeling Service to create labeling tasks, having outsourced personnel manually transcribe all uploaded files.",
          "wg": [
            { "t": "標註任務", "en": "labeling tasks", "ps": "noun" },
            { "t": "轉錄", "en": "transcribe", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 將圖片上傳至 BigQuery，使用 BigQuery ML 的 Object Table 功能與 Remote Functions 呼叫自訂的 Python 腳本進行解析。",
          "en": "(D) Upload images to BigQuery, using BigQuery ML's Object Table feature and Remote Functions to call custom Python scripts for parsing.",
          "wg": [
            { "t": "呼叫", "en": "call", "ps": "verb" },
            { "t": "解析", "en": "parsing", "ps": "noun" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Document AI 是專門用於從非結構化文件 (如 PDF、表單) 提取結構化數據的服務，比單純的 OCR (Vision API) 更適合處理維修日誌。Workflows 是協調複雜業務邏輯 (如信心分數判斷、分支處理) 的最佳無伺服器工具，比在 Cloud Functions 中編寫大量義大利麵條式程式碼 (Spaghetti Code) 更易於維護與視覺化。Eventarc 則負責連接 Storage 事件與 Workflows。選項 (A) Vision API 缺乏表單理解能力。選項 (C) 仍依賴人工，無法達成「自動化」。",
        "en": "Document AI is the service specialized for extracting structured data from unstructured documents (like PDFs, forms), making it superior to simple OCR (Vision API) for service logs. Workflows is the best serverless tool for orchestrating complex business logic (e.g., confidence score decisions, branching), offering better maintainability and visualization than writing massive spaghetti code in Cloud Functions. Eventarc connects Storage events to Workflows. Option (A) Vision API lacks form understanding capabilities. Option (C) still relies on manual labor, failing the \"automation\" goal.",
        "wg": [
          { "t": "非結構化文件", "en": "unstructured documents", "ps": "noun" },
          { "t": "義大利麵條式程式碼", "en": "Spaghetti Code", "ps": "noun" }
        ]
      }
    },
    {
      "no": "36",
      "level": "hard",
      "keywords": "Access Transparency, Access Approval, Compliance, Security",
      "question": [
        {
          "t": "KnightMotives 正在將其核心自動駕駛數據平台遷移至 Google Cloud。由於這些數據包含極度敏感的智慧財產權，且受到嚴格的監管要求，法務部門要求必須具備「完全的可視性與控制權」。",
          "en": "KnightMotives is migrating its core autonomous driving data platform to Google Cloud. Because this data contains highly sensitive intellectual property and is subject to strict regulatory requirements, the legal department demands \"complete visibility and control.\"",
          "wg": [
            { "t": "智慧財產權", "en": "intellectual property", "ps": "noun" },
            { "t": "可視性", "en": "visibility", "ps": "noun" },
            { "t": "控制權", "en": "control", "ps": "noun" }
          ]
        },
        {
          "t": "具體而言，您必須確保當 Google 的支援工程師為了排除故障而需要存取您的內容或設定時，系統必須先徵求您的明確批准，並產生包含存取理由的詳細稽核日誌。應啟用哪兩項服務？",
          "en": "Specifically, you must ensure that when Google support engineers need to access your content or configuration for troubleshooting, the system must first request your explicit approval and generate a detailed audit log containing the justification for access. Which two services should you enable?",
          "wg": [
            { "t": "明確批准", "en": "explicit approval", "ps": "noun" },
            { "t": "存取理由", "en": "justification for access", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 啟用 VPC Service Controls 以建立服務邊界，並設定 Cloud Audit Logs 的資料存取日誌 (Data Access Logs)。",
          "en": "(A) Enable VPC Service Controls to create a service perimeter, and configure Cloud Audit Logs' Data Access Logs.",
          "wg": [
            { "t": "資料存取日誌", "en": "Data Access Logs", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 實施 Cloud EKM (外部金鑰管理)，並設定金鑰存取理由 (Key Access Justifications) 政策，以拒絕所有來自 Google 內部的解密請求。",
          "en": "(B) Implement Cloud EKM (External Key Management) and configure Key Access Justifications policies to deny all decryption requests from within Google.",
          "wg": [
            { "t": "金鑰存取理由", "en": "Key Access Justifications", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 啟用 Access Transparency 與 Access Approval。設定 Access Approval 規則，要求所有 Google 員工的存取請求都必須透過電子郵件發送給指定的資安團隊成員進行審核。",
          "en": "(C) Enable Access Transparency and Access Approval. Configure Access Approval rules to require that all access requests from Google employees be sent via email to designated security team members for review.",
          "wg": [
            { "t": "審核", "en": "review", "ps": "noun" },
            { "t": "指定的", "en": "designated", "ps": "adjective" }
          ]
        },
        {
          "t": "(D) 使用 Chronicle Security Operations 來監控所有 API 活動，並建立警報規則，當偵測到來自 Google IP 範圍的流量時立即通知。",
          "en": "(D) Use Chronicle Security Operations to monitor all API activity and create alert rules to notify immediately when traffic from Google IP ranges is detected.",
          "wg": [
            { "t": "偵測到", "en": "detected", "ps": "verb" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "Access Transparency 提供關於 Google 員工何時以及為何存取您內容的日誌 (這是 Cloud Audit Logs 做不到的)。Access Approval 則更進一步，允許客戶「批准或拒絕」這些存取請求。這兩者的結合完全滿足了法務部門對「可視性 (Transparency)」與「控制權 (Approval)」的嚴格要求。選項 (A) 僅記錄使用者活動，無法記錄 Google 支援人員的後台存取。選項 (B) 僅控制金鑰解密，無法控制對未加密資源或配置的存取。選項 (D) 是一種被動監控，無法主動控制或批准。",
        "en": "Access Transparency provides logs on when and why Google employees access your content (which Cloud Audit Logs cannot do). Access Approval goes a step further, allowing customers to \"approve or deny\" these access requests. The combination perfectly meets the legal department's strict requirements for \"visibility (Transparency)\" and \"control (Approval).\" Option (A) only logs user activity, not Google support's backend access. Option (B) only controls key decryption, not access to unencrypted resources or configurations. Option (D) is reactive monitoring and cannot proactively control or approve access.",
        "wg": [
          { "t": "後台存取", "en": "backend access", "ps": "noun" },
          { "t": "被動監控", "en": "reactive monitoring", "ps": "noun" }
        ]
      }
    },
    {
      "no": "37",
      "level": "hard",
      "keywords": "Cloud DNS, Hybrid Connectivity, Forwarding Zones, Resolution",
      "question": [
        {
          "t": "KnightMotives 的地端資料中心已透過 Interconnect 連接至 Google Cloud。為了支援混合雲應用程式的開發，地端的舊有伺服器需要能夠解析 Google Cloud 中 GKE 服務的內部 DNS 名稱 (例如 `service.cluster.local`)。",
          "en": "KnightMotives' on-premises data centers are connected to Google Cloud via Interconnect. To support hybrid cloud application development, legacy on-premises servers need to resolve internal DNS names of GKE services in Google Cloud (e.g., `service.cluster.local`).",
          "wg": [
            { "t": "解析", "en": "resolve", "ps": "verb" },
            { "t": "內部 DNS 名稱", "en": "internal DNS names", "ps": "noun" }
          ]
        },
        {
          "t": "同時，Google Cloud 中的 VM 也需要解析地端資料庫的主機名稱 (`db.knightmotives.corp`)。您需要設計一個 DNS 架構來實現雙向解析，且無需管理額外的 VM 轉發器。",
          "en": "Simultaneously, VMs in Google Cloud need to resolve on-premises database hostnames (`db.knightmotives.corp`). You need to design a DNS architecture to achieve bidirectional resolution without managing additional VM forwarders.",
          "wg": [
            { "t": "雙向解析", "en": "bidirectional resolution", "ps": "noun" },
            { "t": "轉發器", "en": "forwarders", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 在 Cloud DNS 中設定入站伺服器政策 (Inbound Server Policy) 供地端查詢，並設定出站轉發區域 (Outbound Forwarding Zone) 將 `.corp` 查詢轉送至地端 DNS 伺服器。",
          "en": "(A) Configure a Cloud DNS Inbound Server Policy for on-premises queries, and set up an Outbound Forwarding Zone to forward `.corp` queries to on-premises DNS servers.",
          "wg": [
            { "t": "入站伺服器政策", "en": "Inbound Server Policy", "ps": "noun" },
            { "t": "出站轉發區域", "en": "Outbound Forwarding Zone", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 在地端 DNS 伺服器中新增區域轉送 (Zone Transfer)，將 Google Cloud 的 DNS 記錄定期複製到地端，並在 Cloud DNS 中匯入地端的 Zone 檔案。",
          "en": "(B) Add Zone Transfer in on-premises DNS servers to periodically copy Google Cloud DNS records to on-premises, and import on-premises Zone files into Cloud DNS.",
          "wg": [
            { "t": "區域轉送", "en": "Zone Transfer", "ps": "noun" },
            { "t": "匯入", "en": "import", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 為每個 VPC 網路部署一組自訂的 BIND DNS 伺服器 (在 Compute Engine 上)，並配置 Cloud Router 透過 BGP 廣播這些伺服器的 IP。",
          "en": "(C) Deploy a set of custom BIND DNS servers (on Compute Engine) for each VPC network, and configure Cloud Router to advertise these servers' IPs via BGP.",
          "wg": [
            { "t": "自訂的", "en": "custom", "ps": "adjective" },
            { "t": "廣播", "en": "advertise", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 使用 Directory API 將地端服務註冊到 Service Directory，並允許 GKE 的 CoreDNS 直接查詢 Service Directory 的 private zone。",
          "en": "(D) Use the Directory API to register on-premises services into Service Directory, and allow GKE's CoreDNS to query the Service Directory private zone directly.",
          "wg": [
            { "t": "註冊", "en": "register", "ps": "verb" },
            { "t": "直接查詢", "en": "query ... directly", "ps": "verb" }
          ]
        }
      ],
      "answer": "(A)",
      "why": {
        "t": "Cloud DNS 的入站 (Inbound) 與出站 (Outbound) 功能是實現混合雲雙向 DNS 解析的標準全代管解決方案。入站政策會建立一個轉發 IP，供地端 DNS 伺服器將請求轉送至雲端；出站轉發區域則允許雲端資源查詢地端 DNS。這完全不需要管理 VM (如選項 C 的 BIND)，也不涉及複雜且不即時的區域轉送 (選項 B)。選項 (D) Service Directory 主要用於服務探索，雖然有關聯，但標準的 DNS 解析需求應由 Cloud DNS 處理。",
        "en": "Cloud DNS Inbound and Outbound features are the standard fully managed solution for hybrid cloud bidirectional DNS resolution. The Inbound policy creates a forwarding IP for on-prem DNS servers to send requests to the cloud; the Outbound forwarding zone allows cloud resources to query on-prem DNS. This requires no VM management (unlike Option C's BIND) and avoids complex, non-real-time Zone Transfers (Option B). Option (D) Service Directory is for service discovery; while related, standard DNS resolution needs are best handled by Cloud DNS.",
        "wg": [
          { "t": "標準全代管解決方案", "en": "standard fully managed solution", "ps": "noun" },
          { "t": "不即時", "en": "non-real-time", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "38",
      "level": "hard",
      "keywords": "BigQuery, Partitioning, Clustering, Performance Optimization",
      "question": [
        {
          "t": "KnightMotives 的「數據變現」團隊發現 BigQuery 的分析成本過高。分析師主要查詢過去 30 天內的遙測數據，並且總是會根據「車輛型號 (VehicleModel)」與「地區 (Region)」進行篩選。",
          "en": "KnightMotives' \"Data Monetization\" team finds BigQuery analytics costs excessively high. Analysts primarily query telemetry data from the last 30 days and always filter by \"VehicleModel\" and \"Region.\"",
          "wg": [
            { "t": "分析成本", "en": "analytics costs", "ps": "noun" },
            { "t": "篩選", "en": "filter", "ps": "verb" }
          ]
        },
        {
          "t": "目前的資料表包含數 PB 的歷史數據，且未經優化。您需要重新設計資料表架構，以大幅減少查詢掃描的位元組數 (Bytes Scanned) 並提升查詢速度。應採取哪種策略？",
          "en": "The current table contains petabytes of historical data and is unoptimized. You need to redesign the table schema to significantly reduce query bytes scanned and improve query speed. Which strategy should you adopt?",
          "wg": [
            { "t": "未經優化", "en": "unoptimized", "ps": "adjective" },
            { "t": "查詢掃描的位元組數", "en": "query bytes scanned", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 根據 `VehicleModel` 進行分區 (Partitioning)，並根據 `Timestamp` 進行叢集 (Clustering)。",
          "en": "(A) Partition by `VehicleModel` and Cluster by `Timestamp`.",
          "wg": [
            { "t": "分區", "en": "Partitioning", "ps": "noun" },
            { "t": "叢集", "en": "Clustering", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 為每個 `VehicleModel` 建立單獨的資料表 (Sharding)，並使用萬用字元查詢 (Wildcard Queries) 來跨表分析。",
          "en": "(B) Create separate tables (Sharding) for each `VehicleModel` and use Wildcard Queries for cross-table analysis.",
          "wg": [
            { "t": "萬用字元查詢", "en": "Wildcard Queries", "ps": "noun" },
            { "t": "跨表分析", "en": "cross-table analysis", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 BI Engine 將所有熱數據快取在記憶體中，並購買固定費率 (Flat-rate) 的 Slot 容量。",
          "en": "(C) Use BI Engine to cache all hot data in memory and purchase Flat-rate Slot capacity.",
          "wg": [
            { "t": "熱數據", "en": "hot data", "ps": "noun" },
            { "t": "固定費率", "en": "Flat-rate", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 根據 `IngestionTime` (或時間戳記欄位) 進行分區 (Partitioning)，並根據 `VehicleModel` 與 `Region` 進行叢集 (Clustering)。",
          "en": "(D) Partition by `IngestionTime` (or timestamp column) and Cluster by `VehicleModel` and `Region`.",
          "wg": [
            { "t": "時間戳記欄位", "en": "timestamp column", "ps": "noun" }
          ]
        }
      ],
      "answer": "(D)",
      "why": {
        "t": "在 BigQuery 中，最佳實踐是根據查詢模式中最常用來定義時間範圍的欄位進行「分區 (Partitioning)」，這能直接修剪 (Prune) 掉不需要掃描的歷史分區 (如過去 30 天以外的數據)。接著，針對高基數 (High Cardinality) 且常用的篩選欄位 (如車型、地區) 進行「叢集 (Clustering)」，這能進一步將相關數據物理排序在一起，減少掃描量。選項 (A) BigQuery 每個表的分區數有限制 (4000)，若以車型分區可能會超過限制且管理困難。選項 (B) Sharding 是舊技術，效能差且難以維護。選項 (C) BI Engine 能加速但不解決底層掃描成本問題。",
        "en": "In BigQuery, the best practice is to \"Partition\" by the field most used for time-range filtering, which directly prunes historical partitions (e.g., data older than 30 days) from the scan. Then, \"Cluster\" by high-cardinality, frequently filtered fields (like Vehicle Model, Region) to physically colocate related data, further reducing scanning. Option (A) BigQuery has a limit on partitions per table (4000); partitioning by VehicleModel might exceed this and is hard to manage. Option (B) Sharding is a legacy technique with poor performance and high maintenance. Option (C) BI Engine accelerates queries but doesn't solve the underlying scan cost issue.",
        "wg": [
          { "t": "修剪", "en": "Prune", "ps": "verb" },
          { "t": "高基數", "en": "High Cardinality", "ps": "noun" }
        ]
      }
    },
    {
      "no": "39",
      "level": "hard",
      "keywords": "Multi-Cluster Ingress, GKE, Disaster Recovery, High Availability",
      "question": [
        {
          "t": "KnightMotives 的「車內體驗」後端服務運行在 GKE 上。為了符合「全球規模」與高可用性需求，該服務必須部署在多個地區 (Regions)，且具備單一全球入口 IP。",
          "en": "KnightMotives' \"in-vehicle experience\" backend service runs on GKE. To meet \"global scale\" and high availability requirements, the service must be deployed across multiple Regions and have a single global entry IP.",
          "wg": [
            { "t": "單一全球入口 IP", "en": "single global entry IP", "ps": "noun" },
            { "t": "多個地區", "en": "multiple Regions", "ps": "noun" }
          ]
        },
        {
          "t": "當使用者駕車跨越國界或某個雲端區域發生故障時，流量必須能智慧地導向最近且健康的叢集，且對客戶端完全透明。您應建議哪種架構？",
          "en": "When a user drives across borders or a cloud region fails, traffic must be intelligently routed to the nearest healthy cluster, completely transparent to the client. Which architecture should you recommend?",
          "wg": [
            { "t": "智慧地導向", "en": "intelligently routed", "ps": "verb" },
            { "t": "完全透明", "en": "completely transparent", "ps": "adjective" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 在每個地區部署獨立的 GKE 叢集與區域負載平衡器。在客戶端應用程式中實作邏輯，偵測延遲並切換 API 端點。",
          "en": "(A) Deploy independent GKE clusters and Regional Load Balancers in each region. Implement logic in the client application to detect latency and switch API endpoints.",
          "wg": [
            { "t": "切換", "en": "switch", "ps": "verb" },
            { "t": "偵測延遲", "en": "detect latency", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 啟用 GKE Enterprise (Anthos) 並設定 Multi-Cluster Ingress (MCI)。使用 MultiClusterService (MCS) 資源來定義跨叢集服務，並由 MCI 控制器自動管理全球流量路由。",
          "en": "(B) Enable GKE Enterprise (Anthos) and configure Multi-Cluster Ingress (MCI). Use MultiClusterService (MCS) resources to define cross-cluster services, with the MCI controller automatically managing global traffic routing.",
          "wg": [
            { "t": "跨叢集服務", "en": "cross-cluster services", "ps": "noun" },
            { "t": "流量路由", "en": "traffic routing", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Cloud DNS 的地理位置路由策略，將流量分配給不同地區的 GKE Ingress IP。設定健康檢查以在 DNS 層級進行故障轉移。",
          "en": "(C) Use Cloud DNS Geolocation routing policy to distribute traffic to GKE Ingress IPs in different regions. Configure health checks to perform failover at the DNS level.",
          "wg": [
            { "t": "地理位置路由策略", "en": "Geolocation routing policy", "ps": "noun" },
            { "t": "DNS 層級", "en": "DNS level", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 建立一個包含多個區域節點池 (Multi-zonal Node Pools) 的單一 GKE 叢集，並將節點池跨越不同的地理區域 (Regions)。",
          "en": "(D) Create a single GKE cluster with Multi-zonal Node Pools, spanning node pools across different geographical Regions.",
          "wg": [
            { "t": "跨越", "en": "spanning", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Multi-Cluster Ingress (MCI) 是 Google Cloud 針對 GKE 的原生多叢集負載平衡解決方案。它透過單一 Anycast IP (VIP) 接收全球流量，並根據鄰近性 (Proximity) 與健康狀態將流量路由至適當的叢集。這完全符合「單一全球入口」、「智慧路由」與「透明故障轉移」的需求。選項 (A) 加重了客戶端的複雜度。選項 (C) DNS 路由受限於 TTL 且無法像負載平衡器那樣即時感知後端容量與健康。選項 (D) GKE 叢集不能跨越 Region (只能跨 Zone)，因此技術上不可行。",
        "en": "Multi-Cluster Ingress (MCI) is Google Cloud's native multi-cluster load balancing solution for GKE. It accepts global traffic via a single Anycast IP (VIP) and routes it to the appropriate cluster based on proximity and health. This perfectly aligns with \"single global entry,\" \"intelligent routing,\" and \"transparent failover.\" Option (A) burdens the client with complexity. Option (C) DNS routing is limited by TTL and lacks real-time awareness of backend capacity/health like a Load Balancer. Option (D) GKE clusters cannot span Regions (only Zones), so it is technically impossible.",
        "wg": [
          { "t": "原生", "en": "native", "ps": "adjective" },
          { "t": "鄰近性", "en": "Proximity", "ps": "noun" }
        ]
      }
    },
    {
      "no": "40",
      "level": "hard",
      "keywords": "Cloud Trace, Cloud Profiler, Microservices, Latency",
      "question": [
        {
          "t": "KnightMotives 的「線上訂購系統」已重構為運行在 GKE 上的數十個微服務。用戶投訴在結帳流程中偶爾會遇到高延遲。",
          "en": "KnightMotives' \"online ordering system\" has been refactored into dozens of microservices running on GKE. Users complain about occasional high latency during the checkout process.",
          "wg": [
            { "t": "重構", "en": "refactored", "ps": "verb" },
            { "t": "偶爾", "en": "occasional", "ps": "adjective" }
          ]
        },
        {
          "t": "由於服務調用鏈 (Call Chain) 很深，開發團隊難以定位瓶頸是在哪個服務或資料庫查詢中。您需要導入工具來視覺化請求路徑並分析程式碼效能。應使用哪兩項服務？（請選擇兩項）",
          "en": "Because the call chain is deep, the development team struggles to pinpoint whether the bottleneck is in a specific service or a database query. You need to introduce tools to visualize request paths and analyze code performance. Which two services should you use? (Choose two)",
          "wg": [
            { "t": "調用鏈", "en": "Call Chain", "ps": "noun" },
            { "t": "定位瓶頸", "en": "pinpoint the bottleneck", "ps": "verb" },
            { "t": "視覺化", "en": "visualize", "ps": "verb" }
          ]
        }
      ],
      "type": "複選題",
      "options": [
        {
          "t": "(A) Cloud Trace：用於分散式追蹤，蒐集並視覺化跨微服務的請求延遲與瀑布圖。",
          "en": "(A) Cloud Trace: For distributed tracing, collecting and visualizing request latency and waterfall graphs across microservices.",
          "wg": [
            { "t": "分散式追蹤", "en": "distributed tracing", "ps": "noun" },
            { "t": "瀑布圖", "en": "waterfall graphs", "ps": "noun" }
          ]
        },
        {
          "t": "(B) Cloud Logging：將所有微服務的標準輸出 (stdout) 匯出至 BigQuery，並使用 SQL 關聯請求 ID。",
          "en": "(B) Cloud Logging: Export stdout from all microservices to BigQuery and use SQL to correlate request IDs.",
          "wg": [
            { "t": "關聯", "en": "correlate", "ps": "verb" }
          ]
        },
        {
          "t": "(C) Cloud Monitoring：為每個微服務設定 Uptime Checks，並在延遲超過閾值時發送警報。",
          "en": "(C) Cloud Monitoring: Configure Uptime Checks for each microservice and alert when latency exceeds a threshold.",
          "wg": [
            { "t": "閾值", "en": "threshold", "ps": "noun" }
          ]
        },
        {
          "t": "(D) VPC Flow Logs：分析微服務之間的網路封包傳輸時間，以識別網路層級的延遲。",
          "en": "(D) VPC Flow Logs: Analyze network packet transmission times between microservices to identify network-level latency.",
          "wg": [
            { "t": "網路層級", "en": "network-level", "ps": "adjective" }
          ]
        },
        {
          "t": "(E) Cloud Profiler：以低開銷 (Low-overhead) 持續分析生產環境中的 CPU 與記憶體使用狀況，識別耗時的函式。",
          "en": "(E) Cloud Profiler: Continuously analyze production CPU and memory usage with low-overhead to identify time-consuming functions.",
          "wg": [
            { "t": "低開銷", "en": "low-overhead", "ps": "adjective" },
            { "t": "耗時的", "en": "time-consuming", "ps": "adjective" }
          ]
        }
      ],
      "answer": "(A), (E)",
      "why": {
        "t": "針對微服務架構的效能除錯，Cloud Trace (A) 是標準工具，它能產生分散式追蹤瀑布圖，顯示請求在每個微服務停留的時間，幫助定位「哪一個服務慢」。Cloud Profiler (E) 則深入程式碼層級 (Code-level)，持續剖析 CPU 與記憶體 (Heap) 使用，幫助開發者找出「服務內哪一行程式碼或函式慢」。這兩者互補。選項 (B) Logging 雖然有用，但缺乏視覺化的調用鏈分析。選項 (C) Uptime Checks 僅檢查外部可用性，無法深入內部邏輯。選項 (D) Flow Logs 僅看網路層，無法分析應用程式邏輯。",
        "en": "For performance debugging in microservices, Cloud Trace (A) is the standard tool. It generates distributed tracing waterfall graphs showing time spent in each microservice, helping pinpoint \"which service is slow.\" Cloud Profiler (E) goes deeper into the Code-level, continuously profiling CPU and Heap usage to help developers find \"which line of code or function is slow.\" These two are complementary. Option (B) Logging is useful but lacks visualized call chain analysis. Option (C) Uptime Checks only check external availability, not internal logic. Option (D) Flow Logs only see the network layer, not application logic.",
        "wg": [
          { "t": "互補", "en": "complementary", "ps": "adjective" },
          { "t": "深入", "en": "goes deeper into", "ps": "verb" }
        ]
      }
    },
    {
      "no": "41",
      "level": "hard",
      "keywords": "CMEK, Security, Key Management, Compliance",
      "question": [
        {
          "t": "KnightMotives 的資安團隊發現，根據新的合規要求，存儲在 BigQuery 與 Cloud Storage 中的敏感駕駛行為數據必須由公司自行管理加密金鑰。",
          "en": "KnightMotives' security team discovered that, according to new compliance requirements, sensitive driving behavior data stored in BigQuery and Cloud Storage must have its encryption keys managed by the company itself.",
          "wg": [
            { "t": "自行管理", "en": "managed by ... itself", "ps": "verb" },
            { "t": "加密金鑰", "en": "encryption keys", "ps": "noun" }
          ]
        },
        {
          "t": "公司必須具備在懷疑發生數據洩露時，立即撤銷 Google 對數據存取權的能力 (Crypto-shredding)，且金鑰必須存儲在特定的地理位置。您應選擇哪種加密策略？",
          "en": "The company must have the capability to immediately revoke Google's access to the data (Crypto-shredding) if a breach is suspected, and keys must be stored in specific geographic locations. Which encryption strategy should you choose?",
          "wg": [
            { "t": "撤銷", "en": "revoke", "ps": "verb" },
            { "t": "特定的地理位置", "en": "specific geographic locations", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Google 預設加密 (Google-managed encryption keys)。這是預設啟用的，且金鑰會自動在全球輪替，符合大多數標準合規要求。",
          "en": "(A) Use Google-managed encryption keys. This is enabled by default, and keys are automatically rotated globally, meeting most standard compliance requirements.",
          "wg": [
            { "t": "預設加密", "en": "Google-managed encryption keys", "ps": "noun" },
            { "t": "全球輪替", "en": "rotated globally", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 實施客戶端加密 (Client-side Encryption, CSE)。在數據上傳到 Google Cloud 之前，於地端應用程式中對數據進行加密，確保 Google 只能看到加密後的二進位大型物件 (Blob)。",
          "en": "(B) Implement Client-side Encryption (CSE). Encrypt data in on-premises applications before uploading to Google Cloud, ensuring Google only sees encrypted Blobs.",
          "wg": [
            { "t": "客戶端加密", "en": "Client-side Encryption", "ps": "noun" },
            { "t": "二進位大型物件", "en": "Blobs", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用客戶管理的加密金鑰 (Customer-Managed Encryption Keys, CMEK) 搭配 Cloud KMS。建立特定地區的金鑰環 (Key Ring)，並將金鑰授權給 BigQuery 與 Cloud Storage 服務帳戶使用。",
          "en": "(C) Use Customer-Managed Encryption Keys (CMEK) with Cloud KMS. Create Key Rings in specific regions and grant key usage permissions to BigQuery and Cloud Storage service accounts.",
          "wg": [
            { "t": "客戶管理的加密金鑰", "en": "Customer-Managed Encryption Keys", "ps": "noun" },
            { "t": "金鑰環", "en": "Key Ring", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 使用 Cloud HSM (硬體安全模組) 產生金鑰，並手動將金鑰匯出並儲存在地端的保險箱中，每當需要查詢數據時再手動匯入。",
          "en": "(D) Use Cloud HSM (Hardware Security Module) to generate keys, manually export and store them in an on-premises safe, and manually import them whenever data query is needed.",
          "wg": [
            { "t": "硬體安全模組", "en": "Hardware Security Module", "ps": "noun" },
            { "t": "手動匯入", "en": "manually import", "ps": "verb" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "客戶管理的加密金鑰 (CMEK) 是 GCP 提供的標準解決方案，允許客戶控制金鑰的生命週期 (建立、輪替、停用、銷毀) 與儲存位置 (透過 Cloud KMS 選擇 Region)。當客戶停用或銷毀 CMEK 金鑰時，Google 的服務 (如 BigQuery) 將立即失去解密數據的能力，達成 Crypto-shredding 的需求。選項 (A) Google 管理的金鑰不允許客戶撤銷 Google 的存取權。選項 (B) 客戶端加密會導致 BigQuery 無法執行 SQL 查詢分析 (除非使用複雜的同態加密)，嚴重影響數據變現能力。選項 (D) Cloud HSM 的金鑰通常設計為不可匯出 (Non-exportable)，且手動匯入流程不切實際。",
        "en": "Customer-Managed Encryption Keys (CMEK) is the standard GCP solution allowing customers to control key lifecycle (create, rotate, disable, destroy) and storage location (via Cloud KMS Region selection). When a customer disables or destroys a CMEK key, Google services (like BigQuery) immediately lose the ability to decrypt data, achieving Crypto-shredding. Option (A) Google-managed keys do not allow customers to revoke Google's access. Option (B) Client-side encryption renders BigQuery unable to perform SQL analytics (unless using complex homomorphic encryption), severely impacting data monetization. Option (D) Cloud HSM keys are typically designed to be non-exportable, and the manual import process is impractical.",
        "wg": [
          { "t": "生命週期", "en": "lifecycle", "ps": "noun" },
          { "t": "嚴重影響", "en": "severely impacting", "ps": "verb" }
        ]
      }
    },
    {
      "no": "42",
      "level": "hard",
      "keywords": "Network Tiers, Cost Optimization, Global Load Balancing, Latency",
      "question": [
        {
          "t": "KnightMotives 的車聯網平台處理兩種類型的流量：\n1. 「即時安全警報」：必須以最低延遲傳輸給全球駕駛。\n2. 「車輛日誌上傳」：每天產生數 PB 的診斷日誌，對延遲不敏感，但對頻寬成本極為敏感。",
          "en": "KnightMotives' connected car platform handles two types of traffic:\n1. \"Real-time Safety Alerts\": Must be transmitted to global drivers with the lowest possible latency.\n2. \"Vehicle Log Uploads\": Generates petabytes of diagnostic logs daily; latency-insensitive but extremely sensitive to bandwidth costs.",
          "wg": [
            { "t": "即時安全警報", "en": "Real-time Safety Alerts", "ps": "noun" },
            { "t": "對延遲不敏感", "en": "latency-insensitive", "ps": "adjective" },
            { "t": "頻寬成本", "en": "bandwidth costs", "ps": "noun" }
          ]
        },
        {
          "t": "您需要設計網路架構以滿足這兩種需求，同時優化整體雲端支出。應採取哪種策略？",
          "en": "You need to design a network architecture to meet both requirements while optimizing overall cloud spending. Which strategy should you adopt?",
          "wg": [
            { "t": "優化", "en": "optimizing", "ps": "verb" },
            { "t": "雲端支出", "en": "cloud spending", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 將所有服務部署在標準級 (Standard Tier) 網路層級上。這能提供最低的成本，且對於安全警報來說，網際網路的延遲通常是可以接受的。",
          "en": "(A) Deploy all services on the Standard Tier network level. This offers the lowest cost, and internet latency is usually acceptable for safety alerts.",
          "wg": [
            { "t": "標準級", "en": "Standard Tier", "ps": "noun" },
            { "t": "可以接受的", "en": "acceptable", "ps": "adjective" }
          ]
        },
        {
          "t": "(B) 採用混合網路層級策略。將處理「即時安全警報」的負載平衡器設定為進階級 (Premium Tier)，將接收「車輛日誌」的負載平衡器設定為標準級 (Standard Tier)。",
          "en": "(B) Adopt a mixed Network Tier strategy. Configure Load Balancers for \"Real-time Safety Alerts\" to use Premium Tier, and Load Balancers for \"Vehicle Log Uploads\" to use Standard Tier.",
          "wg": [
            { "t": "混合網路層級", "en": "mixed Network Tier", "ps": "noun" },
            { "t": "進階級", "en": "Premium Tier", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Cloud CDN 來快取所有內容。這能加速安全警報的傳遞，同時減少日誌上傳到後端伺服器的流量。",
          "en": "(C) Use Cloud CDN to cache all content. This accelerates safety alert delivery while reducing the traffic of log uploads to backend servers.",
          "wg": [
            { "t": "快取", "en": "cache", "ps": "verb" },
            { "t": "加速", "en": "accelerates", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 全部使用進階級 (Premium Tier) 網路，但為日誌上傳服務購買承諾使用折扣 (Committed Use Discounts) 來降低成本。",
          "en": "(D) Use Premium Tier networking for everything, but purchase Committed Use Discounts for the log upload service to reduce costs.",
          "wg": [
            { "t": "承諾使用折扣", "en": "Committed Use Discounts", "ps": "noun" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Google Cloud 的 Network Tiers 允許針對不同工作負載選擇不同的路由路徑。Premium Tier 使用 Google 的全球骨幹網路，提供最低延遲與最高可靠性，適合「即時安全警報」。Standard Tier 使用公共網際網路進行傳輸，成本較低，適合大量、對延遲不敏感的「日誌上傳」。混合使用這兩者是平衡效能與成本的最佳實踐。選項 (A) Standard Tier 效能不穩定，可能危及安全警報的即時性。選項 (C) Cloud CDN 用於下載快取，不適用於資料「上傳」。選項 (D) 即使有折扣，將 PB 級日誌全部走 Premium Tier 仍極其昂貴且無必要。",
        "en": "Google Cloud Network Tiers allow choosing different routing paths for different workloads. Premium Tier uses Google's global backbone, offering the lowest latency and highest reliability, ideal for \"Real-time Safety Alerts.\" Standard Tier uses the public internet for transit, offering lower costs, suitable for massive, latency-insensitive \"Log Uploads.\" Mixing both is the best practice for balancing performance and cost. Option (A) Standard Tier performance is variable and risks the timeliness of safety alerts. Option (C) Cloud CDN is for download caching, not applicable for data \"uploads.\" Option (D) even with discounts, routing PB-scale logs via Premium Tier is prohibitively expensive and unnecessary.",
        "wg": [
          { "t": "骨幹網路", "en": "backbone network", "ps": "noun" },
          { "t": "極其昂貴", "en": "prohibitively expensive", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "43",
      "level": "hard",
      "keywords": "Cloud Run Jobs, Serverless, Batch Processing, Legacy Migration",
      "question": [
        {
          "t": "KnightMotives 有一個傳統的 Python 腳本，用於每晚執行「經銷商庫存對帳」。該腳本需要連接到 Cloud SQL，執行複雜的數據處理，通常需要運行 45 到 60 分鐘。",
          "en": "KnightMotives has a legacy Python script used for nightly \"dealer inventory reconciliation.\" The script needs to connect to Cloud SQL and perform complex data processing, typically running for 45 to 60 minutes.",
          "wg": [
            { "t": "庫存對帳", "en": "inventory reconciliation", "ps": "noun" },
            { "t": "數據處理", "en": "data processing", "ps": "noun" }
          ]
        },
        {
          "t": "作為現代化策略的一部分，您需要將此工作負載遷移到無伺服器平台，以消除伺服器維護負擔。該平台必須支援容器化執行，並能在處理失敗時自動重試。應選擇哪項服務？",
          "en": "As part of the modernization strategy, you need to migrate this workload to a serverless platform to eliminate server maintenance toil. The platform must support containerized execution and automatically retry upon failure. Which service should you choose?",
          "wg": [
            { "t": "無伺服器平台", "en": "serverless platform", "ps": "noun" },
            { "t": "消除", "en": "eliminate", "ps": "verb" },
            { "t": "自動重試", "en": "automatically retry", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Functions (第 2 代)。設定 HTTP 觸發器，並使用 Cloud Scheduler 每晚呼叫該函式。",
          "en": "(A) Use Cloud Functions (2nd gen). Configure an HTTP trigger and use Cloud Scheduler to call the function nightly.",
          "wg": [
            { "t": "觸發器", "en": "trigger", "ps": "noun" },
            { "t": "呼叫", "en": "call", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 建立一個長時間運行的 Compute Engine 實例，設定 cron job 來執行該腳本，並使用執行個體群組的自動修復功能來確保 VM 存活。",
          "en": "(B) Create a long-running Compute Engine instance, configure a cron job to run the script, and use the Instance Group's auto-healing feature to ensure VM survival.",
          "wg": [
            { "t": "自動修復", "en": "auto-healing", "ps": "noun" },
            { "t": "存活", "en": "survival", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Cloud Run 服務 (Service)。部署容器並設定 Cloud Scheduler 發送 HTTP POST 請求來觸發對帳作業。",
          "en": "(C) Use Cloud Run Service. Deploy the container and configure Cloud Scheduler to send HTTP POST requests to trigger the reconciliation job.",
          "wg": [
            { "t": "服務", "en": "Service", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 使用 Cloud Run Jobs。將腳本容器化並定義為 Job，設定 Cloud Scheduler 定期觸發該 Job 執行。",
          "en": "(D) Use Cloud Run Jobs. Containerize the script and define it as a Job, configuring Cloud Scheduler to trigger the Job execution periodically.",
          "wg": [
            { "t": "作業", "en": "Jobs", "ps": "noun" },
            { "t": "定期觸發", "en": "trigger ... periodically", "ps": "verb" }
          ]
        }
      ],
      "answer": "(D)",
      "why": {
        "t": "Cloud Run Jobs 是專為「完成後退出 (Run-to-completion)」的批次作業設計的無伺服器服務。它支援長時間執行 (最長可達 24 小時，遠超過 Cloud Run Service 或 Cloud Functions 的 60 分鐘/9 分鐘限制)，非常適合運行 45-60 分鐘的對帳腳本。它也內建重試機制與並行處理能力。選項 (A) Cloud Functions 預設逾時通常較短 (第 2 代雖可達 60 分鐘，但並非為長時間運算設計)，且 HTTP 請求可能會中斷。選項 (C) Cloud Run Service 是為回應請求設計的，若沒有請求會縮減為零，且 HTTP 請求有逾時限制。選項 (B) 使用 VM 增加了維護作業系統的負擔，不符合無伺服器目標。",
        "en": "Cloud Run Jobs is a serverless service designed specifically for \"Run-to-completion\" batch workloads. It supports long execution times (up to 24 hours, far exceeding the 60 min/9 min limits of Cloud Run Service/Cloud Functions), making it ideal for the 45-60 minute reconciliation script. It also has built-in retry mechanisms and parallelism. Option (A) Cloud Functions typically have shorter timeouts (2nd gen allows 60 mins but isn't designed for long computation), and HTTP requests may timeout. Option (C) Cloud Run Service is for request-response; it scales to zero without requests, and HTTP requests enforce timeouts. Option (B) using VMs adds OS maintenance toil, failing the serverless goal.",
        "wg": [
          { "t": "完成後退出", "en": "Run-to-completion", "ps": "noun" },
          { "t": "內建重試機制", "en": "built-in retry mechanisms", "ps": "noun" }
        ]
      }
    },
    {
      "no": "44",
      "level": "hard",
      "keywords": "Filestore, HPC, Simulation, Shared File System",
      "question": [
        {
          "t": "KnightMotives 的自動駕駛團隊正在構建一個大規模的高效能運算 (HPC) 模擬叢集。成千上萬個模擬節點需要同時讀寫共享的設定檔與模擬場景數據。",
          "en": "KnightMotives' autonomous driving team is building a large-scale High Performance Computing (HPC) simulation cluster. Thousands of simulation nodes need to simultaneously read and write shared configuration files and simulation scenario data.",
          "wg": [
            { "t": "高效能運算", "en": "High Performance Computing (HPC)", "ps": "noun" },
            { "t": "模擬節點", "en": "simulation nodes", "ps": "noun" }
          ]
        },
        {
          "t": "應用程式依賴 POSIX 相容的檔案系統介面，且要求極高的讀寫吞吐量 (IOPS) 與低延遲。您應建議哪種儲存解決方案？",
          "en": "The application relies on a POSIX-compliant file system interface and requires extremely high read/write throughput (IOPS) and low latency. Which storage solution should you recommend?",
          "wg": [
            { "t": "POSIX 相容", "en": "POSIX-compliant", "ps": "adjective" },
            { "t": "吞吐量", "en": "throughput", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 部署 Filestore Enterprise 執行個體。將其掛載到所有模擬節點的 VM 上。",
          "en": "(A) Deploy a Filestore Enterprise instance. Mount it onto all simulation node VMs.",
          "wg": [
            { "t": "掛載", "en": "Mount", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 使用 Cloud Storage FUSE 將 GCS Bucket 掛載為檔案系統。這提供了無限的擴展性與低成本。",
          "en": "(B) Use Cloud Storage FUSE to mount a GCS Bucket as a file system. This offers infinite scalability and low cost.",
          "wg": [
            { "t": "無限的擴展性", "en": "infinite scalability", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 為每個 VM 配置一個 Read-Write-Many (RWX) 模式的 Persistent Disk，並使用 NFS 伺服器進行共享。",
          "en": "(C) Configure a Persistent Disk in Read-Write-Many (RWX) mode for each VM, and use an NFS server for sharing.",
          "wg": [
            { "t": "共享", "en": "sharing", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 將數據遷移至 Firestore，並重寫應用程式以使用 NoSQL API 進行存取。",
          "en": "(D) Migrate data to Firestore and rewrite the application to use NoSQL APIs for access.",
          "wg": [
            { "t": "重寫", "en": "rewrite", "ps": "verb" }
          ]
        }
      ],
      "answer": "(A)",
      "why": {
        "t": "Filestore 是 Google Cloud 的全代管 NFS 檔案儲存服務。Filestore Enterprise/High Scale 專為 HPC 工作負載設計，提供 POSIX 相容性、高 IOPS 與低延遲，並支援數千個客戶端同時連線。這完全符合模擬叢集的需求。選項 (B) Cloud Storage FUSE 雖然提供檔案介面，但延遲較高且不完全支援 POSIX (如隨機寫入效能差)，不適合 HPC。選項 (C) 單一 NFS 伺服器會成為效能瓶頸，且自行維護 NFS 叢集增加維運負擔。選項 (D) 重寫應用程式違反了「應用程式依賴 POSIX」的限制。",
        "en": "Filestore is Google Cloud's fully managed NFS file storage service. Filestore Enterprise/High Scale is designed for HPC workloads, offering POSIX compliance, high IOPS, low latency, and support for thousands of concurrent clients. This matches the simulation cluster needs perfectly. Option (B) Cloud Storage FUSE offers a file interface but has higher latency and incomplete POSIX support (poor random write performance), making it unsuitable for HPC. Option (C) a single NFS server becomes a bottleneck, and self-managing NFS clusters increases toil. Option (D) rewriting applications violates the \"relies on POSIX\" constraint.",
        "wg": [
          { "t": "全代管", "en": "fully managed", "ps": "adjective" },
          { "t": "效能瓶頸", "en": "performance bottleneck", "ps": "noun" }
        ]
      }
    },
    {
      "no": "45",
      "level": "hard",
      "keywords": "Cloud Logging, Log Exclusion, Cost Management, Observability",
      "question": [
        {
          "t": "KnightMotives 發現 Cloud Logging 的費用在過去一個月暴增。經調查，這是因為開發團隊在數百萬輛車的車載軟體中意外留下了 `DEBUG` 層級的日誌輸出。",
          "en": "KnightMotives noticed a surge in Cloud Logging costs over the past month. Investigation revealed that the development team accidentally left `DEBUG` level log output enabled in the in-vehicle software of millions of cars.",
          "wg": [
            { "t": "暴增", "en": "surge", "ps": "verb" },
            { "t": "意外", "en": "accidentally", "ps": "adverb" }
          ]
        },
        {
          "t": "由於無法立即對所有車輛進行 OTA 更新，您需要立即在雲端平台端降低日誌攝取成本，同時確保 `ERROR` 與 `CRITICAL` 層級的日誌仍被保留以供監控。應採取哪項行動？",
          "en": "Since an immediate OTA update to all vehicles is not possible, you need to immediately reduce log ingestion costs on the cloud platform side, while ensuring `ERROR` and `CRITICAL` level logs are retained for monitoring. Which action should you take?",
          "wg": [
            { "t": "攝取成本", "en": "ingestion costs", "ps": "noun" },
            { "t": "保留", "en": "retained", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 刪除 `_Default` Log Sink，並建立一個新的 Sink 將所有日誌匯出至 Cloud Storage Archive class。",
          "en": "(A) Delete the `_Default` Log Sink, and create a new Sink to export all logs to Cloud Storage Archive class.",
          "wg": [
            { "t": "刪除", "en": "Delete", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 在 `_Default` Log Sink 上設定採樣率 (Sampling Rate) 為 10%，以隨機丟棄 90% 的日誌。",
          "en": "(B) Configure a Sampling Rate of 10% on the `_Default` Log Sink to randomly drop 90% of logs.",
          "wg": [
            { "t": "採樣率", "en": "Sampling Rate", "ps": "noun" },
            { "t": "丟棄", "en": "drop", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 在 `_Default` Log Sink 上設定排除過濾器 (Exclusion Filter)，規則為 `severity=DEBUG`，並選擇「停止攝取」(Stop Ingestion)。",
          "en": "(C) Configure an Exclusion Filter on the `_Default` Log Sink with the rule `severity=DEBUG`, and select \"Stop Ingestion.\"",
          "wg": [
            { "t": "排除過濾器", "en": "Exclusion Filter", "ps": "noun" },
            { "t": "停止攝取", "en": "Stop Ingestion", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 安裝 Ops Agent 到所有車輛上，並在代理程式設定檔中過濾掉 DEBUG 日誌，然後重新部署。",
          "en": "(D) Install Ops Agent on all vehicles, filter out DEBUG logs in the agent configuration, and redeploy.",
          "wg": [
            { "t": "重新部署", "en": "redeploy", "ps": "verb" }
          ]
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "Log Exclusion (排除過濾器) 是控制 Cloud Logging 成本的最有效方法。透過設定過濾規則 (如 `severity=DEBUG`)，這些日誌在進入 Log Bucket 之前就會被丟棄，因此不會產生攝取費用 (Ingestion Cost) 或儲存費用。這能精確保留重要的 `ERROR` 日誌。選項 (A) 雖然 Archive Storage 便宜，但匯出過程本身可能仍需支付部分費用，且失去了在 Cloud Logging 中即時查詢錯誤的能力。選項 (B) 隨機採樣可能會遺失關鍵的錯誤日誌。選項 (D) 題目已說明「無法立即進行 OTA 更新」，因此修改車端 Agent 不可行。",
        "en": "Log Exclusion is the most effective way to control Cloud Logging costs. By setting an exclusion rule (e.g., `severity=DEBUG`), these logs are discarded before entering the Log Bucket, thus incurring no Ingestion Cost or storage fees. This precisely retains critical `ERROR` logs. Option (A) while Archive Storage is cheap, exporting might still incur costs and loses real-time query capability in Cloud Logging. Option (B) random sampling might drop critical error logs. Option (D) the scenario states \"immediate OTA update is not possible,\" so modifying the vehicle-side agent is not feasible.",
        "wg": [
          { "t": "最有效方法", "en": "most effective way", "ps": "noun" },
          { "t": "不可行", "en": "not feasible", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "46",
      "level": "hard",
      "keywords": "Datastream, CDC, Mainframe, BigQuery",
      "question": [
        {
          "t": "KnightMotives 的供應鏈數據目前鎖定在地端 IBM Db2 大型主機資料庫中。為了支援「數據變現」並即時調整經銷商庫存，數據團隊需要將這些交易數據即時同步至 BigQuery。",
          "en": "KnightMotives' supply chain data is currently locked in an on-premises IBM Db2 mainframe database. To support \"Data Monetization\" and real-time dealer inventory adjustments, the data team needs to synchronize this transaction data to BigQuery in real-time.",
          "wg": [
            { "t": "鎖定", "en": "locked", "ps": "verb" },
            { "t": "即時同步", "en": "synchronize ... in real-time", "ps": "verb" }
          ]
        },
        {
          "t": "大型主機資源極為昂貴且負載已滿，解決方案必須對來源資料庫的效能影響降至最低 (Minimal Impact)，且不應涉及繁瑣的批次匯出作業。應採用哪種架構？",
          "en": "Mainframe resources are extremely expensive and fully loaded. The solution must have minimal impact on the source database performance and should not involve cumbersome batch export operations. Which architecture should you adopt?",
          "wg": [
            { "t": "效能影響降至最低", "en": "minimal impact on ... performance", "ps": "noun" },
            { "t": "繁瑣的", "en": "cumbersome", "ps": "adjective" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Dataflow 編寫 JDBC 連接器，設定每 5 分鐘對 Db2 執行一次 `SELECT *` 查詢，並將結果寫入 BigQuery。",
          "en": "(A) Use Dataflow to write a JDBC connector, configuring it to execute a `SELECT *` query against Db2 every 5 minutes and write results to BigQuery.",
          "wg": [
            { "t": "連接器", "en": "connector", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 部署 Datastream。設定無代理程式 (Agentless) 的變更資料擷取 (CDC) 管道，讀取 Db2 的交易日誌 (Transaction Logs)，並將變更串流至 BigQuery。",
          "en": "(B) Deploy Datastream. Configure an agentless Change Data Capture (CDC) pipeline to read Db2 transaction logs and stream changes to BigQuery.",
          "wg": [
            { "t": "變更資料擷取", "en": "Change Data Capture (CDC)", "ps": "noun" },
            { "t": "交易日誌", "en": "Transaction Logs", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 BigQuery Omni 建立與地端 Db2 的直接關聯 (Federated Query)，讓分析師直接查詢大型主機數據。",
          "en": "(C) Use BigQuery Omni to create a direct federation (Federated Query) with on-premises Db2, allowing analysts to query mainframe data directly.",
          "wg": [
            { "t": "直接關聯", "en": "direct federation", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 在大型主機上安裝 Logstash，過濾並解析應用程式日誌，然後將其轉發到 Cloud Pub/Sub，再由 BigQuery 訂閱並寫入。",
          "en": "(D) Install Logstash on the mainframe to filter and parse application logs, forward them to Cloud Pub/Sub, and have BigQuery subscribe and write the data.",
          "wg": [
            { "t": "轉發", "en": "forward", "ps": "verb" },
            { "t": "訂閱", "en": "subscribe", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Datastream 是 Google Cloud 的無伺服器 CDC (Change Data Capture) 服務，專為低延遲數據複寫設計。透過讀取資料庫的「交易日誌 (Transaction Logs)」而非直接查詢資料表，它能將對來源資料庫的效能影響降至最低，完美符合「Minimal Impact」與「Real-time」的需求。選項 (A) 定期執行 `SELECT *` (Polling) 會對主機造成巨大的讀取負載。選項 (C) 聯合查詢 (Federated Query) 效能差且會直接消耗主機運算資源。選項 (D) 依賴應用程式日誌而非資料庫日誌，容易遺失數據且不準確。",
        "en": "Datastream is Google Cloud's serverless CDC (Change Data Capture) service designed for low-latency data replication. By reading the database's \"Transaction Logs\" instead of querying tables directly, it minimizes performance impact on the source, perfectly meeting the \"Minimal Impact\" and \"Real-time\" requirements. Option (A) periodic `SELECT *` (Polling) places a huge read load on the mainframe. Option (C) Federated Query has poor performance and directly consumes mainframe compute resources. Option (D) relying on app logs instead of DB logs is prone to data loss and inaccuracy.",
        "wg": [
          { "t": "無伺服器", "en": "serverless", "ps": "adjective" },
          { "t": "讀取負載", "en": "read load", "ps": "noun" }
        ]
      }
    },
    {
      "no": "47",
      "level": "hard",
      "keywords": "Identity Platform, CIAM, Scalability, Firebase",
      "question": [
        {
          "t": "KnightMotives 正在轉型為「數位優先」品牌，即將推出一款面對全球數百萬消費者的行動應用程式 (App)。該 App 允許使用者設定車輛、預約維修並查看行車數據。",
          "en": "KnightMotives is transforming into a \"digital-first\" brand and is about to launch a mobile app for millions of global consumers. The app allows users to configure vehicles, schedule service, and view driving data.",
          "wg": [
            { "t": "數位優先", "en": "digital-first", "ps": "adjective" },
            { "t": "行動應用程式", "en": "mobile app", "ps": "noun" }
          ]
        },
        {
          "t": "您需要設計身分驗證系統，支援電子郵件、電話號碼以及社交登入 (Google/Facebook)，並具備多重因素驗證 (MFA) 功能。該系統必須能自動擴展以處理新車發布期間的登入高峰。應選擇哪項服務？",
          "en": "You need to design an identity authentication system supporting email, phone number, and social logins (Google/Facebook), with Multi-Factor Authentication (MFA). The system must autoscale to handle login spikes during new car launches. Which service should you choose?",
          "wg": [
            { "t": "身分驗證系統", "en": "identity authentication system", "ps": "noun" },
            { "t": "登入高峰", "en": "login spikes", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Identity Premium。為每個 App 使用者建立一個 Google 帳戶，並將其加入特定的組織單位 (OU)。",
          "en": "(A) Use Cloud Identity Premium. Create a Google account for each app user and add them to a specific Organizational Unit (OU).",
          "wg": [
            { "t": "組織單位", "en": "Organizational Unit (OU)", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 實施 Identity Platform (基於 Firebase Authentication)。這是一個客戶身分與存取管理 (CIAM) 解決方案，支援多種驗證提供者與自動擴展。",
          "en": "(B) Implement Identity Platform (based on Firebase Authentication). This is a Customer Identity and Access Management (CIAM) solution supporting multiple auth providers and autoscaling.",
          "wg": [
            { "t": "客戶身分與存取管理", "en": "Customer Identity and Access Management (CIAM)", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 在 GKE 上自行託管 Keycloak 叢集，並使用 Cloud SQL 作為後端資料庫。設定 Horizontal Pod Autoscaler (HPA) 以應對流量。",
          "en": "(C) Self-host a Keycloak cluster on GKE, using Cloud SQL as the backend database. Configure Horizontal Pod Autoscaler (HPA) to handle traffic.",
          "wg": [
            { "t": "自行託管", "en": "Self-host", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 使用 Identity-Aware Proxy (IAP) 搭配外部身分提供者。將使用者導向企業內部的 Active Directory 進行驗證。",
          "en": "(D) Use Identity-Aware Proxy (IAP) with an external identity provider. Redirect users to the corporate internal Active Directory for authentication.",
          "wg": [
            { "t": "導向", "en": "Redirect", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Identity Platform (CIAM) 是 Google Cloud 針對消費者應用 (B2C) 的標準身分解決方案。它基於 Firebase Auth，原生支援社交登入、MFA，且是無伺服器的，能輕鬆處理數百萬用戶與突發流量，無需管理基礎設施。選項 (A) Cloud Identity 是針對企業內部員工 (B2E) 設計的，不適合管理外部消費者帳戶。選項 (C) 自建 Keycloak 雖然可行，但增加了巨大的維運負擔 (Toil)，不符合「減少維運」的策略。選項 (D) Active Directory 也是針對內部員工，不適用於一般消費者註冊。",
        "en": "Identity Platform (CIAM) is Google Cloud's standard identity solution for consumer applications (B2C). Based on Firebase Auth, it natively supports social logins, MFA, and is serverless, easily handling millions of users and traffic spikes without infrastructure management. Option (A) Cloud Identity is designed for internal employees (B2E), not suitable for managing external consumer accounts. Option (C) self-hosting Keycloak introduces massive operational toil, contradicting the \"reduce toil\" strategy. Option (D) Active Directory is also for internal employees, not applicable for general consumer registration.",
        "wg": [
          { "t": "消費者應用", "en": "consumer applications", "ps": "noun" },
          { "t": "突發流量", "en": "traffic spikes", "ps": "noun" }
        ]
      }
    },
    {
      "no": "48",
      "level": "hard",
      "keywords": "Anthos Config Management, GitOps, Governance, Policy Controller",
      "question": [
        {
          "t": "KnightMotives 的 IT 團隊管理著數十個 GKE 叢集，分佈在 Google Cloud、地端資料中心以及邊緣工廠。由於「碎片化」嚴重，各叢集的安全設定 (如 Pod 安全策略、網路策略) 不一致。",
          "en": "KnightMotives' IT team manages dozens of GKE clusters distributed across Google Cloud, on-premises data centers, and edge factories. Due to severe \"fragmentation,\" security configurations (e.g., Pod Security Policies, Network Policies) are inconsistent across clusters.",
          "wg": [
            { "t": "不一致", "en": "inconsistent", "ps": "adjective" },
            { "t": "碎片化", "en": "fragmentation", "ps": "noun" }
          ]
        },
        {
          "t": "您需要實施一個 GitOps 工作流程，確保所有叢集自動同步統一的設定與安全政策 (Policy)。如果有人手動修改了叢集設定，系統必須能自動修正 (Self-healing)。應使用哪項工具？",
          "en": "You need to implement a GitOps workflow to ensure all clusters automatically synchronize unified configurations and security policies. If someone manually modifies a cluster configuration, the system must automatically correct it (Self-healing). Which tool should you use?",
          "wg": [
            { "t": "自動同步", "en": "automatically synchronize", "ps": "verb" },
            { "t": "自動修正", "en": "automatically correct", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Build 建立 CI/CD 管道。每當 Git 儲存庫更新時，觸發 `kubectl apply` 指令將設定推送到所有叢集。",
          "en": "(A) Use Cloud Build to create a CI/CD pipeline. Whenever the Git repository updates, trigger `kubectl apply` commands to push configurations to all clusters.",
          "wg": [
            { "t": "推送", "en": "push", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 啟用 GKE Enterprise (Anthos) 的 Config Sync 與 Policy Controller。將 Git 儲存庫設為單一事實來源 (Source of Truth)，Config Sync 會持續監控並強制同步狀態。",
          "en": "(B) Enable GKE Enterprise (Anthos) Config Sync and Policy Controller. Set a Git repository as the Single Source of Truth; Config Sync will continuously monitor and enforce synchronization state.",
          "wg": [
            { "t": "單一事實來源", "en": "Single Source of Truth", "ps": "noun" },
            { "t": "強制同步", "en": "enforce synchronization", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 編寫 Terraform 模組來定義 GKE 資源。使用 `terraform apply` 定期執行排程任務，以確保基礎設施即程式碼 (IaC) 的一致性。",
          "en": "(C) Write Terraform modules to define GKE resources. Run `terraform apply` as a scheduled task to ensure Infrastructure as Code (IaC) consistency.",
          "wg": [
            { "t": "排程任務", "en": "scheduled task", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 在每個叢集中部署 Open Policy Agent (OPA) Gatekeeper，並編寫 Rego 規則來拒絕不合規的 API 請求。",
          "en": "(D) Deploy Open Policy Agent (OPA) Gatekeeper in each cluster and write Rego rules to deny non-compliant API requests.",
          "wg": [
            { "t": "拒絕", "en": "deny", "ps": "verb" },
            { "t": "不合規的", "en": "non-compliant", "ps": "adjective" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Anthos Config Sync 是專為大規模多叢集管理設計的 GitOps 工具。它在叢集內部運行代理程式，主動從 Git 拉取 (Pull) 設定並應用。關鍵在於它具備「自我修復 (Self-healing)」能力：若有人繞過 Git 手動修改 (Drift)，Config Sync 會立即偵測並還原設定。Policy Controller 則確保合規性。選項 (A) 和 (C) 是推播式 (Push-based) 的，無法即時偵測並修復手動變更 (Drift Detection 較弱)。選項 (D) OPA 僅能「攔截」請求，無法「分發與同步」基礎設施設定 (如 Namespace, Quota)。",
        "en": "Anthos Config Sync is a GitOps tool designed for large-scale multi-cluster management. It runs agents inside clusters to proactively Pull configs from Git and apply them. Crucially, it has \"Self-healing\" capabilities: if someone bypasses Git and manually modifies configs (Drift), Config Sync immediately detects and reverts it. Policy Controller ensures compliance. Options (A) and (C) are Push-based and cannot immediately detect and fix manual changes (weak Drift Detection). Option (D) OPA only \"intercepts\" requests but cannot \"distribute and sync\" infrastructure configs (like Namespaces, Quotas).",
        "wg": [
          { "t": "主動", "en": "proactively", "ps": "adverb" },
          { "t": "自我修復", "en": "Self-healing", "ps": "noun" }
        ]
      }
    },
    {
      "no": "49",
      "level": "hard",
      "keywords": "Serverless VPC Access, Cloud Run, Cloud SQL, Private IP",
      "question": [
        {
          "t": "KnightMotives 的「線上訂購系統」後端 API 已遷移至 Cloud Run。該 API 需要存取儲存客戶個資 (PII) 的 Cloud SQL 資料庫。",
          "en": "KnightMotives' \"online ordering system\" backend API has been migrated to Cloud Run. This API needs to access a Cloud SQL database storing customer PII.",
          "wg": [
            { "t": "後端 API", "en": "backend API", "ps": "noun" }
          ]
        },
        {
          "t": "為了符合嚴格的資安政策，Cloud SQL 實例必須「僅使用私有 IP (Private IP Only)」，完全禁止公開 IP 存取。您應如何配置網路以允許 Cloud Run 安全地連線至資料庫？",
          "en": "To comply with strict security policies, the Cloud SQL instance must be \"Private IP Only,\" completely prohibiting public IP access. How should you configure the network to allow Cloud Run to securely connect to the database?",
          "wg": [
            { "t": "完全禁止", "en": "completely prohibiting", "ps": "verb" },
            { "t": "安全地連線", "en": "securely connect", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 在 Cloud Run 服務中設定 Cloud SQL Auth Proxy 容器作為 Sidecar，並透過 localhost 連線。",
          "en": "(A) Configure Cloud SQL Auth Proxy container as a Sidecar in the Cloud Run service and connect via localhost.",
          "wg": [
            { "t": "Sidecar", "en": "Sidecar", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 設定無伺服器 VPC 存取連接器 (Serverless VPC Access Connector) 或直接 VPC 輸出 (Direct VPC Egress)，將 Cloud Run 連接到 Cloud SQL 所在的 VPC。",
          "en": "(B) Configure Serverless VPC Access Connector or Direct VPC Egress to connect Cloud Run to the VPC where Cloud SQL resides.",
          "wg": [
            { "t": "存取連接器", "en": "Access Connector", "ps": "noun" },
            { "t": "直接 VPC 輸出", "en": "Direct VPC Egress", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 為 Cloud SQL 啟用 Public IP，但設定授權網路 (Authorized Networks) 僅允許 Cloud Run 的 IP 範圍存取，並強制使用 SSL。",
          "en": "(C) Enable Public IP for Cloud SQL, but configure Authorized Networks to allow access only from Cloud Run's IP ranges, enforcing SSL.",
          "wg": [
            { "t": "授權網路", "en": "Authorized Networks", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 使用 Private Service Connect (PSC)，將 Cloud SQL 發布為服務，並在 Cloud Run 專案中建立端點。",
          "en": "(D) Use Private Service Connect (PSC) to publish Cloud SQL as a service, and create an endpoint in the Cloud Run project.",
          "wg": [
            { "t": "發布", "en": "publish", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Cloud Run 是無伺服器服務，預設運行在 Google 的租戶網路中，無法直接存取使用者 VPC 內的私有 IP資源。要連線至 Private IP Only 的 Cloud SQL，必須使用「Serverless VPC Access Connector」或較新的「Direct VPC Egress」功能，將 Cloud Run 的流量橋接到 VPC 內部。選項 (A) Sidecar 模式適用於 GKE，Cloud Run (第 1 代) 原生支援 SQL 連線但仍需網路路徑通暢，若 SQL 只有私有 IP 則仍需 VPC Access。選項 (C) 違反了「僅使用私有 IP」的政策。選項 (D) PSC 主要用於跨 VPC 存取，雖然 Cloud SQL 支援 PSC，但對於同專案或簡單 VPC 連線，VPC Access 是標準做法。",
        "en": "Cloud Run is serverless and runs in Google's tenant network by default, unable to directly access Private IP resources in the user's VPC. To connect to a Private IP Only Cloud SQL, you must use \"Serverless VPC Access Connector\" or the newer \"Direct VPC Egress\" to bridge Cloud Run traffic into the VPC. Option (A) Sidecar pattern is for GKE; Cloud Run (Gen 1) natively supports SQL connections but requires a network path—if SQL is private-only, VPC Access is still needed. Option (C) violates the \"Private IP Only\" policy. Option (D) PSC is for cross-VPC access; while Cloud SQL supports PSC, VPC Access is the standard for simple VPC connectivity.",
        "wg": [
          { "t": "租戶網路", "en": "tenant network", "ps": "noun" },
          { "t": "橋接", "en": "bridge", "ps": "verb" }
        ]
      }
    },
    {
      "no": "50",
      "level": "hard",
      "keywords": "Cloud Deploy, CI/CD, GKE, Delivery Pipeline",
      "question": [
        {
          "t": "KnightMotives 希望改善開發團隊與維運團隊之間的溝通，並現代化應用程式的發布流程。目前的手動發布過程容易出錯，導致不同環境 (Dev, Staging, Prod) 之間版本不一致。",
          "en": "KnightMotives wants to improve communication between dev and ops teams and modernize the application release process. The current manual release process is error-prone, leading to version inconsistencies across environments (Dev, Staging, Prod).",
          "wg": [
            { "t": "手動發布過程", "en": "manual release process", "ps": "noun" },
            { "t": "版本不一致", "en": "version inconsistencies", "ps": "noun" }
          ]
        },
        {
          "t": "您需要建立一個完全託管的持續交付 (CD) 管道，支援 GKE 目標，並具備發布審核 (Approval Gates) 與一鍵回滾 (Rollback) 功能。應採用哪種組合？",
          "en": "You need to establish a fully managed Continuous Delivery (CD) pipeline supporting GKE targets, with Approval Gates and One-click Rollback capabilities. Which combination should you adopt?",
          "wg": [
            { "t": "持續交付", "en": "Continuous Delivery (CD)", "ps": "noun" },
            { "t": "發布審核", "en": "Approval Gates", "ps": "noun" },
            { "t": "一鍵回滾", "en": "One-click Rollback", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Jenkins 部署在 GKE 上。安裝 Google Cloud 外掛程式，並編寫 Groovy 腳本來定義 Pipeline 階段與審核步驟。",
          "en": "(A) Use Jenkins deployed on GKE. Install Google Cloud plugins and write Groovy scripts to define Pipeline stages and approval steps.",
          "wg": [
            { "t": "外掛程式", "en": "plugins", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 使用 Cloud Build 建置容器映像檔，並利用 Google Cloud Deploy 來管理交付管道。定義 `skaffold.yaml` 來描述渲染與部署邏輯。",
          "en": "(B) Use Cloud Build to build container images, and leverage Google Cloud Deploy to manage the delivery pipeline. Define `skaffold.yaml` to describe rendering and deployment logic.",
          "wg": [
            { "t": "交付管道", "en": "delivery pipeline", "ps": "noun" },
            { "t": "渲染", "en": "rendering", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Spinnaker on Google Cloud。設定 Kayenta 進行自動金絲雀分析，並配置手動判斷 (Manual Judgment) 階段進行審核。",
          "en": "(C) Use Spinnaker on Google Cloud. Configure Kayenta for automated canary analysis and set up Manual Judgment stages for approval.",
          "wg": [
            { "t": "手動判斷", "en": "Manual Judgment", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 編寫 Cloud Functions 監聽 Container Registry 的更新事件。當新映像檔上傳時，觸發函式執行 `kubectl set image` 更新 GKE Deployment。",
          "en": "(D) Write Cloud Functions to listen for Container Registry update events. When a new image is uploaded, trigger the function to execute `kubectl set image` to update the GKE Deployment.",
          "wg": [
            { "t": "監聽", "en": "listen for", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Google Cloud Deploy 是 GCP 原生的全代管持續交付服務，專為 GKE 與 Cloud Run 設計。它與 Cloud Build 無縫整合，使用 Skaffold 配置，並提供開箱即用的「發布審核 (Promote with approval)」、「一鍵回滾」與「交付指標 (DORA metrics)」功能。這消除了自行維護 Jenkins (A) 或 Spinnaker (C) 的維運負擔 (Toil)，且比選項 (D) 的自製腳本更安全、正規。符合「現代化」與「改善溝通 (視覺化管道)」的目標。",
        "en": "Google Cloud Deploy is GCP's native fully managed Continuous Delivery service designed for GKE and Cloud Run. It integrates seamlessly with Cloud Build, uses Skaffold for configuration, and provides out-of-the-box \"Promote with approval,\" \"One-click Rollback,\" and \"Delivery Metrics (DORA)\" features. This eliminates the operational toil of self-maintaining Jenkins (A) or Spinnaker (C), and is more secure and formal than the homemade scripts in Option (D). It aligns with the goals of \"modernization\" and \"improving communication (visualized pipelines).\"",
        "wg": [
          { "t": "開箱即用", "en": "out-of-the-box", "ps": "adjective" },
          { "t": "維運負擔", "en": "operational toil", "ps": "noun" }
        ]
      }
    },
    {
      "no": "51",
      "level": "hard",
      "keywords": "Looker Studio, BI, Caching, Cost",
      "question": [
        {
          "t": "KnightMotives 希望為經銷商提供一個「銷售與庫存儀表板」，讓他們能即時查看區域內的熱門車款趨勢。",
          "en": "KnightMotives wants to provide dealers with a \"Sales and Inventory Dashboard\" to view real-time trends of popular vehicle models in their region.",
          "wg": [
            { "t": "儀表板", "en": "Dashboard", "ps": "noun" },
            { "t": "熱門車款趨勢", "en": "trends of popular vehicle models", "ps": "noun" }
          ]
        },
        {
          "t": "由於經銷商「沒有預算購買新設備」，該儀表板必須透過瀏覽器存取。數據儲存在 BigQuery 中，您需要一個無伺服器、低成本且易於分享的視覺化解決方案，同時要避免頻繁查詢 BigQuery 導致成本失控。",
          "en": "Since dealers have \"no budget for new equipment,\" the dashboard must be accessible via a browser. Data is stored in BigQuery, and you need a serverless, low-cost, and easy-to-share visualization solution that avoids cost spiraling from frequent BigQuery queries.",
          "wg": [
            { "t": "無伺服器", "en": "serverless", "ps": "adjective" },
            { "t": "成本失控", "en": "cost spiraling", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 開發一個 App Engine 應用程式，使用 Python Pandas 讀取數據並使用 D3.js 渲染圖表。實作 Memcached 來快取查詢結果。",
          "en": "(A) Develop an App Engine application using Python Pandas to read data and D3.js to render charts. Implement Memcached to cache query results.",
          "wg": [
            { "t": "渲染", "en": "render", "ps": "verb" },
            { "t": "快取", "en": "cache", "ps": "verb" }
          ]
        },
        {
          "t": "(B) 使用 Looker Studio (原 Data Studio) 建立儀表板並連接至 BigQuery。啟用 BI Engine 並設定「已提取的資料來源 (Extracted Data Source)」或使用快取功能來減少即時查詢。",
          "en": "(B) Use Looker Studio (formerly Data Studio) to create the dashboard and connect to BigQuery. Enable BI Engine and configure \"Extracted Data Source\" or use caching features to reduce live queries.",
          "wg": [
            { "t": "已提取的資料來源", "en": "Extracted Data Source", "ps": "noun" },
            { "t": "即時查詢", "en": "live queries", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 部署 Tableau Server 在 Compute Engine 上，並設定與 BigQuery 的即時連線。要求經銷商安裝 Tableau Reader。",
          "en": "(C) Deploy Tableau Server on Compute Engine and configure a live connection to BigQuery. Require dealers to install Tableau Reader.",
          "wg": [
            { "t": "即時連線", "en": "live connection", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 將彙總後的數據匯出至 Google Sheets，並使用 Sheets 的內建圖表功能分享給經銷商。",
          "en": "(D) Export aggregated data to Google Sheets and share with dealers using Sheets' built-in charting features.",
          "wg": [
            { "t": "彙總後的", "en": "aggregated", "ps": "adjective" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Looker Studio 是 Google Cloud 的無伺服器 BI 工具，完全符合「無需新設備 (瀏覽器存取)」與「低成本」的需求。為了防止 BigQuery 查詢成本失控，Looker Studio 提供了快取機制，且結合 BI Engine 或使用「提取 (Extract)」模式可以顯著降低對 BigQuery 的掃描次數並提升效能。選項 (A) 開發客製化 App 維護成本高 (Toil)。選項 (C) Tableau Server 授權費用高且需管理 VM，經銷商可能需安裝軟體。選項 (D) Google Sheets 無法處理大數據且安全性較差。",
        "en": "Looker Studio is Google Cloud's serverless BI tool, perfectly matching the \"no new equipment (browser access)\" and \"low cost\" requirements. To prevent BigQuery cost spiraling, Looker Studio offers caching mechanisms, and combining it with BI Engine or using \"Extract\" mode significantly reduces BigQuery scans and improves performance. Option (A) developing a custom App has high maintenance toil. Option (C) Tableau Server has high licensing costs and requires VM management; dealers might need to install software. Option (D) Google Sheets cannot handle big data and has lower security.",
        "wg": [
          { "t": "快取機制", "en": "caching mechanisms", "ps": "noun" },
          { "t": "授權費用", "en": "licensing costs", "ps": "noun" }
        ]
      }
    },
    {
      "no": "52",
      "level": "hard",
      "keywords": "Cloud Build, Private Pools, Hybrid Connectivity, Security",
      "question": [
        {
          "t": "KnightMotives 正在現代化其供應鏈應用程式。CI/CD 管道的建置步驟 (Build Steps) 需要從地端的大型主機 (Mainframe) 提取相依套件與設定檔。",
          "en": "KnightMotives is modernizing its supply chain application. The Build Steps of the CI/CD pipeline need to fetch dependencies and configuration files from the on-premises Mainframe.",
          "wg": [
            { "t": "提取", "en": "fetch", "ps": "verb" },
            { "t": "相依套件", "en": "dependencies", "ps": "noun" }
          ]
        },
        {
          "t": "地端環境已透過 Interconnect 連接至 VPC，且防火牆嚴格禁止來自公共網際網路的連線。預設的 Cloud Build 環境無法存取這些私有資源。應如何設定 Cloud Build？",
          "en": "The on-premises environment is connected to the VPC via Interconnect, and firewalls strictly prohibit connections from the public internet. The default Cloud Build environment cannot access these private resources. How should you configure Cloud Build?",
          "wg": [
            { "t": "嚴格禁止", "en": "strictly prohibit", "ps": "verb" },
            { "t": "預設的", "en": "default", "ps": "adjective" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Build 私有集區 (Private Pools)。將私有集區配置在與 Interconnect 連接的 VPC 網路中 (Peered Network)，以允許存取地端資源。",
          "en": "(A) Use Cloud Build Private Pools. Configure the private pool in the VPC network peered with the Interconnect to allow access to on-premises resources.",
          "wg": [
            { "t": "私有集區", "en": "Private Pools", "ps": "noun" },
            { "t": "對等互連的網路", "en": "Peered Network", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 在大型主機防火牆上將 Cloud Build 的公開 IP 範圍列入白名單，並啟用 Cloud NAT 以固定來源 IP。",
          "en": "(B) Whitelist Cloud Build's public IP ranges on the mainframe firewall and enable Cloud NAT to fix the source IP.",
          "wg": [
            { "t": "列入白名單", "en": "Whitelist", "ps": "verb" },
            { "t": "固定", "en": "fix", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 使用 Jenkins 安裝在 GKE 私有叢集中，並使用 Cloud Build 觸發 Jenkins Pipeline。Jenkins Agent 透過 VPC 存取地端。",
          "en": "(C) Use Jenkins installed in a private GKE cluster, and trigger the Jenkins Pipeline using Cloud Build. The Jenkins Agent accesses on-prem via VPC.",
          "wg": [
            { "t": "私有叢集", "en": "private cluster", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 將相依套件預先下載並上傳至 Cloud Storage，修改 Cloud Build 步驟以從 GCS 拉取，避免直接連線至地端。",
          "en": "(D) Pre-download dependencies and upload them to Cloud Storage, creating a Cloud Build step to pull from GCS, avoiding direct connection to on-prem.",
          "wg": [
            { "t": "預先下載", "en": "Pre-download", "ps": "verb" },
            { "t": "避免", "en": "avoiding", "ps": "verb" }
          ]
        }
      ],
      "answer": "(A)",
      "why": {
        "t": "預設的 Cloud Build 執行在 Google 管理的專案中，無法直接存取使用者的私有 VPC 或地端資源。Cloud Build Private Pools (私有集區) 允許您在自己的 VPC 中配置專屬的 worker pool。透過 VPC Peering，這些 worker 可以經由 Interconnect 安全地存取地端大型主機，完全不經過公共網際網路。選項 (B) Cloud Build 公開 IP 範圍很大且經常變動，白名單管理困難且不安全。選項 (C) 引入 Jenkins 增加了管理負擔。選項 (D) 對於動態或頻繁變更的依賴項，手動同步流程不可行。",
        "en": "Default Cloud Build runs in a Google-managed project and cannot directly access user private VPCs or on-prem resources. Cloud Build Private Pools allow you to provision dedicated worker pools within your own VPC. Through VPC Peering, these workers can securely access the on-prem mainframe via Interconnect, completely bypassing the public internet. Option (B) Cloud Build public IP ranges are large and change frequently; whitelisting is hard and insecure. Option (C) introducing Jenkins adds management toil. Option (D) manual sync processes are infeasible for dynamic or frequently changing dependencies.",
        "wg": [
          { "t": "專屬的", "en": "dedicated", "ps": "adjective" },
          { "t": "繞過", "en": "bypassing", "ps": "verb" }
        ]
      }
    },
    {
      "no": "53",
      "level": "hard",
      "keywords": "BigQuery, Reservations, Slots, Workload Management",
      "question": [
        {
          "t": "KnightMotives 的「數據變現」業務增長迅速，許多外部合作夥伴付費訂閱了 BigQuery 數據分析服務。然而，當公司內部的資料科學團隊執行大型模型訓練查詢時，合作夥伴經常抱怨查詢速度變慢。",
          "en": "KnightMotives' \"Data Monetization\" business is growing fast, with many external partners subscribing to BigQuery analytics services. However, when the internal data science team runs large model training queries, partners often complain about slow query speeds.",
          "wg": [
            { "t": "付費訂閱", "en": "subscribing", "ps": "verb" },
            { "t": "變慢", "en": "slow ... speeds", "ps": "adjective" }
          ]
        },
        {
          "t": "您需要確保「付費合作夥伴」始終享有保證的查詢效能，同時允許內部團隊使用剩餘的閒置資源。應採用哪種 BigQuery 資源管理策略？",
          "en": "You need to ensure \"paying partners\" always have guaranteed query performance while allowing internal teams to use remaining idle resources. Which BigQuery resource management strategy should you adopt?",
          "wg": [
            { "t": "保證的", "en": "guaranteed", "ps": "adjective" },
            { "t": "閒置資源", "en": "idle resources", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 為合作夥伴建立獨立的 Google Cloud 專案，並使用 Billing Account 限制內部團隊專案的每日查詢支出上限。",
          "en": "(A) Create a separate Google Cloud Project for partners and use the Billing Account to cap the daily query spending of internal team projects.",
          "wg": [
            { "t": "支出上限", "en": "spending cap", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 使用 BigQuery Reservations。購買專用的 Slot 容量，並建立兩個預約 (Reservations)：一個給合作夥伴 (設為 Baseline)，一個給內部團隊。將閒置 Slot 分享設定為開啟。",
          "en": "(B) Use BigQuery Reservations. Purchase dedicated Slot capacity and create two Reservations: one for partners (set as Baseline) and one for internal teams. Enable idle slot sharing.",
          "wg": [
            { "t": "預約", "en": "Reservations", "ps": "noun" },
            { "t": "閒置 Slot 分享", "en": "idle slot sharing", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 將合作夥伴的數據匯出至 Bigtable，因為 Bigtable 提供更穩定的讀取延遲，適合對外服務。",
          "en": "(C) Export partner data to Bigtable, as Bigtable provides more stable read latency, suitable for external-facing services.",
          "wg": [
            { "t": "穩定的", "en": "stable", "ps": "adjective" }
          ]
        },
        {
          "t": "(D) 使用查詢優先順序 (Query Priorities)。要求內部團隊在所有 SQL 查詢中加入 `priority=BATCH` 標籤，以讓出資源給互動式查詢。",
          "en": "(D) Use Query Priorities. Require internal teams to add the `priority=BATCH` tag to all SQL queries to yield resources to interactive queries.",
          "wg": [
            { "t": "優先順序", "en": "Priorities", "ps": "noun" },
            { "t": "讓出", "en": "yield", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "BigQuery Reservations (Slots) 是管理工作負載效能隔離的標準機制。透過購買 Slot 並分配給不同的 Reservations (如 Partner vs Internal)，您可以保證關鍵業務 (Partner) 獲得固定的運算能力。啟用「閒置 Slot 分享 (Idle Slot Sharing)」則允許內部團隊在合作夥伴未使用時借用這些資源，最大化資源利用率。選項 (A) 限制支出會導致內部查詢失敗，而非效能隔離。選項 (C) Bigtable 不支援複雜的 SQL 分析。選項 (D) 依賴開發者自覺設定 Batch 優先級並不可靠，且無法提供硬性的效能保證。",
        "en": "BigQuery Reservations (Slots) is the standard mechanism for managing workload performance isolation. By purchasing Slots and assigning them to different Reservations (e.g., Partner vs Internal), you guarantee fixed compute capacity for critical business (Partners). Enabling \"Idle Slot Sharing\" allows internal teams to borrow these resources when partners aren't using them, maximizing utilization. Option (A) capping spending causes internal queries to fail, not isolate performance. Option (C) Bigtable doesn't support complex SQL analytics. Option (D) relying on developers to set Batch priority is unreliable and doesn't offer hard performance guarantees.",
        "wg": [
          { "t": "效能隔離", "en": "performance isolation", "ps": "noun" },
          { "t": "最大化", "en": "maximizing", "ps": "verb" }
        ]
      }
    },
    {
      "no": "54",
      "level": "hard",
      "keywords": "IAP, OS Login, SSH, Security",
      "question": [
        {
          "t": "KnightMotives 仍有部分舊有的 ICE 車輛生產線控制系統運行在 Compute Engine 的 Linux VM 上。管理員需要透過 SSH 進行維護。",
          "en": "KnightMotives still has some legacy ICE vehicle production line control systems running on Compute Engine Linux VMs. Administrators need to perform maintenance via SSH.",
          "wg": [
            { "t": "控制系統", "en": "control systems", "ps": "noun" },
            { "t": "維護", "en": "maintenance", "ps": "noun" }
          ]
        },
        {
          "t": "為了防止「過去的數據洩露」重演，您必須消除所有長期的 SSH 金鑰 (Long-lived keys)，並確保 VM 不需要公開 IP 位址即可被存取。應採用哪種安全連線方式？",
          "en": "To prevent a recurrence of \"past data breaches,\" you must eliminate all Long-lived SSH keys and ensure VMs can be accessed without Public IP addresses. Which secure connection method should you adopt?",
          "wg": [
            { "t": "消除", "en": "eliminate", "ps": "verb" },
            { "t": "公開 IP 位址", "en": "Public IP addresses", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 為 VM 配置外部 IP，並在防火牆中僅允許公司 VPN 的 IP 範圍進行 SSH (Port 22) 連線。",
          "en": "(A) Configure external IPs for VMs and allow SSH (Port 22) connections only from the corporate VPN IP range in the firewall.",
          "wg": [
            { "t": "外部 IP", "en": "external IPs", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 啟用 OS Login 並使用 Identity-Aware Proxy (IAP) 進行 TCP 轉發。授權管理員使用其 Google 身分登入，無需管理 SSH 金鑰。",
          "en": "(B) Enable OS Login and use Identity-Aware Proxy (IAP) for TCP forwarding. Authorize administrators to login using their Google Identity without managing SSH keys.",
          "wg": [
            { "t": "TCP 轉發", "en": "TCP forwarding", "ps": "noun" },
            { "t": "授權", "en": "Authorize", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 使用 Cloud Shell。因為 Cloud Shell 位於 Google 網路內部，可以直接連線至僅有私有 IP 的 VM。",
          "en": "(C) Use Cloud Shell. Since Cloud Shell is inside Google's network, it can directly connect to Private IP-only VMs.",
          "wg": [
            { "t": "位於...內部", "en": "inside", "ps": "preposition" }
          ]
        },
        {
          "t": "(D) 在每個子網路中部署一台 Bastion Host (跳板機)，並為其配置公開 IP。管理員先連線至 Bastion，再跳轉至目標 VM。",
          "en": "(D) Deploy a Bastion Host in each subnet with a public IP. Administrators connect to the Bastion first, then jump to the target VM.",
          "wg": [
            { "t": "跳板機", "en": "Bastion Host", "ps": "noun" },
            { "t": "跳轉", "en": "jump", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Identity-Aware Proxy (IAP) 的 TCP 轉發功能允許使用者透過 HTTPS 通道建立 SSH 連線，因此 VM 不需要公開 IP 位址。結合 OS Login，系統會將 SSH 存取與 Google IAM 身分綁定 (使用短暫憑證)，徹底消除了管理長期 SSH 金鑰的風險。這是 Google 推薦的最安全實踐。選項 (A) 需要公開 IP，增加了攻擊面。選項 (C) Cloud Shell 雖然方便，但預設無法直接存取私有 VPC 資源 (除非也是透過 IAP)。選項 (D) Bastion Host 成為單點故障且本身需要維護與防護，不如無伺服器的 IAP 安全。",
        "en": "Identity-Aware Proxy (IAP) TCP forwarding allows users to establish SSH connections via an HTTPS tunnel, so VMs do not need public IPs. Combined with OS Login, SSH access is bound to Google IAM identities (using ephemeral certificates), completely eliminating the risk of managing long-lived SSH keys. This is the Google-recommended best practice. Option (A) requires public IPs, increasing the attack surface. Option (C) Cloud Shell cannot directly access private VPC resources by default (unless also using IAP). Option (D) Bastion Hosts become single points of failure and require maintenance/hardening, making them less secure than serverless IAP.",
        "wg": [
          { "t": "攻擊面", "en": "attack surface", "ps": "noun" },
          { "t": "單點故障", "en": "single points of failure", "ps": "noun" }
        ]
      }
    },
    {
      "no": "55",
      "level": "hard",
      "keywords": "Committed Use Discounts, Cost Optimization, Compute Engine, Migration",
      "question": [
        {
          "t": "KnightMotives 有數千台 VM 用於支援傳統的 ICE 車輛製造系統。這些工作負載非常穩定，且預計在未來 3 年內不會有重大架構變更。",
          "en": "KnightMotives has thousands of VMs supporting legacy ICE vehicle manufacturing systems. These workloads are stable and not expected to undergo significant architectural changes for the next 3 years.",
          "wg": [
            { "t": "穩定的", "en": "stable", "ps": "adjective" },
            { "t": "架構變更", "en": "architectural changes", "ps": "noun" }
          ]
        },
        {
          "t": "為了達成「全球規模的財務優先順序轉變」，您需要最大程度地降低這些 VM 的運算成本，同時不影響可用性。應購買哪種折扣方案？",
          "en": "To achieve a \"shift in financial priorities on a global scale,\" you need to maximize compute cost savings for these VMs without compromising availability. Which discount plan should you purchase?",
          "wg": [
            { "t": "最大程度地降低", "en": "maximize ... savings", "ps": "verb" },
            { "t": "不影響", "en": "without compromising", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 持續使用折扣 (SUDs)。這是自動套用的，無需任何前期承諾或設定。",
          "en": "(A) Sustained Use Discounts (SUDs). These are applied automatically without any upfront commitment or configuration.",
          "wg": [
            { "t": "自動套用", "en": "applied automatically", "ps": "verb" },
            { "t": "前期承諾", "en": "upfront commitment", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 購買 3 年期的承諾使用折扣 (Committed Use Discounts, CUDs)。這能提供比 SUDs 更高的折扣率 (高達 57% 或更多)。",
          "en": "(B) Purchase 3-year Committed Use Discounts (CUDs). This offers a higher discount rate than SUDs (up to 57% or more).",
          "wg": [
            { "t": "折扣率", "en": "discount rate", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 將所有 VM 轉換為 Spot VMs。這能節省高達 91% 的成本，但可能會被隨時搶佔。",
          "en": "(C) Convert all VMs to Spot VMs. This saves up to 91% costs but risks preemption at any time.",
          "wg": [
            { "t": "搶佔", "en": "preemption", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 等待 Google 自動推薦並套用「預測性自動擴展 (Predictive Autoscaling)」來關閉閒置 VM。",
          "en": "(D) Wait for Google to automatically recommend and apply \"Predictive Autoscaling\" to turn off idle VMs.",
          "wg": [
            { "t": "預測性自動擴展", "en": "Predictive Autoscaling", "ps": "noun" },
            { "t": "閒置", "en": "idle", "ps": "adjective" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "對於「穩定且長期 (3年)」的工作負載，承諾使用折扣 (CUDs) 是節省成本的最佳工具。3 年期 CUD 的折扣幅度遠高於 SUD (持續使用折扣)，且適用於這種不會變動的 ICE 車輛系統。選項 (A) SUD 是自動的但折扣較少 (約 30%)。選項 (C) Spot VMs 雖然最便宜，但會隨時中斷，題目明確要求「不影響可用性」，且傳統製造系統通常不是無狀態 (Stateless) 的，無法容忍中斷。選項 (D) 僅針對擴展，無法降低基礎負載的單價。",
        "en": "For \"stable and long-term (3 years)\" workloads, Committed Use Discounts (CUDs) are the best tool for cost savings. The 3-year CUD discount rate is significantly higher than SUD (Sustained Use Discounts) and fits these unchanging ICE vehicle systems. Option (A) SUD is automatic but offers less discount (~30%). Option (C) Spot VMs are cheapest but interruptible; the prompt specifically requires \"without compromising availability,\" and legacy manufacturing systems are typically not stateless/fault-tolerant. Option (D) only addresses scaling, not the unit price of the base load.",
        "wg": [
          { "t": "節省成本", "en": "cost savings", "ps": "noun" },
          { "t": "無狀態", "en": "Stateless", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "56",
      "level": "hard",
      "keywords": "Workload Identity Federation, IAM, Security, Hybrid",
      "question": [
        {
          "t": "KnightMotives 的地端資料中心運行著一套以 GitLab CI 為基礎的自動化部署管道。該管道負責將經過測試的容器映像檔推送到 Google Artifact Registry。",
          "en": "KnightMotives' on-premises data center runs a GitLab CI-based automated deployment pipeline. This pipeline is responsible for pushing tested container images to Google Artifact Registry.",
          "wg": [
            { "t": "自動化部署管道", "en": "automated deployment pipeline", "ps": "noun" },
            { "t": "推送到", "en": "pushing ... to", "ps": "verb" }
          ]
        },
        {
          "t": "資安長 (CISO) 嚴格禁止下載與儲存任何 Google Cloud 服務帳戶金鑰 (Service Account Keys)，因為這類長效憑證容易發生洩露。您需要設定一種機制，讓地端 GitLab Runner 能夠安全地驗證並存取 Google Cloud 資源。應採用哪種方法？",
          "en": "The CISO strictly prohibits downloading and storing any Google Cloud Service Account Keys, as such long-lived credentials are prone to leakage. You need to configure a mechanism that allows on-premises GitLab Runners to securely authenticate and access Google Cloud resources. Which method should you adopt?",
          "wg": [
            { "t": "嚴格禁止", "en": "strictly prohibits", "ps": "verb" },
            { "t": "長效憑證", "en": "long-lived credentials", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 在 GitLab Runner 上安裝 Cloud SDK，並使用 `gcloud auth login` 透過使用者的 Google 帳戶進行互動式登入。",
          "en": "(A) Install Cloud SDK on the GitLab Runner and use `gcloud auth login` to perform interactive login via a user's Google account.",
          "wg": [
            { "t": "互動式登入", "en": "interactive login", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 實施 Workload Identity Federation。設定一個與 OIDC 相容的識別身分集區 (Workload Identity Pool)，信任地端 GitLab 簽發的 Token，並將其交換為 Google 短效憑證。",
          "en": "(B) Implement Workload Identity Federation. Configure an OIDC-compatible Workload Identity Pool to trust tokens issued by the on-premises GitLab, exchanging them for short-lived Google credentials.",
          "wg": [
            { "t": "識別身分集區", "en": "Workload Identity Pool", "ps": "noun" },
            { "t": "交換", "en": "exchanging", "ps": "verb" },
            { "t": "短效憑證", "en": "short-lived credentials", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 建立一個服務帳戶，並將其金鑰儲存在 HashiCorp Vault 中。設定 GitLab Runner 在執行時從 Vault 動態擷取金鑰。",
          "en": "(C) Create a Service Account and store its key in HashiCorp Vault. Configure the GitLab Runner to dynamically retrieve the key from Vault at runtime.",
          "wg": [
            { "t": "動態擷取", "en": "dynamically retrieve", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 使用 Cloud VPN 將地端網路延伸至 Google Cloud，並允許地端機器直接使用 Compute Engine 的預設服務帳戶。",
          "en": "(D) Use Cloud VPN to extend the on-premises network to Google Cloud, allowing on-premises machines to directly use the Compute Engine default service account.",
          "wg": [
            { "t": "延伸", "en": "extend", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Workload Identity Federation 是 Google Cloud 推薦用於「消除服務帳戶金鑰 (Keyless)」的安全實踐。它允許外部環境 (如 AWS, Azure, 或地端 OIDC/SAML 供應商) 的工作負載使用其自身的憑證 (如 GitLab CI Job Token) 來交換 Google Cloud 的短效存取權杖。這完全符合 CISO 對於「禁止下載儲存金鑰」的要求。選項 (A) 互動式登入不適合自動化管道。選項 (C) 雖然使用了 Vault，但根本上還是產生了長效金鑰 (Long-lived Key)，只是改變了儲存位置，風險仍在。選項 (D) 地端機器無法直接使用 GCP VM 的 Metadata Server 服務帳戶。",
        "en": "Workload Identity Federation is the Google Cloud recommended security practice for \"Keyless\" authentication. It allows workloads in external environments (like AWS, Azure, or on-prem OIDC/SAML providers) to use their own credentials (like GitLab CI Job Tokens) to exchange for short-lived Google Cloud access tokens. This strictly complies with the CISO's requirement to \"prohibit downloading/storing keys.\" Option (A) interactive login is unsuitable for automated pipelines. Option (C) while using Vault, fundamentally still generates a Long-lived Key, merely shifting its storage location; the risk remains. Option (D) on-prem machines cannot directly use the GCP VM Metadata Server service account.",
        "wg": [
          { "t": "安全實踐", "en": "security practice", "ps": "noun" },
          { "t": "根本上", "en": "fundamentally", "ps": "adverb" }
        ]
      }
    },
    {
      "no": "57",
      "level": "hard",
      "keywords": "Memorystore, Redis, Caching, Latency",
      "question": [
        {
          "t": "KnightMotives 的「線上訂購系統」在新車發布期間會遭遇極高的流量。使用者反映在瀏覽選配清單 (如顏色、輪框樣式) 時載入速度緩慢。",
          "en": "KnightMotives' \"online ordering system\" experiences extremely high traffic during new car launches. Users report slow loading times when browsing the options list (e.g., colors, rim styles).",
          "wg": [
            { "t": "選配清單", "en": "options list", "ps": "noun" },
            { "t": "載入速度緩慢", "en": "slow loading times", "ps": "noun" }
          ]
        },
        {
          "t": "這些選配資料儲存在 Cloud SQL 中，很少變更但讀取頻率極高。為了減輕資料庫負載並將回應時間降至毫秒級，您應建議哪種架構優化？",
          "en": "These options data are stored in Cloud SQL, change rarely but are read very frequently. To reduce database load and lower response times to milliseconds, which architectural optimization should you recommend?",
          "wg": [
            { "t": "很少變更", "en": "change rarely", "ps": "verb" },
            { "t": "毫秒級", "en": "milliseconds", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 增加 Cloud SQL 的 vCPU 與記憶體規格，並將硬碟升級為極速 PD (Extreme PD)。",
          "en": "(A) Increase Cloud SQL vCPU and memory specifications, and upgrade the disk to Extreme PD.",
          "wg": [
            { "t": "規格", "en": "specifications", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 部署 Memorystore for Redis。在應用程式與資料庫之間實作「快取旁路 (Cache-aside)」模式，將熱門的選配資料快取在記憶體中。",
          "en": "(B) Deploy Memorystore for Redis. Implement the \"Cache-aside\" pattern between the application and database to cache popular options data in memory.",
          "wg": [
            { "t": "快取旁路", "en": "Cache-aside", "ps": "noun" },
            { "t": "熱門的", "en": "popular", "ps": "adjective" }
          ]
        },
        {
          "t": "(C) 使用 BigQuery 作為後端資料庫，並啟用 BI Engine 來加速查詢。",
          "en": "(C) Use BigQuery as the backend database and enable BI Engine to accelerate queries.",
          "wg": [
            { "t": "加速", "en": "accelerate", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 在 Cloud SQL 前端部署 Cloud CDN，並設定 Cache-Control 標頭以快取 SQL 回應。",
          "en": "(D) Deploy Cloud CDN in front of Cloud SQL, and configure Cache-Control headers to cache SQL responses.",
          "wg": [
            { "t": "前端", "en": "in front of", "ps": "preposition" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Memorystore for Redis 是全代管的記憶體內資料儲存服務，能提供次毫秒級 (Sub-millisecond) 的資料存取。對於「讀多寫少 (Read-heavy, Write-rarely)」的資料 (如產品目錄、設定選項)，使用 Cache-aside 模式是標準做法，能顯著降低 Cloud SQL 的壓力並提升使用者體驗。選項 (A) 垂直擴展 (Scale Up) 成本高且有極限，無法像快取那樣提供毫秒級延遲。選項 (C) BigQuery 是分析型資料庫 (OLAP)，不適合線上交易處理 (OLTP) 的應用程式後端。選項 (D) Cloud CDN 用於快取 HTTP 內容，無法直接快取 SQL 協定的流量。",
        "en": "Memorystore for Redis is a fully managed in-memory data store providing sub-millisecond data access. For \"Read-heavy, Write-rarely\" data (like product catalogs, configuration options), using the Cache-aside pattern is the standard practice to significantly reduce Cloud SQL load and improve UX. Option (A) Scaling Up is costly and has limits, failing to provide millisecond latency like caching. Option (C) BigQuery is an analytical database (OLAP), unsuitable as a backend for OLTP applications. Option (D) Cloud CDN caches HTTP content and cannot directly cache SQL protocol traffic.",
        "wg": [
          { "t": "讀多寫少", "en": "Read-heavy, Write-rarely", "ps": "adjective" },
          { "t": "次毫秒級", "en": "Sub-millisecond", "ps": "adjective" }
        ]
      }
    },
    {
      "no": "58",
      "level": "hard",
      "keywords": "Cloud Tasks, Rate Limiting, Legacy, Decoupling",
      "question": [
        {
          "t": "KnightMotives 的新線上訂購系統非常受歡迎，但在促銷活動期間，瞬間湧入的大量訂單請求會壓垮後端過時的 ERP 系統 (該系統無法水平擴展)。",
          "en": "KnightMotives' new online ordering system is very popular, but during promotions, the sudden influx of order requests overwhelms the backend legacy ERP system (which cannot scale horizontally).",
          "wg": [
            { "t": "湧入", "en": "influx", "ps": "noun" },
            { "t": "壓垮", "en": "overwhelms", "ps": "verb" },
            { "t": "水平擴展", "en": "scale horizontally", "ps": "verb" }
          ]
        },
        {
          "t": "您需要引入一個緩衝機制，確保即使前端流量激增，發送給 ERP 的請求速率 (Rate) 仍保持在每秒 50 個請求 (RPS) 以下，且不會遺失任何訂單。應使用哪項服務？",
          "en": "You need to introduce a buffering mechanism to ensure that even if frontend traffic spikes, the request Rate sent to the ERP remains under 50 requests per second (RPS), without losing any orders. Which service should you use?",
          "wg": [
            { "t": "緩衝機制", "en": "buffering mechanism", "ps": "noun" },
            { "t": "流量激增", "en": "traffic spikes", "ps": "verb" },
            { "t": "遺失", "en": "losing", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Pub/Sub 接收訂單，並使用 Dataflow 串流作業讀取訊息。在 Dataflow 中實作 `GroupByKey` 與 Timer 來限制輸出速率。",
          "en": "(A) Use Pub/Sub to ingest orders and a Dataflow streaming job to read messages. Implement `GroupByKey` and Timer in Dataflow to limit output rate.",
          "wg": [
            { "t": "串流作業", "en": "streaming job", "ps": "noun" },
            { "t": "輸出速率", "en": "output rate", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 使用 Cloud Tasks 建立一個佇列 (Queue)。將訂單請求加入該佇列，並設定 `maxDispatchesPerSecond` 為 50。由 Cloud Tasks 負責以固定速率呼叫 ERP API。",
          "en": "(B) Use Cloud Tasks to create a Queue. Enqueue order requests and configure `maxDispatchesPerSecond` to 50. Cloud Tasks is responsible for calling the ERP API at a fixed rate.",
          "wg": [
            { "t": "佇列", "en": "Queue", "ps": "noun" },
            { "t": "固定速率", "en": "fixed rate", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 在 ERP 前端部署 Cloud Load Balancer，並啟用 Cloud Armor 的速率限制 (Rate Limiting) 策略，將超過閾值的請求直接拒絕 (429 Too Many Requests)。",
          "en": "(C) Deploy a Cloud Load Balancer in front of the ERP and enable Cloud Armor Rate Limiting policy to directly deny requests exceeding the threshold (429 Too Many Requests).",
          "wg": [
            { "t": "速率限制", "en": "Rate Limiting", "ps": "noun" },
            { "t": "拒絕", "en": "deny", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 使用 Cloud Functions 接收訂單，並在函式程式碼中使用 `time.sleep()` 來延遲執行，以確保不會過快呼叫 ERP。",
          "en": "(D) Use Cloud Functions to receive orders, and use `time.sleep()` in the function code to delay execution, ensuring the ERP is not called too quickly.",
          "wg": [
            { "t": "延遲", "en": "delay", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Cloud Tasks 是處理非同步任務執行、速率限制 (Rate Limiting) 與重試的最佳託管服務。透過設定佇列層級的 `maxDispatchesPerSecond`，可以輕鬆保護下游無法擴展的舊系統 (Throttling)，同時確保任務持久化不遺失。選項 (A) 使用 Dataflow 實作速率限制過於複雜且成本高昂。選項 (C) Cloud Armor 會直接「拒絕」請求導致訂單失敗，而不是「緩衝」訂單。選項 (D) 使用 `sleep` 會導致 Cloud Functions 執行時間過長，增加成本並可能超時，且無法精確控制全域併發量。",
        "en": "Cloud Tasks is the premier managed service for asynchronous task execution, Rate Limiting, and retries. By configuring `maxDispatchesPerSecond` at the queue level, you can easily protect non-scalable downstream legacy systems (Throttling) while ensuring task persistence and zero loss. Option (A) implementing rate limiting in Dataflow is overly complex and costly. Option (C) Cloud Armor would \"deny\" requests causing order failures, rather than \"buffering\" them. Option (D) using `sleep` keeps Cloud Functions running longer, increasing costs and risking timeouts, and cannot precisely control global concurrency.",
        "wg": [
          { "t": "非同步任務", "en": "asynchronous task", "ps": "noun" },
          { "t": "持久化", "en": "persistence", "ps": "noun" }
        ]
      }
    },
    {
      "no": "59",
      "level": "hard",
      "keywords": "Cloud Asset Inventory, Compliance, IAM, Analysis",
      "question": [
        {
          "t": "KnightMotives 的法務部門要求提供過去一年內所有 Google Cloud 專案中防火牆規則變更的完整歷史紀錄，以進行安全稽核。此外，他們還需要一份當前所有公開可存取 (Publicly Accessible) 的儲存桶清單。",
          "en": "KnightMotives' legal department requests a complete history of firewall rule changes across all Google Cloud projects over the past year for a security audit. Additionally, they need a list of all currently Publicly Accessible storage buckets.",
          "wg": [
            { "t": "完整歷史紀錄", "en": "complete history", "ps": "noun" },
            { "t": "公開可存取", "en": "Publicly Accessible", "ps": "adjective" }
          ]
        },
        {
          "t": "手動檢查數百個專案是不可能的。您需要一個自動化且高效率的方式來匯出這些數據並進行分析。應使用哪項服務？",
          "en": "Manually checking hundreds of projects is impossible. You need an automated and efficient way to export this data for analysis. Which service should you use?",
          "wg": [
            { "t": "自動化", "en": "automated", "ps": "adjective" },
            { "t": "匯出", "en": "export", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Logging。在 Log Explorer 中編寫進階查詢來搜尋 `compute.firewalls.patch` 事件，並將結果匯出為 JSON。",
          "en": "(A) Use Cloud Logging. Write advanced queries in Log Explorer to search for `compute.firewalls.patch` events and export results as JSON.",
          "wg": [
            { "t": "進階查詢", "en": "advanced queries", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 使用 Cloud Asset Inventory (CAI)。使用 `ExportAssets` API 將當前狀態匯出至 BigQuery，並使用 `ExportAssetHistory` API 將資源變更歷史匯出以進行時序分析。",
          "en": "(B) Use Cloud Asset Inventory (CAI). Use the `ExportAssets` API to export current state to BigQuery, and use the `ExportAssetHistory` API to export resource change history for time-series analysis.",
          "wg": [
            { "t": "資源變更歷史", "en": "resource change history", "ps": "noun" },
            { "t": "時序分析", "en": "time-series analysis", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 Security Command Center (SCC) Premium。在控制台中查看「資產 (Assets)」頁面，並手動截圖相關的防火牆變更。",
          "en": "(C) Use Security Command Center (SCC) Premium. View the \"Assets\" page in the console and manually screenshot relevant firewall changes.",
          "wg": [
            { "t": "手動截圖", "en": "manually screenshot", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 編寫一個 Shell Script，迴圈遍歷所有專案並執行 `gcloud compute firewall-rules list`，將輸出儲存到 Cloud Storage。",
          "en": "(D) Write a Shell Script to loop through all projects and execute `gcloud compute firewall-rules list`, saving the output to Cloud Storage.",
          "wg": [
            { "t": "迴圈遍歷", "en": "loop through", "ps": "verb" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Cloud Asset Inventory (CAI) 是專為大規模資產分析與稽核設計的服務。它能提供組織層級的資源快照 (`ExportAssets`) 和歷史變更記錄 (`ExportAssetHistory`)。將這些數據匯出至 BigQuery 後，可以使用 SQL 輕鬆查詢「過去一年所有防火牆變更」或「所有公開 Bucket」。選項 (A) Logs 雖然包含操作紀錄，但難以重建資產的完整狀態 (State) 且查詢效率不如 BigQuery。選項 (C) 手動截圖無法滿足稽核需求。選項 (D) 腳本只能取得「當前」狀態，無法取得「歷史」變更。",
        "en": "Cloud Asset Inventory (CAI) is the service designed for large-scale asset analysis and auditing. It provides organization-level resource snapshots (`ExportAssets`) and historical change records (`ExportAssetHistory`). Exporting this data to BigQuery allows easy SQL querying for \"all firewall changes in the past year\" or \"all public buckets.\" Option (A) Logs contain operation records but struggle to reconstruct the full asset State and are less efficient to query than BigQuery. Option (C) manual screenshots do not meet audit needs. Option (D) scripts only fetch \"current\" state, not \"historical\" changes.",
        "wg": [
          { "t": "大規模", "en": "large-scale", "ps": "adjective" },
          { "t": "重建", "en": "reconstruct", "ps": "verb" }
        ]
      }
    },
    {
      "no": "60",
      "level": "hard",
      "keywords": "Network Intelligence Center, Troubleshooting, Connectivity, Packet Drop",
      "question": [
        {
          "t": "KnightMotives 的地端工廠回報無法連線至 Google Cloud 上的庫存應用程式 (位於 Private VPC)。您已確認 Interconnect 線路狀態正常，且防火牆規則看似正確。",
          "en": "KnightMotives' on-premises factories report inability to connect to the inventory application on Google Cloud (located in a Private VPC). You have confirmed the Interconnect line status is healthy and firewall rules appear correct.",
          "wg": [
            { "t": "無法連線", "en": "inability to connect", "ps": "noun" },
            { "t": "看似正確", "en": "appear correct", "ps": "verb" }
          ]
        },
        {
          "t": "您需要一個工具來模擬從地端 IP 到雲端 VM 的網路封包路徑，以精確診斷封包是在哪個節點 (例如：特定防火牆規則、路由或 VPC Service Control) 被丟棄。應使用哪項功能？",
          "en": "You need a tool to simulate the network packet path from an on-premises IP to a cloud VM to precisely diagnose where packets are being dropped (e.g., specific firewall rule, route, or VPC Service Control). Which feature should you use?",
          "wg": [
            { "t": "模擬", "en": "simulate", "ps": "verb" },
            { "t": "診斷", "en": "diagnose", "ps": "verb" },
            { "t": "被丟棄", "en": "being dropped", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 VPC Flow Logs。啟用後等待數小時，分析流量日誌中是否有 `REJECT` 的紀錄。",
          "en": "(A) Use VPC Flow Logs. Enable and wait for several hours, then analyze traffic logs for `REJECT` records.",
          "wg": [
            { "t": "流量日誌", "en": "traffic logs", "ps": "noun" }
          ]
        },
        {
          "t": "(B) 使用 Network Intelligence Center 的連線測試 (Connectivity Tests)。建立一個測試，指定地端來源 IP 與雲端目標 VM，系統會靜態分析設定並視覺化封包路徑與丟棄原因。",
          "en": "(B) Use Network Intelligence Center Connectivity Tests. Create a test specifying the on-premises source IP and cloud destination VM. The system statically analyzes configurations and visualizes the packet path and drop reason.",
          "wg": [
            { "t": "連線測試", "en": "Connectivity Tests", "ps": "noun" },
            { "t": "靜態分析", "en": "statically analyzes", "ps": "verb" },
            { "t": "丟棄原因", "en": "drop reason", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 在地端機器上執行 `traceroute` 或 `ping` 指令，並查看在哪個跳躍點 (Hop) 中斷。",
          "en": "(C) Run `traceroute` or `ping` commands on the on-premises machine and observe at which Hop the connection breaks.",
          "wg": [
            { "t": "跳躍點", "en": "Hop", "ps": "noun" },
            { "t": "中斷", "en": "breaks", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 暫時將 VPC 防火牆規則設定為 `Allow All` (0.0.0.0/0)，如果連線恢復，則逐步縮小範圍以找出問題規則。",
          "en": "(D) Temporarily set VPC firewall rules to `Allow All` (0.0.0.0/0). If connectivity restores, incrementally narrow the scope to find the problematic rule.",
          "wg": [
            { "t": "逐步縮小", "en": "incrementally narrow", "ps": "verb" },
            { "t": "有問題的", "en": "problematic", "ps": "adjective" }
          ]
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Network Intelligence Center 的 Connectivity Tests (連線測試) 是診斷複雜網路問題的最佳工具。它不需要發送真實封包，而是根據 GCP 的網路配置 (防火牆、路由、VPN、IAM 等) 進行「靜態可達性分析」。它能明確指出封包被丟棄的確切原因 (例如：「被防火牆規則 deny-all-ingress 阻擋」)，非常適合除錯混合雲連線。選項 (A) Flow Logs 是被動紀錄，需要真實流量且分析耗時。選項 (C) Traceroute 經常被防火牆阻擋 (ICMP)，且無法顯示雲端內部的邏輯阻擋原因。選項 (D) 這種「試誤法 (Trial-and-error)」在生產環境中極度危險且不專業。",
        "en": "Network Intelligence Center Connectivity Tests is the best tool for diagnosing complex network issues. It performs \"static reachability analysis\" based on GCP network configurations (firewalls, routes, VPNs, IAM, etc.) without sending real packets. It explicitly pinpoints the exact reason for drops (e.g., \"blocked by firewall rule deny-all-ingress\"), making it ideal for debugging hybrid connectivity. Option (A) Flow Logs are reactive and require real traffic/time to analyze. Option (C) Traceroute is often blocked (ICMP) and can't show internal cloud logic drops. Option (D) \"Trial-and-error\" is extremely dangerous and unprofessional in production.",
        "wg": [
          { "t": "靜態可達性分析", "en": "static reachability analysis", "ps": "noun" },
          { "t": "試誤法", "en": "Trial-and-error", "ps": "noun" }
        ]
      }
    }
  ]