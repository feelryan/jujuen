[
  {
    "no": "1",
    "level": "hard",
    "keywords": "Hybrid Connectivity, Dedicated Interconnect, SLA",
    "question": [
      {
        "t": "EHR Healthcare 正在將其面向客戶的應用程式遷移到 Google Cloud，以應對指數級的業務增長並替換租約即將到期的託管設施。",
        "en": "EHR Healthcare is migrating its customer-facing applications to Google Cloud to handle exponential business growth and replace colocation facilities where the lease is expiring.",
        "wg": [
          { "t": "遷移", "en": "migrating", "ps": "verb" },
          { "t": "託管設施", "en": "colocation facilities", "ps": "noun" }
        ]
      },
      {
        "t": "然而，數個關鍵的傳統檔案與 API 整合系統仍將保留在地端，且在未來幾年內沒有升級或遷移的計畫。",
        "en": "However, several critical legacy file- and API-based integration systems will remain on-premises, with no plans to upgrade or move them in the next several years.",
        "wg": [
          { "t": "地端", "en": "on-premises", "ps": "adj" },
          { "t": "傳統系統", "en": "legacy systems", "ps": "noun" }
        ]
      },
      {
        "t": "您需要設計一個連接架構，以滿足「在地端系統與 Google Cloud 之間提供安全且高效能連線」的技術需求，同時必須支援面向客戶系統所需的 99.9% 可用性目標。",
        "en": "You need to design a connectivity architecture to meet the technical requirement of providing a \"secure and high-performance connection between on-premises systems and Google Cloud,\" while supporting the 99.9% availability target required for customer-facing systems.",
        "wg": [
          { "t": "連接架構", "en": "connectivity architecture", "ps": "noun" },
          { "t": "高效能", "en": "high-performance", "ps": "adj" }
        ]
      },
      {
        "t": "考量到資料傳輸量大且對延遲敏感，您應該推薦哪種解決方案？",
        "en": "Considering the high volume of data transfer and latency sensitivity, which solution should you recommend?",
        "wg": [
          { "t": "延遲敏感", "en": "latency sensitivity", "ps": "adj" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 配置雲端 VPN (Cloud VPN) 高可用性 (HA) 閘道器，並透過網際網路建立兩條通道，以確保連線的備援性與安全性。",
        "en": "(A) Configure Cloud VPN High Availability (HA) gateway and establish two tunnels over the internet to ensure connection redundancy and security.",
        "wg": [
          { "t": "雲端 VPN", "en": "Cloud VPN", "ps": "product" },
          { "t": "網際網路", "en": "internet", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 透過合作夥伴互連 (Partner Interconnect) 連接，並選擇一家提供 99.9% 可用性 SLA 的服務供應商，以快速建立連接。",
        "en": "(B) Connect via Partner Interconnect and choose a service provider that offers a 99.9% availability SLA to establish connectivity quickly.",
        "wg": [
          { "t": "合作夥伴互連", "en": "Partner Interconnect", "ps": "product" }
        ]
      },
      {
        "t": "(C) 建置專用互連 (Dedicated Interconnect)，在單一都會區 (Metropolitan Area) 內配置兩個互連連線 (Interconnect connections)，以滿足 99.9% 的 SLA 並提供一致的高吞吐量。",
        "en": "(C) Provision Dedicated Interconnect with two interconnect connections in a single metropolitan area to meet the 99.9% SLA and provide consistent high throughput.",
        "wg": [
          { "t": "專用互連", "en": "Dedicated Interconnect", "ps": "product" },
          { "t": "單一都會區", "en": "single metropolitan area", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用營運商對等互連 (Carrier Peering) 直接連接到 Google 的邊緣網路，以減少中介跳躍點並降低成本。",
        "en": "(D) Use Carrier Peering to connect directly to Google's edge network to reduce intermediate hops and lower costs.",
        "wg": [
          { "t": "營運商對等互連", "en": "Carrier Peering", "ps": "product" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "專用互連 (Dedicated Interconnect) 是滿足「高效能」與「安全」連線的最佳選擇，且在單一都會區配置兩個連線即可符合 Google Cloud 的 99.9% 可用性 SLA，精準對應案例需求。",
      "en": "Dedicated Interconnect is the best choice for 'high-performance' and 'secure' connectivity. Configuring two connections in a single metropolitan area meets Google Cloud's 99.9% availability SLA, strictly aligning with the case requirements.",
      "wg": [
        { "t": "專用互連", "en": "Dedicated Interconnect", "ps": "product" },
        { "t": "可用性", "en": "availability", "ps": "noun" }
      ]
    }
  },
  {
    "no": "2",
    "level": "hard",
    "keywords": "GKE Enterprise, Multi-cluster, Policy Management",
    "question": [
      {
        "t": "為了滿足「提供一致的方式來管理基於容器的面向客戶應用程式」這一技術需求，EHR Healthcare 決定將其應用程式容器化並部署到 Google Kubernetes Engine (GKE)。",
        "en": "To meet the technical requirement of 'providing a consistent way to manage customer-facing applications that are container-based,' EHR Healthcare has decided to containerize its applications and deploy them to Google Kubernetes Engine (GKE).",
        "wg": [
          { "t": "一致的方式", "en": "consistent way", "ps": "adj" },
          { "t": "容器化", "en": "containerize", "ps": "verb" }
        ]
      },
      {
        "t": "隨著業務擴展，您需要在多個環境（包括開發、預備和生產環境）中動態擴展並配置新叢集。",
        "en": "As the business scales, you need to dynamically scale and provision new clusters across multiple environments (including development, staging, and production).",
        "wg": [
          { "t": "動態擴展", "en": "dynamically scale", "ps": "verb" },
          { "t": "配置", "en": "provision", "ps": "verb" }
        ]
      },
      {
        "t": "您必須確保所有叢集都遵循相同的安全政策與合規性標準，同時將維運負擔降至最低。",
        "en": "You must ensure that all clusters adhere to the same security policies and compliance standards while minimizing operational overhead.",
        "wg": [
          { "t": "安全政策", "en": "security policies", "ps": "noun" },
          { "t": "維運負擔", "en": "operational overhead", "ps": "noun" }
        ]
      },
      {
        "t": "您應該採取哪種架構策略？",
        "en": "Which architectural strategy should you adopt?",
        "wg": [
          { "t": "架構策略", "en": "architectural strategy", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用 GKE Enterprise (Anthos)，使用 Config Sync 來集中管理所有叢集的配置與政策，並利用 Policy Controller 強制執行合規性檢查。",
        "en": "(A) Enable GKE Enterprise (Anthos), use Config Sync to centrally manage configurations and policies across all clusters, and leverage Policy Controller to enforce compliance checks.",
        "wg": [
          { "t": "GKE Enterprise", "en": "GKE Enterprise", "ps": "product" },
          { "t": "集中管理", "en": "centrally manage", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 編寫 Terraform 腳本來定義標準的 GKE 叢集配置，並使用 Cloud Build 觸發器在每次程式碼更動時自動將變更部署到所有叢集。",
        "en": "(B) Write Terraform scripts to define standard GKE cluster configurations and use Cloud Build triggers to automatically deploy changes to all clusters upon code updates.",
        "wg": [
          { "t": "Terraform", "en": "Terraform", "ps": "tool" },
          { "t": "觸發器", "en": "triggers", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 為每個環境建立獨立的 GKE 叢集，並指派專職的維運團隊手動審核並應用 Kubernetes Network Policies 以確保隔離性。",
        "en": "(C) Create separate GKE clusters for each environment and assign dedicated operations teams to manually audit and apply Kubernetes Network Policies to ensure isolation.",
        "wg": [
          { "t": "手動審核", "en": "manually audit", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Deployment Manager 建立叢集模板，並透過二進制授權 (Binary Authorization) 確保只有受信任的容器映像檔能被部署。",
        "en": "(D) Use Cloud Deployment Manager to create cluster templates and ensure only trusted container images are deployed via Binary Authorization.",
        "wg": [
          { "t": "二進制授權", "en": "Binary Authorization", "ps": "product" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "GKE Enterprise (前身為 Anthos) 專為解決多叢集管理的一致性問題而設計。Config Sync 和 Policy Controller 能以聲明式的方式自動同步配置並強制執行政策，最符合「提供一致管理方式」且「降低維運成本」的需求。",
      "en": "GKE Enterprise (formerly Anthos) is specifically designed to address consistency in multi-cluster management. Config Sync and Policy Controller automatically sync configurations and enforce policies declaratively, best fitting the requirements for 'consistent management' and 'reduced operational costs'.",
      "wg": [
        { "t": "聲明式", "en": "declarative", "ps": "adj" },
        { "t": "強制執行", "en": "enforce", "ps": "verb" }
      ]
    }
  },
  {
    "no": "3",
    "level": "hard",
    "keywords": "Data Analytics, Compliance, DLP, BigQuery",
    "question": [
      {
        "t": "EHR Healthcare 希望利用累積的供應商資料來「根據供應商資料進行預測並產生產業趨勢報告」，從而轉型為資料洞察供應商。",
        "en": "EHR Healthcare wants to leverage accumulated provider data to 'make predictions and generate reports on industry trends based on provider data,' transforming into a data insights provider.",
        "wg": [
          { "t": "產業趨勢", "en": "industry trends", "ps": "noun" },
          { "t": "資料洞察", "en": "data insights", "ps": "noun" }
        ]
      },
      {
        "t": "這些原始資料包含受 HIPAA 保護的高度敏感病患資訊 (PII/PHI)。",
        "en": "This raw data contains highly sensitive patient information (PII/PHI) protected by HIPAA.",
        "wg": [
          { "t": "高度敏感", "en": "highly sensitive", "ps": "adj" }
        ]
      },
      {
        "t": "您需要設計一個資料攝取與處理流程，確保在資料進入 BigQuery 進行分析之前已完成去識別化 (De-identification)，同時需盡可能減少基礎架構的管理成本。",
        "en": "You need to design a data ingestion and processing pipeline ensuring de-identification is completed before data enters BigQuery for analysis, while minimizing infrastructure management costs.",
        "wg": [
          { "t": "去識別化", "en": "De-identification", "ps": "noun" },
          { "t": "攝取", "en": "ingestion", "ps": "noun" }
        ]
      },
      {
        "t": "您應該建議採用哪種解決方案？",
        "en": "Which solution should you recommend?",
        "wg": [
          { "t": "解決方案", "en": "solution", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將資料匯入 Cloud SQL，編寫 SQL 腳本將敏感欄位遮罩 (Masking)，然後使用 BigQuery 聯合查詢 (Federated Queries) 直接讀取清洗後的資料。",
        "en": "(A) Import data into Cloud SQL, write SQL scripts to mask sensitive fields, and then use BigQuery Federated Queries to read the cleansed data directly.",
        "wg": [
          { "t": "聯合查詢", "en": "Federated Queries", "ps": "feature" }
        ]
      },
      {
        "t": "(B) 使用 Cloud Data Fusion 建立 ETL 流程，在管線中整合 Cloud DLP 插件進行即時去識別化，最後將處理過的資料寫入 BigQuery。",
        "en": "(B) Create an ETL pipeline using Cloud Data Fusion, integrate the Cloud DLP plugin within the pipeline for real-time de-identification, and write the processed data to BigQuery.",
        "wg": [
          { "t": "ETL 流程", "en": "ETL pipeline", "ps": "noun" },
          { "t": "插件", "en": "plugin", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 建立 Dataflow 管線來攝取資料，並在管線中呼叫 Cloud Data Loss Prevention (DLP) API 進行去識別化，將結果串流至 BigQuery。",
        "en": "(C) Build a Dataflow pipeline to ingest data, call the Cloud Data Loss Prevention (DLP) API within the pipeline for de-identification, and stream the results to BigQuery.",
        "wg": [
          { "t": "管線", "en": "pipeline", "ps": "noun" },
          { "t": "串流", "en": "stream", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 將原始資料直接載入 BigQuery 的原始資料集 (Raw Dataset)，設定 IAM 權限僅允許少數管理員存取，並建立授權視圖 (Authorized Views) 供分析師查詢已排除敏感欄位的資料。",
        "en": "(D) Load raw data directly into a BigQuery Raw Dataset, configure IAM permissions to allow access only to a few admins, and create Authorized Views for analysts to query data with sensitive fields excluded.",
        "wg": [
          { "t": "授權視圖", "en": "Authorized Views", "ps": "feature" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Dataflow 是全託管的無伺服器資料處理服務，結合 DLP API 可在資料落地前進行轉換與去識別化，完全符合「減少管理成本」與「維持合規性」的要求。選項 (D) 雖然常用，但在儲存層仍保留了明文 PII，風險較高。",
      "en": "Dataflow is a fully managed serverless data processing service. Combining it with the DLP API allows for transformation and de-identification before data lands, perfectly meeting the requirements for 'reduced management costs' and 'maintaining compliance'. Option (D) retains plain text PII in the storage layer, which poses a higher risk.",
      "wg": [
        { "t": "無伺服器", "en": "serverless", "ps": "adj" },
        { "t": "落地", "en": "lands", "ps": "verb" }
      ]
    }
  },
  {
    "no": "4",
    "level": "hard",
    "keywords": "Operations, Monitoring, Alerting",
    "question": [
      {
        "t": "目前 EHR Healthcare 的監控是使用各種開源工具完成的，導致「警報透過電子郵件發送且經常被忽略」，這掩蓋了真正的系統效能問題。",
        "en": "Currently, EHR Healthcare's monitoring is done via various open source tools, resulting in 'alerts sent via email and often ignored,' which masks real system performance issues.",
        "wg": [
          { "t": "監控", "en": "monitoring", "ps": "noun" },
          { "t": "掩蓋", "en": "masks", "ps": "verb" }
        ]
      },
      {
        "t": "為了滿足「提供集中視覺化與主動應對系統效能和使用情況」的業務需求，您需要設計一個現代化的維運架構。",
        "en": "To meet the business requirement of 'providing centralized visibility and proactive action on system performance and usage,' you need to design a modernized operational architecture.",
        "wg": [
          { "t": "集中視覺化", "en": "centralized visibility", "ps": "noun" },
          { "t": "主動應對", "en": "proactive action", "ps": "noun" }
        ]
      },
      {
        "t": "該架構必須能夠有效減少警報疲勞 (Alert Fatigue) 並確保關鍵問題能被及時處理。",
        "en": "The architecture must effectively reduce Alert Fatigue and ensure critical issues are handled in a timely manner.",
        "wg": [
          { "t": "警報疲勞", "en": "Alert Fatigue", "ps": "noun" }
        ]
      },
      {
        "t": "下列哪項措施最能解決此痛點？",
        "en": "Which of the following actions best addresses this pain point?",
        "wg": [
          { "t": "痛點", "en": "pain point", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 GKE 叢集中部署 Prometheus 和 Grafana，並設定 Alertmanager 將所有警報發送至專用的 Slack 頻道，以便工程團隊即時討論。",
        "en": "(A) Deploy Prometheus and Grafana in GKE clusters, and configure Alertmanager to send all alerts to a dedicated Slack channel for real-time discussion by the engineering team.",
        "wg": [
          { "t": "部署", "en": "deploy", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 實作 Google Cloud Operations Suite (以前稱為 Stackdriver)，設定基於日誌的指標 (Log-based metrics) 來捕捉特定錯誤，並建立警報策略 (Alerting Policies) 將通知發送到 PagerDuty 等事故管理平台，而非僅使用電子郵件。",
        "en": "(B) Implement Google Cloud Operations Suite (formerly Stackdriver), configure Log-based metrics to capture specific errors, and create Alerting Policies to send notifications to incident management platforms like PagerDuty instead of just email.",
        "wg": [
          { "t": "基於日誌的指標", "en": "Log-based metrics", "ps": "feature" },
          { "t": "事故管理平台", "en": "incident management platforms", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 將所有應用程式日誌匯出至 Cloud Storage，並設定 Cloud Functions 定期分析日誌檔案，若發現異常則觸發 SendGrid API 發送標記為「高優先級」的電子郵件。",
        "en": "(C) Export all application logs to Cloud Storage, and configure Cloud Functions to periodically analyze log files. If anomalies are found, trigger the SendGrid API to send emails marked as 'High Priority'.",
        "wg": [
          { "t": "定期分析", "en": "periodically analyze", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Logging 接收所有日誌，並建立一個包含所有系統指標的 Cloud Monitoring 儀表板 (Dashboard)，賦予開發人員檢視權限以進行自主監控。",
        "en": "(D) Use Cloud Logging to ingest all logs, create a Cloud Monitoring Dashboard containing all system metrics, and grant developers view access for self-monitoring.",
        "wg": [
          { "t": "自主監控", "en": "self-monitoring", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "選項 (B) 透過「基於日誌的指標」過濾雜訊，並整合 PagerDuty 等工具進行「主動應對」，直接解決了警報被忽略與警報疲勞的問題。選項 (A) 仍屬於自行管理的開源工具，未充分利用 Google Cloud 的全託管優勢以降低管理成本。",
      "en": "Option (B) filters noise via 'Log-based metrics' and integrates with tools like PagerDuty for 'proactive action,' directly solving the issues of ignored alerts and alert fatigue. Option (A) relies on self-managed open-source tools, failing to fully leverage Google Cloud's fully managed benefits to reduce administrative costs.",
      "wg": [
        { "t": "過濾雜訊", "en": "filters noise", "ps": "verb" },
        { "t": "全託管", "en": "fully managed", "ps": "adj" }
      ]
    }
  },
  {
    "no": "5",
    "level": "hard",
    "keywords": "Database Migration, Managed Services, Cost Optimization",
    "question": [
      {
        "t": "EHR Healthcare 的資料目前儲存在混合的資料庫環境中，包括 MySQL、MS SQL Server、Redis 和 MongoDB。",
        "en": "EHR Healthcare's data is currently stored in a mixed database environment, including MySQL, MS SQL Server, Redis, and MongoDB.",
        "wg": [
          { "t": "混合的", "en": "mixed", "ps": "adj" }
        ]
      },
      {
        "t": "為了達成「降低基礎架構管理成本」與「提供至少 99.9% 可用性」的目標，您計畫將這些資料庫遷移至 Google Cloud 的全託管服務。",
        "en": "To achieve the goals of 'decreasing infrastructure administration costs' and 'providing a minimum 99.9% availability,' you plan to migrate these databases to Google Cloud fully managed services.",
        "wg": [
          { "t": "遷移", "en": "migrate", "ps": "verb" }
        ]
      },
      {
        "t": "請針對 MySQL、MS SQL Server 和 Redis 的遷移，選擇兩項最合適的技術決策組合。(請選擇兩項)",
        "en": "For the migration of MySQL, MS SQL Server, and Redis, select the two most appropriate technical decisions. (Choose two)",
        "wg": [
          { "t": "技術決策", "en": "technical decisions", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 將 MySQL 和 MS SQL Server 遷移至 Cloud SQL，並啟用高可用性 (HA) 配置以確保自動故障轉移。",
        "en": "(A) Migrate MySQL and MS SQL Server to Cloud SQL, and enable High Availability (HA) configuration to ensure automatic failover.",
        "wg": [
          { "t": "故障轉移", "en": "failover", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 將 MySQL 和 MS SQL Server 部署在 Compute Engine 的託管執行個體群組 (MIG) 上，並使用永久磁碟快照進行備份。",
        "en": "(B) Deploy MySQL and MS SQL Server on Managed Instance Groups (MIG) in Compute Engine, and use persistent disk snapshots for backups.",
        "wg": [
          { "t": "託管執行個體群組", "en": "Managed Instance Groups", "ps": "product" }
        ]
      },
      {
        "t": "(C) 將 Redis 資料庫遷移至 Cloud Bigtable，以獲得更高的寫入吞吐量與全球擴展性。",
        "en": "(C) Migrate the Redis database to Cloud Bigtable to gain higher write throughput and global scalability.",
        "wg": [
          { "t": "寫入吞吐量", "en": "write throughput", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 將 Redis 資料庫遷移至 Memorystore for Redis，以獲得全託管的記憶體內快取服務，並降低維護負擔。",
        "en": "(D) Migrate the Redis database to Memorystore for Redis to obtain a fully managed in-memory caching service and reduce maintenance burden.",
        "wg": [
          { "t": "記憶體內快取", "en": "in-memory caching", "ps": "noun" }
        ]
      },
      {
        "t": "(E) 將所有關聯式資料庫轉換為 Cloud Spanner，以統一資料庫架構並實現全球強一致性。",
        "en": "(E) Convert all relational databases to Cloud Spanner to unify the database architecture and achieve global strong consistency.",
        "wg": [
          { "t": "強一致性", "en": "strong consistency", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A), (D)",
    "why": {
      "t": "Cloud SQL 是 MySQL 和 MS SQL Server 的原生全託管服務，提供 HA 和自動備份，直接降低管理成本。Memorystore 是 Redis 的對應託管服務。選項 (B) 需要自行管理 OS 和 DB，不符成本效益；選項 (E) 需要重寫應用程式，對於「快速擴展」的需求來說成本過高。",
      "en": "Cloud SQL is the native fully managed service for MySQL and MS SQL Server, offering HA and automated backups, which directly reduces administrative costs. Memorystore is the corresponding managed service for Redis. Option (B) requires self-managing the OS and DB, which is not cost-effective; Option (E) requires rewriting applications, which is too costly given the need for 'fast scaling'.",
      "wg": [
        { "t": "原生", "en": "native", "ps": "adj" },
        { "t": "重寫", "en": "rewriting", "ps": "verb" }
      ]
    }
  },
  {
    "no": "6",
    "level": "hard",
    "keywords": "CI/CD, GKE, Binary Authorization, Security",
    "question": [
      {
        "t": "EHR Healthcare 希望實現「推出新的持續部署功能」以快速更新軟體，同時必須確保軟體供應鏈的安全性。",
        "en": "EHR Healthcare wants to 'roll out new continuous deployment capabilities' to update software at a fast pace, while ensuring the security of the software supply chain.",
        "wg": [
          { "t": "軟體供應鏈", "en": "software supply chain", "ps": "noun" },
          { "t": "持續部署", "en": "continuous deployment", "ps": "noun" }
        ]
      },
      {
        "t": "開發團隊已經將應用程式容器化，並準備部署到 Google Kubernetes Engine (GKE) 叢集。",
        "en": "The development team has containerized the applications and is ready to deploy them to Google Kubernetes Engine (GKE) clusters.",
        "wg": [
          { "t": "容器化", "en": "containerized", "ps": "verb" }
        ]
      },
      {
        "t": "您需要設計一個自動化流程，確保只有經過受信任的建置系統驗證並簽署的容器映像檔，才能被部署到生產環境中，且需盡量減少手動介入。",
        "en": "You need to design an automated process ensuring that only container images verified and signed by a trusted build system can be deployed to the production environment, with minimal manual intervention.",
        "wg": [
          { "t": "簽署", "en": "signed", "ps": "verb" },
          { "t": "手動介入", "en": "manual intervention", "ps": "noun" }
        ]
      },
      {
        "t": "您應該採取哪種架構設計？",
        "en": "Which architectural design should you adopt?",
        "wg": [
          { "t": "架構設計", "en": "architectural design", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 Compute Engine 上建立 Jenkins 伺服器，設定管線在建置後執行弱點掃描，若通過則使用 kubectl apply 指令部署到 GKE。",
        "en": "(A) Set up a Jenkins server on Compute Engine, configure the pipeline to run vulnerability scans after build, and use the kubectl apply command to deploy to GKE if passed.",
        "wg": [
          { "t": "弱點掃描", "en": "vulnerability scans", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 使用 Cloud Build 建立容器映像檔並儲存於 Container Registry，設定 IAM 策略僅允許 Cloud Build 服務帳戶擁有 GKE 的部署權限。",
        "en": "(B) Use Cloud Build to create container images and store them in Container Registry, configuring IAM policies to allow only the Cloud Build service account to have deployment permissions on GKE.",
        "wg": [
          { "t": "服務帳戶", "en": "service account", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Build 建置映像檔並推送到 Artifact Registry，在管線中建立證明 (Attestations)，並在 GKE 叢集啟用二進制授權 (Binary Authorization) 以強制執行簽署驗證。",
        "en": "(C) Use Cloud Build to build images and push to Artifact Registry, create Attestations within the pipeline, and enable Binary Authorization on the GKE cluster to enforce signature verification.",
        "wg": [
          { "t": "證明", "en": "Attestations", "ps": "noun" },
          { "t": "二進制授權", "en": "Binary Authorization", "ps": "product" }
        ]
      },
      {
        "t": "(D) 利用 Spinnaker 進行持續交付，設定手動核准關卡 (Manual Approval Gates)，由安全團隊人工檢查映像檔雜湊值後再觸發部署。",
        "en": "(D) Leverage Spinnaker for continuous delivery, setting up Manual Approval Gates where the security team manually checks image hashes before triggering deployment.",
        "wg": [
          { "t": "手動核准關卡", "en": "Manual Approval Gates", "ps": "noun" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "二進制授權 (Binary Authorization) 是 Google Cloud 原生的安全控制機制，能確保只有具備有效證明 (Attestations) 的映像檔能部署到 GKE。結合 Cloud Build 和 Artifact Registry，這構成了符合「安全供應鏈」與「自動化」需求的最佳實踐。",
      "en": "Binary Authorization is a Google Cloud native security control that ensures only images with valid Attestations can be deployed to GKE. Combined with Cloud Build and Artifact Registry, this constitutes the best practice for 'secure supply chain' and 'automation' requirements.",
      "wg": [
        { "t": "原生的", "en": "native", "ps": "adj" },
        { "t": "最佳實踐", "en": "best practice", "ps": "noun" }
      ]
    }
  },
  {
    "no": "7",
    "level": "hard",
    "keywords": "Latency, Global Load Balancing, CDN, GKE",
    "question": [
      {
        "t": "為了滿足「降低對所有客戶的延遲」這項業務需求，EHR Healthcare 正在重新設計其面向客戶的 Web 應用程式網路架構。",
        "en": "To meet the business requirement of 'reducing latency to all customers,' EHR Healthcare is redesigning the network architecture for its customer-facing web application.",
        "wg": [
          { "t": "網路架構", "en": "network architecture", "ps": "noun" }
        ]
      },
      {
        "t": "應用程式託管在 GKE 上，且使用者遍布全球。靜態內容（如醫療報告範本、圖片）佔流量的很大一部分，而動態 API 請求則需要路由到最近的健康後端。",
        "en": "The application is hosted on GKE, with users located globally. Static content (e.g., medical report templates, images) accounts for a large portion of traffic, while dynamic API requests need to be routed to the nearest healthy backend.",
        "wg": [
          { "t": "靜態內容", "en": "static content", "ps": "noun" },
          { "t": "路由", "en": "routed", "ps": "verb" }
        ]
      },
      {
        "t": "您需要提供一個能最大化效能並提供 DDoS 防護的解決方案。",
        "en": "You need to provide a solution that maximizes performance and offers DDoS protection.",
        "wg": [
          { "t": "DDoS 防護", "en": "DDoS protection", "ps": "noun" }
        ]
      },
      {
        "t": "哪項配置最能達成此目標？",
        "en": "Which configuration best achieves this goal?",
        "wg": [
          { "t": "配置", "en": "configuration", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 設定全球外部 HTTP(S) 負載平衡器，啟用 Cloud CDN 來快取靜態內容，並配置 Google Cloud Armor 安全政策來過濾惡意流量。",
        "en": "(A) Configure a Global External HTTP(S) Load Balancer, enable Cloud CDN to cache static content, and configure Google Cloud Armor security policies to filter malicious traffic.",
        "wg": [
          { "t": "全球外部 HTTP(S) 負載平衡器", "en": "Global External HTTP(S) Load Balancer", "ps": "product" },
          { "t": "快取", "en": "cache", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 在每個區域部署區域性外部 HTTP(S) 負載平衡器，並使用 Cloud DNS 的地理位置路由策略將使用者引導至最近的區域。",
        "en": "(B) Deploy Regional External HTTP(S) Load Balancers in each region, and use Cloud DNS geolocation routing policies to direct users to the nearest region.",
        "wg": [
          { "t": "區域性", "en": "Regional", "ps": "adj" },
          { "t": "地理位置路由", "en": "geolocation routing", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Cloud CDN 直接指向 GKE 的 NodePort 服務，並在 GKE 叢集內部配置 HPA (Horizontal Pod Autoscaling) 以處理流量高峰。",
        "en": "(C) Use Cloud CDN pointing directly to GKE NodePort services, and configure HPA (Horizontal Pod Autoscaling) within the GKE cluster to handle traffic spikes.",
        "wg": [
          { "t": "指向", "en": "pointing", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 部署 Apigee API 管理平台來處理所有傳入流量，利用其內建的快取機制，並將請求轉發到後端的 GKE 服務。",
        "en": "(D) Deploy the Apigee API management platform to handle all incoming traffic, leverage its built-in caching mechanism, and forward requests to the backend GKE services.",
        "wg": [
          { "t": "API 管理平台", "en": "API management platform", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "全球外部 HTTP(S) 負載平衡器利用 Google 的全球邊緣網路與 Anycast IP，能自動將使用者路由至最近的後端，解決「降低延遲」需求。Cloud CDN 處理靜態內容進一步加速，而 Cloud Armor 提供所需的 DDoS 防護。這是處理全球 Web 流量的標準最佳實踐。",
      "en": "The Global External HTTP(S) Load Balancer uses Google's global edge network and Anycast IP to automatically route users to the nearest backend, addressing the 'reduce latency' requirement. Cloud CDN accelerates static content, and Cloud Armor provides the necessary DDoS protection. This is the standard best practice for handling global web traffic.",
      "wg": [
        { "t": "邊緣網路", "en": "edge network", "ps": "noun" },
        { "t": "加速", "en": "accelerates", "ps": "verb" }
      ]
    }
  },
  {
    "no": "8",
    "level": "hard",
    "keywords": "Disaster Recovery, Cloud SQL, RTO/RPO",
    "question": [
      {
        "t": "EHR Healthcare 需要「調整其災難復原計畫」以因應業務成長。目前其關聯式資料庫（MySQL 與 MS SQL Server）是單點故障的隱憂。",
        "en": "EHR Healthcare needs to 'adapt their disaster recovery plan' to accommodate business growth. Currently, their relational databases (MySQL and MS SQL Server) are a single point of failure concern.",
        "wg": [
          { "t": "災難復原計畫", "en": "disaster recovery plan", "ps": "noun" },
          { "t": "單點故障", "en": "single point of failure", "ps": "noun" }
        ]
      },
      {
        "t": "您計畫將這些資料庫遷移至 Cloud SQL。業務需求要求在區域性災難發生時，能夠以最短的停機時間 (Low RTO) 和最少的資料遺失 (Low RPO) 恢復服務。",
        "en": "You plan to migrate these databases to Cloud SQL. Business requirements dictate that in the event of a regional disaster, services must be restored with minimal downtime (Low RTO) and minimal data loss (Low RPO).",
        "wg": [
          { "t": "停機時間", "en": "downtime", "ps": "noun" },
          { "t": "資料遺失", "en": "data loss", "ps": "noun" }
        ]
      },
      {
        "t": "同時，您必須盡量降低日常的維運複雜度。",
        "en": "At the same time, you must minimize daily operational complexity.",
        "wg": [
          { "t": "維運複雜度", "en": "operational complexity", "ps": "noun" }
        ]
      },
      {
        "t": "您應該實施哪項策略？",
        "en": "Which strategy should you implement?",
        "wg": [
          { "t": "策略", "en": "strategy", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用 Cloud SQL 的自動備份功能，並編寫 Cloud Functions 腳本，定期將備份檔案複製到位於不同區域的 Cloud Storage 儲存桶中。",
        "en": "(A) Enable Cloud SQL automated backups and write Cloud Functions scripts to periodically copy backup files to a Cloud Storage bucket in a different region.",
        "wg": [
          { "t": "自動備份", "en": "automated backups", "ps": "feature" }
        ]
      },
      {
        "t": "(B) 在主要區域配置 Cloud SQL 高可用性 (HA) 執行個體，並在另一個區域建立跨地區唯讀複本 (Cross-Region Read Replica)，災難發生時將其提升為主要執行個體。",
        "en": "(B) Configure a Cloud SQL High Availability (HA) instance in the primary region, and create a Cross-Region Read Replica in another region, promoting it to the primary instance in case of disaster.",
        "wg": [
          { "t": "跨地區唯讀複本", "en": "Cross-Region Read Replica", "ps": "feature" },
          { "t": "提升", "en": "promoting", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 Database Migration Service (DMS) 設定持續性複寫，將地端資料庫同步到 Compute Engine 上的 SQL Server，並使用永久磁碟快照作為災難復原手段。",
        "en": "(C) Use Database Migration Service (DMS) to set up continuous replication syncing on-premises databases to SQL Server on Compute Engine, using persistent disk snapshots as a disaster recovery method.",
        "wg": [
          { "t": "持續性複寫", "en": "continuous replication", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 將應用程式架構重構為使用 Cloud Spanner，並設定多區域組態 (Multi-region configuration) 以獲得 99.999% 的可用性與強一致性。",
        "en": "(D) Refactor the application architecture to use Cloud Spanner and set up a Multi-region configuration to achieve 99.999% availability and strong consistency.",
        "wg": [
          { "t": "重構", "en": "Refactor", "ps": "verb" },
          { "t": "多區域組態", "en": "Multi-region configuration", "ps": "feature" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "選項 (B) 利用 Cloud SQL 的原生功能（HA 與跨地區複本）來解決 DR 需求。HA 處理區域內的故障，而跨地區複本則為區域級災難提供了低 RTO/RPO 的復原路徑，且無需像選項 (A) 那樣進行手動還原，或像選項 (D) 需要昂貴的應用程式重寫。",
      "en": "Option (B) leverages Cloud SQL native features (HA and Cross-Region Replica) to address DR requirements. HA handles intra-region failures, while the Cross-Region Replica provides a low RTO/RPO recovery path for regional disasters, without the manual restoration required in Option (A) or the expensive application rewrite in Option (D).",
      "wg": [
        { "t": "原生功能", "en": "native features", "ps": "noun" },
        { "t": "復原路徑", "en": "recovery path", "ps": "noun" }
      ]
    }
  },
  {
    "no": "9",
    "level": "hard",
    "keywords": "IAM, Hybrid Identity, Directory Sync, SSO",
    "question": [
      {
        "t": "EHR Healthcare 的使用者目前透過 Microsoft Active Directory (AD) 進行管理。公司政策要求所有雲端存取必須使用現有的企業憑證進行驗證，以維持統一的身分管理。",
        "en": "EHR Healthcare's users are currently managed via Microsoft Active Directory (AD). Company policy requires that all cloud access must be authenticated using existing corporate credentials to maintain unified identity management.",
        "wg": [
          { "t": "企業憑證", "en": "corporate credentials", "ps": "noun" },
          { "t": "身分管理", "en": "identity management", "ps": "noun" }
        ]
      },
      {
        "t": "您需要設計一個解決方案，將這些使用者佈建到 Google Cloud，並啟用單一登入 (SSO)，同時確保當地端 AD 中的使用者被停用時，Google Cloud 的存取權限也會隨之撤銷。",
        "en": "You need to design a solution to provision these users into Google Cloud and enable Single Sign-On (SSO), ensuring that when a user is disabled in the on-premises AD, their access to Google Cloud is also revoked.",
        "wg": [
          { "t": "佈建", "en": "provision", "ps": "verb" },
          { "t": "撤銷", "en": "revoked", "ps": "verb" }
        ]
      },
      {
        "t": "哪兩個步驟是達成此需求的最佳實務組合？(請選擇兩項)",
        "en": "Which two steps are the best practice combination to achieve this requirement? (Choose two)",
        "wg": [
          { "t": "最佳實務", "en": "best practice", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 在 Google Cloud Identity 中設定第三方身分提供者 (IdP)，並將地端 AD Federation Services (AD FS) 配置為 SAML 2.0 提供者以處理身分驗證。",
        "en": "(A) Configure a third-party Identity Provider (IdP) in Google Cloud Identity, and configure on-premises AD Federation Services (AD FS) as the SAML 2.0 provider to handle authentication.",
        "wg": [
          { "t": "身分提供者", "en": "Identity Provider", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 安裝並設定 Google Cloud Directory Sync (GCDS)，定期將使用者帳戶與群組從 Active Directory 同步到 Google Cloud Identity。",
        "en": "(B) Install and configure Google Cloud Directory Sync (GCDS) to periodically sync user accounts and groups from Active Directory to Google Cloud Identity.",
        "wg": [
          { "t": "同步", "en": "sync", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 Cloud VPN 連接 AD 伺服器，並在每個 Compute Engine 執行個體上安裝 Windows AD 代理程式，以直接對地端進行驗證。",
        "en": "(C) Connect to the AD server using Cloud VPN and install Windows AD agents on each Compute Engine instance to authenticate directly against on-premises.",
        "wg": [
          { "t": "代理程式", "en": "agents", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 將 Active Directory 使用者匯出為 CSV 檔案，並使用 gcloud 命令行工具將其匯入 Cloud IAM，並設定排程腳本每日執行。",
        "en": "(D) Export Active Directory users to a CSV file, use the gcloud command-line tool to import them into Cloud IAM, and set up a scheduled script to run daily.",
        "wg": [
          { "t": "匯出", "en": "Export", "ps": "verb" }
        ]
      },
      {
        "t": "(E) 在 Google Cloud 中部署 Managed Service for Microsoft Active Directory，並建立雙向樹系信任 (Two-way Forest Trust) 以完全複製地端目錄。",
        "en": "(E) Deploy Managed Service for Microsoft Active Directory in Google Cloud and establish a Two-way Forest Trust to fully replicate the on-premises directory.",
        "wg": [
          { "t": "樹系信任", "en": "Forest Trust", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A), (B)",
    "why": {
      "t": "這是一個標準的混合身分模式。GCDS (選項 B) 負責「佈建」與生命週期管理（同步使用者與群組狀態），而 SSO/SAML (選項 A) 負責「驗證」。這兩者結合能讓使用者使用現有憑證登入，並確保離職時權限自動移除。Managed AD (選項 E) 通常用於應用程式相容性，而非作為主要的 IAM 身分同步工具。",
      "en": "This is a standard hybrid identity pattern. GCDS (Option B) handles 'provisioning' and lifecycle management (syncing user/group states), while SSO/SAML (Option A) handles 'authentication'. Combined, they allow users to log in with existing credentials and ensure permissions are automatically removed upon departure. Managed AD (Option E) is typically used for application compatibility, not as the primary IAM identity sync tool.",
      "wg": [
        { "t": "混合身分模式", "en": "hybrid identity pattern", "ps": "noun" },
        { "t": "生命週期管理", "en": "lifecycle management", "ps": "noun" }
      ]
    }
  },
  {
    "no": "10",
    "level": "hard",
    "keywords": "Compliance, GCS, Object Versioning, Retention Policy",
    "question": [
      {
        "t": "EHR Healthcare 需要在 Cloud Storage 中儲存敏感的病患歷史記錄檔案。根據法規要求，這些檔案一旦寫入，必須保留至少 7 年，且在此期間內不得被任何人（包括管理員）覆寫或刪除。",
        "en": "EHR Healthcare needs to store sensitive patient history files in Cloud Storage. Regulatory requirements dictate that once written, these files must be retained for at least 7 years and cannot be overwritten or deleted by anyone (including administrators) during this period.",
        "wg": [
          { "t": "覆寫", "en": "overwritten", "ps": "verb" },
          { "t": "刪除", "en": "deleted", "ps": "verb" }
        ]
      },
      {
        "t": "此外，為了防止勒索軟體攻擊，即使是授權的應用程式也應該受到防護，避免意外的資料加密或破壞。",
        "en": "Additionally, to protect against ransomware attacks, even authorized applications should be guarded against accidental data encryption or destruction.",
        "wg": [
          { "t": "勒索軟體", "en": "ransomware", "ps": "noun" },
          { "t": "意外的", "en": "accidental", "ps": "adj" }
        ]
      },
      {
        "t": "您應該如何配置 Cloud Storage 儲存桶？",
        "en": "How should you configure the Cloud Storage bucket?",
        "wg": [
          { "t": "配置", "en": "configure", "ps": "verb" }
        ]
      },
      {
        "t": "請選擇最符合合規性與安全性需求的解決方案。",
        "en": "Select the solution that best meets compliance and security requirements.",
        "wg": [
          { "t": "合規性", "en": "compliance", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用物件版本控制 (Object Versioning)，並設定生命週期管理規則 (Lifecycle Management Rule) 在 7 年後將舊版本轉移至 Archive Storage。",
        "en": "(A) Enable Object Versioning and configure a Lifecycle Management Rule to move old versions to Archive Storage after 7 years.",
        "wg": [
          { "t": "物件版本控制", "en": "Object Versioning", "ps": "feature" }
        ]
      },
      {
        "t": "(B) 設定儲存桶鎖定 (Bucket Lock) 並配置保留政策 (Retention Policy) 為 7 年，鎖定該政策以防止縮短保留期或刪除。",
        "en": "(B) Configure Bucket Lock and set a Retention Policy of 7 years, locking the policy to prevent reducing the duration or deletion.",
        "wg": [
          { "t": "儲存桶鎖定", "en": "Bucket Lock", "ps": "feature" },
          { "t": "保留政策", "en": "Retention Policy", "ps": "feature" }
        ]
      },
      {
        "t": "(C) 使用客戶管理加密金鑰 (CMEK) 加密所有資料，並將金鑰存放在 Cloud HSM 中，限制僅有合規官員可以存取金鑰進行解密。",
        "en": "(C) Encrypt all data using Customer-Managed Encryption Keys (CMEK) hosted in Cloud HSM, restricting key access for decryption to compliance officers only.",
        "wg": [
          { "t": "客戶管理加密金鑰", "en": "Customer-Managed Encryption Keys", "ps": "feature" }
        ]
      },
      {
        "t": "(D) 將 IAM 權限設定為僅允許應用程式擁有 `storage.objects.create` 權限，並移除所有使用者的 `storage.objects.delete` 權限。",
        "en": "(D) Set IAM permissions to allow the application only `storage.objects.create` permission and remove `storage.objects.delete` permission for all users.",
        "wg": [
          { "t": "權限", "en": "permission", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "儲存桶鎖定 (Bucket Lock) 實作了 WORM (Write Once, Read Many) 模型，這是滿足「不得被任何人覆寫或刪除」法規要求的唯一方法。一旦政策被鎖定，即便是專案擁有者也無法刪除未過期的物件，這也提供了極強的勒索軟體防護能力。選項 (A) 和 (D) 無法防止擁有者或惡意軟體取得高權限後的破壞。",
      "en": "Bucket Lock implements the WORM (Write Once, Read Many) model, which is the only way to meet the regulatory requirement of 'cannot be overwritten or deleted by anyone'. Once the policy is locked, even project owners cannot delete unexpired objects, offering strong protection against ransomware. Options (A) and (D) cannot prevent destruction if an owner or malware gains high privileges.",
      "wg": [
        { "t": "WORM 模型", "en": "WORM model", "ps": "concept" },
        { "t": "惡意軟體", "en": "malware", "ps": "noun" }
      ]
    }
  },{
    "no": "11",
    "level": "hard",
    "keywords": "Vertex AI, BigQuery ML, Predictive Analytics",
    "question": [
      {
        "t": "EHR Healthcare 希望實現「根據供應商資料進行預測並產生產業趨勢報告」的業務需求。分析團隊精通 SQL，但對於編寫複雜的機器學習 (ML) 程式碼或管理 ML 基礎架構經驗較少。",
        "en": "EHR Healthcare wants to fulfill the business requirement to 'make predictions and generate reports on industry trends based on provider data.' The analytics team is proficient in SQL but has limited experience in writing complex Machine Learning (ML) code or managing ML infrastructure.",
        "wg": [
          { "t": "預測", "en": "predictions", "ps": "noun" },
          { "t": "基礎架構", "en": "infrastructure", "ps": "noun" }
        ]
      },
      {
        "t": "資料已經儲存在 BigQuery 中。您需要推薦一個解決方案，讓團隊能快速建立針對病患再入院率的預測模型，並將模型整合到現有的資料工作流中，同時盡可能降低學習曲線與維運工作。",
        "en": "The data is already stored in BigQuery. You need to recommend a solution that allows the team to quickly build predictive models for patient readmission rates and integrate the models into existing data workflows, while minimizing the learning curve and operational effort.",
        "wg": [
          { "t": "再入院率", "en": "readmission rates", "ps": "noun" },
          { "t": "學習曲線", "en": "learning curve", "ps": "noun" }
        ]
      },
      {
        "t": "哪種方法最符合這些限制？",
        "en": "Which approach best fits these constraints?",
        "wg": [
          { "t": "限制", "en": "constraints", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Dataproc 啟動 Spark MLlib 叢集，編寫 PySpark 作業來訓練模型，並將結果匯出為 CSV 檔案供 BigQuery 載入。",
        "en": "(A) Use Dataproc to spin up a Spark MLlib cluster, write PySpark jobs to train the model, and export the results as CSV files for BigQuery to load.",
        "wg": [
          { "t": "叢集", "en": "cluster", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 利用 BigQuery ML (BQML) 直接使用標準 SQL 查詢來建立並執行機器學習模型，並透過 Vertex AI Model Registry 進行模型管理。",
        "en": "(B) Leverage BigQuery ML (BQML) to create and execute machine learning models directly using standard SQL queries, and manage models via Vertex AI Model Registry.",
        "wg": [
          { "t": "標準 SQL", "en": "standard SQL", "ps": "noun" },
          { "t": "模型管理", "en": "model management", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 將資料匯出至 Cloud Storage，使用 Vertex AI Training 執行自訂的 TensorFlow 訓練應用程式，並將模型部署到 Vertex AI Endpoint 進行線上預測。",
        "en": "(C) Export data to Cloud Storage, use Vertex AI Training to run a custom TensorFlow training application, and deploy the model to a Vertex AI Endpoint for online predictions.",
        "wg": [
          { "t": "自訂的", "en": "custom", "ps": "adj" },
          { "t": "線上預測", "en": "online predictions", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Dataflow 建立資料預處理管線，並呼叫 Cloud Natural Language API 來分析非結構化資料，將結果存回 BigQuery。",
        "en": "(D) Use Cloud Dataflow to build a data preprocessing pipeline, call the Cloud Natural Language API to analyze unstructured data, and store results back to BigQuery.",
        "wg": [
          { "t": "非結構化資料", "en": "unstructured data", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "BigQuery ML (BQML) 允許資料分析師使用他們熟悉的 SQL 語言直接在資料倉儲內建立 ML 模型，無需移動資料或學習 Python/TensorFlow，完全符合「降低學習曲線」與「利用現有 SQL 技能」的需求。整合 Vertex AI 則提供了進一步的 MLOps 管理功能。",
      "en": "BigQuery ML (BQML) allows data analysts to create ML models directly within the data warehouse using their familiar SQL language, without moving data or learning Python/TensorFlow. This perfectly matches the requirements to 'minimize the learning curve' and 'leverage existing SQL skills'. Integration with Vertex AI offers further MLOps management capabilities.",
      "wg": [
        { "t": "資料倉儲", "en": "data warehouse", "ps": "noun" },
        { "t": "無需移動資料", "en": "without moving data", "ps": "phrase" }
      ]
    }
  },
  {
    "no": "12",
    "level": "hard",
    "keywords": "Security, Private GKE, IAP, Access Control",
    "question": [
      {
        "t": "EHR Healthcare 的資安團隊要求加強對 GKE 叢集的存取控制。為了符合 HIPAA 合規性，生產環境的 GKE 叢集必須配置為「私人叢集 (Private Cluster)」，禁止節點擁有公共 IP 位址。",
        "en": "EHR Healthcare's security team requires tighter access control for GKE clusters. To comply with HIPAA, production GKE clusters must be configured as 'Private Clusters,' prohibiting nodes from having public IP addresses.",
        "wg": [
          { "t": "私人叢集", "en": "Private Cluster", "ps": "feature" },
          { "t": "公共 IP 位址", "en": "public IP addresses", "ps": "noun" }
        ]
      },
      {
        "t": "然而，開發人員仍需要偶爾存取叢集以使用 `kubectl` 進行除錯。公司政策禁止為每個開發人員設定 VPN 用戶端，也不允許將管理連接埠 (Control Plane) 開放給全網際網路。",
        "en": "However, developers still need occasional access to the cluster to use `kubectl` for debugging. Company policy forbids configuring VPN clients for every developer and does not allow exposing the Control Plane to the entire internet.",
        "wg": [
          { "t": "除錯", "en": "debugging", "ps": "verb" },
          { "t": "管理連接埠", "en": "Control Plane", "ps": "noun" }
        ]
      },
      {
        "t": "您應該如何設計連線架構以滿足這些嚴格的安全需求？",
        "en": "How should you design the connectivity architecture to meet these strict security requirements?",
        "wg": [
          { "t": "連線架構", "en": "connectivity architecture", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在與 GKE 相同的 VPC 中部署一台只有內部 IP 的堡壘機 (Bastion Host)，並使用身分感知代理 (Identity-Aware Proxy, IAP) 的 TCP 轉發功能建立通往該堡壘機的通道，再從該處存取叢集。",
        "en": "(A) Deploy a Bastion Host with only an internal IP in the same VPC as GKE, use Identity-Aware Proxy (IAP) TCP forwarding to establish a tunnel to the bastion, and access the cluster from there.",
        "wg": [
          { "t": "堡壘機", "en": "Bastion Host", "ps": "noun" },
          { "t": "身分感知代理", "en": "Identity-Aware Proxy", "ps": "product" }
        ]
      },
      {
        "t": "(B) 將 GKE 控制平面的授權網路 (Authorized Networks) 設定為 `0.0.0.0/0`，但依賴 Cloud IAM 進行身分驗證，確保只有擁有 `container.clusterViewer` 角色的使用者能存取。",
        "en": "(B) Set the Authorized Networks for the GKE Control Plane to `0.0.0.0/0`, but rely on Cloud IAM for authentication, ensuring only users with the `container.clusterViewer` role can access it.",
        "wg": [
          { "t": "授權網路", "en": "Authorized Networks", "ps": "feature" }
        ]
      },
      {
        "t": "(C) 為每個開發人員分配一個靜態外部 IP，並將這些 IP 逐一加入 GKE 主節點的授權網路白名單中。",
        "en": "(C) Assign a static external IP to each developer and add these IPs one by one to the Authorized Networks allowlist of the GKE master.",
        "wg": [
          { "t": "白名單", "en": "allowlist", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Shell，因為它位於 Google 的網路內部，預設可以存取私人 GKE 叢集的控制平面，無需額外配置。",
        "en": "(D) Use Cloud Shell, as it resides within Google's network and can access the Private GKE Cluster control plane by default without additional configuration.",
        "wg": [
          { "t": "預設", "en": "default", "ps": "adj" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "在私人叢集中，節點沒有公共 IP，控制平面通常也限制存取。使用 IAP 進行 TCP 轉發到堡壘機 (Bastion) 是標準的安全模式，它允許開發人員透過 IAM 驗證後，經由 HTTPS 通道安全地存取 VPC 內部資源，而無需暴露公共 IP 或管理 VPN。選項 (D) 錯誤，因為 Cloud Shell 無法直接存取僅有私人端點的 GKE 控制平面，除非配置了 Private Service Connect 或類似機制。",
      "en": "In a Private Cluster, nodes have no public IPs, and the control plane access is usually restricted. Using IAP for TCP forwarding to a Bastion is the standard security pattern. It allows developers to securely access internal VPC resources via an HTTPS tunnel after IAM authentication, without exposing public IPs or managing VPNs. Option (D) is incorrect because Cloud Shell cannot directly access a GKE control plane with only a private endpoint unless Private Service Connect or a similar mechanism is configured.",
      "wg": [
        { "t": "TCP 轉發", "en": "TCP forwarding", "ps": "feature" },
        { "t": "暴露", "en": "exposing", "ps": "verb" }
      ]
    }
  },
  {
    "no": "13",
    "level": "hard",
    "keywords": "Service Mesh, Observability, Traffic Management, Security",
    "question": [
      {
        "t": "EHR Healthcare 已將其微服務架構遷移至 GKE。為了符合「提供一致的日誌記錄、監控與警報」以及「維持監管合規性（如加密傳輸）」的需求，您需要引入 Service Mesh 技術。",
        "en": "EHR Healthcare has migrated its microservices architecture to GKE. To meet the requirements of 'providing consistent logging, monitoring, and alerting' and 'maintaining regulatory compliance (e.g., encryption in transit),' you need to introduce Service Mesh technology.",
        "wg": [
          { "t": "微服務", "en": "microservices", "ps": "noun" },
          { "t": "加密傳輸", "en": "encryption in transit", "ps": "noun" }
        ]
      },
      {
        "t": "此外，開發團隊希望能進行金絲雀部署 (Canary Deployments)，以更安全地推出新功能。您希望選擇一個全託管的解決方案來減少叢集內的維運負擔。",
        "en": "Additionally, the development team wants to perform Canary Deployments to roll out new features more safely. You want to choose a fully managed solution to reduce the operational burden within the cluster.",
        "wg": [
          { "t": "金絲雀部署", "en": "Canary Deployments", "ps": "noun" },
          { "t": "全託管", "en": "fully managed", "ps": "adj" }
        ]
      },
      {
        "t": "您應該推薦使用什麼 Google Cloud 產品？",
        "en": "Which Google Cloud product should you recommend?",
        "wg": [
          { "t": "推薦", "en": "recommend", "ps": "verb" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Load Balancing，並配置進階流量分割功能來處理金絲雀部署，使用 SSL 卸載 (SSL Offloading) 來處理加密。",
        "en": "(A) Cloud Load Balancing with advanced traffic splitting configuration for canary deployments, using SSL Offloading to handle encryption.",
        "wg": [
          { "t": "流量分割", "en": "traffic splitting", "ps": "feature" },
          { "t": "SSL 卸載", "en": "SSL Offloading", "ps": "feature" }
        ]
      },
      {
        "t": "(B) 手動在每個 Pod 中部署 Envoy Proxy 作為 Sidecar，並使用自建的 Istio 控制平面來管理憑證與流量規則。",
        "en": "(B) Manually deploy Envoy Proxy as a Sidecar in each Pod, and use a self-managed Istio control plane to manage certificates and traffic rules.",
        "wg": [
          { "t": "自建的", "en": "self-managed", "ps": "adj" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Service Mesh (前身為 Anthos Service Mesh) 的託管控制平面，啟用 mTLS 自動加密服務間通訊，並利用其流量管理功能進行灰度發布。",
        "en": "(C) Use Cloud Service Mesh (formerly Anthos Service Mesh) with a managed control plane, enabling mTLS to automatically encrypt inter-service communication, and leveraging its traffic management capabilities for progressive rollouts.",
        "wg": [
          { "t": "託管控制平面", "en": "managed control plane", "ps": "feature" },
          { "t": "灰度發布", "en": "progressive rollouts", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 VPC Flow Logs 結合 Packet Mirroring 來監控所有流量，並依靠應用程式層級的程式庫 (Library) 來處理加密與路由。",
        "en": "(D) Use VPC Flow Logs combined with Packet Mirroring to monitor all traffic, and rely on application-level libraries to handle encryption and routing.",
        "wg": [
          { "t": "程式庫", "en": "Library", "ps": "noun" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Service Mesh 提供全託管的 Istio 體驗，能自動處理服務間的 mTLS 加密（滿足合規性），並提供開箱即用的黃金指標（延遲、錯誤率、流量）與進階流量控制（金絲雀部署）。相較於自建 Istio (B) 或僅依賴負載平衡器 (A)，這是最符合「減少維運負擔」且功能最全面的選擇。",
      "en": "Cloud Service Mesh provides a fully managed Istio experience, automatically handling inter-service mTLS encryption (meeting compliance) and offering out-of-the-box golden metrics (latency, error rates, traffic) along with advanced traffic control (Canary deployments). Compared to self-managed Istio (B) or relying solely on load balancers (A), this is the most comprehensive choice that fits 'reducing operational burden'.",
      "wg": [
        { "t": "開箱即用", "en": "out-of-the-box", "ps": "adj" },
        { "t": "黃金指標", "en": "golden metrics", "ps": "term" }
      ]
    }
  },
  {
    "no": "14",
    "level": "hard",
    "keywords": "Lifecycle Management, Cost Optimization, Storage Class",
    "question": [
      {
        "t": "EHR Healthcare 正計畫將其傳統檔案系統遷移到 Cloud Storage。這些資料包含大量的醫療影像檔 (DICOM)。",
        "en": "EHR Healthcare is planning to migrate its legacy file systems to Cloud Storage. This data includes a massive amount of medical imaging files (DICOM).",
        "wg": [
          { "t": "醫療影像檔", "en": "medical imaging files", "ps": "noun" }
        ]
      },
      {
        "t": "根據存取模式分析：新產生的影像在最初 30 天內會被頻繁存取以進行診斷；之後存取頻率急劇下降，但依據法規必須保留 7 年。偶爾會有研究人員需要調閱 1 年前的舊資料。",
        "en": "Based on access pattern analysis: newly generated images are frequently accessed for diagnosis within the first 30 days; afterwards, access frequency drops sharply, but they must be retained for 7 years per regulations. Occasionally, researchers need to retrieve old data from 1 year ago.",
        "wg": [
          { "t": "存取模式", "en": "access pattern", "ps": "noun" },
          { "t": "調閱", "en": "retrieve", "ps": "verb" }
        ]
      },
      {
        "t": "您需要設計一個最具成本效益的儲存策略，同時確保資料在需要時立即可用（無取回延遲）。",
        "en": "You need to design the most cost-effective storage strategy while ensuring data is immediately available when needed (no retrieval latency).",
        "wg": [
          { "t": "最具成本效益", "en": "most cost-effective", "ps": "adj" },
          { "t": "取回延遲", "en": "retrieval latency", "ps": "noun" }
        ]
      },
      {
        "t": "您應該如何配置？",
        "en": "How should you configure this?",
        "wg": [
          { "t": "配置", "en": "configure", "ps": "verb" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將所有資料儲存在 Standard Storage 級別，因為它提供最佳的效能，並購買承諾使用折扣 (CUD) 來降低長期成本。",
        "en": "(A) Store all data in the Standard Storage class as it offers the best performance, and purchase Committed Use Discounts (CUD) to reduce long-term costs.",
        "wg": [
          { "t": "承諾使用折扣", "en": "Committed Use Discounts", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 使用物件生命週期管理 (Object Lifecycle Management)，設定規則：建立 30 天後轉移至 Nearline Storage，365 天後轉移至 Coldline Storage，7 年後刪除。",
        "en": "(B) Use Object Lifecycle Management to set rules: transition to Nearline Storage after 30 days, to Coldline Storage after 365 days, and delete after 7 years.",
        "wg": [
          { "t": "物件生命週期管理", "en": "Object Lifecycle Management", "ps": "feature" }
        ]
      },
      {
        "t": "(C) 使用物件生命週期管理，設定規則：建立 30 天後轉移至 Archive Storage，因為這是最便宜的選項。",
        "en": "(C) Use Object Lifecycle Management to set rules: transition to Archive Storage after 30 days since it is the cheapest option.",
        "wg": [
          { "t": "最便宜的", "en": "cheapest", "ps": "adj" }
        ]
      },
      {
        "t": "(D) 啟用 Cloud Storage 的 Autoclass 功能，讓 Google 自動根據存取頻率在不同儲存級別間移動物件。",
        "en": "(D) Enable the Autoclass feature of Cloud Storage to allow Google to automatically move objects between storage classes based on access frequency.",
        "wg": [
          { "t": "存取頻率", "en": "access frequency", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "選項 (B) 透過生命週期規則精確匹配已知的存取模式：前 30 天用 Standard/Nearline，之後轉入更便宜的 Coldline (適合每年存取一次以下，且無取回延遲)。Archive Storage (選項 C) 雖然便宜，但有取回成本且不適合這類可能仍需「偶爾調閱」且要求「無延遲」的場景（Archive 適合備份）。選項 (D) Autoclass 雖然方便，但會產生管理費用，對於如此明確且規律的存取模式，手動設定生命週期規則通常更具成本效益。",
      "en": "Option (B) precisely matches the known access pattern via lifecycle rules: Standard/Nearline for the first 30 days, then moving to cheaper Coldline (suitable for less than once a year access, with no retrieval latency). Archive Storage (Option C) is cheaper but incurs retrieval costs and isn't suitable for scenarios requiring 'occasional retrieval' with 'no latency' (Archive is for backups). Option (D) Autoclass is convenient but incurs management fees; for such a clear and regular access pattern, manual lifecycle rules are usually more cost-effective.",
      "wg": [
        { "t": "取回成本", "en": "retrieval costs", "ps": "noun" }
      ]
    }
  },
  {
    "no": "15",
    "level": "hard",
    "keywords": "Hybrid Connectivity, Cloud DNS, Private IP",
    "question": [
      {
        "t": "您已透過專用互連 (Dedicated Interconnect) 建立了地端資料中心與 Google Cloud VPC 之間的高效能連線。雙方網路均使用 RFC 1918 私人 IP 位址，且 CIDR 範圍不重疊。",
        "en": "You have established a high-performance connection between the on-premises data center and the Google Cloud VPC via Dedicated Interconnect. Both networks use RFC 1918 private IP addresses with non-overlapping CIDR ranges.",
        "wg": [
          { "t": "專用互連", "en": "Dedicated Interconnect", "ps": "product" },
          { "t": "不重疊", "en": "non-overlapping", "ps": "adj" }
        ]
      },
      {
        "t": "現在您面臨 DNS 解析的問題：Google Cloud 上的 GKE Pods 需要解析地端傳統資料庫的主機名稱；同時，地端應用程式也需要解析 Cloud SQL 的私人 IP 位址。",
        "en": "Now you face DNS resolution issues: GKE Pods on Google Cloud need to resolve the hostnames of on-premises legacy databases; simultaneously, on-premises applications need to resolve Cloud SQL private IP addresses.",
        "wg": [
          { "t": "解析", "en": "resolve", "ps": "verb" },
          { "t": "主機名稱", "en": "hostnames", "ps": "noun" }
        ]
      },
      {
        "t": "您應該在 Cloud DNS 中配置哪兩項功能來實現雙向的 DNS 解析？(請選擇兩項)",
        "en": "Which two features should you configure in Cloud DNS to achieve bidirectional DNS resolution? (Choose two)",
        "wg": [
          { "t": "雙向的", "en": "bidirectional", "ps": "adj" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 建立一個 Cloud DNS 轉發區域 (Forwarding Zone)，將地端網域的查詢轉發到地端 DNS 伺服器的 IP 位址。",
        "en": "(A) Create a Cloud DNS Forwarding Zone to forward queries for the on-premises domain to the IP addresses of the on-premises DNS servers.",
        "wg": [
          { "t": "轉發區域", "en": "Forwarding Zone", "ps": "feature" }
        ]
      },
      {
        "t": "(B) 設定 Cloud DNS 入站轉發策略 (Inbound Server Policy)，允許地端 DNS 伺服器查詢 Google Cloud 的內部 DNS。",
        "en": "(B) Configure a Cloud DNS Inbound Server Policy to allow on-premises DNS servers to query Google Cloud's internal DNS.",
        "wg": [
          { "t": "入站轉發策略", "en": "Inbound Server Policy", "ps": "feature" }
        ]
      },
      {
        "t": "(C) 在所有 Compute Engine 執行個體和 GKE 節點上編輯 `/etc/hosts` 文件，手動新增關鍵資料庫的 IP 對應。",
        "en": "(C) Edit the `/etc/hosts` file on all Compute Engine instances and GKE nodes to manually add IP mappings for critical databases.",
        "wg": [
          { "t": "手動新增", "en": "manually add", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 部署一組自訂的 BIND DNS 伺服器在 Google Cloud VM 上，配置區域傳送 (Zone Transfer) 以同步地端 DNS 記錄。",
        "en": "(D) Deploy a set of custom BIND DNS servers on Google Cloud VMs and configure Zone Transfer to sync on-premises DNS records.",
        "wg": [
          { "t": "區域傳送", "en": "Zone Transfer", "ps": "term" }
        ]
      },
      {
        "t": "(E) 使用 Google Public DNS (8.8.8.8) 作為所有系統的解析器，並在公共 DNS 註冊內部 IP 位址。",
        "en": "(E) Use Google Public DNS (8.8.8.8) as the resolver for all systems and register internal IP addresses in the public DNS.",
        "wg": [
          { "t": "解析器", "en": "resolver", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A), (B)",
    "why": {
      "t": "這是混合雲 DNS 解析的標準架構。選項 (A) 的轉發區域解決了「雲端查地端」的需求（將地端域名的查詢送回地端 DNS）。選項 (B) 的入站轉發策略提供了一個從互連進入的入口點 IP，解決了「地端查雲端」的需求。這兩者結合實現了無縫的雙向解析，無需維護額外的 DNS 伺服器 (D) 或修改主機文件 (C)。",
      "en": "This is the standard architecture for hybrid cloud DNS resolution. Option (A) Forwarding Zone addresses 'Cloud querying On-prem' (sending queries for on-prem domains back to on-prem DNS). Option (B) Inbound Server Policy provides an entry point IP accessible via the Interconnect, addressing 'On-prem querying Cloud'. Combined, they achieve seamless bidirectional resolution without maintaining extra DNS servers (D) or modifying host files (C).",
      "wg": [
        { "t": "混合雲", "en": "hybrid cloud", "ps": "noun" },
        { "t": "入口點", "en": "entry point", "ps": "noun" }
      ]
    }
  },{
    "no": "16",
    "level": "hard",
    "keywords": "Security, CMEK, Compliance, BigQuery",
    "question": [
      {
        "t": "EHR Healthcare 需要確保其儲存在 BigQuery 中的資料分析倉儲符合嚴格的醫療合規性標準。",
        "en": "EHR Healthcare needs to ensure that its data analytics warehouse stored in BigQuery meets strict medical compliance standards.",
        "wg": [
          { "t": "合規性標準", "en": "compliance standards", "ps": "noun" }
        ]
      },
      {
        "t": "雖然 Google Cloud 預設會加密靜態資料，但內部的安全政策要求：加密金鑰必須由 EHR Healthcare 自行產生與管理，而不是由 Google 管理。此外，這些金鑰必須每 90 天自動輪替一次。",
        "en": "Although Google Cloud encrypts data at rest by default, internal security policy requires that encryption keys must be generated and managed by EHR Healthcare, not Google. Additionally, these keys must be automatically rotated every 90 days.",
        "wg": [
          { "t": "加密金鑰", "en": "encryption keys", "ps": "noun" },
          { "t": "輪替", "en": "rotated", "ps": "verb" }
        ]
      },
      {
        "t": "您需要配置 BigQuery 資料集以滿足此需求，同時盡量減少維運開銷。",
        "en": "You need to configure the BigQuery dataset to meet this requirement while minimizing operational overhead.",
        "wg": [
          { "t": "維運開銷", "en": "operational overhead", "ps": "noun" }
        ]
      },
      {
        "t": "您應該採取什麼行動？",
        "en": "What action should you take?",
        "wg": [
          { "t": "行動", "en": "action", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用客戶提供的加密金鑰 (CSEK)，在每次執行載入作業或查詢時，透過應用程式層級提供金鑰。",
        "en": "(A) Use Customer-Supplied Encryption Keys (CSEK) and provide the keys via the application layer each time a load job or query is executed.",
        "wg": [
          { "t": "客戶提供的加密金鑰", "en": "Customer-Supplied Encryption Keys", "ps": "term" }
        ]
      },
      {
        "t": "(B) 在 Cloud Key Management Service (Cloud KMS) 中建立金鑰環與金鑰，設定 90 天的自動輪替週期。將 BigQuery 資料集設定為使用此客戶管理加密金鑰 (CMEK) 進行加密。",
        "en": "(B) Create a Key Ring and Key in Cloud Key Management Service (Cloud KMS), and set a 90-day automatic rotation period. Configure the BigQuery dataset to use this Customer-Managed Encryption Key (CMEK) for encryption.",
        "wg": [
          { "t": "客戶管理加密金鑰", "en": "Customer-Managed Encryption Key", "ps": "term" },
          { "t": "金鑰環", "en": "Key Ring", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 HashiCorp Vault 部署在地端，產生金鑰並透過 Cloud VPN 將其匯入 Cloud HSM。手動建立 Cron Job 每 90 天更新一次金鑰。",
        "en": "(C) Deploy HashiCorp Vault on-premises, generate keys, and import them into Cloud HSM via Cloud VPN. Manually create a Cron Job to update the keys every 90 days.",
        "wg": [
          { "t": "匯入", "en": "import", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 依賴 BigQuery 的預設加密，並使用 IAM 條件 (IAM Conditions) 限制只有在特定時間範圍內才能存取資料，以模擬金鑰輪替的效果。",
        "en": "(D) Rely on BigQuery's default encryption and use IAM Conditions to restrict data access to specific time ranges, simulating the effect of key rotation.",
        "wg": [
          { "t": "IAM 條件", "en": "IAM Conditions", "ps": "feature" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "CMEK (客戶管理加密金鑰) 是 Google Cloud 提供的標準機制，允許客戶控制金鑰的生命週期（包括自動輪替），同時將加密/解密的重擔交給 Google 服務處理。這滿足了「由客戶管理」與「自動輪替」的需求，且比 CSEK (選項 A) 或自建 Vault (選項 C) 的維運成本低得多。",
      "en": "CMEK (Customer-Managed Encryption Keys) is the standard mechanism provided by Google Cloud that allows customers to control the key lifecycle (including automatic rotation) while offloading the encryption/decryption burden to Google services. This meets the 'customer-managed' and 'automatic rotation' requirements with much lower operational costs than CSEK (Option A) or self-hosted Vault (Option C).",
      "wg": [
        { "t": "生命週期", "en": "lifecycle", "ps": "noun" },
        { "t": "重擔", "en": "burden", "ps": "noun" }
      ]
    }
  },
  {
    "no": "17",
    "level": "hard",
    "keywords": "GKE, Scaling, Over-provisioning, Availability",
    "question": [
      {
        "t": "EHR Healthcare 的高層聲明指出，過去的許多中斷是由於「管理流量高峰的容量不足」所致。",
        "en": "The Executive Statement from EHR Healthcare notes that many past outages were a result of 'inadequate capacity to manage spikes in traffic.'",
        "wg": [
          { "t": "中斷", "en": "outages", "ps": "noun" },
          { "t": "流量高峰", "en": "traffic spikes", "ps": "noun" }
        ]
      },
      {
        "t": "您已將應用程式遷移至 GKE 並配置了水平 Pod 自動擴展 (HPA) 和叢集自動擴展 (Cluster Autoscaler)。然而，在極端的突發流量下，新節點啟動並加入叢集仍需數分鐘，導致這段期間的部分請求失敗。",
        "en": "You have migrated applications to GKE and configured Horizontal Pod Autoscaling (HPA) and Cluster Autoscaler. However, during extreme traffic bursts, new nodes still take minutes to boot and join the cluster, causing some requests to fail during this period.",
        "wg": [
          { "t": "突發流量", "en": "traffic bursts", "ps": "noun" },
          { "t": "請求失敗", "en": "requests to fail", "ps": "phrase" }
        ]
      },
      {
        "t": "您需要在不大幅改變架構的前提下，消除這段擴展延遲。",
        "en": "You need to eliminate this scaling latency without significantly changing the architecture.",
        "wg": [
          { "t": "擴展延遲", "en": "scaling latency", "ps": "noun" }
        ]
      },
      {
        "t": "您應該實施哪項最佳實務？",
        "en": "Which best practice should you implement?",
        "wg": [
          { "t": "最佳實務", "en": "best practice", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將所有節點集區 (Node Pools) 轉換為使用 Spot VM，因為它們啟動速度更快且成本更低。",
        "en": "(A) Convert all Node Pools to use Spot VMs because they boot faster and are lower cost.",
        "wg": [
          { "t": "Spot VM", "en": "Spot VMs", "ps": "product" }
        ]
      },
      {
        "t": "(B) 部署一組使用低優先級 PriorityClass 的「暫停 Pod (Pause Pods)」，預先佔用額外的節點資源。當真實流量激增時，這些暫停 Pod 會被驅逐，立即釋放資源給應用程式 Pod 使用。",
        "en": "(B) Deploy a set of 'Pause Pods' with a low PriorityClass to pre-occupy extra node resources. When real traffic spikes, these pause pods are evicted, instantly releasing resources for application pods.",
        "wg": [
          { "t": "暫停 Pod", "en": "Pause Pods", "ps": "term" },
          { "t": "驅逐", "en": "evicted", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 增加 HPA 的目標 CPU 使用率門檻（例如從 50% 提高到 90%），以延後觸發擴展的時間。",
        "en": "(C) Increase the HPA target CPU utilization threshold (e.g., from 50% to 90%) to delay the triggering of scaling.",
        "wg": [
          { "t": "門檻", "en": "threshold", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 手動將叢集節點數量固定在歷史最高峰值的 150%，完全停用叢集自動擴展器。",
        "en": "(D) Manually fix the number of cluster nodes at 150% of the historical peak and completely disable the Cluster Autoscaler.",
        "wg": [
          { "t": "固定", "en": "fix", "ps": "verb" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "這是一種稱為「超額配置 (Over-provisioning)」的標準 Kubernetes 模式。透過部署低優先級的 Pause Pods，您可以保持緩衝節點隨時待命。當高優先級的應用程式 Pod 需要擴展時，K8s 會立即刪除 Pause Pods 騰出空間，從而消除節點啟動的數分鐘延遲。選項 (D) 雖然有效但成本極高且不具彈性。",
      "en": "This is a standard Kubernetes pattern known as 'Over-provisioning.' By deploying low-priority Pause Pods, you keep buffer nodes warm and ready. When high-priority application pods need to scale, K8s instantly preempts the Pause Pods to make room, eliminating the minutes of node boot latency. Option (D) is effective but extremely costly and inflexible.",
      "wg": [
        { "t": "超額配置", "en": "Over-provisioning", "ps": "term" },
        { "t": "緩衝節點", "en": "buffer nodes", "ps": "noun" }
      ]
    }
  },
  {
    "no": "18",
    "level": "hard",
    "keywords": "Private Google Access, Hybrid Connectivity, DNS",
    "question": [
      {
        "t": "EHR Healthcare 的地端傳統系統需要定期將備份資料上傳到 Cloud Storage 以進行封存。基於安全考量，這些資料傳輸「不得經過公共網際網路」。",
        "en": "EHR Healthcare's legacy on-premises systems need to regularly upload backup data to Cloud Storage for archiving. For security reasons, this data transfer 'must not traverse the public internet.'",
        "wg": [
          { "t": "封存", "en": "archiving", "ps": "verb" },
          { "t": "公共網際網路", "en": "public internet", "ps": "noun" }
        ]
      },
      {
        "t": "您已經配置了專用互連 (Dedicated Interconnect) 連接地端與 VPC。現在您需要配置網路與 DNS，讓地端伺服器能透過私有 IP 存取 Cloud Storage API。",
        "en": "You have already configured Dedicated Interconnect connecting on-premises to the VPC. Now you need to configure the network and DNS so that on-premises servers can access Cloud Storage APIs via private IPs.",
        "wg": [
          { "t": "配置", "en": "configure", "ps": "verb" }
        ]
      },
      {
        "t": "您應該執行哪項操作？",
        "en": "Which action should you perform?",
        "wg": [
          { "t": "操作", "en": "action", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 VPC 上啟用私人 Google 存取權 (Private Google Access)，並在地端 DNS 伺服器上將 `storage.googleapis.com` 解析為 `private.googleapis.com` 的 IP 範圍 (199.36.153.8/30)。",
        "en": "(A) Enable Private Google Access on the VPC, and on the on-premises DNS servers, resolve `storage.googleapis.com` to the IP range of `private.googleapis.com` (199.36.153.8/30).",
        "wg": [
          { "t": "私人 Google 存取權", "en": "Private Google Access", "ps": "feature" }
        ]
      },
      {
        "t": "(B) 建立一個 Cloud NAT 閘道器，並設定路由規則將前往 Google API 的流量導向互連連線。",
        "en": "(B) Create a Cloud NAT gateway and configure routing rules to direct traffic destined for Google APIs through the Interconnect connection.",
        "wg": [
          { "t": "閘道器", "en": "gateway", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 VPC Service Controls 建立服務邊界，將 Cloud Storage 和地端網路範圍納入同一邊界內。",
        "en": "(C) Use VPC Service Controls to create a service perimeter, including both Cloud Storage and the on-premises network range within the same perimeter.",
        "wg": [
          { "t": "服務邊界", "en": "service perimeter", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 在地端防火牆上開啟連接埠 443，允許直接連線到 Google 的公共 IP 範圍，並信任 Google 的 SSL 憑證。",
        "en": "(D) Open port 443 on the on-premises firewall to allow direct connection to Google's public IP ranges and trust Google's SSL certificates.",
        "wg": [
          { "t": "防火牆", "en": "firewall", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "要讓地端主機透過互連存取 Google API（如 Storage），必須使用「適用於地端主機的私人 Google 存取權 (Private Google Access for On-Premises)」。這需要在地端將 API 網域名稱 (CNAME) 指向 `private.googleapis.com` (或 restricted) 的特定 VIP 範圍，並透過互連路由這些流量。選項 (D) 違反了「不經過公共網際網路」的要求。",
      "en": "To allow on-premises hosts to access Google APIs (like Storage) via Interconnect, you must use 'Private Google Access for On-Premises.' This requires configuring on-premises DNS to point API domains (CNAME) to the specific VIP range of `private.googleapis.com` (or restricted) and routing this traffic through the Interconnect. Option (D) violates the 'must not traverse the public internet' requirement.",
      "wg": [
        { "t": "網域名稱", "en": "domain names", "ps": "noun" },
        { "t": "違反", "en": "violates", "ps": "verb" }
      ]
    }
  },
  {
    "no": "19",
    "level": "hard",
    "keywords": "Organization Policy, Governance, Security",
    "question": [
      {
        "t": "為了滿足「降低基礎架構管理成本」並防止配置錯誤，EHR Healthcare 希望實施集中式治理。",
        "en": "To meet the goal of 'decreasing infrastructure administration costs' and preventing misconfigurations, EHR Healthcare wants to implement centralized governance.",
        "wg": [
          { "t": "集中式治理", "en": "centralized governance", "ps": "noun" },
          { "t": "配置錯誤", "en": "misconfigurations", "ps": "noun" }
        ]
      },
      {
        "t": "安全稽核發現，部分開發人員在開發環境中為 Compute Engine VM 分配了外部公共 IP，這違反了安全政策。您需要確保整個組織內的所有新 VM 預設都無法配置外部 IP，且未來無法手動覆寫此設定。",
        "en": "A security audit revealed that some developers assigned external public IPs to Compute Engine VMs in the development environment, violating security policy. You need to ensure that, by default, no new VMs in the entire organization can be configured with external IPs, and this cannot be manually overridden in the future.",
        "wg": [
          { "t": "外部公共 IP", "en": "external public IPs", "ps": "noun" },
          { "t": "手動覆寫", "en": "manually overridden", "ps": "verb" }
        ]
      },
      {
        "t": "您應該在組織層級配置哪項控制措施？",
        "en": "Which control measure should you configure at the organization level?",
        "wg": [
          { "t": "控制措施", "en": "control measure", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 建立一個 VPC 防火牆規則，拒絕所有來自 `0.0.0.0/0` 的入站流量，並將其套用到所有專案。",
        "en": "(A) Create a VPC firewall rule to deny all inbound traffic from `0.0.0.0/0` and apply it to all projects.",
        "wg": [
          { "t": "入站流量", "en": "inbound traffic", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 設定組織政策 (Organization Policy)，強制執行 `constraints/compute.vmExternalIpAccess` 限制，將允許的清單設定為「無 (None)」。",
        "en": "(B) Configure an Organization Policy to enforce the `constraints/compute.vmExternalIpAccess` constraint, setting the allowed list to 'None'.",
        "wg": [
          { "t": "組織政策", "en": "Organization Policy", "ps": "feature" },
          { "t": "強制執行", "en": "enforce", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 IAM 角色管理，從所有開發人員的帳戶中移除 `compute.instances.create` 權限。",
        "en": "(C) Use IAM role management to remove the `compute.instances.create` permission from all developer accounts.",
        "wg": [
          { "t": "移除", "en": "remove", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 編寫 Cloud Asset Inventory 觸發的 Cloud Functions，當偵測到有 VM 建立並帶有外部 IP 時，自動將其刪除。",
        "en": "(D) Write a Cloud Function triggered by Cloud Asset Inventory that automatically deletes any VM detected with an external IP upon creation.",
        "wg": [
          { "t": "偵測到", "en": "detected", "ps": "verb" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "組織政策 (Organization Policy) 是 Google Cloud 用於在資源層級強制執行配置限制的工具。`constraints/compute.vmExternalIpAccess` 是專門用於禁止 VM 獲取外部 IP 的約束條件。這是預防性的（Preventative）控制，優於防火牆（無法阻止 IP 分配）或 Cloud Functions（反應性/Reactive）。",
      "en": "Organization Policy is the Google Cloud tool for enforcing configuration constraints at the resource level. `constraints/compute.vmExternalIpAccess` is the specific constraint to prohibit VMs from acquiring external IPs. This is a preventative control, superior to firewalls (which cannot prevent IP assignment) or Cloud Functions (which are reactive).",
      "wg": [
        { "t": "預防性的", "en": "Preventative", "ps": "adj" },
        { "t": "反應性", "en": "Reactive", "ps": "adj" }
      ]
    }
  },
  {
    "no": "20",
    "level": "hard",
    "keywords": "Observability, Troubleshooting, Microservices, Trace",
    "question": [
      {
        "t": "EHR Healthcare 接獲使用者投訴，指出新的微服務應用程式偶爾會出現高延遲。由於應用程式由數十個 GKE 服務和 Cloud SQL 資料庫組成，開發團隊難以確定延遲發生的確切位置（是應用程式程式碼、資料庫查詢還是網路）。",
        "en": "EHR Healthcare has received user complaints that the new microservices application occasionally experiences high latency. Since the application consists of dozens of GKE services and Cloud SQL databases, the development team is struggling to pinpoint the exact location of the latency (whether it's application code, database queries, or the network).",
        "wg": [
          { "t": "高延遲", "en": "high latency", "ps": "noun" },
          { "t": "確切位置", "en": "exact location", "ps": "noun" }
        ]
      },
      {
        "t": "為了滿足「提供集中視覺化與主動應對系統效能」的需求，您需要建議一組工具來協助進行根因分析。",
        "en": "To meet the requirement of 'providing centralized visibility and proactive action on system performance,' you need to recommend a set of tools to assist in root cause analysis.",
        "wg": [
          { "t": "根因分析", "en": "root cause analysis", "ps": "noun" }
        ]
      },
      {
        "t": "哪兩種工具組合最能有效解決此問題？(請選擇兩項)",
        "en": "Which combination of two tools best effectively solves this problem? (Choose two)",
        "wg": [
          { "t": "工具組合", "en": "combination of tools", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 啟用 Cloud Trace (分散式追蹤)，以視覺化單一請求跨越微服務與資料庫的完整路徑與延遲。",
        "en": "(A) Enable Cloud Trace (distributed tracing) to visualize the full path and latency of a single request across microservices and databases.",
        "wg": [
          { "t": "分散式追蹤", "en": "distributed tracing", "ps": "term" },
          { "t": "視覺化", "en": "visualize", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 使用 Cloud Profiler 來持續分析生產環境中應用程式的 CPU 與記憶體使用狀況，找出程式碼層級的效能瓶頸。",
        "en": "(B) Use Cloud Profiler to continuously analyze CPU and memory usage of the application in production to identify code-level performance bottlenecks.",
        "wg": [
          { "t": "效能瓶頸", "en": "performance bottlenecks", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 設定 VPC Flow Logs 並匯出至 BigQuery，分析封包層級的傳輸時間。",
        "en": "(C) Configure VPC Flow Logs and export to BigQuery to analyze packet-level transmission times.",
        "wg": [
          { "t": "封包層級", "en": "packet-level", "ps": "adj" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Logging 搜尋所有相關的錯誤訊息，並計算每分鐘的錯誤率。",
        "en": "(D) Use Cloud Logging to search for all relevant error messages and calculate the error rate per minute.",
        "wg": [
          { "t": "錯誤率", "en": "error rate", "ps": "noun" }
        ]
      },
      {
        "t": "(E) 在所有 VM 上安裝 OS Config Agent，並監控磁碟 I/O 指標。",
        "en": "(E) Install the OS Config Agent on all VMs and monitor disk I/O metrics.",
        "wg": [
          { "t": "指標", "en": "metrics", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A), (B)",
    "why": {
      "t": "對於微服務架構的延遲分析，Cloud Trace 是關鍵工具，它能顯示請求的瀑布圖 (Waterfall)，清楚指出時間是花在 API 呼叫、資料庫等待還是網路。Cloud Profiler 則補足了「程式碼內部」的分析，能指出特定函數佔用了過多 CPU 或記憶體。這兩者結合提供了完整的應用程式效能視圖。VPC Flow Logs (C) 更多用於網路連通性與流量分析，而非應用程式邏輯延遲。",
      "en": "For latency analysis in microservices architecture, Cloud Trace is the key tool. It displays the request waterfall, clearly indicating whether time is spent on API calls, database waits, or the network. Cloud Profiler complements this with 'internal code' analysis, pinpointing specific functions consuming excessive CPU or memory. Together, they provide a complete view of application performance. VPC Flow Logs (C) are used more for network connectivity and traffic analysis rather than application logic latency.",
      "wg": [
        { "t": "瀑布圖", "en": "waterfall", "ps": "term" },
        { "t": "應用程式邏輯", "en": "application logic", "ps": "noun" }
      ]
    }
  }
]