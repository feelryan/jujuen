[
  {
    "no": "61",
    "level": "hard",
    "keywords": "Stakeholder Management, Business Process, Conflict Resolution, Security",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在為一家金融新創公司設計雲端架構。",
        "en": "You are designing a cloud architecture for a financial startup.",
        "wg": []
      },
      {
        "t": "技術長 (CTO) 希望使用 Cloud Run 來最大化開發速度並降低維運成本。",
        "en": "The CTO wants to use Cloud Run to maximize development velocity and reduce operational costs.",
        "wg": [
          {
            "t": "開發速度",
            "en": "development velocity",
            "ps": "N"
          },
          {
            "t": "維運成本",
            "en": "operational cost",
            "ps": "N"
          }
        ]
      },
      {
        "t": "然而，資安長 (CISO) 反對此提議，堅持加密金鑰必須儲存在通過 FIPS 140-2 Level 3 認證的專用硬體安全模組 (HSM) 中，且金鑰不得離開硬體邊界。",
        "en": "However, the CISO opposes this, insisting that encryption keys must be stored in FIPS 140-2 Level 3 certified dedicated Hardware Security Modules (HSM) and keys must not leave the hardware boundary.",
        "wg": [
          {
            "t": "硬體安全模組",
            "en": "Hardware Security Module",
            "ps": "N"
          },
          {
            "t": "硬體邊界",
            "en": "hardware boundary",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該如何解決這個利益相關者的衝突？",
        "en": "How should you resolve this stakeholder conflict?",
        "wg": [
          {
            "t": "利益相關者",
            "en": "stakeholder",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 說服資安長 Cloud Run 的預設加密已經足夠安全，無需額外硬體。",
        "en": "(A) Persuade the CISO that Cloud Run's default encryption is secure enough without extra hardware.",
        "wg": []
      },
      {
        "t": "(B) 放棄 Cloud Run，改用 Compute Engine 並手動連接地端 HSM。",
        "en": "(B) Abandon Cloud Run, switch to Compute Engine, and manually connect to on-premises HSM.",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud Run，並整合 Cloud Key Management Service (KMS) 與 Cloud HSM。",
        "en": "(C) Use Cloud Run and integrate Cloud Key Management Service (KMS) with Cloud HSM.",
        "wg": [
          {
            "t": "整合",
            "en": "integrate",
            "ps": "V"
          }
        ]
      },
      {
        "t": "(D) 開發一個自定義的 Sidecar 容器來處理加密，並部署在 GKE 上。",
        "en": "(D) Develop a custom Sidecar container to handle encryption and deploy on GKE.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud HSM 是 Google Cloud 的全託管服務，提供 FIPS 140-2 Level 3 認證的硬體金鑰儲存。它可以透過 Cloud KMS API 與 Cloud Run 無縫整合。這既滿足了 CTO 對無伺服器 (Serverless) 的需求，也滿足了 CISO 對硬體級別安全合規的要求，是最佳的權衡方案。",
      "en": "Cloud HSM is a fully managed service in Google Cloud providing FIPS 140-2 Level 3 certified hardware key storage. It integrates seamlessly with Cloud Run via the Cloud KMS API. This satisfies the CTO's need for Serverless and the CISO's requirement for hardware-level security compliance, making it the best trade-off.",
      "wg": [
        {
          "t": "無縫整合",
          "en": "seamlessly integrate",
          "ps": "V"
        },
        {
          "t": "權衡方案",
          "en": "trade-off",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "62",
    "level": "medium",
    "keywords": "Skill Assessment, Migration Strategy, GCVE, VMware",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的客戶擁有一支精通 VMware vSphere 管理的維運團隊。",
        "en": "Your client has an operations team proficient in VMware vSphere management.",
        "wg": [
          {
            "t": "精通",
            "en": "proficient",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "他們被要求在三個月內撤離目前的資料中心並遷移至 Google Cloud。",
        "en": "They are mandated to evacuate their current data center and migrate to Google Cloud within three months.",
        "wg": [
          {
            "t": "撤離",
            "en": "evacuate",
            "ps": "V"
          }
        ]
      },
      {
        "t": "該團隊缺乏 Kubernetes 或重構應用程式的經驗，且希望能盡量減少重新培訓的時間。",
        "en": "The team lacks experience with Kubernetes or application refactoring and wants to minimize retraining time.",
        "wg": [
          {
            "t": "重構",
            "en": "refactoring",
            "ps": "N"
          },
          {
            "t": "重新培訓",
            "en": "retraining",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該推薦哪種遷移策略？",
        "en": "Which migration strategy should you recommend?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將應用程式容器化並遷移至 GKE Autopilot。",
        "en": "(A) Containerize applications and migrate to GKE Autopilot.",
        "wg": [
          {
            "t": "容器化",
            "en": "containerize",
            "ps": "V"
          }
        ]
      },
      {
        "t": "(B) 使用 Google Cloud VMware Engine (GCVE) 進行「直接遷移」(Lift and Shift)。",
        "en": "(B) Use Google Cloud VMware Engine (GCVE) for a \"Lift and Shift\" migration.",
        "wg": [
          {
            "t": "直接遷移",
            "en": "Lift and Shift",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 使用 Compute Engine 重新託管 (Rehost) 所有 VM，並使用 Terraform 管理。",
        "en": "(C) Rehost all VMs using Compute Engine and manage them with Terraform.",
        "wg": []
      },
      {
        "t": "(D) 重寫應用程式以使用 Cloud Functions。",
        "en": "(D) Rewrite applications to use Cloud Functions.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "考慮到團隊的現有技能 (VMware) 和緊迫的時間限制 (3個月)，GCVE 是最佳選擇。它允許團隊繼續使用熟悉的 vCenter 工具與流程，無需學習新的雲端原生概念或重構代碼，能最快完成遷移並降低風險。",
      "en": "Considering the team's existing skills (VMware) and tight timeline (3 months), GCVE is the best choice. It allows the team to continue using familiar vCenter tools and processes without learning new cloud-native concepts or refactoring code, enabling the fastest migration with reduced risk.",
      "wg": [
        {
          "t": "現有技能",
          "en": "existing skills",
          "ps": "N"
        },
        {
          "t": "雲端原生",
          "en": "cloud-native",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "63",
    "level": "hard",
    "keywords": "Data Transfer, Migration, Transfer Appliance, Networking",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您需要將 800 TB 的歷史封存資料從本地資料中心遷移至 Google Cloud Storage。",
        "en": "You need to migrate 800 TB of historical archive data from an on-premises data center to Google Cloud Storage.",
        "wg": [
          {
            "t": "歷史封存資料",
            "en": "historical archive data",
            "ps": "N"
          }
        ]
      },
      {
        "t": "該資料中心只有一條 1 Gbps 的共享網際網路連線，且日常業務佔用了 80% 的頻寬。",
        "en": "The data center only has a 1 Gbps shared internet connection, and daily business operations consume 80% of the bandwidth.",
        "wg": [
          {
            "t": "共享",
            "en": "shared",
            "ps": "Adj"
          },
          {
            "t": "頻寬",
            "en": "bandwidth",
            "ps": "N"
          }
        ]
      },
      {
        "t": "專案要求必須在 30 天內完成遷移。您應該採用哪種方法？",
        "en": "The project requires the migration to be completed within 30 days. Which method should you adopt?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 `gsutil -m cp` 指令透過現有網路進行多執行緒上傳。",
        "en": "(A) Use `gsutil -m cp` command for multi-threaded upload over the existing network.",
        "wg": [
          {
            "t": "多執行緒",
            "en": "multi-threaded",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "(B) 訂購 Transfer Appliance 並以離線方式傳輸資料。",
        "en": "(B) Order Transfer Appliance and transfer data offline.",
        "wg": [
          {
            "t": "離線方式",
            "en": "offline",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "(C) 設定 Storage Transfer Service 透過 HTTPS 代理傳輸。",
        "en": "(C) Configure Storage Transfer Service to transfer via HTTPS proxy.",
        "wg": []
      },
      {
        "t": "(D) 升級網路連線至 10 Gbps Dedicated Interconnect。",
        "en": "(D) Upgrade network connection to 10 Gbps Dedicated Interconnect.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "計算可用頻寬：1 Gbps 的 20% 僅有 200 Mbps。傳輸 800 TB 需要超過一年，遠超 30 天期限。即使升級網路 (D) 也需要漫長的佈建時間 (通常數週到數月)。Transfer Appliance 是實體設備，可快速運送到資料中心，複製資料後運回 Google 上傳，是唯一能在期限內完成的大量資料遷移方案。",
      "en": "Calculating available bandwidth: 20% of 1 Gbps is only 200 Mbps. Transferring 800 TB would take over a year, far exceeding the 30-day deadline. Even upgrading the network (D) takes a long provisioning time (usually weeks to months). Transfer Appliance is a physical device that can be shipped to the data center, filled with data, and shipped back to Google for upload, making it the only feasible solution for this volume within the deadline.",
      "wg": [
        {
          "t": "佈建時間",
          "en": "provisioning time",
          "ps": "N"
        },
        {
          "t": "實體設備",
          "en": "physical device",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "64",
    "level": "medium",
    "keywords": "Migration Center, Discovery, Dependency Mapping, Assessment",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的公司計畫遷移一個複雜的多層式應用程式 (Multi-tier Application)，該應用程式由數十個 VM 組成。",
        "en": "Your company plans to migrate a complex multi-tier application consisting of dozens of VMs.",
        "wg": [
          {
            "t": "多層式應用程式",
            "en": "multi-tier application",
            "ps": "N"
          }
        ]
      },
      {
        "t": "目前的 CMDB 文件已過時，您不確定哪些 VM 之間有相依性，也不清楚資源使用率。",
        "en": "The current CMDB documentation is outdated, and you are unsure about the dependencies between VMs or their resource utilization.",
        "wg": [
          {
            "t": "已過時",
            "en": "outdated",
            "ps": "Adj"
          },
          {
            "t": "相依性",
            "en": "dependency",
            "ps": "N"
          },
          {
            "t": "資源使用率",
            "en": "resource utilization",
            "ps": "N"
          }
        ]
      },
      {
        "t": "為了準確規劃遷移波次 (Waves) 並調整資源大小 (Right-sizing)，您應該首先採取什麼行動？",
        "en": "To accurately plan migration waves and perform right-sizing, what action should you take first?",
        "wg": [
          {
            "t": "遷移波次",
            "en": "migration wave",
            "ps": "N"
          },
          {
            "t": "調整資源大小",
            "en": "right-sizing",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 採訪應用程式開發人員並手動繪製架構圖。",
        "en": "(A) Interview application developers and manually draw architectural diagrams.",
        "wg": []
      },
      {
        "t": "(B) 在 Migration Center 中執行探索與評估 (Discovery and Assessment)，並部署探索客戶端 (Discovery Client) 收集數據。",
        "en": "(B) Run Discovery and Assessment in Migration Center and deploy the Discovery Client to collect data.",
        "wg": [
          {
            "t": "探索與評估",
            "en": "Discovery and Assessment",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 立即將所有 VM 遷移到 Google Cloud，然後透過 Monitoring 觀察流量。",
        "en": "(C) Immediately migrate all VMs to Google Cloud and then observe traffic via Monitoring.",
        "wg": []
      },
      {
        "t": "(D) 檢查 VPC Flow Logs 以推測相依性。",
        "en": "(D) Inspect VPC Flow Logs to infer dependencies.",
        "wg": [
          {
            "t": "推測",
            "en": "infer",
            "ps": "V"
          }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Migration Center (整合了之前的 StratoZone 功能) 提供了自動化探索與評估工具。部署 Discovery Client 可以自動掃描基礎架構，收集精確的效能數據、作業系統資訊以及網路相依性，從而自動產生「遷移分組 (Move Groups)」建議和 TCO 評估，這比手動訪談或單純看 Flow Logs 更準確且有效率。",
      "en": "Migration Center (integrating former StratoZone capabilities) provides automated discovery and assessment tools. Deploying the Discovery Client automatically scans the infrastructure, collecting precise performance data, OS information, and network dependencies, thereby automatically generating \"Move Groups\" recommendations and TCO assessments, which is far more accurate and efficient than manual interviews or just looking at Flow Logs.",
      "wg": [
        {
          "t": "遷移分組",
          "en": "Move Group",
          "ps": "N"
        },
        {
          "t": "自動化探索",
          "en": "automated discovery",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "65",
    "level": "medium",
    "keywords": "Compliance, Data Residency, Organization Policy, Resource Locations",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的跨國企業在德國有嚴格的資料主權要求，規定所有客戶數據與相關的運算資源必須保留在法蘭克福 (europe-west3) 區域。",
        "en": "Your multinational enterprise has strict data sovereignty requirements in Germany, mandating that all customer data and associated compute resources must remain in the Frankfurt (europe-west3) region.",
        "wg": [
          {
            "t": "資料主權",
            "en": "data sovereignty",
            "ps": "N"
          },
          {
            "t": "保留",
            "en": "remain",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您希望確保即使擁有高權限的開發人員，也無法意外地在美國或亞洲區域啟動資源。",
        "en": "You want to ensure that even developers with high privileges cannot accidentally launch resources in US or Asian regions.",
        "wg": [
          {
            "t": "高權限",
            "en": "high privileges",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該設定哪項控制措施？",
        "en": "Which control measure should you configure?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 IAM 中設定條件 (Conditions)，限制只能在特定時間存取。",
        "en": "(A) Configure IAM Conditions to restrict access only to specific times.",
        "wg": []
      },
      {
        "t": "(B) 設定組織政策 (Organization Policy) 的資源位置限制 (Resource Location Restriction) 條件約束。",
        "en": "(B) Configure the Resource Location Restriction constraint in Organization Policy.",
        "wg": [
          {
            "t": "資源位置限制",
            "en": "Resource Location Restriction",
            "ps": "N"
          },
          {
            "t": "條件約束",
            "en": "constraint",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 使用 VPC Service Controls 建立服務邊界。",
        "en": "(C) Use VPC Service Controls to create service perimeters.",
        "wg": []
      },
      {
        "t": "(D) 定期執行 Cloud Asset Inventory 掃描並刪除違規資源。",
        "en": "(D) Regularly run Cloud Asset Inventory scans and delete violating resources.",
        "wg": [
          {
            "t": "違規",
            "en": "violating",
            "ps": "Adj"
          }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "組織政策中的 `gcp.resourceLocations` 條件約束是一項預防性控制 (Preventative Control)，它可以明確定義允許部署資源的實體位置清單。一旦設定，任何試圖在允許清單以外區域建立資源的 API 呼叫都會被拒絕，這是強制執行資料駐留 (Data Residency) 最有效的方法。",
      "en": "The `gcp.resourceLocations` constraint in Organization Policy is a preventative control that explicitly defines a list of allowed physical locations for resource deployment. Once configured, any API call attempting to create resources outside the allowed list will be denied, making it the most effective way to enforce Data Residency.",
      "wg": [
        {
          "t": "預防性控制",
          "en": "Preventative Control",
          "ps": "N"
        },
        {
          "t": "資料駐留",
          "en": "Data Residency",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "66",
    "level": "medium",
    "keywords": "GenAI, Vertex AI Agent Builder, Search, Grounding",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的公司希望建立一個內部的 AI 聊天機器人，協助員工搜尋企業知識庫（PDF、Wiki 頁面）。",
        "en": "Your company wants to build an internal AI chatbot to help employees search the corporate knowledge base (PDFs, Wiki pages).",
        "wg": [
          {
            "t": "企業知識庫",
            "en": "corporate knowledge base",
            "ps": "N"
          }
        ]
      },
      {
        "t": "管理層非常擔心大型語言模型 (LLM) 可能會產生「幻覺」(Hallucinations)，提供錯誤的資訊。",
        "en": "Management is very concerned that Large Language Models (LLMs) might generate \"Hallucinations\" and provide incorrect information.",
        "wg": [
          {
            "t": "幻覺",
            "en": "hallucination",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該使用哪種架構模式來確保回答是基於公司內部的真實資料？",
        "en": "Which architectural pattern should you use to ensure answers are based on the company's actual data?",
        "wg": [
          {
            "t": "真實資料",
            "en": "actual data",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Vertex AI Agent Builder 並啟用「接地」(Grounding) 功能，連結至企業資料儲存區。",
        "en": "(A) Use Vertex AI Agent Builder and enable \"Grounding\" linked to the enterprise data store.",
        "wg": [
          {
            "t": "接地",
            "en": "Grounding",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 增加 Prompt 中的 Temperature 參數值。",
        "en": "(B) Increase the Temperature parameter value in the Prompt.",
        "wg": []
      },
      {
        "t": "(C) 使用更多公開資料來微調 (Fine-tune) 基礎模型。",
        "en": "(C) Fine-tune the base model with more public data.",
        "wg": []
      },
      {
        "t": "(D) 僅使用關鍵字搜尋引擎，不使用 LLM。",
        "en": "(D) Use only a keyword search engine without LLMs.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "RAG (檢索增強生成) 架構透過「接地 (Grounding)」將 LLM 的回答限制在檢索到的企業資料範圍內，並提供引用來源。Vertex AI Agent Builder (前身為 Search and Conversation) 提供了開箱即用的 RAG 解決方案，能有效減少幻覺並確保資訊準確性。",
      "en": "RAG (Retrieval-Augmented Generation) architecture uses \"Grounding\" to restrict LLM responses to the scope of retrieved enterprise data and provides citations. Vertex AI Agent Builder (formerly Search and Conversation) offers an out-of-the-box RAG solution that effectively reduces hallucinations and ensures information accuracy.",
      "wg": [
        {
          "t": "檢索增強生成",
          "en": "Retrieval-Augmented Generation",
          "ps": "N"
        },
        {
          "t": "開箱即用",
          "en": "out-of-the-box",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "67",
    "level": "medium",
    "keywords": "IaC, Terraform, Drift Detection, CI/CD",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的團隊使用 Terraform 管理所有基礎架構。最近發生了一次安全事件，原因是一名維運人員手動在 Cloud Console 中修改了防火牆規則，導致配置偏移 (Drift)。",
        "en": "Your team uses Terraform to manage all infrastructure. A recent security incident occurred because an operator manually modified firewall rules in the Cloud Console, causing configuration drift.",
        "wg": [
          {
            "t": "配置偏移",
            "en": "configuration drift",
            "ps": "N"
          },
          {
            "t": "手動",
            "en": "manually",
            "ps": "Adv"
          }
        ]
      },
      {
        "t": "您希望自動偵測這類未經授權的手動變更。您應該將哪個步驟整合到 CI/CD 管道中？",
        "en": "You want to automatically detect such unauthorized manual changes. Which step should you integrate into your CI/CD pipeline?",
        "wg": [
          {
            "t": "未經授權的",
            "en": "unauthorized",
            "ps": "Adj"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 定期執行 `terraform init`。",
        "en": "(A) Periodically run `terraform init`.",
        "wg": []
      },
      {
        "t": "(B) 定期執行 `terraform plan` 並檢查是否有變更。",
        "en": "(B) Periodically run `terraform plan` and check for changes.",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud Logging 監控所有 API 呼叫。",
        "en": "(C) Use Cloud Logging to monitor all API calls.",
        "wg": []
      },
      {
        "t": "(D) 強制每小時執行 `terraform destroy` 再重建。",
        "en": "(D) Force `terraform destroy` and rebuild every hour.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "`terraform plan` 會將當前的實際狀態 (Actual State) 與預期的設定檔 (Desired State) 進行比對。如果有人手動修改了資源，`plan` 指令會顯示 Terraform 試圖將資源恢復原狀的計畫，從而偵測到配置偏移 (Drift)。",
      "en": "`terraform plan` compares the current Actual State with the Desired State configuration. If someone manually modified a resource, the `plan` command will show Terraform's intention to revert the resource, thereby detecting configuration drift.",
      "wg": [
        {
          "t": "實際狀態",
          "en": "Actual State",
          "ps": "N"
        },
        {
          "t": "預期的設定檔",
          "en": "Desired State",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "68",
    "level": "medium",
    "keywords": "FinOps, Cost Management, Labeling, Billing",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的組織有多個團隊共享同一個 Google Cloud 專案。財務部門無法區分每個團隊的具體成本。",
        "en": "Your organization has multiple teams sharing the same Google Cloud project. The finance department cannot distinguish specific costs for each team.",
        "wg": [
          {
            "t": "共享",
            "en": "share",
            "ps": "V"
          },
          {
            "t": "區分",
            "en": "distinguish",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您需要建立一個機制來準確分攤成本 (Chargeback)。您應該採取的最佳實踐是什麼？",
        "en": "You need to establish a mechanism for accurate cost chargeback. What is the best practice you should adopt?",
        "wg": [
          {
            "t": "分攤成本",
            "en": "chargeback",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 為每個資源強制套用標籤 (Labels)，例如 `team:marketing`，並將帳單匯出至 BigQuery 進行分析。",
        "en": "(A) Enforce Labels on every resource, such as `team:marketing`, and export billing to BigQuery for analysis.",
        "wg": [
          {
            "t": "標籤",
            "en": "Label",
            "ps": "N"
          },
          {
            "t": "帳單匯出",
            "en": "billing export",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 為每個團隊建立獨立的 VPC。",
        "en": "(B) Create separate VPCs for each team.",
        "wg": []
      },
      {
        "t": "(C) 使用資源名稱 (Resource Names) 來包含團隊代碼。",
        "en": "(C) Use Resource Names to include team codes.",
        "wg": []
      },
      {
        "t": "(D) 將所有資源遷移到單一機器類型以簡化計算。",
        "en": "(D) Migrate all resources to a single machine type to simplify calculation.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "標籤 (Labels) 是 Google Cloud 中追蹤成本歸屬的標準方式。透過在資源上套用鍵值對 (Key-Value) 標籤，並結合 Cloud Billing 的 BigQuery 匯出功能，財務團隊可以透過 SQL 查詢精確計算每個標籤 (即每個團隊) 的消耗。",
      "en": "Labels are the standard way to track cost attribution in Google Cloud. By applying Key-Value labels to resources and combining them with Cloud Billing's BigQuery export, the finance team can precisely calculate consumption for each label (i.e., each team) via SQL queries.",
      "wg": [
        {
          "t": "成本歸屬",
          "en": "cost attribution",
          "ps": "N"
        },
        {
          "t": "鍵值對",
          "en": "Key-Value",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "69",
    "level": "hard",
    "keywords": "Business Continuity, Capacity Planning, Quota Management, Stakeholder",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的電子商務平台即將進行一場大規模的促銷活動，行銷部門預估流量將增長 10 倍。",
        "en": "Your e-commerce platform is about to run a massive promotion, and marketing estimates traffic will grow 10x.",
        "wg": [
          {
            "t": "大規模",
            "en": "massive",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "技術團隊擔心雲端資源配額 (Quota) 不足會導致自動擴充失敗。",
        "en": "The tech team is worried that insufficient cloud resource quotas will cause autoscaling failures.",
        "wg": [
          {
            "t": "資源配額",
            "en": "resource quota",
            "ps": "N"
          },
          {
            "t": "自動擴充失敗",
            "en": "autoscaling failure",
            "ps": "N"
          }
        ]
      },
      {
        "t": "為了確保活動順利進行，您應該採取什麼預防措施？",
        "en": "To ensure the event runs smoothly, what precautionary measure should you take?",
        "wg": [
          {
            "t": "預防措施",
            "en": "precautionary measure",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用 Compute Engine 的「突發」(Burstable) 效能模式。",
        "en": "(A) Enable Compute Engine's \"Burstable\" performance mode.",
        "wg": []
      },
      {
        "t": "(B) 使用 Cloud Console 中的配額頁面檢查目前使用量，並提前提交配額增加請求 (Quota Increase Request)。",
        "en": "(B) Check current usage on the Quotas page in Cloud Console and submit a Quota Increase Request in advance.",
        "wg": [
          {
            "t": "配額增加請求",
            "en": "Quota Increase Request",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 依賴 Google Cloud 的自動配額調整功能。",
        "en": "(C) Rely on Google Cloud's automatic quota adjustment feature.",
        "wg": []
      },
      {
        "t": "(D) 購買承諾使用折扣 (CUD) 來保證資源可用性。",
        "en": "(D) Purchase Committed Use Discounts (CUD) to guarantee resource availability.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "配額 (Quota) 是硬性限制，旨在防止意外超支。對於可預見的大規模流量增長，必須主動檢查各個區域 (Region) 和資源類型 (如 CPU、IP) 的配額，並提前向 Google 支援團隊申請調升，以避免在活動高峰期發生 `429 Resource Exhausted` 錯誤。CUD 僅保證價格折扣，不保證配額上限。",
      "en": "Quotas are hard limits designed to prevent accidental overspending. For foreseeable massive traffic growth, you must proactively check quotas for each region and resource type (e.g., CPU, IP) and request an increase from Google Support in advance to avoid `429 Resource Exhausted` errors during the peak. CUDs only guarantee price discounts, not quota limits.",
      "wg": [
        {
          "t": "硬性限制",
          "en": "hard limit",
          "ps": "N"
        },
        {
          "t": "意外超支",
          "en": "accidental overspending",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "70",
    "level": "medium",
    "keywords": "Programmatic Access, Automation, Cloud Shell, IDE",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的開發團隊希望在不離開瀏覽器的情況下，擁有一個預先設定好開發環境 (包含 gcloud, terraform, docker, kubectl) 的 IDE。",
        "en": "Your development team wants an IDE with a pre-configured development environment (including gcloud, terraform, docker, kubectl) without leaving the browser.",
        "wg": [
          {
            "t": "預先設定好",
            "en": "pre-configured",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "他們需要編寫並測試與 Google Cloud API 互動的 Python 腳本。",
        "en": "They need to write and test Python scripts that interact with Google Cloud APIs.",
        "wg": []
      },
      {
        "t": "您應該推薦哪個工具？",
        "en": "Which tool should you recommend?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Shell Editor",
        "en": "(A) Cloud Shell Editor",
        "wg": []
      },
      {
        "t": "(B) Compute Engine Windows VM",
        "en": "(B) Compute Engine Windows VM",
        "wg": []
      },
      {
        "t": "(C) Cloud Functions 內聯編輯器 (Inline Editor)",
        "en": "(C) Cloud Functions Inline Editor",
        "wg": []
      },
      {
        "t": "(D) 本地安裝 VS Code",
        "en": "(D) Locally installed VS Code",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Cloud Shell Editor 是基於瀏覽器的 IDE (Theia/VS Code 風格)，它運行在一個免費的臨時 VM 上，預裝了所有必要的雲端工具 (gcloud, terraform, docker, python 等)。它提供了即開即用的開發環境，完全符合「不離開瀏覽器」且「預先設定」的需求。",
      "en": "Cloud Shell Editor is a browser-based IDE (Theia/VS Code style) running on a free ephemeral VM, pre-installed with all necessary cloud tools (gcloud, terraform, docker, python, etc.). It provides an out-of-the-box development environment, perfectly meeting the requirements of \"without leaving the browser\" and \"pre-configured\".",
      "wg": [
        {
          "t": "即開即用",
          "en": "out-of-the-box",
          "ps": "Adj"
        },
        {
          "t": "臨時",
          "en": "ephemeral",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "71",
    "level": "hard",
    "keywords": "Migration, Database, Dependency, Move Groups",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的團隊正在規劃將一個關鍵的電子商務系統遷移到 Google Cloud。",
        "en": "Your team is planning to migrate a critical e-commerce system to Google Cloud.",
        "wg": []
      },
      {
        "t": "該系統包含前端 Web 伺服器群、應用程式伺服器和一個大型 Oracle 資料庫。",
        "en": "The system consists of a frontend web server farm, application servers, and a large Oracle database.",
        "wg": [
          {
            "t": "伺服器群",
            "en": "server farm",
            "ps": "N"
          }
        ]
      },
      {
        "t": "應用程式伺服器與資料庫之間有極低的延遲要求。您決定分階段遷移，但必須避免因網路延遲導致效能下降。",
        "en": "There is an extremely low latency requirement between the application servers and the database. You decide to migrate in phases but must avoid performance degradation due to network latency.",
        "wg": [
          {
            "t": "分階段遷移",
            "en": "migrate in phases",
            "ps": "V"
          },
          {
            "t": "效能下降",
            "en": "performance degradation",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該如何定義「遷移分組 (Move Groups)」？",
        "en": "How should you define the \"Move Groups\"?",
        "wg": [
          {
            "t": "遷移分組",
            "en": "Move Group",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將 Web、App 和 DB 伺服器全部放入同一個 Move Group，在同一波次中遷移。",
        "en": "(A) Place Web, App, and DB servers all in the same Move Group and migrate them in the same wave.",
        "wg": []
      },
      {
        "t": "(B) 先遷移 Web 伺服器，觀察一週後再遷移 App 和 DB。",
        "en": "(B) Migrate Web servers first, observe for a week, then migrate App and DB.",
        "wg": []
      },
      {
        "t": "(C) 先遷移資料庫到 Bare Metal Solution，然後再遷移 App 伺服器。",
        "en": "(C) Migrate the database to Bare Metal Solution first, and then migrate App servers.",
        "wg": []
      },
      {
        "t": "(D) 根據 VM 的作業系統類型分組 (Linux 一組，Windows 一組)。",
        "en": "(D) Group based on VM operating system type (Linux in one group, Windows in another).",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "由於 App 伺服器與資料庫之間有「極低延遲」的硬性相依性 (Hard Dependency)，將它們分開遷移 (跨混合雲連線) 會引入顯著的網路延遲，極可能導致應用程式失敗。因此，最佳做法是將具有緊密耦合關係的元件定義為同一個 Move Group，確保它們同時遷移，維持區域內的低延遲通訊。",
      "en": "Because there is a \"strict low latency\" hard dependency between the App servers and the database, separating their migration (across a hybrid cloud connection) would introduce significant network latency, likely causing application failure. Therefore, the best practice is to define tightly coupled components as a single Move Group, ensuring they migrate together to maintain intra-region low-latency communication.",
      "wg": [
        {
          "t": "硬性相依性",
          "en": "hard dependency",
          "ps": "N"
        },
        {
          "t": "緊密耦合",
          "en": "tightly coupled",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "72",
    "level": "medium",
    "keywords": "GenAI, Security, Vertex AI, Private Endpoint",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的金融應用程式需要呼叫 Vertex AI 的 Gemini API 進行即時詐欺偵測。",
        "en": "Your financial application needs to call Vertex AI's Gemini API for real-time fraud detection.",
        "wg": [
          {
            "t": "詐欺偵測",
            "en": "fraud detection",
            "ps": "N"
          }
        ]
      },
      {
        "t": "出於合規要求，所有 API 流量都不得離開 Google 的骨幹網路 (Backbone Network)，且不得暴露於公共網際網路。",
        "en": "Due to compliance requirements, all API traffic must not leave Google's Backbone Network and must not be exposed to the public internet.",
        "wg": [
          {
            "t": "骨幹網路",
            "en": "Backbone Network",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該如何設定網路連線？",
        "en": "How should you configure the network connection?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Private Service Connect (PSC) 建立連線到 Google APIs 的端點。",
        "en": "(A) Use Private Service Connect (PSC) to create an endpoint connecting to Google APIs.",
        "wg": [
          {
            "t": "端點",
            "en": "endpoint",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 設定 Cloud NAT 以允許私有 VM 存取網際網路上的 API。",
        "en": "(B) Configure Cloud NAT to allow private VMs to access APIs on the internet.",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud VPN 連接您的 VPC 與 Google 的管理網路。",
        "en": "(C) Use Cloud VPN to connect your VPC with Google's management network.",
        "wg": []
      },
      {
        "t": "(D) 為 VM 分配外部 IP 並設定防火牆只允許 443 埠。",
        "en": "(D) Assign external IPs to VMs and configure firewalls to allow only port 443.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Private Service Connect (PSC) 允許您在 VPC 內部建立一個私有 IP 端點來存取 Google 全球 API (包括 Vertex AI)。這確保了流量完全保留在 Google 骨幹網路內，符合「不暴露於公共網際網路」的合規要求，且比傳統的 Private Google Access (PGA) 更易於管理路由。",
      "en": "Private Service Connect (PSC) allows you to create a private IP endpoint within your VPC to access Google's global APIs (including Vertex AI). This ensures traffic stays entirely within Google's backbone network, meeting the compliance requirement of \"not exposed to the public internet,\" and is easier to manage routing than traditional Private Google Access (PGA).",
      "wg": [
        {
          "t": "私有 IP 端點",
          "en": "private IP endpoint",
          "ps": "N"
        },
        {
          "t": "易於管理",
          "en": "easy to manage",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "73",
    "level": "medium",
    "keywords": "Business Process, Skill Gap, Transformation, Organizational Change",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在協助一家大型零售商進行數位轉型。",
        "en": "You are assisting a large retailer with their digital transformation.",
        "wg": [
          {
            "t": "數位轉型",
            "en": "digital transformation",
            "ps": "N"
          }
        ]
      },
      {
        "t": "雖然技術架構已經設計完畢，但您發現內部 IT 團隊對雲端技術有強烈的抵觸情緒，擔心失業。",
        "en": "Although the technical architecture is designed, you notice strong resistance from the internal IT team towards cloud technologies, fearing job loss.",
        "wg": [
          {
            "t": "抵觸情緒",
            "en": "resistance",
            "ps": "N"
          },
          {
            "t": "失業",
            "en": "job loss",
            "ps": "N"
          }
        ]
      },
      {
        "t": "這種文化阻礙可能會導致遷移專案失敗。作為架構師，您應該建議管理層採取什麼行動？",
        "en": "This cultural barrier could cause the migration project to fail. As an architect, what action should you recommend to management?",
        "wg": [
          {
            "t": "文化阻礙",
            "en": "cultural barrier",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 解雇現有團隊，聘請有經驗的雲端顧問。",
        "en": "(A) Fire the existing team and hire experienced cloud consultants.",
        "wg": []
      },
      {
        "t": "(B) 忽略團隊的情緒，強制執行新的雲端政策。",
        "en": "(B) Ignore the team's sentiments and enforce new cloud policies.",
        "wg": []
      },
      {
        "t": "(C) 建立雲端卓越中心 (CCoE)，並制定培訓計畫 (Training Plan) 以幫助員工技能轉型。",
        "en": "(C) Establish a Cloud Center of Excellence (CCoE) and develop a Training Plan to help employees upskill.",
        "wg": [
          {
            "t": "雲端卓越中心",
            "en": "Cloud Center of Excellence",
            "ps": "N"
          },
          {
            "t": "技能轉型",
            "en": "upskill",
            "ps": "V"
          }
        ]
      },
      {
        "t": "(D) 暫停遷移專案，直到團隊自己改變心意。",
        "en": "(D) Pause the migration project until the team changes their mind.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "成功的雲端轉型不僅是技術問題，更是人員與流程的問題。建立 CCoE 可以推動最佳實踐，而培訓計畫能消除員工對未知的恐懼，將現有領域知識 (Domain Knowledge) 與新雲端技能結合，這是變革管理 (Change Management) 的核心策略。",
      "en": "Successful cloud transformation is not just technical but also about people and processes. Establishing a CCoE drives best practices, and a training plan alleviates fear of the unknown, combining existing Domain Knowledge with new cloud skills, which is a core strategy of Change Management.",
      "wg": [
        {
          "t": "變革管理",
          "en": "Change Management",
          "ps": "N"
        },
        {
          "t": "領域知識",
          "en": "Domain Knowledge",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "74",
    "level": "medium",
    "keywords": "Programmatic Access, gcloud, Filtering, Automation",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您需要編寫一個自動化腳本來列出所有狀態為 `TERMINATED` 且建立時間超過一年的 Compute Engine 實例。",
        "en": "You need to write an automation script to list all Compute Engine instances with a status of `TERMINATED` that were created more than a year ago.",
        "wg": [
          {
            "t": "自動化腳本",
            "en": "automation script",
            "ps": "N"
          }
        ]
      },
      {
        "t": "為了提高效率並減少客戶端處理負擔，您希望在伺服器端就進行過濾。",
        "en": "To improve efficiency and reduce client-side processing load, you want to perform filtering on the server side.",
        "wg": [
          {
            "t": "客戶端處理負擔",
            "en": "client-side processing load",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該使用 `gcloud` 指令的哪個旗標 (Flag)？",
        "en": "Which flag of the `gcloud` command should you use?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) `--filter`",
        "en": "(A) `--filter`",
        "wg": []
      },
      {
        "t": "(B) `--format`",
        "en": "(B) `--format`",
        "wg": []
      },
      {
        "t": "(C) `--sort-by`",
        "en": "(C) `--sort-by`",
        "wg": []
      },
      {
        "t": "(D) `grep` (透過管道)",
        "en": "(D) `grep` (via pipe)",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "`--filter` 旗標允許您使用表達式在伺服器端篩選資源，只有符合條件的資源才會透過網路回傳。相比之下，`grep` 是在客戶端進行過濾，會浪費頻寬下載所有資源資訊。`--format` 用於改變輸出格式 (如 JSON/YAML)，而非篩選。",
      "en": "The `--filter` flag allows you to use expressions to filter resources on the server side; only matching resources are returned over the network. In contrast, `grep` filters on the client side, wasting bandwidth downloading all resource information. `--format` is used to change output format (like JSON/YAML), not for filtering.",
      "wg": [
        {
          "t": "伺服器端",
          "en": "server side",
          "ps": "N"
        },
        {
          "t": "篩選",
          "en": "filter",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "75",
    "level": "hard",
    "keywords": "Compliance, Assured Workloads, Encryption, Key Access Justification",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的客戶是美國政府機構，要求您的解決方案必須符合 FedRAMP High 合規標準。",
        "en": "Your client is a US government agency requiring your solution to comply with FedRAMP High compliance standards.",
        "wg": [
          {
            "t": "合規標準",
            "en": "compliance standard",
            "ps": "N"
          }
        ]
      },
      {
        "t": "除了資料駐留之外，他們還要求即使是 Google 的支援人員，在沒有明確理由和批准的情況下，也絕對無法解密客戶資料。",
        "en": "Beyond data residency, they also require that even Google support personnel cannot decrypt customer data without explicit justification and approval.",
        "wg": [
          {
            "t": "明確理由",
            "en": "explicit justification",
            "ps": "N"
          },
          {
            "t": "解密",
            "en": "decrypt",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該結合哪兩項服務來滿足此極高安全需求？",
        "en": "Which two services should you combine to meet this ultra-high security requirement?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Assured Workloads 與 Key Access Justifications (KAJ)。",
        "en": "(A) Assured Workloads and Key Access Justifications (KAJ).",
        "wg": [
          {
            "t": "金鑰存取理由",
            "en": "Key Access Justification",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) VPC Service Controls 與 Cloud Armor。",
        "en": "(B) VPC Service Controls and Cloud Armor.",
        "wg": []
      },
      {
        "t": "(C) Confidential Computing 與 Cloud NAT。",
        "en": "(C) Confidential Computing and Cloud NAT.",
        "wg": []
      },
      {
        "t": "(D) Identity-Aware Proxy 與 Cloud HSM。",
        "en": "(D) Identity-Aware Proxy and Cloud HSM.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Assured Workloads 提供一個合規的環境設定 (如 FedRAMP)。KAJ 則與外部金鑰管理器 (External Key Manager, EKM) 配合使用，當 Google 系統需要解密資料時 (例如進行支援)，必須附上理由並獲得客戶 EKM 的批准。這提供了針對雲端供應商的最終級別資料存取控制。",
      "en": "Assured Workloads provides a compliant environment configuration (e.g., FedRAMP). KAJ works with an External Key Manager (EKM); when Google systems need to decrypt data (e.g., for support), they must provide a justification and receive approval from the client's EKM. This offers the ultimate level of data access control against the cloud provider.",
      "wg": [
        {
          "t": "外部金鑰管理器",
          "en": "External Key Manager",
          "ps": "N"
        },
        {
          "t": "最終級別",
          "en": "ultimate level",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "76",
    "level": "medium",
    "keywords": "GenAI, Architecture, Vector Search, Embeddings",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在構建一個「以圖搜圖」的應用程式，使用者上傳一張圖片，系統回傳資料庫中相似的圖片。",
        "en": "You are building an \"image-to-image search\" application where a user uploads an image, and the system returns similar images from the database.",
        "wg": [
          {
            "t": "以圖搜圖",
            "en": "image-to-image search",
            "ps": "N"
          },
          {
            "t": "相似的",
            "en": "similar",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您計畫使用 Vertex AI 的多模態嵌入模型 (Multimodal Embeddings) 來將圖片轉換為向量。",
        "en": "You plan to use Vertex AI's Multimodal Embeddings model to convert images into vectors.",
        "wg": [
          {
            "t": "多模態嵌入",
            "en": "Multimodal Embeddings",
            "ps": "N"
          },
          {
            "t": "向量",
            "en": "vector",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該使用哪項服務來儲存這些向量並執行高效的相似度搜尋？",
        "en": "Which service should you use to store these vectors and perform efficient similarity search?",
        "wg": [
          {
            "t": "相似度搜尋",
            "en": "similarity search",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) BigQuery (標準 SQL 查詢)。",
        "en": "(A) BigQuery (Standard SQL queries).",
        "wg": []
      },
      {
        "t": "(B) Vertex AI Vector Search。",
        "en": "(B) Vertex AI Vector Search.",
        "wg": []
      },
      {
        "t": "(C) Cloud Storage。",
        "en": "(C) Cloud Storage.",
        "wg": []
      },
      {
        "t": "(D) Firestore (原生索引)。",
        "en": "(D) Firestore (Native indexing).",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Vertex AI Vector Search (前身為 Matching Engine) 是專為大規模、低延遲的向量相似度搜尋設計的託管服務。它可以處理數十億個向量，並在毫秒級回傳最相似的結果，是實作語意搜尋或推薦系統的理想後端。",
      "en": "Vertex AI Vector Search (formerly Matching Engine) is a managed service designed for large-scale, low-latency vector similarity search. It can handle billions of vectors and return the most similar results in milliseconds, making it the ideal backend for semantic search or recommendation systems.",
      "wg": [
        {
          "t": "語意搜尋",
          "en": "semantic search",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "77",
    "level": "medium",
    "keywords": "Migration, 6 Rs, Strategy, Legacy",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的公司有一個執行在過時 mainframe 上的 COBOL 應用程式，維護成本極高且無人懂程式碼。",
        "en": "Your company has a COBOL application running on an obsolete mainframe. Maintenance costs are extremely high, and no one understands the code.",
        "wg": [
          {
            "t": "過時",
            "en": "obsolete",
            "ps": "Adj"
          },
          {
            "t": "維護成本",
            "en": "maintenance cost",
            "ps": "N"
          }
        ]
      },
      {
        "t": "該應用程式的功能非常簡單，是一個員工休假審批系統。您希望一勞永逸地解決這個技術債。",
        "en": "The application's functionality is very simple; it is an employee leave approval system. You want to resolve this technical debt once and for all.",
        "wg": [
          {
            "t": "技術債",
            "en": "technical debt",
            "ps": "N"
          },
          {
            "t": "一勞永逸",
            "en": "once and for all",
            "ps": "Adv"
          }
        ]
      },
      {
        "t": "根據遷移的「6 R」策略，您應該採取哪種方法？",
        "en": "According to the \"6 Rs\" of migration strategy, which approach should you take?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Rehost (重新託管)：使用 Mainframe 模擬器在 Compute Engine 上執行。",
        "en": "(A) Rehost: Run on Compute Engine using a Mainframe emulator.",
        "wg": []
      },
      {
        "t": "(B) Refactor (重構)：聘請專家將 COBOL 重寫為 Java 微服務。",
        "en": "(B) Refactor: Hire experts to rewrite COBOL into Java microservices.",
        "wg": []
      },
      {
        "t": "(C) Retire (退役) 或 Repurchase (重新採購)：使用現成的 SaaS 解決方案 (如 Workday) 取代它。",
        "en": "(C) Retire or Repurchase: Replace it with an off-the-shelf SaaS solution (like Workday).",
        "wg": [
          {
            "t": "現成的",
            "en": "off-the-shelf",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "(D) Retain (保留)：保持原樣，不做任何變動。",
        "en": "(D) Retain: Keep it as is without any changes.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "對於功能通用 (Commodity) 且非核心競爭力 (Non-core) 的舊系統，如果維護成本高於價值，最佳策略通常是「重新採購 (Repurchase)」(轉向 SaaS) 或「退役 (Retire)」(如果不再需要)。重構 COBOL 風險高且昂貴，重新託管則無法解決沒人懂代碼的問題。",
      "en": "For legacy systems that are commodity and non-core, if maintenance costs exceed value, the best strategy is usually \"Repurchase\" (move to SaaS) or \"Retire\" (if no longer needed). Refactoring COBOL is high-risk and expensive, and Rehosting doesn't solve the problem of no one understanding the code.",
      "wg": [
        {
          "t": "核心競爭力",
          "en": "core competency",
          "ps": "N"
        },
        {
          "t": "通用",
          "en": "commodity",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "78",
    "level": "medium",
    "keywords": "Automation, Cloud Code, IDE, Debugging",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "開發人員正在使用 VS Code 開發一個 Kubernetes 應用程式，並希望能夠在 IDE 中直接部署到 GKE 開發叢集進行測試。",
        "en": "Developers are building a Kubernetes application using VS Code and want to deploy directly to a GKE development cluster for testing within the IDE.",
        "wg": []
      },
      {
        "t": "他們也希望能夠在 IDE 內串流查看 Pod 的日誌並進行互動式除錯。",
        "en": "They also want to stream Pod logs and perform interactive debugging within the IDE.",
        "wg": [
          {
            "t": "互動式除錯",
            "en": "interactive debugging",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該推薦他們安裝哪個擴充功能？",
        "en": "Which extension should you recommend they install?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Code",
        "en": "(A) Cloud Code",
        "wg": []
      },
      {
        "t": "(B) Terraform",
        "en": "(B) Terraform",
        "wg": []
      },
      {
        "t": "(C) Docker",
        "en": "(C) Docker",
        "wg": []
      },
      {
        "t": "(D) Google Cloud SDK",
        "en": "(D) Google Cloud SDK",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Cloud Code 是 Google 官方提供的 IDE 擴充功能 (支援 VS Code 和 IntelliJ)。它整合了 Skaffold，允許開發人員一鍵部署到 GKE/Cloud Run，並支援直接在 IDE 內進行日誌串流、連接埠轉發 (Port-forwarding) 和除錯，大幅提升雲端原生開發的體驗。",
      "en": "Cloud Code is an official IDE extension from Google (supporting VS Code and IntelliJ). It integrates Skaffold, allowing developers to deploy to GKE/Cloud Run with one click, and supports log streaming, port-forwarding, and debugging directly within the IDE, significantly enhancing the cloud-native development experience.",
      "wg": [
        {
          "t": "連接埠轉發",
          "en": "Port-forwarding",
          "ps": "N"
        },
        {
          "t": "一鍵部署",
          "en": "one-click deploy",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "79",
    "level": "medium",
    "keywords": "SRE, Reliability, Error Budget, Decision Making",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的產品團隊希望本週發布三個新功能，但根據 Monitoring 儀表板，該服務本季度的錯誤預算 (Error Budget) 已經耗盡。",
        "en": "Your product team wants to release three new features this week, but according to the Monitoring dashboard, the service's Error Budget for this quarter is exhausted.",
        "wg": [
          {
            "t": "錯誤預算",
            "en": "Error Budget",
            "ps": "N"
          },
          {
            "t": "耗盡",
            "en": "exhausted",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "根據 SRE 原則，您應該做出什麼決定？",
        "en": "According to SRE principles, what decision should you make?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 批准發布，因為業務功能優先於可靠性。",
        "en": "(A) Approve the release, as business features take precedence over reliability.",
        "wg": []
      },
      {
        "t": "(B) 暫停所有非緊急的功能發布，專注於修復可靠性問題，直到預算恢復。",
        "en": "(B) Halt all non-emergency feature releases and focus on fixing reliability issues until the budget recovers.",
        "wg": [
          {
            "t": "非緊急",
            "en": "non-emergency",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "(C) 修改 SLO 目標，將其調低以獲得更多預算。",
        "en": "(C) Modify the SLO target, lowering it to gain more budget.",
        "wg": []
      },
      {
        "t": "(D) 僅發布其中一個功能，看看會發生什麼。",
        "en": "(D) Release only one of the features and see what happens.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "錯誤預算是開發速度與可靠性之間的平衡機制。當預算耗盡時，意味著系統穩定性已低於目標，此時 SRE 的標準做法是「凍結發布 (Freeze Releases)」，將工程資源轉向改善系統穩定性，直到服務表現回到 SLO 範圍內。",
      "en": "Error Budget is a balancing mechanism between velocity and reliability. When the budget is exhausted, it means system stability has fallen below the target. The standard SRE practice is to \"Freeze Releases\" and pivot engineering resources to improve system stability until service performance returns within SLO limits.",
      "wg": [
        {
          "t": "平衡機制",
          "en": "balancing mechanism",
          "ps": "N"
        },
        {
          "t": "凍結發布",
          "en": "Freeze Release",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "80",
    "level": "hard",
    "keywords": "Architecture, Global, Multiregion, Spanner",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在設計一個全球票務系統，使用者遍布亞洲、歐洲和美洲。",
        "en": "You are designing a global ticketing system with users in Asia, Europe, and the Americas.",
        "wg": [
          {
            "t": "票務系統",
            "en": "ticketing system",
            "ps": "N"
          }
        ]
      },
      {
        "t": "系統必須保證絕對的資料一致性 (不能超賣)，同時為全球使用者提供低延遲的讀寫存取，並且能容忍單一地區 (Region) 的完全故障。",
        "en": "The system must guarantee absolute data consistency (no overselling), provide low-latency read/write access for global users, and tolerate a complete single Region failure.",
        "wg": [
          {
            "t": "絕對的",
            "en": "absolute",
            "ps": "Adj"
          },
          {
            "t": "超賣",
            "en": "overselling",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該選擇哪種資料庫設定？",
        "en": "Which database configuration should you choose?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud SQL for PostgreSQL 搭配跨地區唯讀複本 (Read Replicas)。",
        "en": "(A) Cloud SQL for PostgreSQL with cross-region Read Replicas.",
        "wg": []
      },
      {
        "t": "(B) Cloud Spanner 搭配多地區 (Multi-region) 配置。",
        "en": "(B) Cloud Spanner with Multi-region configuration.",
        "wg": []
      },
      {
        "t": "(C) Firestore 處於多地區模式。",
        "en": "(C) Firestore in Multi-region mode.",
        "wg": []
      },
      {
        "t": "(D) Bigtable 搭配多叢集路由。",
        "en": "(D) Bigtable with multi-cluster routing.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Cloud Spanner 是唯一能提供全域強一致性 (Global Strong Consistency) 的關聯式資料庫。多地區配置提供 99.999% 的可用性，可容忍地區級故障。雖然 Firestore 也是多地區，但在全球強一致性和關聯式查詢能力上不如 Spanner 適合票務系統 (防止超賣)。Cloud SQL 的跨區複本是最終一致性，不適合此場景。",
      "en": "Cloud Spanner is the only relational database offering Global Strong Consistency. Multi-region configuration provides 99.999% availability and tolerates region-level failures. While Firestore is also multi-region, it lacks the global strong consistency and relational query capabilities of Spanner suitable for a ticketing system (preventing overselling). Cloud SQL cross-region replicas are eventually consistent and unsuitable for this scenario.",
      "wg": [
        {
          "t": "全域強一致性",
          "en": "Global Strong Consistency",
          "ps": "N"
        },
        {
          "t": "最終一致性",
          "en": "eventual consistency",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "81",
    "level": "hard",
    "keywords": "Security, Supply Chain, Binary Authorization, Attestation",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的公司受到一項嚴格的軟體供應鏈安全政策規範。",
        "en": "Your company is subject to a strict software supply chain security policy.",
        "wg": [
          {
            "t": "供應鏈安全",
            "en": "supply chain security",
            "ps": "N"
          }
        ]
      },
      {
        "t": "只有通過品質保證 (QA) 團隊測試並由資安團隊審核過的容器映像檔，才被允許部署到生產環境的 GKE 叢集。",
        "en": "Only container images that have been tested by the Quality Assurance (QA) team and audited by the Security team are allowed to be deployed to the production GKE cluster.",
        "wg": [
          {
            "t": "品質保證",
            "en": "Quality Assurance",
            "ps": "N"
          },
          {
            "t": "審核",
            "en": "audit",
            "ps": "V"
          }
        ]
      },
      {
        "t": "這兩個團隊各自擁有獨立的私鑰來簽署映像檔。您應該如何強制執行此雙重簽署要求？",
        "en": "Both teams possess independent private keys to sign images. How should you enforce this dual-signing requirement?",
        "wg": [
          {
            "t": "私鑰",
            "en": "private key",
            "ps": "N"
          },
          {
            "t": "雙重簽署",
            "en": "dual-signing",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 設定 Binary Authorization 政策，要求兩個不同的證明者 (Attestors) 同時驗證。",
        "en": "(A) Configure a Binary Authorization policy requiring validation from two different Attestors simultaneously.",
        "wg": [
          {
            "t": "證明者",
            "en": "Attestor",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 在 CI/CD 管道中使用腳本檢查映像檔雜湊值 (Hash)。",
        "en": "(B) Use a script in the CI/CD pipeline to check image Hashes.",
        "wg": []
      },
      {
        "t": "(C) 使用 VPC Service Controls 限制 GKE 只能從特定的 Artifact Registry 下載。",
        "en": "(C) Use VPC Service Controls to restrict GKE to download only from a specific Artifact Registry.",
        "wg": []
      },
      {
        "t": "(D) 僅授予 QA 和資安團隊 `container.deployments.create` 權限。",
        "en": "(D) Only grant the `container.deployments.create` permission to QA and Security teams.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Binary Authorization 支援「多重證明者 (Multi-Attestor)」模式。您可以定義一個政策，明確要求映像檔必須同時具備「QA 證明」和「資安證明」這兩個獨立的數位簽章 (Attestations) 才能被 GKE 准入控制器 (Admission Controller) 放行。這是強制執行職責分離與供應鏈合規的標準做法。",
      "en": "Binary Authorization supports a \"Multi-Attestor\" mode. You can define a policy explicitly requiring an image to have both \"QA Attestation\" and \"Security Attestation\" independent digital signatures before being admitted by the GKE Admission Controller. This is the standard practice for enforcing separation of duties and supply chain compliance.",
      "wg": [
        {
          "t": "准入控制器",
          "en": "Admission Controller",
          "ps": "N"
        },
        {
          "t": "職責分離",
          "en": "separation of duties",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "82",
    "level": "medium",
    "keywords": "Data Security, DLP, BigQuery, De-identification",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的行銷團隊希望分析儲存在 BigQuery 中的客戶資料以改進廣告投放。",
        "en": "Your marketing team wants to analyze customer data stored in BigQuery to improve ad targeting.",
        "wg": [
          {
            "t": "廣告投放",
            "en": "ad targeting",
            "ps": "N"
          }
        ]
      },
      {
        "t": "然而，該資料表包含敏感的 PII (如電子郵件地址)。資安政策禁止行銷分析師直接查看原始 PII，但允許他們使用這些欄位進行 `JOIN` 操作。",
        "en": "However, the table contains sensitive PII (like email addresses). Security policy prohibits marketing analysts from viewing raw PII but allows them to use these fields for `JOIN` operations.",
        "wg": [
          {
            "t": "原始",
            "en": "raw",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您應該使用哪種去識別化 (De-identification) 技術？",
        "en": "Which de-identification technology should you use?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 遮罩 (Masking)：將所有字元替換為 `*`。",
        "en": "(A) Masking: Replace all characters with `*`.",
        "wg": [
          {
            "t": "遮罩",
            "en": "Masking",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 確定性加密 (Deterministic Encryption) 或雜湊 (Hashing)。",
        "en": "(B) Deterministic Encryption or Hashing.",
        "wg": [
          {
            "t": "確定性加密",
            "en": "Deterministic Encryption",
            "ps": "N"
          },
          {
            "t": "雜湊",
            "en": "Hashing",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 隨機替換 (Random Replacement)。",
        "en": "(C) Random Replacement.",
        "wg": []
      },
      {
        "t": "(D) 刪除該欄位 (Dropping)。",
        "en": "(D) Dropping the column.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "為了支援 `JOIN` 操作，相同的原始值 (如 `user@example.com`) 必須始終轉換為相同的去識別化值 (如 `Hash123`)。確定性加密或雜湊能保留參照完整性 (Referential Integrity)，同時隱藏原始資訊，滿足「不可見但可關聯」的需求。",
      "en": "To support `JOIN` operations, the same raw value (e.g., `user@example.com`) must always transform into the same de-identified value (e.g., `Hash123`). Deterministic encryption or hashing preserves referential integrity while hiding original information, meeting the \"invisible but linkable\" requirement.",
      "wg": [
        {
          "t": "參照完整性",
          "en": "Referential Integrity",
          "ps": "N"
        },
        {
          "t": "可關聯",
          "en": "linkable",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "83",
    "level": "medium",
    "keywords": "Networking, Cloud DNS, Hybrid, Forwarding",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的應用程式部署在 Google Cloud VPC 中，需要能夠解析位於本地資料中心 (On-premises) 的內部主機名稱 (如 `db.corp.local`)。",
        "en": "Your application deployed in a Google Cloud VPC needs to resolve internal hostnames located in an on-premises data center (e.g., `db.corp.local`).",
        "wg": [
          {
            "t": "解析",
            "en": "resolve",
            "ps": "V"
          },
          {
            "t": "內部主機名稱",
            "en": "internal hostname",
            "ps": "N"
          }
        ]
      },
      {
        "t": "本地網路與 VPC 之間已透過 Cloud VPN 連接。您應該如何設定 DNS？",
        "en": "The on-premises network and VPC are connected via Cloud VPN. How should you configure DNS?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在每台 VM 的 `/etc/hosts` 檔案中新增項目。",
        "en": "(A) Add entries to the `/etc/hosts` file on every VM.",
        "wg": []
      },
      {
        "t": "(B) 設定 Cloud DNS 轉發區域 (Forwarding Zone)，將 `corp.local` 的查詢導向本地 DNS 伺服器的 IP。",
        "en": "(B) Configure a Cloud DNS Forwarding Zone to direct queries for `corp.local` to the IP of the on-premises DNS server.",
        "wg": [
          {
            "t": "轉發區域",
            "en": "Forwarding Zone",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 建立一個私有區域 (Private Zone) 並手動複製所有本地記錄。",
        "en": "(C) Create a Private Zone and manually copy all on-premises records.",
        "wg": []
      },
      {
        "t": "(D) 使用 Google 公共 DNS (8.8.8.8)。",
        "en": "(D) Use Google Public DNS (8.8.8.8).",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Cloud DNS 轉發區域允許您將特定網域 (如 `corp.local`) 的 DNS 查詢轉發到替代的名稱伺服器 (在此例中為通過 VPN 連接的本地 DNS)。這是實現混合雲 DNS 解析的標準且可擴展的解決方案，無需維護分散的 hosts 檔案或重複的記錄。",
      "en": "Cloud DNS Forwarding Zones allow you to forward DNS queries for specific domains (like `corp.local`) to alternative name servers (in this case, the on-premises DNS connected via VPN). This is the standard and scalable solution for hybrid cloud DNS resolution, eliminating the need to maintain scattered hosts files or duplicate records.",
      "wg": [
        {
          "t": "可擴展的",
          "en": "scalable",
          "ps": "Adj"
        },
        {
          "t": "分散的",
          "en": "scattered",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "84",
    "level": "hard",
    "keywords": "GKE, Security, Workload Identity, IAM",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您在 GKE 叢集中執行多個微服務，其中 `Service-A` 需要讀取 Cloud Storage，而 `Service-B` 需要寫入 BigQuery。",
        "en": "You are running multiple microservices in a GKE cluster, where `Service-A` needs to read from Cloud Storage and `Service-B` needs to write to BigQuery.",
        "wg": []
      },
      {
        "t": "為了遵循最小權限原則，您不希望使用節點服務帳號 (Node Service Account)，因為那會讓該節點上的所有 Pod 共享相同權限。",
        "en": "To follow the principle of least privilege, you do not want to use the Node Service Account, as that would share the same permissions across all Pods on that node.",
        "wg": [
          {
            "t": "節點服務帳號",
            "en": "Node Service Account",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該實作哪項功能？",
        "en": "Which feature should you implement?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將服務帳號金鑰 (JSON) 掛載為 Kubernetes Secret。",
        "en": "(A) Mount Service Account keys (JSON) as Kubernetes Secrets.",
        "wg": []
      },
      {
        "t": "(B) 使用 Workload Identity。",
        "en": "(B) Use Workload Identity.",
        "wg": []
      },
      {
        "t": "(C) 為每個服務建立單獨的節點池 (Node Pool) 並指派不同的服務帳號。",
        "en": "(C) Create separate Node Pools for each service and assign different Service Accounts.",
        "wg": []
      },
      {
        "t": "(D) 在應用程式代碼中寫死 (Hardcode) 憑證。",
        "en": "(D) Hardcode credentials in the application code.",
        "wg": [
          {
            "t": "寫死",
            "en": "Hardcode",
            "ps": "V"
          }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Workload Identity 是 GKE 上推薦的驗證方式。它允許將 Kubernetes Service Account (KSA) 與 Google Service Account (GSA) 綁定。這樣，Pod 可以直接以 GSA 的身分驗證並獲取細緻的 IAM 權限，無需管理金鑰檔案，也避免了節點級別權限過寬的問題。",
      "en": "Workload Identity is the recommended authentication method on GKE. It allows binding a Kubernetes Service Account (KSA) to a Google Service Account (GSA). This way, Pods can authenticate directly as the GSA and access granular IAM permissions without managing key files, avoiding the issue of overly broad node-level permissions.",
      "wg": [
        {
          "t": "綁定",
          "en": "bind",
          "ps": "V"
        },
        {
          "t": "過寬的",
          "en": "overly broad",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "85",
    "level": "medium",
    "keywords": "Serverless, Cloud Run, EventArc, Audit Logs",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您希望每當有人在專案中建立了新的 Compute Engine VM 時，自動觸發一個 Cloud Run 服務來檢查該 VM 是否符合公司標籤規範。",
        "en": "You want to automatically trigger a Cloud Run service to check if a Compute Engine VM complies with corporate tagging standards whenever a new VM is created in the project.",
        "wg": [
          {
            "t": "標籤規範",
            "en": "tagging standard",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該如何以最少的程式碼和維運工作來實現此架構？",
        "en": "How should you implement this architecture with minimal code and operational effort?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud Scheduler 定期輪詢 API。",
        "en": "(A) Use Cloud Scheduler to periodically poll the API.",
        "wg": [
          {
            "t": "輪詢",
            "en": "poll",
            "ps": "V"
          }
        ]
      },
      {
        "t": "(B) 設定 Eventarc 觸發器，監聽 Cloud Audit Logs 中的 `google.compute.instances.insert` 事件。",
        "en": "(B) Configure an Eventarc trigger to listen for `google.compute.instances.insert` events in Cloud Audit Logs.",
        "wg": []
      },
      {
        "t": "(C) 在每個 VM 啟動腳本中加入 `curl` 指令呼叫 Cloud Run。",
        "en": "(C) Add a `curl` command to call Cloud Run in every VM startup script.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud Functions 監控 VPC Flow Logs。",
        "en": "(D) Use Cloud Functions to monitor VPC Flow Logs.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Eventarc 提供了與 Cloud Audit Logs 的原生整合。當資源建立時 (如 `instances.insert`)，Audit Logs 會產生一個事件，Eventarc 可以捕捉該事件並直接推送給 Cloud Run。這是一個完全受管的事件驅動架構，無需編寫輪詢邏輯或修改 VM 內部設定。",
      "en": "Eventarc provides native integration with Cloud Audit Logs. When a resource is created (e.g., `instances.insert`), Audit Logs generates an event which Eventarc can capture and push directly to Cloud Run. This is a fully managed event-driven architecture, eliminating the need for polling logic or modifying VM internal configurations.",
      "wg": [
        {
          "t": "捕捉",
          "en": "capture",
          "ps": "V"
        },
        {
          "t": "原生整合",
          "en": "native integration",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "86",
    "level": "medium",
    "keywords": "Networking, Load Balancing, Serverless NEG, Cloud Run",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您在不同的 Google Cloud 地區 (Region) 部署了多個 Cloud Run 服務。",
        "en": "You have deployed multiple Cloud Run services across different Google Cloud regions.",
        "wg": []
      },
      {
        "t": "您希望使用單一全域 IP 位址作為入口，並根據使用者的地理位置將流量導向最近的服務實例。",
        "en": "You want to use a single global IP address as the entry point and route traffic to the nearest service instance based on the user's geographic location.",
        "wg": [
          {
            "t": "單一全域 IP",
            "en": "single global IP",
            "ps": "N"
          },
          {
            "t": "地理位置",
            "en": "geographic location",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該設定哪個負載平衡器元件？",
        "en": "Which load balancer component should you configure?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 全球外部應用程式負載平衡器搭配無伺服器網路端點群組 (Serverless NEG)。",
        "en": "(A) Global External Application Load Balancer with Serverless Network Endpoint Groups (NEGs).",
        "wg": [
          {
            "t": "無伺服器網路端點群組",
            "en": "Serverless Network Endpoint Group",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 區域性外部應用程式負載平衡器。",
        "en": "(B) Regional External Application Load Balancer.",
        "wg": []
      },
      {
        "t": "(C) TCP Proxy 負載平衡器搭配 Instance Groups。",
        "en": "(C) TCP Proxy Load Balancer with Instance Groups.",
        "wg": []
      },
      {
        "t": "(D) Cloud DNS 地理位置路由策略。",
        "en": "(D) Cloud DNS geolocation routing policy.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Serverless NEG 允許 Cloud Run 服務成為負載平衡器的後端。結合全球外部應用程式負載平衡器 (Global External ALB)，您可以獲得 Anycast IP，並利用其內建的全球路由能力，將流量自動導向離使用者最近且有部署該服務的地區，實現低延遲與高可用性。",
      "en": "Serverless NEGs allow Cloud Run services to act as backends for load balancers. Combined with a Global External ALB, you get an Anycast IP and leverage its built-in global routing capabilities to automatically direct traffic to the region closest to the user where the service is deployed, achieving low latency and high availability.",
      "wg": [
        {
          "t": "內建的",
          "en": "built-in",
          "ps": "Adj"
        },
        {
          "t": "路由能力",
          "en": "routing capability",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "87",
    "level": "medium",
    "keywords": "Operations, Cloud Operations, Monitoring, Dashboard",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的營運團隊需要一個統一的視圖來監控 Google Cloud 資源與 AWS 資源的健康狀態。",
        "en": "Your operations team needs a unified view to monitor the health of both Google Cloud resources and AWS resources.",
        "wg": [
          {
            "t": "統一的視圖",
            "en": "unified view",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您不希望安裝和維護第三方的監控工具。",
        "en": "You do not want to install and maintain third-party monitoring tools.",
        "wg": []
      },
      {
        "t": "您應該如何設定 Google Cloud Operations (前身為 Stackdriver)？",
        "en": "How should you configure Google Cloud Operations (formerly Stackdriver)?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 AWS EC2 上安裝 Ops Agent，並授權其將指標傳送至 Google Cloud 專案。",
        "en": "(A) Install the Ops Agent on AWS EC2 and authorize it to send metrics to the Google Cloud project.",
        "wg": [
          {
            "t": "授權",
            "en": "authorize",
            "ps": "V"
          },
          {
            "t": "指標",
            "en": "metrics",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 使用 AWS CloudWatch 匯出功能將數據傳送到 BigQuery。",
        "en": "(B) Use AWS CloudWatch export to send data to BigQuery.",
        "wg": []
      },
      {
        "t": "(C) 建立 VPN 連接並使用 SNMP 輪詢。",
        "en": "(C) Establish a VPN connection and use SNMP polling.",
        "wg": []
      },
      {
        "t": "(D) Google Cloud Operations 僅支援 Google Cloud 資源，無法達成。",
        "en": "(D) Google Cloud Operations only supports Google Cloud resources and cannot achieve this.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Google Cloud Operations (Monitoring) 支援多雲監控。透過在 AWS EC2 實例上安裝 Google Cloud Ops Agent (或以前的 Stackdriver Agent)，您可以將 AWS 的系統指標與日誌串流到 Google Cloud，並在同一個 Dashboard 中統一檢視與設定警報。",
      "en": "Google Cloud Operations (Monitoring) supports multi-cloud monitoring. By installing the Google Cloud Ops Agent (or formerly Stackdriver Agent) on AWS EC2 instances, you can stream AWS system metrics and logs to Google Cloud, enabling unified viewing and alerting within the same Dashboard.",
      "wg": [
        {
          "t": "多雲監控",
          "en": "multi-cloud monitoring",
          "ps": "N"
        },
        {
          "t": "串流",
          "en": "stream",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "88",
    "level": "hard",
    "keywords": "Case Study, EHR Healthcare, Bigtable, Time-series",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 EHR Healthcare 個案研究。該公司需要儲存來自數百萬個穿戴式裝置的連續健康監測數據 (心率、血壓等)。",
        "en": "Refer to the EHR Healthcare case study. The company needs to store continuous health monitoring data (heart rate, blood pressure, etc.) from millions of wearable devices.",
        "wg": [
          {
            "t": "穿戴式裝置",
            "en": "wearable device",
            "ps": "N"
          },
          {
            "t": "連續健康監測數據",
            "en": "continuous health monitoring data",
            "ps": "N"
          }
        ]
      },
      {
        "t": "數據寫入量極大 (每秒數十萬次寫入)，且分析師需要能快速查詢特定時間範圍內的趨勢。",
        "en": "The write volume is extremely high (hundreds of thousands of writes per second), and analysts need to quickly query trends within specific time ranges.",
        "wg": [
          {
            "t": "每秒數十萬次寫入",
            "en": "hundreds of thousands of writes per second",
            "ps": "N"
          },
          {
            "t": "時間範圍",
            "en": "time range",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該推薦哪種資料庫服務？",
        "en": "Which database service should you recommend?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud SQL",
        "en": "(A) Cloud SQL",
        "wg": []
      },
      {
        "t": "(B) Bigtable",
        "en": "(B) Bigtable",
        "wg": []
      },
      {
        "t": "(C) Firestore",
        "en": "(C) Firestore",
        "wg": []
      },
      {
        "t": "(D) Cloud Storage",
        "en": "(D) Cloud Storage",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Bigtable 是 Google 的 NoSQL 寬列存儲 (Wide-column store)，專為高吞吐量 (Throughput) 和大規模分析設計。它非常適合時間序列數據 (Time-series data) 與物聯網 (IoT) 應用場景，能夠輕鬆處理每秒數百萬次的寫入，且延遲極低 (毫秒級)。",
      "en": "Bigtable is Google's NoSQL wide-column store designed for high throughput and large-scale analytics. It is ideally suited for Time-series data and IoT scenarios, capable of easily handling millions of writes per second with extremely low (millisecond) latency.",
      "wg": [
        {
          "t": "寬列存儲",
          "en": "Wide-column store",
          "ps": "N"
        },
        {
          "t": "高吞吐量",
          "en": "high throughput",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "89",
    "level": "medium",
    "keywords": "Case Study, Cymbal Retail, Cloud Armor, Security Policy",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Cymbal Retail 個案研究。在黑色星期五促銷期間，Cymbal Retail 的網站遭受了來自特定國家的惡意 DDoS 攻擊。",
        "en": "Refer to the Cymbal Retail case study. During the Black Friday promotion, Cymbal Retail's website suffered a malicious DDoS attack originating from specific countries.",
        "wg": [
          {
            "t": "惡意",
            "en": "malicious",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您需要立即阻擋來自這些地理位置的流量，但不能影響其他合法使用者。",
        "en": "You need to immediately block traffic from these geographic locations without affecting other legitimate users.",
        "wg": [
          {
            "t": "阻擋",
            "en": "block",
            "ps": "V"
          },
          {
            "t": "合法使用者",
            "en": "legitimate user",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該在 Cloud Armor 中設定什麼？",
        "en": "What should you configure in Cloud Armor?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 建立安全政策，使用基於地理位置 (Geo-based) 的規則拒絕特定區域代碼。",
        "en": "(A) Create a security policy using Geo-based rules to deny specific region codes.",
        "wg": [
          {
            "t": "基於地理位置",
            "en": "Geo-based",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "(B) 啟用自適應保護 (Adaptive Protection) 並等待其學習。",
        "en": "(B) Enable Adaptive Protection and wait for it to learn.",
        "wg": [
          {
            "t": "自適應保護",
            "en": "Adaptive Protection",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 限制每秒請求數 (Rate Limiting)。",
        "en": "(C) Limit requests per second (Rate Limiting).",
        "wg": []
      },
      {
        "t": "(D) 封鎖所有 UDP 流量。",
        "en": "(D) Block all UDP traffic.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Cloud Armor 支援豐富的規則語言，包括基於來源地理位置的過濾。在遭受特定區域的 DDoS 攻擊時，最快且最精確的緩解措施是明確拒絕來自該國 ISO 國碼的流量 (例如 `origin.region_code == 'XX'`)，這能立即生效且不影響其他地區的正常流量。",
      "en": "Cloud Armor supports a rich rule language, including filtering based on source geography. When under a region-specific DDoS attack, the fastest and most precise mitigation is to explicitly deny traffic from that country's ISO code (e.g., `origin.region_code == 'XX'`), which takes effect immediately without affecting legitimate traffic from other regions.",
      "wg": [
        {
          "t": "緩解措施",
          "en": "mitigation measure",
          "ps": "N"
        },
        {
          "t": "國碼",
          "en": "country code",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "90",
    "level": "medium",
    "keywords": "Deployment, Canary, Istio, Traffic Splitting",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在使用 GKE 上的 Istio (或 Anthos Service Mesh) 來管理微服務流量。",
        "en": "You are using Istio (or Anthos Service Mesh) on GKE to manage microservices traffic.",
        "wg": []
      },
      {
        "t": "您希望執行金絲雀部署 (Canary Deployment)，將 5% 的流量導向新版本 `v2`，但僅限於來自 iPhone 使用者的請求。",
        "en": "You want to perform a Canary Deployment, routing 5% of traffic to the new version `v2`, but only for requests coming from iPhone users.",
        "wg": []
      },
      {
        "t": "您應該如何設定 VirtualService？",
        "en": "How should you configure the VirtualService?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 僅使用 `weight` 欄位設定 5%。",
        "en": "(A) Use only the `weight` field set to 5%.",
        "wg": []
      },
      {
        "t": "(B) 結合 `match` 條件 (檢查 User-Agent Header) 與 `route` 權重。",
        "en": "(B) Combine `match` conditions (checking User-Agent Header) with `route` weights.",
        "wg": [
          {
            "t": "權重",
            "en": "weight",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 部署一個獨立的 Load Balancer 專門服務 iPhone。",
        "en": "(C) Deploy a separate Load Balancer specifically for iPhones.",
        "wg": []
      },
      {
        "t": "(D) 這在 Istio 中無法達成，需要在應用程式層處理。",
        "en": "(D) This cannot be achieved in Istio and must be handled at the application layer.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Istio 的強大之處在於細緻的流量控制。您可以在 VirtualService 中定義 `match` 規則來檢查 HTTP Header (如 `User-Agent` 包含 'iPhone')，然後在該匹配規則下定義路由權重 (95% 到 v1, 5% 到 v2)。這允許基於內容 (Content-based) 的進階金絲雀策略。",
      "en": "The power of Istio lies in granular traffic control. You can define `match` rules in a VirtualService to inspect HTTP Headers (e.g., `User-Agent` contains 'iPhone') and then define routing weights under that match rule (95% to v1, 5% to v2). This allows for advanced content-based canary strategies.",
      "wg": [
        {
          "t": "細緻的",
          "en": "granular",
          "ps": "Adj"
        },
        {
          "t": "基於內容",
          "en": "Content-based",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "91",
    "level": "hard",
    "keywords": "Networking, VPC Peering, Transitive Peering, Hub-and-Spoke",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的組織採用 Hub-and-Spoke 網路拓撲。",
        "en": "Your organization adopts a Hub-and-Spoke network topology.",
        "wg": [
          {
            "t": "網路拓撲",
            "en": "network topology",
            "ps": "N"
          }
        ]
      },
      {
        "t": "Hub VPC 透過 VPC Peering 連接到 Spoke A 和 Spoke B。現在，Spoke A 中的 VM 需要直接與 Spoke B 中的 VM 通訊。",
        "en": "The Hub VPC is connected to Spoke A and Spoke B via VPC Peering. Now, a VM in Spoke A needs to communicate directly with a VM in Spoke B.",
        "wg": []
      },
      {
        "t": "您發現連線失敗。這是因為 Google Cloud 的 VPC Peering 不支援遞移路由 (Transitive Routing)。您應該如何解決此問題？",
        "en": "You find the connection fails. This is because Google Cloud VPC Peering does not support Transitive Routing. How should you resolve this?",
        "wg": [
          {
            "t": "遞移路由",
            "en": "Transitive Routing",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 Spoke A 和 Spoke B 之間建立直接的 VPC Peering 連線。",
        "en": "(A) Establish a direct VPC Peering connection between Spoke A and Spoke B.",
        "wg": []
      },
      {
        "t": "(B) 在 Hub VPC 中設定 Cloud NAT。",
        "en": "(B) Configure Cloud NAT in the Hub VPC.",
        "wg": []
      },
      {
        "t": "(C) 使用 Shared VPC 替代 VPC Peering。",
        "en": "(C) Use Shared VPC instead of VPC Peering.",
        "wg": []
      },
      {
        "t": "(D) 在 Hub VPC 中部署一個用作路由器的 NVA (Network Virtual Appliance)。",
        "en": "(D) Deploy an NVA (Network Virtual Appliance) acting as a router in the Hub VPC.",
        "wg": [
          {
            "t": "網路虛擬設備",
            "en": "Network Virtual Appliance",
            "ps": "N"
          }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "VPC Peering 是非遞移性的 (Non-transitive)，這意味著 A 連到 Hub，Hub 連到 B，並不代表 A 可以透過 Hub 連到 B。最簡單且效能最好的解決方案是直接在 A 和 B 之間建立 Peering (全網狀 Full Mesh)。雖然 (D) NVA 也是技術上可行的解決方案 (透過自訂路由)，但它會引入單點故障與頻寬瓶頸，不如直接 Peering 來的推薦。",
      "en": "VPC Peering is non-transitive, meaning if A connects to Hub and Hub connects to B, A cannot communicate with B via Hub. The simplest and highest-performance solution is to establish a direct Peering connection between A and B (Full Mesh). While (D) NVA is technically feasible (via custom routes), it introduces a single point of failure and bandwidth bottlenecks, making direct Peering the recommended approach.",
      "wg": [
        {
          "t": "非遞移性的",
          "en": "non-transitive",
          "ps": "Adj"
        },
        {
          "t": "全網狀",
          "en": "Full Mesh",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "92",
    "level": "medium",
    "keywords": "Disaster Recovery, Cloud SQL, RPO, Replication",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在規劃 Cloud SQL for PostgreSQL 的災難復原 (DR) 策略。",
        "en": "You are planning a Disaster Recovery (DR) strategy for Cloud SQL for PostgreSQL.",
        "wg": []
      },
      {
        "t": "業務要求復原點目標 (RPO) 必須接近零，並且能夠在主要區域 (Primary Region) 完全故障時快速切換到次要區域。",
        "en": "Business requirements dictate an RPO of near zero and the ability to quickly failover to a secondary region in case of a complete primary region failure.",
        "wg": [
          {
            "t": "接近零",
            "en": "near zero",
            "ps": "Adj"
          },
          {
            "t": "主要區域",
            "en": "Primary Region",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該如何設定？",
        "en": "How should you configure this?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 設定每小時的自動備份，並將備份檔複製到另一個區域。",
        "en": "(A) Configure hourly automated backups and copy backup files to another region.",
        "wg": []
      },
      {
        "t": "(B) 建立跨區域唯讀複本 (Cross-region Read Replica)。",
        "en": "(B) Create a Cross-region Read Replica.",
        "wg": [
          {
            "t": "跨區域唯讀複本",
            "en": "Cross-region Read Replica",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 使用 Cloud Storage 來同步 WAL (Write Ahead Logs) 檔案。",
        "en": "(C) Use Cloud Storage to synchronize WAL (Write Ahead Logs) files.",
        "wg": []
      },
      {
        "t": "(D) 依賴 Cloud SQL 的高可用性 (HA) 設定。",
        "en": "(D) Rely on Cloud SQL's High Availability (HA) configuration.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Cloud SQL 的 HA 僅針對區域內的區域 (Zone) 故障提供保護。針對區域 (Region) 級別的故障與低 RPO 需求，建立跨區域唯讀複本是標準做法。唯讀複本會持續透過非同步複製接收數據，當災難發生時，您可以將該複本「提升 (Promote)」為新的主實例，實現快速復原。",
      "en": "Cloud SQL's HA only protects against zonal failures within a region. For region-level failures and low RPO requirements, creating a Cross-region Read Replica is the standard practice. The replica continuously receives data via asynchronous replication, and in a disaster, you can \"Promote\" the replica to become the new primary instance, achieving fast recovery.",
      "wg": [
        {
          "t": "提升",
          "en": "Promote",
          "ps": "V"
        },
        {
          "t": "非同步複製",
          "en": "asynchronous replication",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "93",
    "level": "medium",
    "keywords": "Cloud Run, Secrets, Environment Variables, Security",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的 Cloud Run 服務需要連接到第三方 API，該 API 需要一組 API Key。",
        "en": "Your Cloud Run service needs to connect to a third-party API that requires an API Key.",
        "wg": []
      },
      {
        "t": "為了安全起見，您不希望將 Key 寫在 Dockerfile 或原始碼中。",
        "en": "For security, you do not want to put the Key in the Dockerfile or source code.",
        "wg": []
      },
      {
        "t": "您應該如何將此 Key 安全地提供給 Cloud Run 服務？",
        "en": "How should you securely provide this Key to the Cloud Run service?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在部署時使用 `--set-env-vars` 旗標傳遞明文 Key。",
        "en": "(A) Pass the plaintext Key using the `--set-env-vars` flag during deployment.",
        "wg": [
          {
            "t": "明文",
            "en": "plaintext",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 將 Key 儲存在 Secret Manager 中，並在 Cloud Run 中將其掛載為環境變數或 Volume。",
        "en": "(B) Store the Key in Secret Manager and mount it in Cloud Run as an environment variable or volume.",
        "wg": []
      },
      {
        "t": "(C) 將 Key 儲存在 Cloud Storage 的加密 Bucket 中，並在應用程式啟動時下載。",
        "en": "(C) Store the Key in an encrypted Cloud Storage bucket and download it upon application startup.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud KMS 直接加密 Key，並將加密後的字串寫入程式碼。",
        "en": "(D) Encrypt the Key directly using Cloud KMS and put the encrypted string in the code.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Secret Manager 是 Google Cloud 專門用於管理敏感資訊的服務。Cloud Run 提供了原生整合，可以直接引用 Secret Manager 中的 Secret 版本，並將其安全地注入為環境變數或掛載為檔案，而無需在部署指令或代碼中暴露任何敏感資訊。",
      "en": "Secret Manager is Google Cloud's dedicated service for managing sensitive information. Cloud Run offers native integration to directly reference Secret versions from Secret Manager and securely inject them as environment variables or mount them as files, without exposing any sensitive information in deployment commands or code.",
      "wg": [
        {
          "t": "引用",
          "en": "reference",
          "ps": "V"
        },
        {
          "t": "注入",
          "en": "inject",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "94",
    "level": "hard",
    "keywords": "IAM, Policy Troubleshooting, Deny Policy, Inheritance",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您是組織管理員。一位專案擁有者 (Project Owner) 抱怨他無法在其專案中為新成員授予 `roles/editor` 角色。",
        "en": "You are an Organization Administrator. A Project Owner complains that they cannot grant the `roles/editor` role to a new member in their project.",
        "wg": [
          {
            "t": "抱怨",
            "en": "complain",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您檢查了 IAM 政策，確認他是 Owner 無誤。您懷疑這是上層策略導致的。",
        "en": "You checked the IAM policy and confirmed they are indeed an Owner. You suspect this is caused by a higher-level policy.",
        "wg": [
          {
            "t": "上層策略",
            "en": "higher-level policy",
            "ps": "N"
          }
        ]
      },
      {
        "t": "以下哪種情況最可能導致此問題？",
        "en": "Which of the following scenarios is most likely causing this issue?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 組織層級設定了 IAM Deny Policy，明確拒絕了該成員的權限。",
        "en": "(A) An IAM Deny Policy is configured at the organization level, explicitly denying permissions for that member.",
        "wg": [
          {
            "t": "明確拒絕",
            "en": "explicitly deny",
            "ps": "V"
          }
        ]
      },
      {
        "t": "(B) 組織政策 (Organization Policy) 設定了 `iam.allowedPolicyMemberDomains` 限制，而新成員的 Email 網域不在允許清單中。",
        "en": "(B) The Organization Policy `iam.allowedPolicyMemberDomains` constraint is configured, and the new member's email domain is not in the allowed list.",
        "wg": [
          {
            "t": "允許清單",
            "en": "allowed list",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 專案配額已滿，無法新增更多 IAM 綁定。",
        "en": "(C) The project quota is full, preventing new IAM bindings.",
        "wg": []
      },
      {
        "t": "(D) 該成員沒有啟用兩步驟驗證 (2FA)。",
        "en": "(D) The member has not enabled Two-Factor Authentication (2FA).",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "組織政策 `iam.allowedPolicyMemberDomains` 常用於限制只能授予權限給特定的企業網域 (例如只允許 `@company.com`)，以防止資料外洩給外部人員 (如 `@gmail.com`)。如果 Owner 嘗試授予權限給外部網域的成員，該操作會被組織政策阻擋，即使 Owner 本身擁有修改 IAM 的權限。",
      "en": "The Organization Policy `iam.allowedPolicyMemberDomains` is commonly used to restrict granting permissions only to specific corporate domains (e.g., only allowing `@company.com`) to prevent data leakage to external parties (e.g., `@gmail.com`). If an Owner attempts to grant permissions to a member from an external domain, the operation will be blocked by the Organization Policy, even if the Owner has permissions to modify IAM.",
      "wg": [
        {
          "t": "外部網域",
          "en": "external domain",
          "ps": "N"
        },
        {
          "t": "阻擋",
          "en": "block",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "95",
    "level": "medium",
    "keywords": "Case Study, KnightMotives, IoT, Pub/Sub, Dataflow",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 KnightMotives Automotive 個案研究。該公司需要從連網車輛收集大量的遙測數據。",
        "en": "Refer to the KnightMotives Automotive case study. The company needs to collect massive amounts of telemetry data from connected vehicles.",
        "wg": [
          {
            "t": "遙測數據",
            "en": "telemetry data",
            "ps": "N"
          }
        ]
      },
      {
        "t": "有些資料需要即時分析以進行駕駛安全警示，有些則只需存檔以供日後進行車輛健康分析。",
        "en": "Some data requires real-time analysis for driver safety alerts, while some only needs to be archived for future vehicle health analysis.",
        "wg": [
          {
            "t": "駕駛安全警示",
            "en": "driver safety alert",
            "ps": "N"
          }
        ]
      },
      {
        "t": "為了處理這兩種不同的存取模式，您應該如何架構數據接收層 (Ingestion Layer)？",
        "en": "To handle these two different access patterns, how should you architect the Ingestion Layer?",
        "wg": [
          {
            "t": "數據接收層",
            "en": "Ingestion Layer",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將所有數據寫入 Cloud SQL，並讓分析工具讀取複本。",
        "en": "(A) Write all data to Cloud SQL and let analytics tools read from replicas.",
        "wg": []
      },
      {
        "t": "(B) 使用 Pub/Sub 接收數據，並建立兩個訂閱 (Subscriptions)：一個給 Dataflow 進行即時處理，另一個透過 BigQuery 訂閱直接寫入資料庫。",
        "en": "(B) Use Pub/Sub to ingest data and create two Subscriptions: one for Dataflow for real-time processing, and another via BigQuery Subscription to write directly to the database.",
        "wg": [
          {
            "t": "訂閱",
            "en": "Subscription",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 使用 Cloud Storage 作為緩衝區，並使用 Cloud Functions 觸發處理。",
        "en": "(C) Use Cloud Storage as a buffer and trigger processing with Cloud Functions.",
        "wg": []
      },
      {
        "t": "(D) 直接將數據發送到 Vertex AI 進行推論。",
        "en": "(D) Send data directly to Vertex AI for inference.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Pub/Sub 是處理大規模 IoT 數據接收的理想緩衝區。透過「扇出 (Fan-out)」模式，您可以為同一個主題 (Topic) 建立多個訂閱，讓不同的下游系統 (即時警示 vs. 離線分析) 獨立消費數據而互不干擾。BigQuery 訂閱更是簡化了將數據存檔到資料庫的流程，無需額外的 ETL 程式碼。",
      "en": "Pub/Sub is the ideal buffer for large-scale IoT data ingestion. Using the \"Fan-out\" pattern, you can create multiple subscriptions for the same Topic, allowing different downstream systems (real-time alerts vs. offline analytics) to consume data independently without interference. BigQuery Subscriptions further simplify archiving data to the database without extra ETL code.",
      "wg": [
        {
          "t": "扇出",
          "en": "Fan-out",
          "ps": "N"
        },
        {
          "t": "互不干擾",
          "en": "without interference",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "96",
    "level": "medium",
    "keywords": "Cost Optimization, Storage, Deduplication, Backup",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的備份系統每天會產生完整的磁碟映像檔並上傳到 Cloud Storage。",
        "en": "Your backup system generates full disk images daily and uploads them to Cloud Storage.",
        "wg": [
          {
            "t": "磁碟映像檔",
            "en": "disk image",
            "ps": "N"
          }
        ]
      },
      {
        "t": "由於大部數據每天都沒有變化，儲存完整的每日備份導致成本極高。",
        "en": "Since most data does not change daily, storing full daily backups results in extremely high costs.",
        "wg": []
      },
      {
        "t": "您希望在不改變現有上傳流程 (不實作客戶端去重複) 的情況下降低儲存成本。您應該啟用哪個功能？",
        "en": "You want to reduce storage costs without changing the existing upload process (without implementing client-side deduplication). Which feature should you enable?",
        "wg": [
          {
            "t": "客戶端去重複",
            "en": "client-side deduplication",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 物件版本控制 (Object Versioning)。",
        "en": "(A) Object Versioning.",
        "wg": []
      },
      {
        "t": "(B) 啟用 Autoclass。",
        "en": "(B) Enable Autoclass.",
        "wg": []
      },
      {
        "t": "(C) 使用 Archive Storage 類別。",
        "en": "(C) Use Archive Storage class.",
        "wg": []
      },
      {
        "t": "(D) 這在 Cloud Storage 中無法原生達成，必須修改備份軟體以進行增量備份。",
        "en": "(D) This cannot be achieved natively in Cloud Storage; you must modify the backup software to perform incremental backups.",
        "wg": [
          {
            "t": "增量備份",
            "en": "incremental backup",
            "ps": "N"
          }
        ]
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud Storage 是物件儲存，它將每個上傳的檔案視為獨立的物件。如果您每天上傳一個 100GB 的檔案，即使內容 99% 相同，Cloud Storage 也會將其視為新的 100GB 物件並全額收費。它沒有原生的「區塊級去重複 (Block-level Deduplication)」功能。要節省空間，必須在應用層 (備份軟體) 改為增量備份或使用支援去重複的備份解決方案 (如 Backup and DR Service)。",
      "en": "Cloud Storage is object storage; it treats every uploaded file as an independent object. If you upload a 100GB file daily, even if 99% of the content is identical, Cloud Storage treats it as a new 100GB object and charges fully. It does not have native \"Block-level Deduplication\". To save space, you must switch to incremental backups at the application layer (backup software) or use a backup solution that supports deduplication (like Backup and DR Service).",
      "wg": [
        {
          "t": "區塊級去重複",
          "en": "Block-level Deduplication",
          "ps": "N"
        },
        {
          "t": "全額收費",
          "en": "charge fully",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "97",
    "level": "medium",
    "keywords": "Compute Engine, OS Patching, VM Manager, Automation",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您管理著一個擁有 500 台 Compute Engine VM 的機隊，包含 Linux 和 Windows。",
        "en": "You manage a fleet of 500 Compute Engine VMs, including both Linux and Windows.",
        "wg": [
          {
            "t": "機隊",
            "en": "fleet",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您需要確保所有 VM 定期安裝最新的作業系統安全性修補程式，並能夠產生合規性報告。",
        "en": "You need to ensure all VMs regularly install the latest OS security patches and can generate compliance reports.",
        "wg": [
          {
            "t": "安全性修補程式",
            "en": "security patch",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該使用哪項工具來自動化此流程？",
        "en": "Which tool should you use to automate this process?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) VM Manager (OS Patch Management)。",
        "en": "(A) VM Manager (OS Patch Management).",
        "wg": []
      },
      {
        "t": "(B) 為每台 VM 設定 Startup Script 執行 `apt-get update`。",
        "en": "(B) Configure a Startup Script for each VM to run `apt-get update`.",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud Build 定期重建映像檔並重新部署所有 VM。",
        "en": "(C) Use Cloud Build to periodically rebuild images and redeploy all VMs.",
        "wg": []
      },
      {
        "t": "(D) 手動 SSH/RDP 進入每台 VM 進行更新。",
        "en": "(D) Manually SSH/RDP into each VM to update.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "VM Manager 是 Google Cloud 用於管理大規模 VM 機隊的套件。其 Patch Management 功能可以自動掃描作業系統漏洞、定義維護視窗 (Maintenance Windows)、自動套用修補程式，並提供合規性儀表板，完全符合需求且無需自行維護腳本。",
      "en": "VM Manager is a suite for managing large-scale VM fleets on Google Cloud. Its Patch Management feature can automatically scan for OS vulnerabilities, define Maintenance Windows, automatically apply patches, and provide compliance dashboards, perfectly meeting the requirements without maintaining custom scripts.",
      "wg": [
        {
          "t": "維護視窗",
          "en": "Maintenance Window",
          "ps": "N"
        },
        {
          "t": "套用",
          "en": "apply",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "98",
    "level": "medium",
    "keywords": "Serverless, Cloud Functions, Event-Driven, Error Handling",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的 Cloud Functions (第 2 代) 由 Pub/Sub 訊息觸發，負責處理訂單。",
        "en": "Your Cloud Functions (2nd gen) is triggered by Pub/Sub messages and is responsible for processing orders.",
        "wg": []
      },
      {
        "t": "如果函式因為外部 API 暫時性故障而崩潰，Pub/Sub 會不斷重試，導致函式陷入無窮迴圈並浪費成本。",
        "en": "If the function crashes due to a transient failure of an external API, Pub/Sub keeps retrying, causing the function to enter an infinite loop and wasting costs.",
        "wg": [
          {
            "t": "暫時性故障",
            "en": "transient failure",
            "ps": "N"
          },
          {
            "t": "無窮迴圈",
            "en": "infinite loop",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該如何改善此架構以優化錯誤處理？",
        "en": "How should you improve this architecture to optimize error handling?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 Cloud Functions 中捕捉所有例外並回傳 HTTP 200 OK。",
        "en": "(A) Catch all exceptions in Cloud Functions and return HTTP 200 OK.",
        "wg": [
          {
            "t": "捕捉",
            "en": "catch",
            "ps": "V"
          },
          {
            "t": "例外",
            "en": "exception",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 在 Pub/Sub 訂閱中設定「死信隊列 (Dead Letter Queue)」。",
        "en": "(B) Configure a \"Dead Letter Queue\" in the Pub/Sub subscription.",
        "wg": [
          {
            "t": "死信隊列",
            "en": "Dead Letter Queue",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 增加 Cloud Functions 的記憶體與 Timeout 時間。",
        "en": "(C) Increase Cloud Functions memory and timeout settings.",
        "wg": []
      },
      {
        "t": "(D) 改用 Cloud Tasks。",
        "en": "(D) Switch to Cloud Tasks.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "設定死信隊列 (DLQ) 允許您定義最大重試次數 (Max Delivery Attempts)。當訊息重試超過此次數仍失敗時，Pub/Sub 會將其移至 DLQ 主題，停止對該訊息的觸發。這能防止「毒藥訊息 (Poison Message)」造成的無限重試，同時保留失敗的訊息以供後續人工調查。",
      "en": "Configuring a Dead Letter Queue (DLQ) allows you to define a Max Delivery Attempts limit. When a message fails retries exceeding this limit, Pub/Sub moves it to the DLQ topic, stopping triggers for that message. This prevents infinite retries caused by \"Poison Messages\" while preserving failed messages for subsequent manual investigation.",
      "wg": [
        {
          "t": "毒藥訊息",
          "en": "Poison Message",
          "ps": "N"
        },
        {
          "t": "人工調查",
          "en": "manual investigation",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "99",
    "level": "medium",
    "keywords": "Case Study, Altostrat Media, GKE, GPU, Node Pools",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Altostrat Media 個案研究。該公司計畫在 GKE 上執行影片轉碼 (Transcoding) 工作負載。",
        "en": "Refer to the Altostrat Media case study. The company plans to run video transcoding workloads on GKE.",
        "wg": [
          {
            "t": "影片轉碼",
            "en": "video transcoding",
            "ps": "N"
          }
        ]
      },
      {
        "t": "轉碼作業需要 GPU 加速，但其他微服務 (如前端 API) 只需要標準 CPU。",
        "en": "Transcoding jobs require GPU acceleration, but other microservices (like frontend APIs) only need standard CPUs.",
        "wg": []
      },
      {
        "t": "為了優化成本與效能，您應該如何設定 GKE 叢集？",
        "en": "To optimize cost and performance, how should you configure the GKE cluster?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 建立一個包含 GPU 的預設節點池 (Default Node Pool)。",
        "en": "(A) Create a Default Node Pool containing GPUs.",
        "wg": []
      },
      {
        "t": "(B) 建立多個節點池 (Node Pools)：一個標準池給一般服務，一個 GPU 池給轉碼作業，並使用 Taints 和 Tolerations 進行調度。",
        "en": "(B) Create multiple Node Pools: a standard pool for general services and a GPU pool for transcoding jobs, using Taints and Tolerations for scheduling.",
        "wg": [
          {
            "t": "調度",
            "en": "scheduling",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 為每個微服務建立獨立的 GKE 叢集。",
        "en": "(C) Create separate GKE clusters for each microservice.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud Run 替代 GKE。",
        "en": "(D) Use Cloud Run instead of GKE.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "GPU 節點成本昂貴，不應浪費在不需要 GPU 的輕量級服務上。透過建立獨立的節點池，並在 GPU 節點上設定 Taints (污點)，您可以確保只有宣告了 Tolerations (容忍度) 的轉碼 Pod 會被調度到 GPU 節點，其他 Pod 則留在便宜的 CPU 節點上，實現最佳的資源隔離與成本效益。",
      "en": "GPU nodes are expensive and should not be wasted on lightweight services that don't need them. By creating separate Node Pools and setting Taints on GPU nodes, you ensure that only transcoding Pods declaring Tolerations are scheduled on GPU nodes, while other Pods stay on cheaper CPU nodes, achieving optimal resource isolation and cost-effectiveness.",
      "wg": [
        {
          "t": "污點",
          "en": "Taint",
          "ps": "N"
        },
        {
          "t": "容忍度",
          "en": "Toleration",
          "ps": "N"
        },
        {
          "t": "資源隔離",
          "en": "resource isolation",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "100",
    "level": "hard",
    "keywords": "Case Study, Cymbal Retail, Analytics, Looker, BigQuery",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Cymbal Retail 個案研究。行銷部門希望使用 Looker 來視覺化 BigQuery 中的銷售數據，並建立即時儀表板。",
        "en": "Refer to the Cymbal Retail case study. The marketing department wants to use Looker to visualize sales data in BigQuery and build real-time dashboards.",
        "wg": [
          {
            "t": "視覺化",
            "en": "visualize",
            "ps": "V"
          },
          {
            "t": "即時儀表板",
            "en": "real-time dashboard",
            "ps": "N"
          }
        ]
      },
      {
        "t": "為了提升查詢效能並降低 BigQuery 的掃描成本，同時不影響資料的新鮮度 (Freshness)，您應該建議哪種優化策略？",
        "en": "To improve query performance and reduce BigQuery scanning costs without compromising data freshness, which optimization strategy should you recommend?",
        "wg": [
          {
            "t": "掃描成本",
            "en": "scanning cost",
            "ps": "N"
          },
          {
            "t": "新鮮度",
            "en": "freshness",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 每天將數據匯出到 CSV 並匯入 Looker。",
        "en": "(A) Export data to CSV daily and import into Looker.",
        "wg": []
      },
      {
        "t": "(B) 在 BigQuery 中使用分區 (Partitioning) 和叢集 (Clustering)，並在 Looker 中使用快取策略或聚合表 (Aggregate Tables)。",
        "en": "(B) Use Partitioning and Clustering in BigQuery, and use Caching policies or Aggregate Tables in Looker.",
        "wg": [
          {
            "t": "分區",
            "en": "Partitioning",
            "ps": "N"
          },
          {
            "t": "叢集",
            "en": "Clustering",
            "ps": "N"
          },
          {
            "t": "聚合表",
            "en": "Aggregate Table",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 增加 BigQuery 的 Slot 數量。",
        "en": "(C) Increase the number of BigQuery Slots.",
        "wg": []
      },
      {
        "t": "(D) 使用 Dataflow 在寫入前預先聚合數據。",
        "en": "(D) Use Dataflow to pre-aggregate data before writing.",
        "wg": [
          {
            "t": "預先聚合",
            "en": "pre-aggregate",
            "ps": "V"
          }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "BigQuery 的分區與叢集能大幅減少掃描的資料量 (Pruning)。Looker 的聚合表功能 (Aggregate Awareness) 則能自動建立並維護匯總資料的表格。當使用者查詢大範圍趨勢時，Looker 會自動查詢較小的聚合表而非原始大表，這樣既保留了鑽取 (Drill-down) 到細節的能力，又極大降低了日常查詢的成本與延遲。",
      "en": "BigQuery Partitioning and Clustering significantly reduce the amount of data scanned (Pruning). Looker's Aggregate Awareness automatically builds and maintains tables of summarized data. When users query broad trends, Looker automatically queries the smaller aggregate tables instead of the raw massive tables, preserving the ability to drill down to details while drastically reducing daily query costs and latency.",
      "wg": [
        {
          "t": "修剪",
          "en": "Pruning",
          "ps": "N"
        },
        {
          "t": "鑽取",
          "en": "Drill-down",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "101",
    "level": "hard",
    "keywords": "Migration, Database, Oracle, Cloud SQL, Heterogeneous",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的公司計畫將一個關鍵的 Oracle 資料庫遷移到 Cloud SQL for PostgreSQL。",
        "en": "Your company plans to migrate a critical Oracle database to Cloud SQL for PostgreSQL.",
        "wg": []
      },
      {
        "t": "這是一個異質遷移 (Heterogeneous Migration)，您需要轉換資料庫結構 (Schema) 並確保在切換期間的停機時間最短。",
        "en": "This is a heterogeneous migration, and you need to convert the database schema and ensure minimal downtime during the cutover.",
        "wg": [
          {
            "t": "異質遷移",
            "en": "Heterogeneous Migration",
            "ps": "N"
          },
          {
            "t": "資料庫結構",
            "en": "Schema",
            "ps": "N"
          },
          {
            "t": "切換",
            "en": "cutover",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該執行哪兩個步驟？(請選擇兩項)",
        "en": "Which two steps should you perform? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 Database Migration Service (DMS) 建立持續複寫作業。",
        "en": "(A) Use Database Migration Service (DMS) to create a continuous replication job.",
        "wg": [
          {
            "t": "持續複寫",
            "en": "continuous replication",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 使用 Google Cloud Schema Conversion (或 Ora2Pg) 工具轉換 schema。",
        "en": "(B) Use Google Cloud Schema Conversion (or Ora2Pg) tool to convert the schema.",
        "wg": []
      },
      {
        "t": "(C) 將 Oracle 資料匯出為 CSV，然後匯入 BigQuery。",
        "en": "(C) Export Oracle data to CSV and import into BigQuery.",
        "wg": []
      },
      {
        "t": "(D) 使用 Datastream 將資料串流至 Cloud Storage。",
        "en": "(D) Use Datastream to stream data to Cloud Storage.",
        "wg": []
      },
      {
        "t": "(E) 建立 Cloud SQL 的跨區域唯讀複本。",
        "en": "(E) Create a cross-region read replica for Cloud SQL.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "異質遷移需要兩個關鍵步驟：1. 結構轉換：因為 Oracle 和 PostgreSQL 語法不同，必須先使用 Schema Conversion 工具。2. 最小停機遷移：DMS 支援 Oracle 到 Cloud SQL for PostgreSQL 的持續複寫 (CDC)，能在遷移過程中保持資料同步，實現最小停機切換。",
      "en": "Heterogeneous migration requires two key steps: 1. Schema Conversion: Since Oracle and PostgreSQL syntaxes differ, you must first use a Schema Conversion tool. 2. Minimal Downtime Migration: DMS supports continuous replication (CDC) from Oracle to Cloud SQL for PostgreSQL, keeping data in sync during migration to enable minimal downtime cutover.",
      "wg": [
        {
          "t": "最小停機",
          "en": "minimal downtime",
          "ps": "N"
        },
        {
          "t": "語法",
          "en": "syntax",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "102",
    "level": "medium",
    "keywords": "GKE, Cost Optimization, Spot VM, Autoscaling",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您在 GKE 上運行大量的批次處理工作負載 (Batch Workloads)，這些工作可以容忍中斷並重新啟動。",
        "en": "You run a large number of batch workloads on GKE that can tolerate interruptions and restarts.",
        "wg": [
          {
            "t": "批次處理工作負載",
            "en": "Batch Workloads",
            "ps": "N"
          },
          {
            "t": "容忍中斷",
            "en": "tolerate interruption",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您希望在不顯著增加管理負擔的情況下，盡可能降低運算成本。",
        "en": "You want to minimize compute costs as much as possible without significantly increasing management overhead.",
        "wg": []
      },
      {
        "t": "您應該結合哪兩項設定？(請選擇兩項)",
        "en": "Which two configurations should you combine? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 建立使用 Spot VM 的節點池 (Node Pool)。",
        "en": "(A) Create a Node Pool using Spot VMs.",
        "wg": []
      },
      {
        "t": "(B) 在該節點池上啟用叢集自動擴充 (Cluster Autoscaler)。",
        "en": "(B) Enable Cluster Autoscaler on that Node Pool.",
        "wg": []
      },
      {
        "t": "(C) 使用具有高記憶體的 N2D 機器類型。",
        "en": "(C) Use N2D machine types with high memory.",
        "wg": []
      },
      {
        "t": "(D) 為每個 Pod 設定 PodDisruptionBudget (PDB)。",
        "en": "(D) Configure PodDisruptionBudget (PDB) for each Pod.",
        "wg": []
      },
      {
        "t": "(E) 手動調整節點數量以匹配工作負載。",
        "en": "(E) Manually scale the number of nodes to match the workload.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Spot VM 提供高達 60-91% 的折扣，非常適合可中斷的批次工作。結合 Cluster Autoscaler，當有工作排隊時自動新增 Spot 節點，當 Spot 節點被 Google 回收或工作結束時自動調整，這是最自動化且具成本效益的組合。",
      "en": "Spot VMs offer discounts of up to 60-91%, making them ideal for interruptible batch jobs. Combined with Cluster Autoscaler, which automatically adds Spot nodes when jobs are queued and scales down when nodes are preempted or jobs finish, this is the most automated and cost-effective combination.",
      "wg": [
        {
          "t": "可中斷的",
          "en": "interruptible",
          "ps": "Adj"
        },
        {
          "t": "回收",
          "en": "preempt/reclaim",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "103",
    "level": "hard",
    "keywords": "Security, Data Exfiltration, VPC Service Controls, IAM",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的組織處理高度敏感的醫療數據。您擔心擁有 BigQuery 存取權限的內部員工可能會將數據匯出到個人的 Google 雲端硬碟或外部的 GCS Bucket。",
        "en": "Your organization handles highly sensitive healthcare data. You are concerned that internal employees with BigQuery access might export data to personal Google Drive or external GCS Buckets.",
        "wg": [
          {
            "t": "匯出",
            "en": "export",
            "ps": "V"
          }
        ]
      },
      {
        "t": "除了 IAM 權限控制外，您還應該實作哪兩項控制措施來防止這種資料外洩？(請選擇兩項)",
        "en": "Besides IAM permission controls, which two control measures should you implement to prevent such data exfiltration? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 設定 VPC Service Controls 邊界，將 BigQuery 和 Cloud Storage 納入保護。",
        "en": "(A) Configure VPC Service Controls perimeters to protect BigQuery and Cloud Storage.",
        "wg": []
      },
      {
        "t": "(B) 設定 VPC Service Controls 的出口規則 (Egress Rules)，僅允許資料傳輸到授權的專案。",
        "en": "(B) Configure VPC Service Controls Egress Rules to allow data transfer only to authorized projects.",
        "wg": [
          {
            "t": "出口規則",
            "en": "Egress Rule",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 移除所有員工的 Viewer 角色。",
        "en": "(C) Remove the Viewer role for all employees.",
        "wg": []
      },
      {
        "t": "(D) 強制所有使用者使用 Cloud Shell。",
        "en": "(D) Enforce all users to use Cloud Shell.",
        "wg": []
      },
      {
        "t": "(E) 啟用 Cloud SQL 的 SSL 連線。",
        "en": "(E) Enable SSL connections for Cloud SQL.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "VPC Service Controls (VPC SC) 是防止資料外洩的核心服務。建立邊界 (A) 可以隔離資源，禁止未經授權的網路存取。更重要的是，透過設定出口規則 (B)，您可以明確限制邊界內的數據只能流向受信任的專案，從而阻擋複製到個人或外部專案的行為。",
      "en": "VPC Service Controls (VPC SC) is the core service for preventing data exfiltration. Creating a perimeter (A) isolates resources and blocks unauthorized network access. More importantly, by configuring egress rules (B), you can explicitly limit data flow from within the perimeter only to trusted projects, thereby blocking copying to personal or external projects.",
      "wg": [
        {
          "t": "邊界",
          "en": "perimeter",
          "ps": "N"
        },
        {
          "t": "隔離",
          "en": "isolate",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "104",
    "level": "medium",
    "keywords": "Observability, Troubleshooting, Trace, Logging",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的微服務應用程式由數十個服務組成，使用 HTTP 和 gRPC 進行通訊。",
        "en": "Your microservices application consists of dozens of services communicating via HTTP and gRPC.",
        "wg": []
      },
      {
        "t": "使用者報告偶爾會遇到高延遲，但您很難確定是哪一個服務造成了瓶頸。",
        "en": "Users report occasional high latency, but it is difficult for you to pinpoint which service is causing the bottleneck.",
        "wg": [
          {
            "t": "瓶頸",
            "en": "bottleneck",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該採取哪兩個步驟來診斷此問題？(請選擇兩項)",
        "en": "Which two steps should you take to diagnose this issue? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 確保所有應用程式都已啟用 Cloud Trace (或 OpenTelemetry)，並傳遞追蹤上下文 (Trace Context)。",
        "en": "(A) Ensure all applications have Cloud Trace (or OpenTelemetry) enabled and propagate Trace Context.",
        "wg": [
          {
            "t": "追蹤上下文",
            "en": "Trace Context",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 在 Cloud Console 中查看 Trace 瀑布圖 (Waterfall View) 以分析請求路徑中的延遲。",
        "en": "(B) View the Trace Waterfall View in the Cloud Console to analyze latency in the request path.",
        "wg": [
          {
            "t": "瀑布圖",
            "en": "Waterfall View",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 增加所有服務的 CPU 配額。",
        "en": "(C) Increase the CPU quota for all services.",
        "wg": []
      },
      {
        "t": "(D) 檢查 VPC Flow Logs 的網路流量總量。",
        "en": "(D) Check VPC Flow Logs for total network traffic volume.",
        "wg": []
      },
      {
        "t": "(E) 為每個服務建立單獨的 BigQuery 表格來儲存日誌。",
        "en": "(E) Create separate BigQuery tables for each service to store logs.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "分散式追蹤 (Distributed Tracing) 是解決微服務延遲問題的關鍵。首先必須在代碼中埋點或使用代理來收集追蹤數據並傳遞 Context (A)。接著，使用 Cloud Trace 的瀑布圖 (B) 可以視覺化單一請求在各個服務間的流轉時間，精確找出耗時最長的環節 (Span)。",
      "en": "Distributed Tracing is key to resolving microservices latency issues. First, you must instrument code or use agents to collect trace data and propagate Context (A). Then, use Cloud Trace's Waterfall View (B) to visualize the flow of a single request across services, precisely identifying the segment (Span) consuming the most time.",
      "wg": [
        {
          "t": "分散式追蹤",
          "en": "Distributed Tracing",
          "ps": "N"
        },
        {
          "t": "埋點",
          "en": "instrument",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "105",
    "level": "medium",
    "keywords": "Networking, Connectivity, Hybrid, Dedicated Interconnect",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的企業需要建立從本地資料中心到 Google Cloud 的 Dedicated Interconnect 連線。",
        "en": "Your enterprise needs to establish a Dedicated Interconnect connection from an on-premises data center to Google Cloud.",
        "wg": []
      },
      {
        "t": "為了滿足 99.99% 的可用性 SLA，您需要正確的實體線路配置。",
        "en": "To meet the 99.99% availability SLA, you need the correct physical circuit configuration.",
        "wg": []
      },
      {
        "t": "您應該採取哪兩個行動？(請選擇兩項)",
        "en": "Which two actions should you take? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 選擇兩個不同的都會區 (Metros)。",
        "en": "(A) Choose two different Metros.",
        "wg": [
          {
            "t": "都會區",
            "en": "Metro",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 在每個都會區中，佈建兩條連接到不同邊緣可用性網域 (Edge Availability Domain) 的線路。",
        "en": "(B) In each Metro, provision two circuits connecting to different Edge Availability Domains.",
        "wg": [
          {
            "t": "邊緣可用性網域",
            "en": "Edge Availability Domain",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 僅使用一個都會區，但佈建四條線路。",
        "en": "(C) Use only one Metro, but provision four circuits.",
        "wg": []
      },
      {
        "t": "(D) 混合使用 Dedicated Interconnect 和 Carrier Peering。",
        "en": "(D) Mix Dedicated Interconnect and Carrier Peering.",
        "wg": []
      },
      {
        "t": "(E) 使用 Cloud VPN 作為備援。",
        "en": "(E) Use Cloud VPN as a backup.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Google Cloud 對 Dedicated Interconnect 的 99.99% SLA 有嚴格定義：您必須在兩個不同的都會區 (Metros) (A)，且每個都會區內要有兩條連接到不同邊緣設備 (Edge Availability Domains) 的線路 (B)，總共 4 條線路。這樣才能同時容忍單一設備故障和區域性災難。",
      "en": "Google Cloud has a strict definition for the 99.99% SLA for Dedicated Interconnect: You must use two different Metros (A), and within each Metro, have two circuits connecting to different Edge Availability Domains (B), totaling 4 circuits. This ensures tolerance for both single device failures and regional disasters.",
      "wg": [
        {
          "t": "嚴格定義",
          "en": "strict definition",
          "ps": "N"
        },
        {
          "t": "容忍",
          "en": "tolerance",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "106",
    "level": "medium",
    "keywords": "Deployment, CI/CD, Cloud Build, Artifact Registry, Security",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在設計一個安全的 CI/CD 管道來部署應用程式到 GKE。",
        "en": "You are designing a secure CI/CD pipeline to deploy applications to GKE.",
        "wg": []
      },
      {
        "t": "您希望確保建置過程是在隔離的環境中執行，且產出的映像檔不含已知的嚴重漏洞。",
        "en": "You want to ensure that the build process runs in an isolated environment and that the resulting images do not contain known critical vulnerabilities.",
        "wg": [
          {
            "t": "隔離的環境",
            "en": "isolated environment",
            "ps": "N"
          },
          {
            "t": "已知",
            "en": "known",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您應該結合哪兩項服務或功能？(請選擇兩項)",
        "en": "Which two services or features should you combine? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 Cloud Build Private Pools。",
        "en": "(A) Use Cloud Build Private Pools.",
        "wg": [
          {
            "t": "私有池",
            "en": "Private Pool",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 在 Artifact Registry 中啟用漏洞掃描 (Vulnerability Scanning)。",
        "en": "(B) Enable Vulnerability Scanning in Artifact Registry.",
        "wg": [
          {
            "t": "漏洞掃描",
            "en": "Vulnerability Scanning",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 使用公開的 Cloud Build worker。",
        "en": "(C) Use public Cloud Build workers.",
        "wg": []
      },
      {
        "t": "(D) 將原始碼儲存在公開的 GitHub 儲存庫。",
        "en": "(D) Store source code in a public GitHub repository.",
        "wg": []
      },
      {
        "t": "(E) 使用 Container Registry 替代 Artifact Registry。",
        "en": "(E) Use Container Registry instead of Artifact Registry.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Cloud Build Private Pools (A) 提供了專屬、隔離且可連接至 VPC 的建置環境，解決了安全與網路隔離需求。Artifact Registry 的漏洞掃描 (B) 則能在映像檔推送到儲存庫時自動檢測 OS 套件的漏洞，是供應鏈安全的關鍵一環。",
      "en": "Cloud Build Private Pools (A) provide dedicated, isolated build environments that can connect to your VPC, addressing security and network isolation needs. Vulnerability Scanning in Artifact Registry (B) automatically detects OS package vulnerabilities when images are pushed, which is a key component of supply chain security.",
      "wg": [
        {
          "t": "專屬",
          "en": "dedicated",
          "ps": "Adj"
        },
        {
          "t": "關鍵一環",
          "en": "key component",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "107",
    "level": "hard",
    "keywords": "Case Study, Cymbal Retail, GenAI, RAG, Vertex AI",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Cymbal Retail 個案研究。該公司希望推出一個 AI 購物助手，根據使用者的自然語言描述推薦商品。",
        "en": "Refer to the Cymbal Retail case study. The company wants to launch an AI shopping assistant that recommends products based on users' natural language descriptions.",
        "wg": [
          {
            "t": "購物助手",
            "en": "shopping assistant",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您需要將產品目錄的文字描述與圖片轉換為向量，並提供給 LLM 進行檢索增強生成 (RAG)。",
        "en": "You need to convert product catalog text descriptions and images into vectors and provide them to an LLM for Retrieval-Augmented Generation (RAG).",
        "wg": []
      },
      {
        "t": "您應該使用哪兩項 Vertex AI 功能？(請選擇兩項)",
        "en": "Which two Vertex AI features should you use? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) Vertex AI Embeddings API (Multimodal)。",
        "en": "(A) Vertex AI Embeddings API (Multimodal).",
        "wg": []
      },
      {
        "t": "(B) Vertex AI Vector Search。",
        "en": "(B) Vertex AI Vector Search.",
        "wg": []
      },
      {
        "t": "(C) AutoML Vision。",
        "en": "(C) AutoML Vision.",
        "wg": []
      },
      {
        "t": "(D) BigQuery ML ARIMA 模型。",
        "en": "(D) BigQuery ML ARIMA model.",
        "wg": []
      },
      {
        "t": "(E) Dialogflow CX。",
        "en": "(E) Dialogflow CX.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "RAG 的核心流程是：1. 向量化：使用 Multimodal Embeddings API (A) 將產品文字和圖片轉換成同一個語意空間的向量。2. 檢索：將這些向量儲存在 Vertex AI Vector Search (B) 中，以便快速找出與使用者查詢最相似的產品。這兩者是構建該 AI 購物助手的基礎。",
      "en": "The core RAG process involves: 1. Vectorization: Use the Multimodal Embeddings API (A) to convert product text and images into vectors in the same semantic space. 2. Retrieval: Store these vectors in Vertex AI Vector Search (B) to quickly find products most similar to the user query. These two are the foundation for building the AI shopping assistant.",
      "wg": [
        {
          "t": "語意空間",
          "en": "semantic space",
          "ps": "N"
        },
        {
          "t": "基礎",
          "en": "foundation",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "108",
    "level": "medium",
    "keywords": "IAM, Organization Policy, Folder, Hierarchy",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的組織有多個部門，每個部門都有不同的合規要求。",
        "en": "Your organization has multiple departments, each with different compliance requirements.",
        "wg": []
      },
      {
        "t": "您希望在「財務部」資料夾下的所有專案都強制禁止使用外部 IP，但在「開發部」資料夾下的專案則允許。",
        "en": "You want to strictly enforce no external IPs for all projects under the \"Finance\" folder, but allow them for projects under the \"Development\" folder.",
        "wg": [
          {
            "t": "強制禁止",
            "en": "strictly enforce",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該如何設定組織政策？(請選擇兩項)",
        "en": "How should you configure the Organization Policies? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 在「財務部」資料夾層級，設定 `compute.vmExternalIpAccess` 為 Deny All。",
        "en": "(A) At the \"Finance\" folder level, set `compute.vmExternalIpAccess` to Deny All.",
        "wg": []
      },
      {
        "t": "(B) 在「開發部」資料夾層級，確保沒有設定該限制，或設定為 Allow All (繼承或覆寫)。",
        "en": "(B) At the \"Development\" folder level, ensure the constraint is not set, or set to Allow All (inherit or override).",
        "wg": [
          {
            "t": "繼承",
            "en": "inherit",
            "ps": "V"
          },
          {
            "t": "覆寫",
            "en": "override",
            "ps": "V"
          }
        ]
      },
      {
        "t": "(C) 在組織層級設定 Deny All，並在開發部專案中使用 IAM 允許。",
        "en": "(C) Set Deny All at the Organization level and use IAM to allow in Development projects.",
        "wg": []
      },
      {
        "t": "(D) 使用 VPC 防火牆規則來控制。",
        "en": "(D) Use VPC firewall rules to control this.",
        "wg": []
      },
      {
        "t": "(E) 在每個財務部專案中單獨設定政策。",
        "en": "(E) Configure policies individually in each Finance project.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "組織政策 (Organization Policy) 支援階層式繼承與覆寫。最佳實踐是利用資料夾 (Folders) 來分組具有相同合規需求的專案。在「財務部」資料夾層級強制 Deny (A)，而在「開發部」資料夾層級允許 (B)，這樣可以大規模管理且無需逐一設定專案，也比 IAM 更能從根本上控制資源配置。",
      "en": "Organization Policy supports hierarchical inheritance and overriding. The best practice is to use Folders to group projects with similar compliance needs. Enforcing Deny at the \"Finance\" folder level (A) and allowing it at the \"Development\" folder level (B) allows for scalable management without configuring each project individually, and it controls resource provisioning more fundamentally than IAM.",
      "wg": [
        {
          "t": "階層式",
          "en": "hierarchical",
          "ps": "Adj"
        },
        {
          "t": "大規模管理",
          "en": "scalable management",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "109",
    "level": "medium",
    "keywords": "Storage, Performance, GKE, Local SSD",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您在 GKE 上執行一個高效能的 NoSQL 資料庫 (如 Cassandra 或 MongoDB)，需要極高的 IOPS 和極低的延遲。",
        "en": "You are running a high-performance NoSQL database (like Cassandra or MongoDB) on GKE, requiring extremely high IOPS and ultra-low latency.",
        "wg": [
          {
            "t": "極高的",
            "en": "extremely high",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "資料庫本身負責處理數據的複製與高可用性 (Application-level Replication)。",
        "en": "The database itself handles data replication and high availability (Application-level Replication).",
        "wg": []
      },
      {
        "t": "您應該為 GKE 節點選擇哪種儲存配置？(請選擇兩項)",
        "en": "Which storage configuration should you choose for the GKE nodes? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 Local SSD。",
        "en": "(A) Use Local SSD.",
        "wg": []
      },
      {
        "t": "(B) 設定具有 NVMe 介面的機器類型。",
        "en": "(B) Configure machine types with NVMe interface.",
        "wg": []
      },
      {
        "t": "(C) 使用 Standard Persistent Disk (pd-standard)。",
        "en": "(C) Use Standard Persistent Disk (pd-standard).",
        "wg": []
      },
      {
        "t": "(D) 使用 Filestore Enterprise。",
        "en": "(D) Use Filestore Enterprise.",
        "wg": []
      },
      {
        "t": "(E) 使用 Cloud Storage FUSE。",
        "en": "(E) Use Cloud Storage FUSE.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Local SSD 直接連接到實體伺服器，提供比任何網路儲存 (如 PD) 更高的 IOPS 和更低的延遲。NVMe 介面能進一步釋放 SSD 的效能。由於資料庫本身處理了複製 (HA)，Local SSD 資料隨實例遺失的特性 (Ephemeral) 是可以接受的權衡，換取極致效能。",
      "en": "Local SSDs are directly attached to the physical server, offering higher IOPS and lower latency than any network storage (like PD). The NVMe interface further unlocks SSD performance. Since the database handles replication (HA) itself, the ephemeral nature of Local SSD data (lost with the instance) is an acceptable trade-off for ultimate performance.",
      "wg": [
        {
          "t": "釋放",
          "en": "unlock",
          "ps": "V"
        },
        {
          "t": "極致效能",
          "en": "ultimate performance",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "110",
    "level": "hard",
    "keywords": "Case Study, EHR Healthcare, HL7v2, Healthcare API, Pub/Sub",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 EHR Healthcare 個案研究。該公司需要構建一個系統來接收來自醫院的 HL7v2 訊息。",
        "en": "Refer to the EHR Healthcare case study. The company needs to build a system to ingest HL7v2 messages from hospitals.",
        "wg": []
      },
      {
        "t": "當接收到訊息時，系統需要：1. 將原始訊息儲存以符合合規要求。2. 將訊息轉換為 FHIR 格式以供應用程式使用。3. 如果轉換失敗，發送通知給維運團隊。",
        "en": "Upon receiving a message, the system needs to: 1. Store the raw message for compliance. 2. Convert the message to FHIR format for application use. 3. If conversion fails, send a notification to the operations team.",
        "wg": [
          {
            "t": "轉換",
            "en": "convert",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該結合哪兩項服務來實現此工作流程？(請選擇兩項)",
        "en": "Which two services should you combine to implement this workflow? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 Cloud Healthcare API 的 HL7v2 Store 和 Pub/Sub 通知。",
        "en": "(A) Use Cloud Healthcare API's HL7v2 Store and Pub/Sub notifications.",
        "wg": []
      },
      {
        "t": "(B) 使用 Cloud Functions 訂閱 Pub/Sub 通知來觸發轉換邏輯或處理錯誤。",
        "en": "(B) Use Cloud Functions subscribed to Pub/Sub notifications to trigger conversion logic or handle errors.",
        "wg": []
      },
      {
        "t": "(C) 使用 Dataproc 進行批次轉換。",
        "en": "(C) Use Dataproc for batch conversion.",
        "wg": []
      },
      {
        "t": "(D) 將所有訊息直接寫入 BigQuery。",
        "en": "(D) Write all messages directly to BigQuery.",
        "wg": []
      },
      {
        "t": "(E) 使用 Google Sheets 記錄錯誤。",
        "en": "(E) Use Google Sheets to log errors.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Cloud Healthcare API (A) 原生支援 HL7v2 儲存與解析，並能在訊息到達時發送 Pub/Sub 通知。Cloud Functions (B) 是一個完美的輕量級計算層，可以訂閱這些通知，呼叫 Healthcare API 進行 HL7v2 到 FHIR 的轉換，並在發生錯誤時發送警報 (例如寫入另一個 Pub/Sub 或呼叫 PagerDuty)。",
      "en": "Cloud Healthcare API (A) natively supports HL7v2 storage and parsing, and can send Pub/Sub notifications upon message arrival. Cloud Functions (B) is a perfect lightweight compute layer to subscribe to these notifications, call the Healthcare API to perform HL7v2 to FHIR conversion, and alert on errors (e.g., writing to another Pub/Sub or calling PagerDuty).",
      "wg": [
        {
          "t": "原生支援",
          "en": "natively support",
          "ps": "V"
        },
        {
          "t": "輕量級",
          "en": "lightweight",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "111",
    "level": "hard",
    "keywords": "Security, IAM, Conditional Access, Org Policy",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的組織有多個外包開發團隊，他們需要存取特定的 Compute Engine 實例。",
        "en": "Your organization has multiple outsourced development teams needing access to specific Compute Engine instances.",
        "wg": [
          {
            "t": "外包",
            "en": "outsourced",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "為了加強安全性，您希望限制他們只能在工作日 (週一至週五) 的上午 9 點到下午 6 點之間存取，且必須是從公司特定的 IP 範圍連線。",
        "en": "To enhance security, you want to restrict their access to only weekdays (Monday to Friday) between 9 AM and 6 PM, and they must connect from the company's specific IP range.",
        "wg": [
          {
            "t": "工作日",
            "en": "weekday",
            "ps": "N"
          },
          {
            "t": "IP 範圍",
            "en": "IP range",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該結合哪兩項設定來實現此需求？(請選擇兩項)",
        "en": "Which two configurations should you combine to fulfill this requirement? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 IAM Conditions 設定基於時間的存取限制。",
        "en": "(A) Use IAM Conditions to configure time-based access restrictions.",
        "wg": [
          {
            "t": "基於時間的",
            "en": "time-based",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "(B) 設定 Access Context Manager 建立存取層級 (Access Level)，定義允許的 IP 子網域。",
        "en": "(B) Configure Access Context Manager to create an Access Level defining allowed IP subnets.",
        "wg": [
          {
            "t": "存取層級",
            "en": "Access Level",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 使用 Cloud Armor 阻擋非公司 IP。",
        "en": "(C) Use Cloud Armor to block non-company IPs.",
        "wg": []
      },
      {
        "t": "(D) 設定 IAM Conditions 結合 `accessPolicies` 來參照 Access Level。",
        "en": "(D) Configure IAM Conditions combining `accessPolicies` to reference the Access Level.",
        "wg": [
          {
            "t": "參照",
            "en": "reference",
            "ps": "V"
          }
        ]
      },
      {
        "t": "(E) 在 VPC 防火牆規則中設定時間排程。",
        "en": "(E) Configure time schedules in VPC firewall rules.",
        "wg": []
      }
    ],
    "answer": "A, D",
    "why": {
      "t": "IAM Conditions 原生支援基於時間 (Time-based) 的條件 (A)。對於 IP 限制，IAM Conditions 本身不直接支援 IP 範圍，而是透過整合 Access Context Manager (BeyondCorp Enterprise 的一部分)。您需要在 Access Context Manager 中定義 Access Level (包含 IP 範圍)，然後在 IAM Conditions 中引用該 Access Level (D)。這是實現細緻化上下文感知存取 (Context-Aware Access) 的標準方法。",
      "en": "IAM Conditions natively support Time-based conditions (A). For IP restrictions, IAM Conditions do not support IP ranges directly but integrate with Access Context Manager (part of BeyondCorp Enterprise). You need to define an Access Level (containing IP ranges) in Access Context Manager and then reference that Access Level in the IAM Conditions (D). This is the standard method for implementing granular Context-Aware Access.",
      "wg": [
        {
          "t": "細緻化",
          "en": "granular",
          "ps": "Adj"
        },
        {
          "t": "上下文感知存取",
          "en": "Context-Aware Access",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "112",
    "level": "medium",
    "keywords": "Storage, Performance, Cost, Tiering",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的應用程式需要儲存使用者上傳的圖片。上傳後的前 24 小時內，圖片會被頻繁存取 (熱資料)。",
        "en": "Your application needs to store user-uploaded images. Within the first 24 hours of upload, images are accessed frequently (hot data).",
        "wg": [
          {
            "t": "熱資料",
            "en": "hot data",
            "ps": "N"
          }
        ]
      },
      {
        "t": "之後，存取頻率會急劇下降，但偶爾仍需被讀取 (溫資料)。一年後，圖片極少被存取，但需保留以供備份 (冷資料)。",
        "en": "After that, access frequency drops sharply, but they still need to be read occasionally (warm data). After one year, images are rarely accessed but must be retained for backup (cold data).",
        "wg": [
          {
            "t": "溫資料",
            "en": "warm data",
            "ps": "N"
          },
          {
            "t": "冷資料",
            "en": "cold data",
            "ps": "N"
          }
        ]
      },
      {
        "t": "為了在不犧牲效能的情況下最小化成本並自動化管理，您應該啟用哪兩個 Cloud Storage 功能？(請選擇兩項)",
        "en": "To minimize costs and automate management without sacrificing performance, which two Cloud Storage features should you enable? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 啟用 Autoclass。",
        "en": "(A) Enable Autoclass.",
        "wg": [
          {
            "t": "啟用",
            "en": "Enable",
            "ps": "V"
          }
        ]
      },
      {
        "t": "(B) 設定物件生命週期管理 (Object Lifecycle Management) 規則。",
        "en": "(B) Configure Object Lifecycle Management rules.",
        "wg": []
      },
      {
        "t": "(C) 使用 Nearline Storage 作為預設類別。",
        "en": "(C) Use Nearline Storage as the default class.",
        "wg": []
      },
      {
        "t": "(D) 使用 Standard Storage 作為預設類別。",
        "en": "(D) Use Standard Storage as the default class.",
        "wg": []
      },
      {
        "t": "(E) 實作 Cloud Functions 每天移動檔案。",
        "en": "(E) Implement Cloud Functions to move files daily.",
        "wg": []
      }
    ],
    "answer": "B, D",
    "why": {
      "t": "由於前 24 小時是「頻繁存取」，預設類別必須是 Standard (D) 以避免其他類別 (Nearline/Coldline) 的資料檢索費 (Retrieval Fees) 和最短存儲期限罰款。接著，使用生命週期管理規則 (B) 自動將超過 30 天的物件轉移至 Nearline，超過 365 天轉移至 Archive，這是最標準且具成本效益的模式。Autoclass (A) 雖然方便，但會收取管理費，對於這種「可預測」的生命週期，手動規則通常更便宜。",
      "en": "Since the first 24 hours involve \"frequent access,\" the default class must be Standard (D) to avoid data retrieval fees and minimum storage duration penalties associated with other classes (Nearline/Coldline). Then, use Lifecycle Management rules (B) to automatically transition objects older than 30 days to Nearline and older than 365 days to Archive. This is the most standard and cost-effective pattern. While Autoclass (A) is convenient, it incurs management fees; for such \"predictable\" lifecycles, manual rules are usually cheaper.",
      "wg": [
        {
          "t": "資料檢索費",
          "en": "Retrieval Fee",
          "ps": "N"
        },
        {
          "t": "罰款",
          "en": "penalty",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "113",
    "level": "hard",
    "keywords": "Case Study, Altostrat Media, Dataflow, Streaming, Windowing",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Altostrat Media 個案研究。該公司正在處理即時影片觀看數據，以計算每分鐘的熱門影片排名。",
        "en": "Refer to the Altostrat Media case study. The company is processing real-time video viewership data to calculate the top trending videos every minute.",
        "wg": [
          {
            "t": "熱門影片排名",
            "en": "top trending video ranking",
            "ps": "N"
          }
        ]
      },
      {
        "t": "由於網路延遲，部分使用者數據可能會晚到 (Late Data)。您需要確保排名計算能包含這些遲到的數據，但又不能無限期等待。",
        "en": "Due to network latency, some user data might arrive late (Late Data). You need to ensure the ranking calculation includes this late data but cannot wait indefinitely.",
        "wg": [
          {
            "t": "晚到",
            "en": "arrive late",
            "ps": "V"
          },
          {
            "t": "無限期",
            "en": "indefinitely",
            "ps": "Adv"
          }
        ]
      },
      {
        "t": "在 Dataflow 管道設計中，您應該使用哪兩個概念？(請選擇兩項)",
        "en": "In the Dataflow pipeline design, which two concepts should you use? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 滑動視窗 (Sliding Windows)。",
        "en": "(A) Sliding Windows.",
        "wg": []
      },
      {
        "t": "(B) 固定視窗 (Fixed/Tumbling Windows)。",
        "en": "(B) Fixed/Tumbling Windows.",
        "wg": []
      },
      {
        "t": "(C) 水印 (Watermarks) 與允許遲到數據 (Allowed Lateness)。",
        "en": "(C) Watermarks and Allowed Lateness.",
        "wg": [
          {
            "t": "水印",
            "en": "Watermark",
            "ps": "N"
          },
          {
            "t": "允許遲到數據",
            "en": "Allowed Lateness",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(D) 全域視窗 (Global Windows)。",
        "en": "(D) Global Windows.",
        "wg": []
      },
      {
        "t": "(E) 批次處理 (Batch Processing)。",
        "en": "(E) Batch Processing.",
        "wg": []
      }
    ],
    "answer": "B, C",
    "why": {
      "t": "計算「每分鐘」的排名通常使用固定視窗 (Fixed Windows) (B) 來將時間切片。為了處理遲到數據，Dataflow 使用水印 (Watermarks) 來推斷視窗何時「應該」結束，並結合 `Allowed Lateness` (C) 設定來定義視窗關閉後多久內仍接受遲到數據的更新 (觸發重新計算)，這是處理串流數據時間正確性的標準模式。",
      "en": "Calculating rankings \"every minute\" typically uses Fixed Windows (B) to slice time. To handle late data, Dataflow uses Watermarks to infer when a window \"should\" close, combined with `Allowed Lateness` (C) settings to define how long after the window closes to still accept late data updates (triggering recalculations). This is the standard pattern for handling time correctness in streaming data.",
      "wg": [
        {
          "t": "時間切片",
          "en": "slice time",
          "ps": "V"
        },
        {
          "t": "推斷",
          "en": "infer",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "114",
    "level": "medium",
    "keywords": "Networking, VPC, Shared VPC, IP Management",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在為一家大型企業設計 VPC 架構。該企業有數百個專案，分為多個部門。",
        "en": "You are designing a VPC architecture for a large enterprise. The enterprise has hundreds of projects divided into multiple departments.",
        "wg": []
      },
      {
        "t": "您希望集中管理 IP 位址空間和防火牆規則，同時賦予各部門專案部署資源 (如 VM) 的權限。",
        "en": "You want to centrally manage IP address space and firewall rules while granting departmental projects permission to deploy resources (like VMs).",
        "wg": [
          {
            "t": "集中管理",
            "en": "centrally manage",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該採取哪兩個行動？(請選擇兩項)",
        "en": "Which two actions should you take? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 建立一個宿主專案 (Host Project) 並啟用 Shared VPC。",
        "en": "(A) Create a Host Project and enable Shared VPC.",
        "wg": [
          {
            "t": "宿主專案",
            "en": "Host Project",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 將各部門的專案連結為服務專案 (Service Projects)。",
        "en": "(B) Attach departmental projects as Service Projects.",
        "wg": [
          {
            "t": "服務專案",
            "en": "Service Project",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 為每個專案建立獨立的 VPC 並使用 VPC Peering 互連。",
        "en": "(C) Create independent VPCs for each project and interconnect them using VPC Peering.",
        "wg": []
      },
      {
        "t": "(D) 將所有資源部署在單一專案中，使用標籤區分。",
        "en": "(D) Deploy all resources in a single project, distinguishing them with labels.",
        "wg": []
      },
      {
        "t": "(E) 授予各部門管理員在 Host Project 中的 `Network Admin` 角色。",
        "en": "(E) Grant departmental administrators the `Network Admin` role in the Host Project.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Shared VPC (共用 VPC) 是解決此需求的核心架構。您在宿主專案 (Host Project) (A) 中定義網路、子網域、路由和防火牆 (集中管理)。然後將業務專案連結為服務專案 (Service Projects) (B)，並授予業務團隊在特定子網域上的 `Compute Network User` 角色 (而非 Network Admin)，讓他們能使用 IP 但無法修改網路設定，實現職責分離。",
      "en": "Shared VPC is the core architecture for this requirement. You define networks, subnets, routes, and firewalls in a Host Project (A) (centralized management). Then, you attach business projects as Service Projects (B) and grant business teams the `Compute Network User` role on specific subnets (not Network Admin), allowing them to use IPs without modifying network settings, achieving separation of duties.",
      "wg": [
        {
          "t": "共用 VPC",
          "en": "Shared VPC",
          "ps": "N"
        },
        {
          "t": "職責分離",
          "en": "separation of duties",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "115",
    "level": "medium",
    "keywords": "Case Study, KnightMotives, Pub/Sub, Ordered Delivery, Dataflow",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 KnightMotives Automotive 個案研究。該公司正在開發一個車輛韌體更新 (OTA) 系統。",
        "en": "Refer to the KnightMotives Automotive case study. The company is developing a Vehicle Firmware Over-the-Air (OTA) update system.",
        "wg": [
          {
            "t": "車輛韌體更新",
            "en": "Vehicle Firmware Over-the-Air update",
            "ps": "N"
          }
        ]
      },
      {
        "t": "更新指令必須嚴格按照順序執行 (例如：下載 -> 驗證 -> 安裝 -> 重啟)。如果順序錯誤，車輛可能會變磚 (Bricked)。",
        "en": "Update commands must be executed in strict order (e.g., Download -> Verify -> Install -> Reboot). If the order is wrong, the vehicle might be bricked.",
        "wg": [
          {
            "t": "嚴格按照順序",
            "en": "strictly in order",
            "ps": "Adv"
          },
          {
            "t": "變磚",
            "en": "bricked",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您使用 Pub/Sub 傳遞這些指令。您應該啟用哪兩個功能來確保順序性？(請選擇兩項)",
        "en": "You use Pub/Sub to deliver these commands. Which two features should you enable to ensure ordering? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 在發布訊息時設定相同的 `ordering_key` (例如車輛 ID)。",
        "en": "(A) Set the same `ordering_key` (e.g., Vehicle ID) when publishing messages.",
        "wg": [
          {
            "t": "排序鍵",
            "en": "ordering_key",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 在訂閱 (Subscription) 上啟用訊息排序 (Message Ordering)。",
        "en": "(B) Enable Message Ordering on the Subscription.",
        "wg": [
          {
            "t": "訊息排序",
            "en": "Message Ordering",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 僅使用單一個 Pub/Sub 主題分區 (Partition)。",
        "en": "(C) Use only a single Pub/Sub topic partition.",
        "wg": []
      },
      {
        "t": "(D) 使用 Dataflow 進行重新排序 (Re-shuffling)。",
        "en": "(D) Use Dataflow for Re-shuffling.",
        "wg": []
      },
      {
        "t": "(E) 在接收端實作緩衝區手動排序。",
        "en": "(E) Implement manual buffering and sorting on the receiver side.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Pub/Sub 支援訊息排序 (Message Ordering)，但需要在兩個地方設定：1. 發布者必須在訊息中包含 `ordering_key` (A)，Pub/Sub 保證相同 Key 的訊息會按順序傳遞。2. 訂閱者必須在訂閱設定中啟用訊息排序 (B)。這樣無需複雜的 Dataflow 或客戶端邏輯，即可保證特定實體 (如單一車輛) 的訊息順序。",
      "en": "Pub/Sub supports Message Ordering, but it requires configuration in two places: 1. The publisher must include an `ordering_key` (A) in the message; Pub/Sub guarantees ordered delivery for messages with the same Key. 2. The subscriber must enable Message Ordering in the subscription settings (B). This guarantees message order for specific entities (like a single vehicle) without complex Dataflow or client-side logic.",
      "wg": [
        {
          "t": "保證",
          "en": "guarantee",
          "ps": "V"
        },
        {
          "t": "實體",
          "en": "entity",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "116",
    "level": "hard",
    "keywords": "GKE, Multi-cluster, MCP, Ingress",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您在美東 (us-east1) 和美西 (us-west1) 兩個區域各部署了一個 GKE 叢集。",
        "en": "You have deployed a GKE cluster in both us-east1 and us-west1 regions.",
        "wg": []
      },
      {
        "t": "您希望設定一個單一的負載平衡器，將流量分發到這兩個叢集，並實現多叢集服務 (Multi-Cluster Services) 的故障轉移。",
        "en": "You want to configure a single load balancer to distribute traffic to both clusters and enable Multi-Cluster Services failover.",
        "wg": [
          {
            "t": "多叢集服務",
            "en": "Multi-Cluster Services",
            "ps": "N"
          },
          {
            "t": "故障轉移",
            "en": "failover",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該使用哪兩個 GKE 功能？(請選擇兩項)",
        "en": "Which two GKE features should you use? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 多叢集閘道 (Multi-cluster Gateway) 控制器。",
        "en": "(A) Multi-cluster Gateway controller.",
        "wg": [
          {
            "t": "多叢集閘道",
            "en": "Multi-cluster Gateway",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 多叢集服務 (Multi-cluster Services, MCS)。",
        "en": "(B) Multi-cluster Services (MCS).",
        "wg": []
      },
      {
        "t": "(C) 使用 Kubemci 工具。",
        "en": "(C) Use the Kubemci tool.",
        "wg": []
      },
      {
        "t": "(D) 獨立為每個叢集設定 Ingress，並使用 Cloud DNS 進行輪詢。",
        "en": "(D) Configure Ingress independently for each cluster and use Cloud DNS round-robin.",
        "wg": []
      },
      {
        "t": "(E) 使用 VPC Network Peering 連接兩個叢集。",
        "en": "(E) Use VPC Network Peering to connect the two clusters.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Kubemci 已被棄用。現代 GKE 的標準做法是使用 GKE Gateway API。Multi-cluster Gateway (A) 允許您定義跨叢集的負載平衡規則 (如 Global Load Balancer)，將流量導向不同區域。Multi-cluster Services (B) 則負責跨叢集的服務發現 (Service Discovery) 和東西向流量，兩者結合提供了完整的跨區高可用性架構。",
      "en": "Kubemci is deprecated. The modern standard for GKE is using the GKE Gateway API. The Multi-cluster Gateway (A) allows you to define cross-cluster load balancing rules (like a Global Load Balancer) to route traffic to different regions. Multi-cluster Services (B) handles cross-cluster Service Discovery and east-west traffic. Combined, they provide a complete cross-region high-availability architecture.",
      "wg": [
        {
          "t": "被棄用",
          "en": "deprecated",
          "ps": "V"
        },
        {
          "t": "東西向流量",
          "en": "east-west traffic",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "117",
    "level": "medium",
    "keywords": "Security, Cloud Storage, Signed URL, App Engine",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的 App Engine 應用程式允許使用者上傳個人檔案。",
        "en": "Your App Engine application allows users to upload profile files.",
        "wg": []
      },
      {
        "t": "您希望使用者能直接將檔案上傳到 Cloud Storage，而不需要經過 App Engine 實例 (以節省頻寬和運算資源)。",
        "en": "You want users to upload files directly to Cloud Storage without passing through App Engine instances (to save bandwidth and compute resources).",
        "wg": [
          {
            "t": "經過",
            "en": "pass through",
            "ps": "V"
          }
        ]
      },
      {
        "t": "同時，您必須確保只有經過驗證的使用者才能上傳，且只能上傳到指定的路徑。",
        "en": "At the same time, you must ensure that only authenticated users can upload, and only to specified paths.",
        "wg": []
      },
      {
        "t": "您應該結合哪兩項技術？(請選擇兩項)",
        "en": "Which two technologies should you combine? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 在 App Engine 後端產生 Signed URLs (V4)。",
        "en": "(A) Generate Signed URLs (V4) in the App Engine backend.",
        "wg": [
          {
            "t": "簽署網址",
            "en": "Signed URL",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 將 Signed URL 提供給客戶端瀏覽器進行 `PUT` 上傳。",
        "en": "(B) Provide the Signed URL to the client browser for `PUT` upload.",
        "wg": []
      },
      {
        "t": "(C) 將 Cloud Storage Bucket 設為 `allUsers` 可寫入。",
        "en": "(C) Set the Cloud Storage Bucket to be writable by `allUsers`.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud Storage ACL 授權每個使用者的 Email。",
        "en": "(D) Use Cloud Storage ACLs to authorize each user's email.",
        "wg": []
      },
      {
        "t": "(E) 使用 Firebase Storage SDK。",
        "en": "(E) Use Firebase Storage SDK.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Signed URLs 是授權臨時上傳/下載權限的標準模式 (Valet Key Pattern)。App Engine 驗證使用者身分後，產生一個帶有簽章、過期時間和特定路徑權限的 URL (A)，然後回傳給客戶端。客戶端使用此 URL 直接對 GCS 進行上傳 (B)，無需透過後端轉發流量，既安全又高效。",
      "en": "Signed URLs are the standard pattern for authorizing temporary upload/download permissions (Valet Key Pattern). After App Engine authenticates the user, it generates a URL with a signature, expiration time, and specific path permissions (A) and returns it to the client. The client uses this URL to upload directly to GCS (B), avoiding backend traffic forwarding, which is both secure and efficient.",
      "wg": [
        {
          "t": "代客泊車鑰匙模式",
          "en": "Valet Key Pattern",
          "ps": "N"
        },
        {
          "t": "轉發",
          "en": "forward",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "118",
    "level": "medium",
    "keywords": "Case Study, Cymbal Retail, Spanner, Schema Design, Performance",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Cymbal Retail 個案研究。該公司正在設計 Cloud Spanner 資料庫來儲存歷史訂單。",
        "en": "Refer to the Cymbal Retail case study. The company is designing a Cloud Spanner database to store historical orders.",
        "wg": []
      },
      {
        "t": "訂單表的主鍵 (Primary Key) 目前設計為 `OrderID`，這是一個遞增的整數 (1, 2, 3...)。",
        "en": "The Primary Key of the Orders table is currently designed as `OrderID`, which is a monotonically increasing integer (1, 2, 3...).",
        "wg": [
          {
            "t": "遞增的",
            "en": "monotonically increasing",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "開發人員擔心這會導致寫入效能問題 (Hotspotting)。您應該建議哪兩種解決方案？(請選擇兩項)",
        "en": "Developers are concerned this will cause write performance issues (Hotspotting). Which two solutions should you recommend? (Choose two)",
        "wg": [
          {
            "t": "熱點問題",
            "en": "Hotspotting",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 UUID Version 4 作為 Primary Key。",
        "en": "(A) Use UUID Version 4 as the Primary Key.",
        "wg": []
      },
      {
        "t": "(B) 對 `OrderID` 進行位元反轉 (Bit-reverse)。",
        "en": "(B) Bit-reverse the `OrderID`.",
        "wg": [
          {
            "t": "位元反轉",
            "en": "Bit-reverse",
            "ps": "V"
          }
        ]
      },
      {
        "t": "(C) 使用時間戳記 (Timestamp) 作為 Primary Key。",
        "en": "(C) Use Timestamp as the Primary Key.",
        "wg": []
      },
      {
        "t": "(D) 建立一個輔助索引 (Secondary Index)。",
        "en": "(D) Create a Secondary Index.",
        "wg": []
      },
      {
        "t": "(E) 增加 Spanner 節點數量。",
        "en": "(E) Increase the number of Spanner nodes.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Spanner 會根據 Primary Key 的範圍將數據分片 (Split)。如果使用遞增整數或時間戳記，所有新寫入都會集中在同一個 Split (即同一個節點) 的末端，造成熱點 (Hotspot)，無法利用分散式系統的平行寫入能力。使用 UUIDv4 (A) 或位元反轉 (B) 可以將寫入隨機打散到整個 Key Space，從而均勻分佈負載。",
      "en": "Spanner splits data based on Primary Key ranges. If using increasing integers or timestamps, all new writes concentrate at the end of the same Split (i.e., the same node), causing a Hotspot and failing to leverage the distributed system's parallel write capabilities. Using UUIDv4 (A) or Bit-reversing (B) randomizes writes across the entire Key Space, evenly distributing the load.",
      "wg": [
        {
          "t": "分片",
          "en": "Split",
          "ps": "N"
        },
        {
          "t": "均勻分佈",
          "en": "evenly distribute",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "119",
    "level": "medium",
    "keywords": "Compute Engine, Availability, Maintenance, Live Migration",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的應用程式運行在 Compute Engine 上，且不是叢集架構 (單一實例)。",
        "en": "Your application runs on Compute Engine and is not clustered (single instance).",
        "wg": []
      },
      {
        "t": "您希望在 Google 進行定期基礎設施維護 (Infrastructure Maintenance) 時，該 VM 能保持運行而不重啟。",
        "en": "You want the VM to remain running without rebooting during Google's periodic Infrastructure Maintenance.",
        "wg": [
          {
            "t": "基礎設施維護",
            "en": "Infrastructure Maintenance",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該確認哪兩項設定？(請選擇兩項)",
        "en": "Which two settings should you confirm? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 將「主機維護期間 (On host maintenance)」設定為 `MIGRATE` (即時遷移)。",
        "en": "(A) Set \"On host maintenance\" to `MIGRATE` (Live Migration).",
        "wg": [
          {
            "t": "即時遷移",
            "en": "Live Migration",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 確保該 VM 沒有使用 GPU 或 Local SSD (除非是特定支援的類型)。",
        "en": "(B) Ensure the VM does not use GPUs or Local SSDs (unless specific supported types).",
        "wg": []
      },
      {
        "t": "(C) 將「自動重新啟動 (Automatic restart)」設定為 `OFF`。",
        "en": "(C) Set \"Automatic restart\" to `OFF`.",
        "wg": []
      },
      {
        "t": "(D) 使用先佔 (Spot) 實例。",
        "en": "(D) Use Spot instances.",
        "wg": []
      },
      {
        "t": "(E) 設定快照排程。",
        "en": "(E) Configure a snapshot schedule.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Google Cloud 的 Live Migration 功能允許 VM 在主機維護期間無縫轉移到另一台主機，應用程式幾乎無感 (A)。然而，某些硬體配置 (如附加了 GPU 或傳統 Local SSD) 傳統上不支援 Live Migration (必須設為 Terminate)。雖然新一代 Local SSD 已開始支援，但在考試情境中，避開不支援的硬體限制 (B) 是確保 Live Migration 成功的關鍵條件。",
      "en": "Google Cloud's Live Migration feature allows VMs to seamlessly transfer to another host during maintenance with virtually no application impact (A). However, certain hardware configurations (like attached GPUs or traditional Local SSDs) historically do not support Live Migration (must be set to Terminate). While newer Local SSDs support it, avoiding unsupported hardware constraints (B) is a key condition for successful Live Migration in exam scenarios.",
      "wg": [
        {
          "t": "無感",
          "en": "no impact",
          "ps": "N"
        },
        {
          "t": "限制",
          "en": "constraint",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "120",
    "level": "medium",
    "keywords": "Security, Cloud Build, Service Account, IAM",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在使用 Cloud Build 部署資源到 App Engine。",
        "en": "You are using Cloud Build to deploy resources to App Engine.",
        "wg": []
      },
      {
        "t": "預設的 Cloud Build Service Account 權限過大，您希望遵循最小權限原則。",
        "en": "The default Cloud Build Service Account has overly broad permissions, and you want to follow the principle of least privilege.",
        "wg": []
      },
      {
        "t": "您應該採取哪兩個步驟？(請選擇兩項)",
        "en": "Which two steps should you take? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 建立一個使用者管理的服務帳號 (User-managed Service Account)，並僅授予 `appengine.appAdmin` 和 `storage.objectViewer` 等必要角色。",
        "en": "(A) Create a User-managed Service Account and grant only necessary roles like `appengine.appAdmin` and `storage.objectViewer`.",
        "wg": [
          {
            "t": "使用者管理的服務帳號",
            "en": "User-managed Service Account",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 在 Cloud Build 的觸發器 (Trigger) 設定中，指定使用該自訂服務帳號。",
        "en": "(B) In the Cloud Build Trigger settings, specify to use this custom Service Account.",
        "wg": []
      },
      {
        "t": "(C) 修改預設 Cloud Build 服務帳號的權限，移除 Editor 角色。",
        "en": "(C) Modify permissions of the default Cloud Build Service Account, removing the Editor role.",
        "wg": []
      },
      {
        "t": "(D) 將 App Engine 部署權限授予 Compute Engine 預設服務帳號。",
        "en": "(D) Grant App Engine deployment permissions to the Compute Engine default Service Account.",
        "wg": []
      },
      {
        "t": "(E) 在 `cloudbuild.yaml` 中寫死服務帳號金鑰。",
        "en": "(E) Hardcode the Service Account key in `cloudbuild.yaml`.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "最佳實踐是避免使用預設服務帳號 (因為它們通常具有 Editor 等寬鬆權限)。正確做法是建立一個專用的自訂服務帳號，並僅授予部署所需的最小權限 (A)。然後，在 Cloud Build 觸發器或提交建置時，明確指定使用這個身分 (B)，而非預設身分。",
      "en": "Best practice is to avoid using default Service Accounts (as they often have broad permissions like Editor). The correct approach is to create a dedicated custom Service Account and grant only the minimum permissions required for deployment (A). Then, explicitly specify this identity (B) in the Cloud Build Trigger or build submission, instead of the default identity.",
      "wg": [
        {
          "t": "寬鬆權限",
          "en": "broad permissions",
          "ps": "N"
        },
        {
          "t": "明確指定",
          "en": "explicitly specify",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "121",
    "level": "hard",
    "keywords": "Networking, BGP, Cloud Router, Route Priority",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的企業使用 Dedicated Interconnect 連接本地資料中心與 Google Cloud。",
        "en": "Your enterprise uses Dedicated Interconnect to connect the on-premises data center to Google Cloud.",
        "wg": []
      },
      {
        "t": "您還配置了一條 Cloud VPN 通道作為備援 (Backup)。",
        "en": "You have also configured a Cloud VPN tunnel as a backup.",
        "wg": [
          {
            "t": "備援",
            "en": "backup",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您希望確保在正常情況下，所有流量都優先使用 Interconnect，只有在 Interconnect 故障時才切換到 VPN。您應該如何設定 BGP？(請選擇兩項)",
        "en": "You want to ensure that under normal circumstances, all traffic prioritizes the Interconnect, switching to VPN only if the Interconnect fails. How should you configure BGP? (Choose two)",
        "wg": [
          {
            "t": "優先使用",
            "en": "prioritize",
            "ps": "V"
          }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 對於從 Google Cloud 到本地的流量，在 Cloud Router 上為 VPN 通道設定較低的 MED (Multi-Exit Discriminator) 值。",
        "en": "(A) For traffic from Google Cloud to on-premises, configure a lower MED (Multi-Exit Discriminator) value for the VPN tunnel on Cloud Router.",
        "wg": []
      },
      {
        "t": "(B) 對於從 Google Cloud 到本地的流量，在 Cloud Router 上為 VPN 通道設定較低的路由優先級 (Route Priority) (即較高的數值)。",
        "en": "(B) For traffic from Google Cloud to on-premises, configure a lower Route Priority (i.e., higher number) for the VPN tunnel on Cloud Router.",
        "wg": [
          {
            "t": "路由優先級",
            "en": "Route Priority",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 對於從本地到 Google Cloud的流量，在本地路由器上為 VPN 路徑設定較長的 AS Path (AS Prepending) 或較低的 Local Preference。",
        "en": "(C) For traffic from on-premises to Google Cloud, configure a longer AS Path (AS Prepending) or lower Local Preference for the VPN path on the on-premises router.",
        "wg": [
          {
            "t": "AS 路徑前置",
            "en": "AS Prepending",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(D) 停用 VPN 通道的動態路由，改用靜態路由。",
        "en": "(D) Disable dynamic routing for the VPN tunnel and use static routing instead.",
        "wg": []
      },
      {
        "t": "(E) 在 Cloud Router 上將 Interconnect 的基本優先級 (Base Priority) 設為 200，VPN 設為 100。",
        "en": "(E) Set the Base Priority of Interconnect to 200 and VPN to 100 on Cloud Router.",
        "wg": []
      }
    ],
    "answer": "B, C",
    "why": {
      "t": "路由是雙向的。1. Google 到本地 (Egress)：Cloud Router 使用「路由優先級 (Route Priority/MED)」來決定出口。數值越小優先級越高。因此，應確保 Interconnect 的優先級數值小於 VPN (或 VPN 的數值較大/優先級較低) (B)。2. 本地到 Google (Ingress)：需要控制本地路由器的選擇。通常透過 AS Prepending (讓 VPN 路徑看起來更長) 或調整 Local Preference 來讓本地路由器偏好 Interconnect (C)。",
      "en": "Routing is bidirectional. 1. Google to On-premises (Egress): Cloud Router uses \"Route Priority (MED)\" to decide the exit. Lower values mean higher priority. Thus, ensure Interconnect has a smaller priority value than VPN (or VPN has a larger number/lower priority) (B). 2. On-premises to Google (Ingress): You need to influence the on-premises router's choice. Typically, this is done via AS Prepending (making the VPN path look longer) or adjusting Local Preference so the on-premises router prefers Interconnect (C).",
      "wg": [
        {
          "t": "數值越小優先級越高",
          "en": "lower value means higher priority",
          "ps": "Phrase"
        }
      ]
    }
  },
  {
    "no": "122",
    "level": "medium",
    "keywords": "GKE, Autopilot, Security, Restriction",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在評估使用 GKE Autopilot 模式來簡化叢集管理。",
        "en": "You are evaluating using GKE Autopilot mode to simplify cluster management.",
        "wg": []
      },
      {
        "t": "然而，您的某些工作負載具有特殊需求。以下哪兩種情境 **不適合** 或 **不支援** 使用 GKE Autopilot？(請選擇兩項)",
        "en": "However, some of your workloads have special requirements. Which two scenarios are **NOT suitable** or **NOT supported** on GKE Autopilot? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 需要使用 SSH 登入底層節點進行除錯。",
        "en": "(A) Need to SSH into underlying nodes for debugging.",
        "wg": [
          {
            "t": "底層節點",
            "en": "underlying node",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 需要使用特權容器 (Privileged Containers) 修改核心參數。",
        "en": "(B) Need to use Privileged Containers to modify kernel parameters.",
        "wg": [
          {
            "t": "特權容器",
            "en": "Privileged Container",
            "ps": "N"
          },
          {
            "t": "核心參數",
            "en": "kernel parameter",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 需要使用 Horizontal Pod Autoscaler (HPA)。",
        "en": "(C) Need to use Horizontal Pod Autoscaler (HPA).",
        "wg": []
      },
      {
        "t": "(D) 需要使用 Spot Pods 來節省成本。",
        "en": "(D) Need to use Spot Pods to save costs.",
        "wg": []
      },
      {
        "t": "(E) 需要與 Cloud Logging 和 Monitoring 整合。",
        "en": "(E) Need integration with Cloud Logging and Monitoring.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "GKE Autopilot 為了確保安全性與穩定性，鎖定了底層基礎架構。它禁止使用者 SSH 登入節點 (A) (因為節點由 Google 管理)，也禁止大多數特權容器 (Privileged Containers) (B) 或修改 Linux 核心功能的行為。這與 GKE Standard 允許完全控制節點形成對比。HPA、Spot Pods 和 Cloud Operations 都是 Autopilot 支援且鼓勵使用的功能。",
      "en": "To ensure security and stability, GKE Autopilot locks down the underlying infrastructure. It prohibits users from SSHing into nodes (A) (as nodes are managed by Google) and disallows most Privileged Containers (B) or actions that modify Linux kernel capabilities. This contrasts with GKE Standard, which allows full node control. HPA, Spot Pods, and Cloud Operations are all supported and encouraged features in Autopilot.",
      "wg": [
        {
          "t": "鎖定",
          "en": "lock down",
          "ps": "V"
        },
        {
          "t": "形成對比",
          "en": "contrast with",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "123",
    "level": "medium",
    "keywords": "Cloud Run, Sidecar, Proxy, Architecture",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您正在將一個使用傳統架構的微服務遷移到 Cloud Run。",
        "en": "You are migrating a microservice with a traditional architecture to Cloud Run.",
        "wg": []
      },
      {
        "t": "該服務需要一個本地執行的代理 (Local Proxy) 來處理與舊版資料庫的加密連線，且該代理必須與主應用程式共享相同的 localhost 網路介面。",
        "en": "The service requires a locally running proxy to handle encrypted connections to a legacy database, and the proxy must share the same localhost network interface with the main application.",
        "wg": [
          {
            "t": "本地執行的代理",
            "en": "locally running proxy",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該如何設定 Cloud Run 服務？(請選擇兩項)",
        "en": "How should you configure the Cloud Run service? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 啟用 Cloud Run 的多容器 (Sidecar) 支援。",
        "en": "(A) Enable Cloud Run multi-container (Sidecar) support.",
        "wg": [
          {
            "t": "多容器",
            "en": "multi-container",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 在 YAML 配置中定義兩個容器：一個是應用程式，一個是代理。",
        "en": "(B) Define two containers in the YAML configuration: one for the application and one for the proxy.",
        "wg": []
      },
      {
        "t": "(C) 將兩個程序打包在同一個 Docker 映像檔中，並使用 Supervisord 啟動。",
        "en": "(C) Package both processes in a single Docker image and use Supervisord to start them.",
        "wg": [
          {
            "t": "程序",
            "en": "process",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(D) 使用 VPC Connector 來模擬 localhost。",
        "en": "(D) Use VPC Connector to simulate localhost.",
        "wg": []
      },
      {
        "t": "(E) 部署兩個獨立的 Cloud Run 服務並通過 HTTPS 通訊。",
        "en": "(E) Deploy two separate Cloud Run services and communicate via HTTPS.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Cloud Run 現在支援多容器 (Multi-container) 部署 (Sidecar 模式) (A)。這允許您在同一個服務實例中定義多個容器 (B)，它們共享相同的網路命名空間 (Network Namespace)，因此可以透過 `localhost` 互相通訊。這比將多個程序塞進一個容器 (C) 更符合雲端原生最佳實踐 (解耦與單一職責)。",
      "en": "Cloud Run now supports multi-container deployment (Sidecar pattern) (A). This allows you to define multiple containers within the same service instance (B). They share the same Network Namespace, enabling communication via `localhost`. This aligns better with cloud-native best practices (decoupling and single responsibility) than stuffing multiple processes into a single container (C).",
      "wg": [
        {
          "t": "解耦",
          "en": "decouple",
          "ps": "V"
        },
        {
          "t": "單一職責",
          "en": "single responsibility",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "124",
    "level": "medium",
    "keywords": "Cost Optimization, BigQuery, Slot, Flex Slots",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的團隊使用 BigQuery 進行資料分析。工作負載在月底結算時會激增，其餘時間則很低。",
        "en": "Your team uses BigQuery for data analytics. The workload spikes during month-end closing and is low the rest of the time.",
        "wg": [
          {
            "t": "月底結算",
            "en": "month-end closing",
            "ps": "N"
          },
          {
            "t": "激增",
            "en": "spike",
            "ps": "V"
          }
        ]
      },
      {
        "t": "目前的「隨選 (On-demand)」計費模式在月底時成本過高，且查詢速度受限。",
        "en": "The current \"On-demand\" billing model is too expensive during month-end and query speed is limited.",
        "wg": [
          {
            "t": "隨選",
            "en": "On-demand",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您希望在月底獲得可預測的效能並控制成本。您應該採取哪兩個行動？(請選擇兩項)",
        "en": "You want predictable performance and cost control during month-end. Which two actions should you take? (Choose two)",
        "wg": [
          {
            "t": "可預測的效能",
            "en": "predictable performance",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 切換到 BigQuery Editions (如 Standard 或 Enterprise)。",
        "en": "(A) Switch to BigQuery Editions (e.g., Standard or Enterprise).",
        "wg": [
          {
            "t": "版本",
            "en": "Edition",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 設定 Slot Autoscaling，並設定最大 Slot 上限。",
        "en": "(B) Configure Slot Autoscaling and set a maximum Slot limit.",
        "wg": [
          {
            "t": "插槽自動擴充",
            "en": "Slot Autoscaling",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 購買 1 年期的固定 Slot 承諾。",
        "en": "(C) Purchase a 1-year fixed Slot commitment.",
        "wg": []
      },
      {
        "t": "(D) 繼續使用 On-demand 模式，但最佳化 SQL 查詢。",
        "en": "(D) Continue using On-demand mode but optimize SQL queries.",
        "wg": []
      },
      {
        "t": "(E) 為每位分析師建立單獨的專案。",
        "en": "(E) Create separate projects for each analyst.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "BigQuery 已推出 Editions (A) 來取代舊的 Flat-rate。對於波動大的負載，使用 Editions 搭配 Autoscaling (B) 是最佳選擇。它允許系統在月底自動增加 Slot 以滿足效能需求 (解決速度受限)，同時透過設定上限來控制預算。購買 1 年承諾 (C) 對於僅在月底使用的場景來說會導致其他時間的浪費。",
      "en": "BigQuery introduced Editions (A) to replace the old Flat-rate model. For fluctuating workloads, using Editions with Autoscaling (B) is the best choice. It allows the system to automatically scale up Slots during month-end to meet performance needs (solving speed limits) while controlling the budget via a cap. Purchasing a 1-year commitment (C) would result in waste during non-peak times.",
      "wg": [
        {
          "t": "波動大",
          "en": "fluctuating",
          "ps": "Adj"
        },
        {
          "t": "上限",
          "en": "cap / limit",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "125",
    "level": "medium",
    "keywords": "Case Study, Cymbal Retail, Cloud Deploy, Skaffold, GKE",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Cymbal Retail 個案研究。開發團隊希望標準化 GKE 應用程式的部署流程，橫跨開發 (Dev)、預備 (Staging) 和生產 (Prod) 環境。",
        "en": "Refer to the Cymbal Retail case study. The development team wants to standardize the deployment process for GKE applications across Dev, Staging, and Prod environments.",
        "wg": [
          {
            "t": "標準化",
            "en": "standardize",
            "ps": "V"
          }
        ]
      },
      {
        "t": "他們希望能夠追蹤每個發布版本的狀態，並支援一鍵核准 (Approval) 和復原 (Rollback)。",
        "en": "They want to track the status of each release and support one-click Approval and Rollback.",
        "wg": [
          {
            "t": "一鍵核准",
            "en": "one-click Approval",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該結合哪兩項工具？(請選擇兩項)",
        "en": "Which two tools should you combine? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) Google Cloud Deploy。",
        "en": "(A) Google Cloud Deploy.",
        "wg": []
      },
      {
        "t": "(B) Skaffold。",
        "en": "(B) Skaffold.",
        "wg": []
      },
      {
        "t": "(C) Jenkins。",
        "en": "(C) Jenkins.",
        "wg": []
      },
      {
        "t": "(D) Spinnaker。",
        "en": "(D) Spinnaker.",
        "wg": []
      },
      {
        "t": "(E) Cloud Build 觸發器。",
        "en": "(E) Cloud Build Triggers.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Google Cloud Deploy 是全託管的持續交付服務，專為 GKE 和 Cloud Run 設計。它使用 Skaffold (B) 作為底層設定檔格式來定義渲染和部署邏輯。Cloud Deploy (A) 提供了管道視覺化、發布追蹤、手動核准閘門 (Approval Gates) 和復原功能，完全滿足標準化與治理需求。",
      "en": "Google Cloud Deploy is a fully managed continuous delivery service designed for GKE and Cloud Run. It uses Skaffold (B) as the underlying configuration format to define rendering and deployment logic. Cloud Deploy (A) provides pipeline visualization, release tracking, manual Approval Gates, and rollback capabilities, fully meeting standardization and governance needs.",
      "wg": [
        {
          "t": "持續交付",
          "en": "continuous delivery",
          "ps": "N"
        },
        {
          "t": "治理",
          "en": "governance",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "126",
    "level": "hard",
    "keywords": "Security, Compliance, Key Management, EKM",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的客戶要求擁有對雲端資料加密金鑰的絕對控制權。",
        "en": "Your client demands absolute control over cloud data encryption keys.",
        "wg": [
          {
            "t": "絕對控制權",
            "en": "absolute control",
            "ps": "N"
          }
        ]
      },
      {
        "t": "即使是 Cloud KMS 也不應儲存金鑰材料 (Key Material)。金鑰必須保留在第三方金鑰管理系統中，且在解密時，金鑰材料不得傳輸給 Google。",
        "en": "Even Cloud KMS should not store Key Material. Keys must remain in a third-party key management system, and Key Material must not be transferred to Google during decryption.",
        "wg": [
          {
            "t": "金鑰材料",
            "en": "Key Material",
            "ps": "N"
          }
        ]
      },
      {
        "t": "這是非常嚴格的要求。您應該推薦哪種解決方案？",
        "en": "This is a very strict requirement. Which solution should you recommend?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud KMS 搭配 Cloud HSM。",
        "en": "(A) Cloud KMS with Cloud HSM.",
        "wg": []
      },
      {
        "t": "(B) Cloud EKM (External Key Manager) 透過網際網路連接。",
        "en": "(B) Cloud EKM (External Key Manager) connected via the internet.",
        "wg": []
      },
      {
        "t": "(C) Cloud EKM 搭配 Key Access Justifications (KAJ)。",
        "en": "(C) Cloud EKM with Key Access Justifications (KAJ).",
        "wg": []
      },
      {
        "t": "(D) 客戶提供的加密金鑰 (CSEK)。",
        "en": "(D) Customer-Supplied Encryption Keys (CSEK).",
        "wg": []
      }
    ],
    "answer": "B",
    "why": {
      "t": "注意題目：金鑰材料**不得傳輸**給 Google。Cloud EKM (B) 允許 Google Cloud 服務透過 API 呼叫外部系統進行加解密操作，金鑰本身永遠留在外部系統中。CSEK (D) 雖然也是客戶提供，但金鑰會被傳送到 Google 的記憶體中短暫使用，不符合「不得傳輸」的嚴格定義。KAJ (C) 是關於存取理由，與金鑰位置無直接關係，但 EKM 是基礎。",
      "en": "Note the question: Key Material must **not be transferred** to Google. Cloud EKM (B) allows Google Cloud services to call an external system via API for encryption/decryption operations; the key itself stays in the external system. CSEK (D), while customer-supplied, involves sending the key to Google's memory for temporary use, which fails the strict \"no transfer\" requirement. KAJ (C) is about access justification, not directly about key location, though EKM is the foundation.",
      "wg": [
        {
          "t": "短暫使用",
          "en": "temporary use",
          "ps": "N"
        },
        {
          "t": "嚴格定義",
          "en": "strict definition",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "127",
    "level": "medium",
    "keywords": "Case Study, EHR Healthcare, DICOM, Healthcare API, Storage",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 EHR Healthcare 個案研究。醫生需要低延遲地存取高解析度的 X 光片和 MRI 影像 (DICOM 格式)。",
        "en": "Refer to the EHR Healthcare case study. Doctors need low-latency access to high-resolution X-rays and MRI images (DICOM format).",
        "wg": [
          {
            "t": "高解析度",
            "en": "high-resolution",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "這些影像目前儲存在本地的 PACS 系統中。您需要將其遷移到雲端，並提供符合 DICOMweb 標準的介面。",
        "en": "These images are currently stored in an on-premises PACS system. You need to migrate them to the cloud and provide a DICOMweb standard-compliant interface.",
        "wg": [
          {
            "t": "符合",
            "en": "compliant",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您應該結合哪兩項服務？(請選擇兩項)",
        "en": "Which two services should you combine? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) Cloud Healthcare API 的 DICOM Store。",
        "en": "(A) Cloud Healthcare API's DICOM Store.",
        "wg": []
      },
      {
        "t": "(B) Cloud Storage FUSE。",
        "en": "(B) Cloud Storage FUSE.",
        "wg": []
      },
      {
        "t": "(C) 醫療影像分析套件 (Medical Imaging Suite)。",
        "en": "(C) Medical Imaging Suite.",
        "wg": []
      },
      {
        "t": "(D) 使用 Transfer Appliance 進行初始遷移。",
        "en": "(D) Use Transfer Appliance for initial migration.",
        "wg": []
      },
      {
        "t": "(E) BigQuery。",
        "en": "(E) BigQuery.",
        "wg": []
      }
    ],
    "answer": "A, C",
    "why": {
      "t": "Cloud Healthcare API 的 DICOM Store (A) 是核心服務，提供託管的 DICOM 儲存與 DICOMweb API。Medical Imaging Suite (C) 是 Google Cloud 針對醫療影像的完整解決方案，整合了 Healthcare API 並提供優化的檢視器 (Viewer) 支援和 AI 輔助診斷能力，能滿足醫生對效能與功能的期待。",
      "en": "Cloud Healthcare API's DICOM Store (A) is the core service, providing managed DICOM storage and DICOMweb APIs. The Medical Imaging Suite (C) is Google Cloud's comprehensive solution for medical imaging, integrating the Healthcare API and offering optimized viewer support and AI-assisted diagnostic capabilities, meeting doctors' expectations for performance and functionality.",
      "wg": [
        {
          "t": "完整解決方案",
          "en": "comprehensive solution",
          "ps": "N"
        },
        {
          "t": "輔助診斷",
          "en": "assisted diagnostic",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "128",
    "level": "medium",
    "keywords": "Networking, CDN, Signed Cookie, Security",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的媒體串流應用程式使用 Cloud CDN 來分發付費影片內容。",
        "en": "Your media streaming application uses Cloud CDN to distribute paid video content.",
        "wg": []
      },
      {
        "t": "您需要防止使用者分享影片連結給未付費的人。由於影片由數百個小片段 (TS files) 組成，為每個檔案產生 Signed URL 不切實際。",
        "en": "You need to prevent users from sharing video links with non-paying individuals. Since the video consists of hundreds of small segments (TS files), generating a Signed URL for each file is impractical.",
        "wg": [
          {
            "t": "不切實際",
            "en": "impractical",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您應該使用哪種方法來保護內容？",
        "en": "Which method should you use to protect the content?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud CDN Signed Cookies。",
        "en": "(A) Use Cloud CDN Signed Cookies.",
        "wg": [
          {
            "t": "簽署 Cookie",
            "en": "Signed Cookie",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 設定 Cloud Armor IP 白名單。",
        "en": "(B) Configure Cloud Armor IP allowlist.",
        "wg": []
      },
      {
        "t": "(C) 使用 Identity-Aware Proxy (IAP)。",
        "en": "(C) Use Identity-Aware Proxy (IAP).",
        "wg": []
      },
      {
        "t": "(D) 要求使用者透過 VPN 連線。",
        "en": "(D) Require users to connect via VPN.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Signed URL 適合單一檔案下載。對於像 HLS/DASH 這種包含大量片段的串流媒體，Signed Cookies 是最佳選擇。您只需驗證使用者一次，發給一個 Signed Cookie，該 Cookie 允許使用者在一段時間內存取具有特定 URL 前綴 (Prefix) 的所有檔案，既安全又高效。",
      "en": "Signed URLs are suitable for single file downloads. For streaming media like HLS/DASH containing many segments, Signed Cookies are the best choice. You verify the user once, issue a Signed Cookie, and that cookie allows access to all files with a specific URL prefix for a period of time, offering both security and efficiency.",
      "wg": [
        {
          "t": "前綴",
          "en": "Prefix",
          "ps": "N"
        },
        {
          "t": "片段",
          "en": "segment",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "129",
    "level": "medium",
    "keywords": "Case Study, KnightMotives, Machine Learning, Vertex AI Pipelines",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 KnightMotives Automotive 個案研究。資料科學團隊希望將他們的自動駕駛訓練模型從筆記型電腦遷移到雲端，並建立自動化的再訓練管道 (Retraining Pipeline)。",
        "en": "Refer to the KnightMotives Automotive case study. The data science team wants to migrate their autonomous driving training models from laptops to the cloud and build an automated Retraining Pipeline.",
        "wg": [
          {
            "t": "再訓練管道",
            "en": "Retraining Pipeline",
            "ps": "N"
          }
        ]
      },
      {
        "t": "他們希望能夠版本化每一各步驟 (預處理、訓練、評估)，並追蹤資料的血緣關係 (Lineage)。",
        "en": "They want to version each step (preprocessing, training, evaluation) and track data Lineage.",
        "wg": [
          {
            "t": "血緣關係",
            "en": "Lineage",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該推薦使用哪兩個組件？(請選擇兩項)",
        "en": "Which two components should you recommend? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) Vertex AI Pipelines。",
        "en": "(A) Vertex AI Pipelines.",
        "wg": []
      },
      {
        "t": "(B) Vertex AI Metadata。",
        "en": "(B) Vertex AI Metadata.",
        "wg": []
      },
      {
        "t": "(C) Cloud Composer (Airflow)。",
        "en": "(C) Cloud Composer (Airflow).",
        "wg": []
      },
      {
        "t": "(D) Cloud Build。",
        "en": "(D) Cloud Build.",
        "wg": []
      },
      {
        "t": "(E) Dataproc。",
        "en": "(E) Dataproc.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Vertex AI Pipelines (A) 是建立 ML 工作流程的標準工具 (基於 Kubeflow Pipelines)。它自動與 Vertex AI Metadata (B) 整合，後者負責記錄管道執行的每一個 Artifact (資料集、模型) 及其來源與參數 (Lineage)。雖然 Cloud Composer 也能編排，但對於 ML 特有的 Metadata 追蹤與模型比較，Vertex AI 原生工具更具優勢。",
      "en": "Vertex AI Pipelines (A) is the standard tool for building ML workflows (based on Kubeflow Pipelines). It automatically integrates with Vertex AI Metadata (B), which records every Artifact (dataset, model) produced by pipeline execution, along with its source and parameters (Lineage). While Cloud Composer can also orchestrate, Vertex AI native tools offer superior advantages for ML-specific Metadata tracking and model comparison.",
      "wg": [
        {
          "t": "編排",
          "en": "orchestrate",
          "ps": "V"
        },
        {
          "t": "原生工具",
          "en": "native tool",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "130",
    "level": "hard",
    "keywords": "Security, Compliance, Organizational Policy, Firewall",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的安全團隊要求在整個組織範圍內封鎖 SSH (22 埠) 和 RDP (3389 埠) 對公共網際網路 (0.0.0.0/0) 的開放。",
        "en": "Your security team requires blocking SSH (port 22) and RDP (port 3389) access from the public internet (0.0.0.0/0) organization-wide.",
        "wg": []
      },
      {
        "t": "您不能依賴個別專案管理員去設定 VPC 防火牆，必須由中央強制執行。",
        "en": "You cannot rely on individual project administrators to configure VPC firewalls; it must be enforced centrally.",
        "wg": [
          {
            "t": "中央強制執行",
            "en": "enforce centrally",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該使用哪種方法？",
        "en": "Which method should you use?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在組織層級建立階層式防火牆政策 (Hierarchical Firewall Policy)。",
        "en": "(A) Create a Hierarchical Firewall Policy at the Organization level.",
        "wg": [
          {
            "t": "階層式防火牆政策",
            "en": "Hierarchical Firewall Policy",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 使用組織政策限制 `compute.restrictVpcFirewallRules`。",
        "en": "(B) Use Organization Policy to restrict `compute.restrictVpcFirewallRules`.",
        "wg": []
      },
      {
        "t": "(C) 撰寫一個 Cloud Function 監控所有防火牆變更並自動復原。",
        "en": "(C) Write a Cloud Function to monitor all firewall changes and automatically revert them.",
        "wg": []
      },
      {
        "t": "(D) 使用 Shared VPC 並在 Host Project 中設定規則。",
        "en": "(D) Use Shared VPC and configure rules in the Host Project.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "階層式防火牆政策 (Hierarchical Firewall Policies) 允許您在組織或資料夾層級定義防火牆規則。這些規則會被下層的所有專案繼承，且無法被專案級別的規則覆寫 (如果是 Enforce 模式)。這是實作全組織範圍「基礎安全防護網」的最佳方式。",
      "en": "Hierarchical Firewall Policies allow you to define firewall rules at the Organization or Folder level. These rules are inherited by all projects underneath and cannot be overridden by project-level rules (if in Enforce mode). This is the best way to implement an organization-wide \"security baseline\".",
      "wg": [
        {
          "t": "繼承",
          "en": "inherit",
          "ps": "V"
        },
        {
          "t": "基礎安全防護網",
          "en": "security baseline",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "131",
    "level": "hard",
    "keywords": "Anthos, Multi-cloud, GKE Enterprise, Config Management",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的企業在 Google Cloud (GKE)、AWS (EKS) 和本地資料中心 (Bare Metal) 都有 Kubernetes 叢集。",
        "en": "Your enterprise has Kubernetes clusters on Google Cloud (GKE), AWS (EKS), and on-premises data centers (Bare Metal).",
        "wg": []
      },
      {
        "t": "您希望擁有一致的安全性政策 (如 OPA Gatekeeper) 和配置管理，並能夠從單一控制台監控所有叢集。",
        "en": "You want consistent security policies (like OPA Gatekeeper) and configuration management, and the ability to monitor all clusters from a single console.",
        "wg": [
          {
            "t": "一致的",
            "en": "consistent",
            "ps": "Adj"
          },
          {
            "t": "配置管理",
            "en": "configuration management",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該實作哪兩項 GKE Enterprise (Anthos) 元件？(請選擇兩項)",
        "en": "Which two GKE Enterprise (Anthos) components should you implement? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) Config Sync。",
        "en": "(A) Config Sync.",
        "wg": []
      },
      {
        "t": "(B) Connect Gateway。",
        "en": "(B) Connect Gateway.",
        "wg": []
      },
      {
        "t": "(C) Anthos Service Mesh (ASM)。",
        "en": "(C) Anthos Service Mesh (ASM).",
        "wg": []
      },
      {
        "t": "(D) Binary Authorization。",
        "en": "(D) Binary Authorization.",
        "wg": []
      },
      {
        "t": "(E) Policy Controller。",
        "en": "(E) Policy Controller.",
        "wg": []
      }
    ],
    "answer": "A, E",
    "why": {
      "t": "Config Sync (A) 允許您使用 GitOps 方式將設定檔 (YAML) 同步到所有註冊的叢集，確保配置一致性。Policy Controller (E) (基於 OPA Gatekeeper) 則允許您定義並強制執行跨叢集的合規性政策 (如禁止特權容器)。這兩者是 GKE Enterprise 多雲治理的核心。",
      "en": "Config Sync (A) allows you to sync configuration files (YAML) to all registered clusters using GitOps, ensuring configuration consistency. Policy Controller (E) (based on OPA Gatekeeper) allows you to define and enforce cross-cluster compliance policies (e.g., forbidding privileged containers). These two are the core of GKE Enterprise multi-cloud governance.",
      "wg": [
        {
          "t": "強制執行",
          "en": "enforce",
          "ps": "V"
        },
        {
          "t": "治理",
          "en": "governance",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "132",
    "level": "medium",
    "keywords": "Storage, Performance, Parallel File System, HPC",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的研究團隊正在執行高效能運算 (HPC) 模擬，涉及數千個 Compute Engine 核心同時讀寫同一組大型數據集。",
        "en": "Your research team is running High-Performance Computing (HPC) simulations involving thousands of Compute Engine cores simultaneously reading and writing the same large dataset.",
        "wg": [
          {
            "t": "高效能運算",
            "en": "High-Performance Computing",
            "ps": "N"
          },
          {
            "t": "模擬",
            "en": "simulation",
            "ps": "N"
          }
        ]
      },
      {
        "t": "標準的 NFS 解決方案 (如 Filestore Basic) 已經成為 I/O 瓶頸。您需要一個能夠提供亞毫秒級延遲和每秒數百 GB 吞吐量的平行檔案系統。",
        "en": "Standard NFS solutions (like Filestore Basic) have become an I/O bottleneck. You need a parallel file system capable of providing sub-millisecond latency and hundreds of GBps throughput.",
        "wg": [
          {
            "t": "平行檔案系統",
            "en": "parallel file system",
            "ps": "N"
          },
          {
            "t": "亞毫秒級",
            "en": "sub-millisecond",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您應該選擇哪種儲存解決方案？",
        "en": "Which storage solution should you choose?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Filestore Enterprise。",
        "en": "(A) Filestore Enterprise.",
        "wg": []
      },
      {
        "t": "(B) Parallelstore (基於 DAOS)。",
        "en": "(B) Parallelstore (based on DAOS).",
        "wg": []
      },
      {
        "t": "(C) Google Cloud NetApp Volumes。",
        "en": "(C) Google Cloud NetApp Volumes.",
        "wg": []
      },
      {
        "t": "(D) 使用 Local SSD 自行架設 Lustre。",
        "en": "(D) Self-managed Lustre using Local SSD.",
        "wg": []
      }
    ],
    "answer": "B",
    "why": {
      "t": "Parallelstore 是 Google Cloud 針對極致效能 HPC 和 AI/ML 工作負載推出的全託管平行檔案系統 (基於 Intel DAOS)。它比傳統 NFS (Filestore) 或甚至 NetApp Volumes 提供更高的並行吞吐量和更低的延遲。雖然自行架設 Lustre (D) 也是一種選擇，但在全託管服務可用的情況下，Parallelstore 能大幅降低維運負擔。",
      "en": "Parallelstore is Google Cloud's fully managed parallel file system (based on Intel DAOS) designed for extreme performance HPC and AI/ML workloads. It offers significantly higher parallel throughput and lower latency than traditional NFS (Filestore) or even NetApp Volumes. While self-managed Lustre (D) is an option, Parallelstore drastically reduces operational overhead when a fully managed service is available.",
      "wg": [
        {
          "t": "極致效能",
          "en": "extreme performance",
          "ps": "N"
        },
        {
          "t": "並行吞吐量",
          "en": "parallel throughput",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "133",
    "level": "medium",
    "keywords": "Security, Key Management, Encryption, Signed Key",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的應用程式需要將加密的資料寫入 Cloud Storage。您希望使用自己的金鑰進行加密，但不希望將金鑰上傳到 Google Cloud (即不使用 CSEK)。",
        "en": "Your application needs to write encrypted data to Cloud Storage. You want to encrypt using your own keys but do not want to upload the keys to Google Cloud (i.e., not using CSEK).",
        "wg": [
          {
            "t": "加密",
            "en": "encrypt",
            "ps": "V"
          }
        ]
      },
      {
        "t": "相反，您希望在客戶端 (Client-side) 進行加密，然後將密文上傳。",
        "en": "Instead, you want to perform encryption on the Client-side and then upload the ciphertext.",
        "wg": [
          {
            "t": "客戶端",
            "en": "Client-side",
            "ps": "N"
          },
          {
            "t": "密文",
            "en": "ciphertext",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您可以使用哪個開源程式庫來簡化與 Cloud KMS 的信封加密 (Envelope Encryption) 整合？",
        "en": "Which open-source library can you use to simplify Envelope Encryption integration with Cloud KMS?",
        "wg": [
          {
            "t": "信封加密",
            "en": "Envelope Encryption",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Tink。",
        "en": "(A) Tink.",
        "wg": []
      },
      {
        "t": "(B) Bouncy Castle。",
        "en": "(B) Bouncy Castle.",
        "wg": []
      },
      {
        "t": "(C) OpenSSL。",
        "en": "(C) OpenSSL.",
        "wg": []
      },
      {
        "t": "(D) Google Cloud Storage Client Library。",
        "en": "(D) Google Cloud Storage Client Library.",
        "wg": []
      }
    ],
    "answer": "A",
    "why": {
      "t": "Tink 是 Google 開發的多語言加密程式庫。它提供了與 Cloud KMS 的原生整合，能輕鬆實作信封加密：Tink 會產生一個資料加密金鑰 (DEK) 在本地加密資料，然後呼叫 Cloud KMS 使用金鑰加密金鑰 (KEK) 來加密 DEK。這確保了資料在離開客戶端前已被加密，且金鑰管理依然集中化。",
      "en": "Tink is a multi-language cryptography library developed by Google. It provides native integration with Cloud KMS to easily implement Envelope Encryption: Tink generates a Data Encryption Key (DEK) to encrypt data locally, then calls Cloud KMS to encrypt the DEK using a Key Encryption Key (KEK). This ensures data is encrypted before leaving the client while maintaining centralized key management.",
      "wg": [
        {
          "t": "資料加密金鑰",
          "en": "Data Encryption Key",
          "ps": "N"
        },
        {
          "t": "集中化",
          "en": "centralized",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "134",
    "level": "hard",
    "keywords": "Case Study, KnightMotives, TPU, AI Hypercomputer, Training",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 KnightMotives Automotive 個案研究。該公司正在開發新一代的自動駕駛模型，模型參數量高達數千億。",
        "en": "Refer to the KnightMotives Automotive case study. The company is developing next-generation autonomous driving models with hundreds of billions of parameters.",
        "wg": [
          {
            "t": "參數",
            "en": "parameter",
            "ps": "N"
          }
        ]
      },
      {
        "t": "訓練工作需要跨越多個加速器節點進行同步 (Synchronous Training)，對網路頻寬和延遲極為敏感。",
        "en": "Training jobs require Synchronous Training across multiple accelerator nodes and are extremely sensitive to network bandwidth and latency.",
        "wg": [
          {
            "t": "同步訓練",
            "en": "Synchronous Training",
            "ps": "N"
          },
          {
            "t": "加速器",
            "en": "accelerator",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該推薦使用哪種基礎設施？",
        "en": "Which infrastructure should you recommend?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud TPU v5p Pods。",
        "en": "(A) Cloud TPU v5p Pods.",
        "wg": []
      },
      {
        "t": "(B) Compute Engine N2 VM 搭配 NVIDIA T4 GPU。",
        "en": "(B) Compute Engine N2 VMs with NVIDIA T4 GPUs.",
        "wg": []
      },
      {
        "t": "(C) Standard GKE Cluster。",
        "en": "(C) Standard GKE Cluster.",
        "wg": []
      },
      {
        "t": "(D) Vertex AI AutoML。",
        "en": "(D) Vertex AI AutoML.",
        "wg": []
      }
    ],
    "answer": "A",
    "why": {
      "t": "Cloud TPU v5p 是專為大規模 LLM 和生成式 AI 訓練設計的。TPU Pods 透過專用的超高速互連網路 (Inter-chip Interconnect, ICI) 連接，提供比標準以太網快得多的晶片間通訊，非常適合需要大量參數同步的超大型模型訓練。",
      "en": "Cloud TPU v5p is designed specifically for large-scale LLM and generative AI training. TPU Pods are connected via a dedicated ultra-high-speed Inter-chip Interconnect (ICI), providing much faster chip-to-chip communication than standard Ethernet, making them ideal for massive model training requiring extensive parameter synchronization.",
      "wg": [
        {
          "t": "互連網路",
          "en": "Interconnect",
          "ps": "N"
        },
        {
          "t": "參數同步",
          "en": "parameter synchronization",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "135",
    "level": "medium",
    "keywords": "Networking, Private Service Connect, Consumer, Producer",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的 SaaS 公司希望將其應用程式以託管服務的形式提供給其他 Google Cloud 客戶 (Tenants)。",
        "en": "Your SaaS company wants to offer its application as a managed service to other Google Cloud customers (Tenants).",
        "wg": [
          {
            "t": "託管服務",
            "en": "managed service",
            "ps": "N"
          },
          {
            "t": "租戶",
            "en": "Tenant",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您希望避免 IP 位址重疊 (IP Overlap) 問題，並且不希望管理複雜的 VPC Peering 網格。",
        "en": "You want to avoid IP Overlap issues and do not want to manage a complex VPC Peering mesh.",
        "wg": [
          {
            "t": "重疊",
            "en": "Overlap",
            "ps": "N"
          },
          {
            "t": "網格",
            "en": "mesh",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該如何發布您的服務？",
        "en": "How should you publish your service?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Private Service Connect (PSC) 發布服務。",
        "en": "(A) Publish the service using Private Service Connect (PSC).",
        "wg": []
      },
      {
        "t": "(B) 建立 Shared VPC 並邀請客戶加入。",
        "en": "(B) Create a Shared VPC and invite customers to join.",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud VPN 連接每個客戶。",
        "en": "(C) Connect each customer using Cloud VPN.",
        "wg": []
      },
      {
        "t": "(D) 公開服務到網際網路，並使用 mTLS 驗證。",
        "en": "(D) Expose the service to the internet and use mTLS authentication.",
        "wg": []
      }
    ],
    "answer": "A",
    "why": {
      "t": "Private Service Connect (PSC) 是專為這種「生產者-消費者 (Producer-Consumer)」模型設計的。生產者將服務發布為一個 Attachment，消費者則在自己的 VPC 中建立一個 Endpoint 連接到該 Attachment。這完全消除了 VPC Peering 的 IP 重疊問題，並且提供了更好的隔離性與單向連線控制。",
      "en": "Private Service Connect (PSC) is specifically designed for this \"Producer-Consumer\" model. The producer publishes the service as an Attachment, and the consumer creates an Endpoint in their own VPC connecting to that Attachment. This completely eliminates VPC Peering IP overlap issues and provides better isolation and unidirectional connection control.",
      "wg": [
        {
          "t": "生產者",
          "en": "Producer",
          "ps": "N"
        },
        {
          "t": "隔離性",
          "en": "isolation",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "136",
    "level": "medium",
    "keywords": "Case Study, Cymbal Retail, Data Quality, Dataplex, Governance",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Cymbal Retail 個案研究。隨著數據湖 (Data Lake) 的擴張，數據品質成為一個主要問題。",
        "en": "Refer to the Cymbal Retail case study. As the Data Lake expands, data quality has become a major issue.",
        "wg": [
          {
            "t": "數據湖",
            "en": "Data Lake",
            "ps": "N"
          },
          {
            "t": "擴張",
            "en": "expand",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您需要自動掃描 BigQuery 和 Cloud Storage 中的數據，識別敏感資訊 (PII)，並建立數據目錄 (Data Catalog) 以供發現。",
        "en": "You need to automatically scan data in BigQuery and Cloud Storage, identify sensitive information (PII), and create a Data Catalog for discovery.",
        "wg": [
          {
            "t": "數據目錄",
            "en": "Data Catalog",
            "ps": "N"
          },
          {
            "t": "發現",
            "en": "discovery",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該使用哪項服務來統一管理這些數據治理任務？",
        "en": "Which service should you use to unify these data governance tasks?",
        "wg": [
          {
            "t": "數據治理",
            "en": "data governance",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Dataplex。",
        "en": "(A) Dataplex.",
        "wg": []
      },
      {
        "t": "(B) Dataflow。",
        "en": "(B) Dataflow.",
        "wg": []
      },
      {
        "t": "(C) Pub/Sub。",
        "en": "(C) Pub/Sub.",
        "wg": []
      },
      {
        "t": "(D) BigQuery Omni。",
        "en": "(D) BigQuery Omni.",
        "wg": []
      }
    ],
    "answer": "A",
    "why": {
      "t": "Dataplex 是 Google Cloud 的智慧數據經緯 (Data Fabric) 服務，專為分散式數據的統一管理與治理設計。它整合了 Data Catalog (用於發現)、自動數據品質檢查 (AutoDQ) 以及數據分析環境的配置，能跨 BigQuery 和 GCS 自動掃描並組織數據。",
      "en": "Dataplex is Google Cloud's intelligent Data Fabric service designed for unified management and governance of distributed data. It integrates Data Catalog (for discovery), automated data quality checks (AutoDQ), and data analysis environment provisioning, capable of automatically scanning and organizing data across BigQuery and GCS.",
      "wg": [
        {
          "t": "數據經緯",
          "en": "Data Fabric",
          "ps": "N"
        },
        {
          "t": "分散式",
          "en": "distributed",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "137",
    "level": "medium",
    "keywords": "Serverless, Cloud Run, Traffic Management, Gradual Rollout",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您已將新版本的 Cloud Run 服務部署為 `Revision 2`。",
        "en": "You have deployed a new version of your Cloud Run service as `Revision 2`.",
        "wg": []
      },
      {
        "t": "您希望將 10% 的生產流量導向 `Revision 2` 進行測試，其餘 90% 仍保留在 `Revision 1`。",
        "en": "You want to route 10% of production traffic to `Revision 2` for testing, while keeping 90% on `Revision 1`.",
        "wg": []
      },
      {
        "t": "此外，您希望為內部測試團隊提供一個特定的 URL，讓他們能 100% 存取 `Revision 2` (標記流量)。",
        "en": "Additionally, you want to provide a specific URL to the internal testing team so they can access `Revision 2` 100% of the time (Tagged Traffic).",
        "wg": [
          {
            "t": "標記流量",
            "en": "Tagged Traffic",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您應該如何設定？(請選擇兩項)",
        "en": "How should you configure this? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用流量分配 (Traffic Splitting) 功能，將 10% 分配給 `Revision 2`。",
        "en": "(A) Use Traffic Splitting to assign 10% to `Revision 2`.",
        "wg": [
          {
            "t": "流量分配",
            "en": "Traffic Splitting",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 為 `Revision 2` 分配一個流量標記 (Traffic Tag)，例如 `preview`。",
        "en": "(B) Assign a Traffic Tag, such as `preview`, to `Revision 2`.",
        "wg": [
          {
            "t": "流量標記",
            "en": "Traffic Tag",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 部署另一個 Cloud Run 服務作為 `Revision 2`。",
        "en": "(C) Deploy another Cloud Run service as `Revision 2`.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud Load Balancer 的 URL Map。",
        "en": "(D) Use Cloud Load Balancer's URL Map.",
        "wg": []
      },
      {
        "t": "(E) 在應用程式內部實作路由邏輯。",
        "en": "(E) Implement routing logic within the application.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Cloud Run 內建強大的流量管理功能。您可以直接設定百分比 (A) 來進行漸進式發布 (Canary)。同時，透過為特定 Revision 分配標記 (Tag) (B)，Cloud Run 會自動產生一個專用的 URL (如 `preview---service-url`)，讓測試人員可以直接存取該版本，而不受主 URL 流量百分比的影響。",
      "en": "Cloud Run has built-in powerful traffic management. You can directly set percentages (A) for gradual rollout (Canary). Simultaneously, by assigning a Tag (B) to a specific Revision, Cloud Run automatically generates a dedicated URL (e.g., `preview---service-url`), allowing testers to access that version directly, bypassing the main URL's traffic percentages.",
      "wg": [
        {
          "t": "漸進式發布",
          "en": "gradual rollout",
          "ps": "N"
        },
        {
          "t": "繞過",
          "en": "bypass",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "138",
    "level": "hard",
    "keywords": "Case Study, EHR Healthcare, Compliance, Audit, BigQuery",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 EHR Healthcare 個案研究。為了符合 HIPAA 稽核要求，您必須記錄所有對病患資料 (BigQuery) 的查詢操作。",
        "en": "Refer to the EHR Healthcare case study. To meet HIPAA audit requirements, you must log all query operations on patient data (BigQuery).",
        "wg": [
          {
            "t": "稽核要求",
            "en": "audit requirement",
            "ps": "N"
          },
          {
            "t": "查詢操作",
            "en": "query operation",
            "ps": "N"
          }
        ]
      },
      {
        "t": "稽核記錄必須包含「誰」(Who)、「什麼時候」(When) 以及「具體查詢了什麼數據」(What - SQL Text)。",
        "en": "Audit logs must include \"Who\", \"When\", and \"Specifically what data was queried\" (What - SQL Text).",
        "wg": []
      },
      {
        "t": "此外，這些稽核日誌本身必須受到保護，防止被竄改，並保留至少 7 年。",
        "en": "Additionally, these audit logs must be protected from tampering and retained for at least 7 years.",
        "wg": [
          {
            "t": "竄改",
            "en": "tamper",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該採取哪兩個行動？(請選擇兩項)",
        "en": "Which two actions should you take? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 啟用 Cloud Audit Logs 的 Data Access Logs (BigQuery)。",
        "en": "(A) Enable Data Access Logs (BigQuery) in Cloud Audit Logs.",
        "wg": [
          {
            "t": "資料存取日誌",
            "en": "Data Access Log",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 建立 Log Sink，將稽核日誌匯出到設有「Bucket Lock」的 Cloud Storage Bucket。",
        "en": "(B) Create a Log Sink to export audit logs to a Cloud Storage Bucket with \"Bucket Lock\" enabled.",
        "wg": [
          {
            "t": "日誌接收器",
            "en": "Log Sink",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 僅啟用 Admin Activity Logs。",
        "en": "(C) Enable only Admin Activity Logs.",
        "wg": []
      },
      {
        "t": "(D) 將日誌匯出到 Pub/Sub 並寫入本地 SIEM。",
        "en": "(D) Export logs to Pub/Sub and write to on-premises SIEM.",
        "wg": []
      },
      {
        "t": "(E) 定期手動備份日誌。",
        "en": "(E) Periodically manually backup logs.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Admin Activity Logs 只記錄管理操作 (如建立 Dataset)，不包含讀取數據的 SQL。要記錄「查詢了什麼」，必須啟用 Data Access Logs (A)。為了滿足 7 年不可竄改 (WORM - Write Once Read Many) 的合規要求，將日誌匯出到 GCS 並啟用 Bucket Lock (B) 是最標準的解決方案。",
      "en": "Admin Activity Logs only record administrative actions (like creating a Dataset), not the SQL reading the data. To record \"what was queried,\" you must enable Data Access Logs (A). To meet the 7-year immutable (WORM - Write Once Read Many) compliance requirement, exporting logs to GCS and enabling Bucket Lock (B) is the standard solution.",
      "wg": [
        {
          "t": "不可竄改",
          "en": "immutable",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "139",
    "level": "medium",
    "keywords": "Cost Optimization, Compute Engine, Recommendation, Rightsizing",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您接手了一個既有的 Google Cloud 專案，發現其中有許多 Compute Engine 實例的 CPU 使用率長期低於 5%。",
        "en": "You took over an existing Google Cloud project and found many Compute Engine instances with CPU usage consistently below 5%.",
        "wg": [
          {
            "t": "既有的",
            "en": "existing",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您希望在不影響應用程式穩定性的前提下，自動找出這些閒置或過度配置 (Over-provisioned) 的資源並進行調整。",
        "en": "You want to automatically identify these idle or over-provisioned resources and adjust them without affecting application stability.",
        "wg": [
          {
            "t": "過度配置",
            "en": "Over-provisioned",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您應該使用哪項工具？",
        "en": "Which tool should you use?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) VM Rightsizing Recommendations (Active Assist)。",
        "en": "(A) VM Rightsizing Recommendations (Active Assist).",
        "wg": [
          {
            "t": "調整大小建議",
            "en": "Rightsizing Recommendation",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) Cloud Monitoring Metrics。",
        "en": "(B) Cloud Monitoring Metrics.",
        "wg": []
      },
      {
        "t": "(C) Billing Reports。",
        "en": "(C) Billing Reports.",
        "wg": []
      },
      {
        "t": "(D) Autoscaler。",
        "en": "(D) Autoscaler.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Active Assist 的 Rightsizing Recommendations 會分析過去 8 天 (預設) 的系統指標，智慧地建議將機器類型縮小 (例如從 n1-standard-4 到 n1-standard-1) 或刪除閒置 VM。它提供了具體的「預估節省金額」，是進行成本優化最直接的工具。",
      "en": "Active Assist's Rightsizing Recommendations analyze system metrics from the past 8 days (default) and intelligently suggest downsizing machine types (e.g., from n1-standard-4 to n1-standard-1) or deleting idle VMs. It provides specific \"estimated savings,\" making it the most direct tool for cost optimization.",
      "wg": [
        {
          "t": "智慧地",
          "en": "intelligently",
          "ps": "Adv"
        },
        {
          "t": "縮小",
          "en": "downsize",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "140",
    "level": "medium",
    "keywords": "Identity, Cloud Identity, Directory Sync, SSO",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的公司使用 Microsoft Active Directory (AD) 作為主要的身分來源 (IdP)。",
        "en": "Your company uses Microsoft Active Directory (AD) as the primary Identity Provider (IdP).",
        "wg": [
          {
            "t": "身分來源",
            "en": "Identity Provider",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您希望員工能使用現有的 AD 帳號登入 Google Cloud Console，並且當員工離職時，AD 中的停用操作能自動同步到 Google Cloud。",
        "en": "You want employees to log in to the Google Cloud Console using their existing AD credentials, and when an employee leaves, disabling them in AD should automatically sync to Google Cloud.",
        "wg": [
          {
            "t": "停用",
            "en": "disable",
            "ps": "V"
          },
          {
            "t": "同步",
            "en": "sync",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該結合哪兩項服務？(請選擇兩項)",
        "en": "Which two services should you combine? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) Google Cloud Directory Sync (GCDS)。",
        "en": "(A) Google Cloud Directory Sync (GCDS).",
        "wg": []
      },
      {
        "t": "(B) Cloud Identity (設定 SSO)。",
        "en": "(B) Cloud Identity (Configure SSO).",
        "wg": []
      },
      {
        "t": "(C) Identity Platform。",
        "en": "(C) Identity Platform.",
        "wg": []
      },
      {
        "t": "(D) Managed Service for Microsoft Active Directory。",
        "en": "(D) Managed Service for Microsoft Active Directory.",
        "wg": []
      },
      {
        "t": "(E) IAM Workload Identity。",
        "en": "(E) IAM Workload Identity.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "這是一個標準的混合身分 (Hybrid Identity) 場景。GCDS (A) 是一個工具，負責將 AD 中的使用者和群組單向同步到 Cloud Identity。Cloud Identity (B) 則作為 Google 端的目錄，並透過 SAML 設定單一登入 (SSO) 指向 AD (或 ADFS/Azure AD)，讓驗證發生在微軟端，授權發生在 Google 端。",
      "en": "This is a standard Hybrid Identity scenario. GCDS (A) is a tool that one-way syncs users and groups from AD to Cloud Identity. Cloud Identity (B) acts as the directory on the Google side and is configured with SSO via SAML pointing to AD (or ADFS/Azure AD), so authentication happens on the Microsoft side while authorization happens on the Google side.",
      "wg": [
        {
          "t": "單向同步",
          "en": "one-way sync",
          "ps": "V"
        },
        {
          "t": "驗證",
          "en": "authentication",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "141",
    "level": "hard",
    "keywords": "Networking, VPC, Route, Peering, Transitivity",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的網路架構包含三個 VPC：VPC-A (本地連線)、VPC-B (應用程式) 和 VPC-C (資料庫)。",
        "en": "Your network architecture consists of three VPCs: VPC-A (On-premises connectivity), VPC-B (Application), and VPC-C (Database).",
        "wg": []
      },
      {
        "t": "VPC-A 透過 VPN 連接到本地資料中心。VPC-A 與 VPC-B 有 Peering，VPC-B 與 VPC-C 有 Peering (鏈式拓撲 A-B-C)。",
        "en": "VPC-A is connected to the on-premises data center via VPN. VPC-A peers with VPC-B, and VPC-B peers with VPC-C (Chain topology A-B-C).",
        "wg": [
          {
            "t": "鏈式拓撲",
            "en": "Chain topology",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您希望本地資料中心的伺服器能夠直接存取 VPC-C 中的資料庫。由於 Peering 不具遞移性，連線失敗。",
        "en": "You want on-premises servers to access the database in VPC-C directly. The connection fails because Peering is non-transitive.",
        "wg": [
          {
            "t": "不具遞移性",
            "en": "non-transitive",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您應該採取哪兩個步驟來解決此問題？(請選擇兩項)",
        "en": "Which two steps should you take to resolve this? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 在 VPC-A 和 VPC-C 之間建立直接的 VPC Peering。",
        "en": "(A) Establish a direct VPC Peering between VPC-A and VPC-C.",
        "wg": []
      },
      {
        "t": "(B) 在 VPC-A 的 VPN Cloud Router 上設定自訂路由廣播 (Custom Route Advertisement)，宣告 VPC-C 的子網域。",
        "en": "(B) Configure Custom Route Advertisement on VPC-A's VPN Cloud Router to advertise VPC-C's subnets.",
        "wg": [
          {
            "t": "自訂路由廣播",
            "en": "Custom Route Advertisement",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 在 VPC-A 和 VPC-C 的 Peering 設定中，啟用「匯出/匯入自訂路由 (Export/Import Custom Routes)」。",
        "en": "(C) Enable \"Export/Import Custom Routes\" in the Peering settings of VPC-A and VPC-C.",
        "wg": []
      },
      {
        "t": "(D) 將 VPC-B 轉換為 Shared VPC 的 Host Project。",
        "en": "(D) Convert VPC-B to a Shared VPC Host Project.",
        "wg": []
      },
      {
        "t": "(E) 在 VPC-B 中設定 Cloud NAT。",
        "en": "(E) Configure Cloud NAT in VPC-B.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "要讓本地端存取 VPC-C，必須解決兩個路由問題：1. Google Cloud 內部路由：VPC-A 和 VPC-C 必須直接互通，因為 Peering 不能跨越 VPC-B。建立直接 Peering (A) 是最簡單的方法。2. BGP 路由廣播：本地路由器必須知道 VPC-C 的存在。因此，必須在 VPC-A 的 Cloud Router 上設定自訂廣播 (B)，將 VPC-C 的網段宣告給本地端 (因為預設只會廣播 VPC-A 自己的網段)。",
      "en": "To allow on-premises access to VPC-C, two routing issues must be solved: 1. Internal Google Cloud routing: VPC-A and VPC-C must communicate directly because Peering cannot transit through VPC-B. Direct Peering (A) is the simplest way. 2. BGP Route Advertisement: The on-premises router must know about VPC-C. Thus, you must configure Custom Route Advertisement on VPC-A's Cloud Router (B) to advertise VPC-C's subnets to on-premises (since default only advertises VPC-A's own subnets).",
      "wg": [
        {
          "t": "跨越",
          "en": "transit through",
          "ps": "V"
        },
        {
          "t": "宣告",
          "en": "advertise",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "142",
    "level": "medium",
    "keywords": "BigQuery, Security, Column-level Security, IAM",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您有一個 BigQuery 表格包含員工資料，其中包括 `Salary` (薪資) 和 `SSN` (身分證號) 等敏感欄位。",
        "en": "You have a BigQuery table containing employee data, including sensitive columns like `Salary` and `SSN`.",
        "wg": []
      },
      {
        "t": "您希望允許資料分析師查詢該表格以進行統計分析，但必須嚴格禁止他們看到 `Salary` 和 `SSN` 的具體數值。",
        "en": "You want to allow data analysts to query the table for statistical analysis but strictly prohibit them from seeing specific values of `Salary` and `SSN`.",
        "wg": [
          {
            "t": "嚴格禁止",
            "en": "strictly prohibit",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該結合哪兩項設定？(請選擇兩項)",
        "en": "Which two configurations should you combine? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 Policy Tags (Taxonomy) 標記敏感欄位。",
        "en": "(A) Use Policy Tags (Taxonomy) to tag sensitive columns.",
        "wg": [
          {
            "t": "分類",
            "en": "Taxonomy",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 授予分析師 `roles/bigquery.dataViewer` 角色。",
        "en": "(B) Grant analysts the `roles/bigquery.dataViewer` role.",
        "wg": []
      },
      {
        "t": "(C) 確保分析師 **沒有** 獲得該 Policy Tag 的 `Data Catalog Fine-Grained Reader` 角色。",
        "en": "(C) Ensure analysts are **NOT** granted the `Data Catalog Fine-Grained Reader` role for that Policy Tag.",
        "wg": [
          {
            "t": "細緻讀取者",
            "en": "Fine-Grained Reader",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(D) 建立一個授權視圖 (Authorized View) 排除這兩個欄位。",
        "en": "(D) Create an Authorized View excluding these two columns.",
        "wg": [
          {
            "t": "授權視圖",
            "en": "Authorized View",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(E) 使用 AES-256 加密這兩個欄位。",
        "en": "(E) Encrypt these two columns using AES-256.",
        "wg": []
      }
    ],
    "answer": "A, C",
    "why": {
      "t": "BigQuery 的欄位級安全性 (Column-level Security) 是透過 Policy Tags 實作的 (A)。其運作邏輯是：只有擁有該 Policy Tag 對應之 `Fine-Grained Reader` 權限的使用者才能讀取被標記的欄位。因此，要「禁止」分析師看到，您必須確保他們**沒有**獲得該權限 (C)。如果他們嘗試查詢 `SELECT *`，BigQuery 會因為權限不足而拒絕存取這些受保護的欄位。",
      "en": "BigQuery Column-level Security is implemented via Policy Tags (A). The logic is: only users with the `Fine-Grained Reader` permission for that Policy Tag can read the tagged columns. Therefore, to \"prohibit\" analysts from seeing them, you must ensure they are **NOT** granted that permission (C). If they try `SELECT *`, BigQuery will deny access to the protected columns due to insufficient permissions.",
      "wg": [
        {
          "t": "權限不足",
          "en": "insufficient permissions",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "143",
    "level": "medium",
    "keywords": "IaC, Terraform, Security, Service Account Impersonation",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的團隊使用 Terraform 在本機電腦上開發和測試基礎架構程式碼。",
        "en": "Your team uses Terraform to develop and test infrastructure code on local machines.",
        "wg": []
      },
      {
        "t": "為了安全，您已被禁止下載任何服務帳號的 JSON 金鑰 (Long-lived Keys)。",
        "en": "For security, you have been prohibited from downloading any Service Account JSON keys (Long-lived Keys).",
        "wg": [
          {
            "t": "長期的",
            "en": "Long-lived",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "您應該如何設定 Terraform Provider 以便安全地以高權限服務帳號的身分執行部署？(請選擇兩項)",
        "en": "How should you configure the Terraform Provider to securely deploy as a high-privilege Service Account? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 在本地執行 `gcloud auth application-default login` 使用您的個人憑證。",
        "en": "(A) Run `gcloud auth application-default login` locally using your personal credentials.",
        "wg": []
      },
      {
        "t": "(B) 在 Terraform `provider`區塊中設定 `impersonate_service_account` 參數，指定目標服務帳號的 Email。",
        "en": "(B) Configure the `impersonate_service_account` parameter in the Terraform `provider` block, specifying the target Service Account email.",
        "wg": [
          {
            "t": "模擬服務帳號",
            "en": "impersonate_service_account",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 授予您的個人帳號 `roles/iam.serviceAccountTokenCreator` 權限。",
        "en": "(C) Grant your personal account the `roles/iam.serviceAccountTokenCreator` role.",
        "wg": [
          {
            "t": "服務帳號權杖建立者",
            "en": "Service Account Token Creator",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(D) 使用 `gcloud auth activate-service-account`。",
        "en": "(D) Use `gcloud auth activate-service-account`.",
        "wg": []
      },
      {
        "t": "(E) 在 Cloud Shell 中執行，因為它會自動擁有 Owner 權限。",
        "en": "(E) Run in Cloud Shell, as it automatically has Owner permissions.",
        "wg": []
      }
    ],
    "answer": "B, C",
    "why": {
      "t": "這是「服務帳號模擬 (Service Account Impersonation)」的標準流程。首先，您的個人帳號需要被授權可以「扮演」該服務帳號，這需要 `Token Creator` 角色 (C)。接著，在 Terraform 設定中告訴 Provider 使用該服務帳號進行模擬 (B)。Terraform 會使用您的個人憑證 (透過 `gcloud auth application-default login` 取得) 去換取該服務帳號的短期 Token 來執行操作，完全無需下載 JSON 金鑰。",
      "en": "This is the standard process for \"Service Account Impersonation\". First, your personal account needs authorization to \"act as\" the service account, requiring the `Token Creator` role (C). Next, tell the Provider in Terraform configuration to impersonate that service account (B). Terraform will use your personal credentials (obtained via `gcloud auth application-default login`) to exchange for a short-lived token of that service account to perform operations, without ever downloading JSON keys.",
      "wg": [
        {
          "t": "扮演",
          "en": "act as",
          "ps": "V"
        },
        {
          "t": "短期",
          "en": "short-lived",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "144",
    "level": "medium",
    "keywords": "Case Study, Altostrat Media, GKE, Storage, Content Management",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Altostrat Media 個案研究。該公司正在將其內容管理系統 (CMS) 遷移到 GKE。",
        "en": "Refer to the Altostrat Media case study. The company is migrating its Content Management System (CMS) to GKE.",
        "wg": []
      },
      {
        "t": "CMS 需要一個共享的檔案系統來儲存上傳的媒體資產，以便多個 Pod 可以同時讀寫 (ReadWriteMany)。",
        "en": "The CMS requires a shared file system to store uploaded media assets so that multiple Pods can read and write simultaneously (ReadWriteMany).",
        "wg": [
          {
            "t": "共享的檔案系統",
            "en": "shared file system",
            "ps": "N"
          }
        ]
      },
      {
        "t": "此外，舊有的應用程式代碼依賴於 POSIX 檔案系統介面，無法輕易修改為使用 Cloud Storage API。",
        "en": "Additionally, the legacy application code relies on POSIX file system interfaces and cannot be easily modified to use Cloud Storage APIs.",
        "wg": [
          {
            "t": "依賴於",
            "en": "rely on",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該推薦哪兩個解決方案？(請選擇兩項)",
        "en": "Which two solutions should you recommend? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 Filestore (NFS) 並透過 Persistent Volume (PV) / Persistent Volume Claim (PVC) 掛載。",
        "en": "(A) Use Filestore (NFS) mounted via Persistent Volume (PV) / Persistent Volume Claim (PVC).",
        "wg": []
      },
      {
        "t": "(B) 使用 Cloud Storage FUSE CSI 驅動程式。",
        "en": "(B) Use Cloud Storage FUSE CSI driver.",
        "wg": []
      },
      {
        "t": "(C) 使用 Compute Engine Persistent Disk (GCE PD) 設為 ReadWriteMany。",
        "en": "(C) Use Compute Engine Persistent Disk (GCE PD) set to ReadWriteMany.",
        "wg": []
      },
      {
        "t": "(D) 在每個 Pod 中使用 emptyDir。",
        "en": "(D) Use emptyDir in each Pod.",
        "wg": []
      },
      {
        "t": "(E) 設定應用程式使用 Signed URLs。",
        "en": "(E) Configure the application to use Signed URLs.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "Filestore (A) 是完全相容 POSIX 的託管 NFS，原生支援 GKE 的 ReadWriteMany 模式，是 CMS 的理想選擇。Cloud Storage FUSE (B) 現在也有 GKE CSI 驅動程式，可以將 GCS Bucket 掛載為本地檔案系統，同樣支援 POSIX 語義和多 Pod 存取，且成本可能更低 (適合大量非結構化數據)。GCE PD (C) 不支援 ReadWriteMany (除非是 ReadOnly)。",
      "en": "Filestore (A) is a fully POSIX-compliant managed NFS that natively supports GKE's ReadWriteMany mode, making it ideal for CMS. Cloud Storage FUSE (B) now has a GKE CSI driver, allowing GCS buckets to be mounted as local file systems, also supporting POSIX semantics and multi-Pod access, potentially at a lower cost (suitable for massive unstructured data). GCE PD (C) does not support ReadWriteMany (unless ReadOnly).",
      "wg": [
        {
          "t": "非結構化數據",
          "en": "unstructured data",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "145",
    "level": "hard",
    "keywords": "SRE, Reliability, Load Balancing, Capacity",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的全球應用程式使用 Global External Application Load Balancer 分發流量。",
        "en": "Your global application uses a Global External Application Load Balancer to distribute traffic.",
        "wg": []
      },
      {
        "t": "某個地區 (Region A) 的後端服務突然因部署錯誤而導致容量 (Capacity) 下降 50%。",
        "en": "A backend service in one region (Region A) suddenly experienced a 50% drop in capacity due to a deployment error.",
        "wg": [
          {
            "t": "容量",
            "en": "Capacity",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您希望負載平衡器能夠自動察覺此情況，並將溢出的流量導向鄰近的健康地區 (Region B)，而不是讓 Region A 的剩餘實例過載。",
        "en": "You want the load balancer to automatically detect this and route overflow traffic to a nearby healthy region (Region B), rather than overloading the remaining instances in Region A.",
        "wg": [
          {
            "t": "溢出的流量",
            "en": "overflow traffic",
            "ps": "N"
          },
          {
            "t": "過載",
            "en": "overload",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該設定哪兩個後端服務參數？(請選擇兩項)",
        "en": "Which two backend service parameters should you configure? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 設定「平衡模式 (Balancing Mode)」為 `RATE` (每秒請求數) 或 `UTILIZATION` (CPU 利用率)。",
        "en": "(A) Set \"Balancing Mode\" to `RATE` (RPS) or `UTILIZATION` (CPU utilization).",
        "wg": [
          {
            "t": "平衡模式",
            "en": "Balancing Mode",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 設定「最大目標容量 (Maximum Target Capacity)」(例如 80%)。",
        "en": "(B) Set \"Maximum Target Capacity\" (e.g., 80%).",
        "wg": [
          {
            "t": "最大目標容量",
            "en": "Maximum Target Capacity",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 啟用 Cloud CDN。",
        "en": "(C) Enable Cloud CDN.",
        "wg": []
      },
      {
        "t": "(D) 設定連線排空 (Connection Draining) 時間。",
        "en": "(D) Configure Connection Draining timeout.",
        "wg": []
      },
      {
        "t": "(E) 使用 DNS 地理位置路由。",
        "en": "(E) Use DNS geolocation routing.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "全球負載平衡器的「容量感知 (Capacity-Aware)」路由依賴於正確定義的容量指標。您必須設定平衡模式 (A) (例如，定義每個實例最多處理 100 RPS)。同時設定目標容量 (B) (通常小於 100% 以留緩衝)。當 Region A 的健康實例減少，總可用容量下降，一旦流量超過設定的閾值，LB 就會自動將多餘請求溢位 (Spillover) 到最近且有剩餘容量的 Region B。",
      "en": "Global Load Balancer's \"Capacity-Aware\" routing relies on correctly defined capacity metrics. You must set the Balancing Mode (A) (e.g., define max 100 RPS per instance). Also set the Target Capacity (B) (usually < 100% for buffer). When healthy instances in Region A drop, total available capacity decreases. Once traffic exceeds the configured threshold, the LB automatically spills over excess requests to the nearest Region B with remaining capacity.",
      "wg": [
        {
          "t": "容量感知",
          "en": "Capacity-Aware",
          "ps": "Adj"
        },
        {
          "t": "溢位",
          "en": "Spillover",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "146",
    "level": "medium",
    "keywords": "Case Study, KnightMotives, CI/CD, Testing, Quality",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 KnightMotives Automotive 個案研究。為了確保車輛軟體的安全性，QA 團隊要求在 CI/CD 管道中整合模糊測試 (Fuzz Testing)。",
        "en": "Refer to the KnightMotives Automotive case study. To ensure vehicle software safety, the QA team requires integrating Fuzz Testing into the CI/CD pipeline.",
        "wg": [
          {
            "t": "模糊測試",
            "en": "Fuzz Testing",
            "ps": "N"
          }
        ]
      },
      {
        "t": "模糊測試非常消耗運算資源，且執行時間長短不一。",
        "en": "Fuzz Testing consumes significant compute resources and has variable execution times.",
        "wg": [
          {
            "t": "消耗",
            "en": "consume",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您希望將此測試步驟自動化並平行化，以縮短回饋循環。您應該使用哪兩個 Cloud Build 功能？(請選擇兩項)",
        "en": "You want to automate and parallelize this testing step to shorten the feedback loop. Which two Cloud Build features should you use? (Choose two)",
        "wg": [
          {
            "t": "平行化",
            "en": "parallelize",
            "ps": "V"
          },
          {
            "t": "回饋循環",
            "en": "feedback loop",
            "ps": "N"
          }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用高規格的機器類型 (Machine Types) (如 `e2-highcpu-8`)。",
        "en": "(A) Use high-spec Machine Types (e.g., `e2-highcpu-8`).",
        "wg": [
          {
            "t": "高規格",
            "en": "high-spec",
            "ps": "Adj"
          }
        ]
      },
      {
        "t": "(B) 設定較長的 `timeout` 值 (預設為 10 分鐘，可能不足)。",
        "en": "(B) Configure a longer `timeout` value (default is 10 minutes, which might be insufficient).",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud Build 的 `waitFor` 屬性來定義平行步驟。",
        "en": "(C) Use Cloud Build's `waitFor` property to define parallel steps.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud Functions 來觸發測試。",
        "en": "(D) Use Cloud Functions to trigger tests.",
        "wg": []
      },
      {
        "t": "(E) 僅在主分支 (Main Branch) 上執行測試。",
        "en": "(E) Only run tests on the Main Branch.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "模糊測試是計算密集型的。Cloud Build 允許您為特定步驟或整個構建指定機器類型 (A)，以加速執行。同時，由於模糊測試可能運行數小時，Cloud Build 預設的 10 分鐘超時限制肯定不足，必須顯式增加 `timeout` (B) (最高可達 24 小時)。雖然 `waitFor` (C) 支援平行，但 A 和 B 是解決「資源消耗與長時間執行」問題的關鍵配置。",
      "en": "Fuzz testing is compute-intensive. Cloud Build allows you to specify machine types (A) for specific steps or the entire build to accelerate execution. Also, since fuzz testing can run for hours, Cloud Build's default 10-minute timeout is insufficient, so you must explicitly increase the `timeout` (B) (up to 24 hours). While `waitFor` (C) enables parallelism, A and B are the critical configurations for addressing \"resource consumption and long execution times\".",
      "wg": [
        {
          "t": "顯式",
          "en": "explicitly",
          "ps": "Adv"
        }
      ]
    }
  },
  {
    "no": "147",
    "level": "medium",
    "keywords": "Security, Secrets, Rotation, Cloud Functions",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您的 Cloud Functions 需要存取一個外部資料庫，該資料庫的密碼每 90 天會強制輪替 (Rotate) 一次。",
        "en": "Your Cloud Functions need to access an external database whose password is forcibly rotated every 90 days.",
        "wg": [
          {
            "t": "輪替",
            "en": "rotate",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您希望在密碼變更時，Cloud Functions 能夠自動獲取新密碼，而無需重新部署函式。",
        "en": "You want Cloud Functions to automatically retrieve the new password when it changes, without redeploying the function.",
        "wg": [
          {
            "t": "重新部署",
            "en": "redeploy",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您應該採取哪兩個步驟？(請選擇兩項)",
        "en": "Which two steps should you take? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 在 Secret Manager 中啟用自動輪替 (Rotation Schedule)。",
        "en": "(A) Enable Rotation Schedule in Secret Manager.",
        "wg": []
      },
      {
        "t": "(B) 在 Cloud Functions 中，透過 API (Client Library) 在執行時動態讀取 Secret Manager 的 `latest` 版本。",
        "en": "(B) In Cloud Functions, dynamically read the `latest` version from Secret Manager via API (Client Library) at runtime.",
        "wg": [
          {
            "t": "執行時",
            "en": "runtime",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 將 Secret 作為環境變數掛載。",
        "en": "(C) Mount the Secret as an environment variable.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud Build 觸發器在密碼變更時自動重新部署。",
        "en": "(D) Use Cloud Build triggers to automatically redeploy when the password changes.",
        "wg": []
      },
      {
        "t": "(E) 將新密碼寫入 Cloud Storage，函式定期輪詢。",
        "en": "(E) Write the new password to Cloud Storage and have the function poll periodically.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "如果將 Secret 作為環境變數掛載 (C)，密碼值會在部署時被鎖定，輪替後必須重新部署才能生效。為了實現「無需重新部署」的自動更新，程式碼必須在執行時 (Runtime) 透過 API 主動去 Secret Manager 抓取 `latest` 版本的 Secret (B)。同時，Secret Manager 需設定輪替排程 (A) 來管理密碼的更新生命週期。",
      "en": "If mounting Secret as an environment variable (C), the value is locked at deployment time, requiring redeployment to take effect after rotation. To achieve automatic updates \"without redeployment,\" the code must proactively fetch the `latest` version of the Secret via API at Runtime (B). Additionally, Secret Manager needs a configured Rotation Schedule (A) to manage the password update lifecycle.",
      "wg": [
        {
          "t": "抓取",
          "en": "fetch",
          "ps": "V"
        }
      ]
    }
  },
  {
    "no": "148",
    "level": "hard",
    "keywords": "Case Study, Cymbal Retail, Spanner, Backup, PITR",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "參考 Cymbal Retail 個案研究。一位資料庫管理員意外地執行了錯誤的 `UPDATE` 指令，導致部分訂單資料損壞。",
        "en": "Refer to the Cymbal Retail case study. A database administrator accidentally executed an erroneous `UPDATE` command, corrupting some order data.",
        "wg": [
          {
            "t": "損壞",
            "en": "corrupt",
            "ps": "V"
          }
        ]
      },
      {
        "t": "該錯誤發生在 30 分鐘前。您需要將資料庫恢復到錯誤發生前的狀態，且停機時間越短越好。",
        "en": "The error occurred 30 minutes ago. You need to restore the database to the state before the error, with minimal downtime.",
        "wg": []
      },
      {
        "t": "您應該使用哪項 Cloud Spanner 功能？",
        "en": "Which Cloud Spanner feature should you use?",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用時間點復原 (Point-in-Time Recovery, PITR)。",
        "en": "(A) Use Point-in-Time Recovery (PITR).",
        "wg": [
          {
            "t": "時間點復原",
            "en": "Point-in-Time Recovery",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 從昨晚的備份還原。",
        "en": "(B) Restore from last night's backup.",
        "wg": []
      },
      {
        "t": "(C) 使用 Stale Read (過期讀取) 查詢舊資料並手動修復。",
        "en": "(C) Use Stale Read to query old data and manually fix it.",
        "wg": [
          {
            "t": "過期讀取",
            "en": "Stale Read",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(D) 請求 Google 支援團隊協助回滾。",
        "en": "(D) Request Google Support to assist with rollback.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Cloud Spanner 支援時間點復原 (PITR)，允許您將資料庫還原到過去保留期 (Retention Period，預設 7 天) 內的任何微秒級時間點。這是處理人為邏輯錯誤 (如誤刪、誤改) 最快且最精確的方法，遠比還原昨晚的備份 (會遺失一整天的資料) 或手動修復更有效率。",
      "en": "Cloud Spanner supports Point-in-Time Recovery (PITR), allowing you to restore the database to any microsecond-level timestamp within the retention period (default 7 days). This is the fastest and most precise method for handling human logical errors (like accidental deletion or modification), far more efficient than restoring last night's backup (losing a day's data) or manual fixing.",
      "wg": [
        {
          "t": "保留期",
          "en": "Retention Period",
          "ps": "N"
        },
        {
          "t": "人為邏輯錯誤",
          "en": "human logical error",
          "ps": "N"
        }
      ]
    }
  },
  {
    "no": "149",
    "level": "medium",
    "keywords": "Cost Optimization, FinOps, Budget, Alerting",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "作為 FinOps 團隊的一員，您希望防止開發專案的支出失控。",
        "en": "As a member of the FinOps team, you want to prevent runaway spending in development projects.",
        "wg": [
          {
            "t": "支出失控",
            "en": "runaway spending",
            "ps": "N"
          }
        ]
      },
      {
        "t": "您設定了預算 (Budget)，但發現預算警報 (Alerts) 只能通知，無法主動阻止資源建立。",
        "en": "You configured Budgets, but realized that Budget Alerts only notify and cannot proactively stop resource creation.",
        "wg": [
          {
            "t": "主動阻止",
            "en": "proactively stop",
            "ps": "V"
          }
        ]
      },
      {
        "t": "您希望在預算達到 90% 時，自動停用該專案的計費功能 (Billing) 以停止所有支出。您應該結合哪兩項服務？(請選擇兩項)",
        "en": "You want to automatically disable Billing for the project to stop all spending when the budget reaches 90%. Which two services should you combine? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 將預算警報發布到 Pub/Sub 主題。",
        "en": "(A) Publish Budget Alerts to a Pub/Sub topic.",
        "wg": []
      },
      {
        "t": "(B) 撰寫一個 Cloud Function 訂閱該主題，並呼叫 Cloud Billing API 來移除專案的 Billing Account 關聯。",
        "en": "(B) Write a Cloud Function to subscribe to that topic and call the Cloud Billing API to remove the project's Billing Account association.",
        "wg": [
          {
            "t": "關聯",
            "en": "association",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(C) 使用 Cloud Monitoring 的 Uptime Check。",
        "en": "(C) Use Cloud Monitoring Uptime Check.",
        "wg": []
      },
      {
        "t": "(D) 使用組織政策限制資源建立。",
        "en": "(D) Use Organization Policy to restrict resource creation.",
        "wg": []
      },
      {
        "t": "(E) 寄信給專案擁有者要求手動關閉。",
        "en": "(E) Email the project owner requesting manual shutdown.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "這是一個經典的「程式化預算控制 (Programmatic Budget Control)」模式。Cloud Billing Budgets 可以將通知傳送到 Pub/Sub (A)。然後，您可以部署一個 Cloud Function (B) 來消費這些訊息。當訊息內容顯示已超過閾值 (如 90%) 時，Cloud Function 使用 Billing API 移除該專案與 Billing Account 的連結，從而立即停止所有會產生費用的服務 (這是一個激烈的手段，通常僅用於沙盒環境)。",
      "en": "This is a classic \"Programmatic Budget Control\" pattern. Cloud Billing Budgets can send notifications to Pub/Sub (A). Then, you deploy a Cloud Function (B) to consume these messages. When the message indicates a threshold (e.g., 90%) is breached, the Cloud Function uses the Billing API to unlink the project from the Billing Account, immediately stopping all billable services (this is a drastic measure, usually for sandbox environments only).",
      "wg": [
        {
          "t": "程式化",
          "en": "Programmatic",
          "ps": "Adj"
        },
        {
          "t": "激烈的",
          "en": "drastic",
          "ps": "Adj"
        }
      ]
    }
  },
  {
    "no": "150",
    "level": "medium",
    "keywords": "Compute Engine, Automation, Startup Script, Metadata",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "您需要部署一組 Compute Engine 實例，這些實例在啟動時需要從 Cloud Storage 下載一個大型的設定檔。",
        "en": "You need to deploy a set of Compute Engine instances that need to download a large configuration file from Cloud Storage upon startup.",
        "wg": []
      },
      {
        "t": "由於設定檔會經常變更，您不希望每次變更都重新建立自訂映像檔 (Custom Image)。",
        "en": "Since the configuration file changes frequently, you do not want to recreate a Custom Image every time.",
        "wg": []
      },
      {
        "t": "您應該使用哪兩種機制來達成此目標？(請選擇兩項)",
        "en": "Which two mechanisms should you use to achieve this? (Choose two)",
        "wg": []
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用啟動腳本 (Startup Script) 來執行 `gsutil cp` 指令。",
        "en": "(A) Use a Startup Script to execute the `gsutil cp` command.",
        "wg": [
          {
            "t": "啟動腳本",
            "en": "Startup Script",
            "ps": "N"
          }
        ]
      },
      {
        "t": "(B) 授予 VM 的服務帳號 `roles/storage.objectViewer` 權限。",
        "en": "(B) Grant the VM's Service Account the `roles/storage.objectViewer` role.",
        "wg": []
      },
      {
        "t": "(C) 將設定檔打包在 ISO 中並掛載。",
        "en": "(C) Package the configuration file in an ISO and mount it.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud Build 在啟動時建置應用程式。",
        "en": "(D) Use Cloud Build to build the application at startup.",
        "wg": []
      },
      {
        "t": "(E) 在 VM 中儲存長期的 Service Account Key。",
        "en": "(E) Store a long-lived Service Account Key in the VM.",
        "wg": []
      }
    ],
    "answer": "A, B",
    "why": {
      "t": "啟動腳本 (Startup Script) (A) 是在 VM 啟動時動態執行邏輯 (如下載最新檔案) 的標準方法，避免了頻繁重建映像檔的開銷。為了讓腳本能夠存取 GCS，必須遵循最小權限原則，授予附加在 VM 上的服務帳號讀取 GCS 的 IAM 權限 (B)，而不是儲存靜態金鑰。",
      "en": "Startup Scripts (A) are the standard method for dynamically executing logic (like downloading the latest files) at VM boot, avoiding the overhead of frequent image rebuilding. To allow the script to access GCS, you must follow the principle of least privilege by granting the Service Account attached to the VM the IAM permission to read GCS (B), rather than storing static keys.",
      "wg": [
        {
          "t": "動態執行",
          "en": "dynamically execute",
          "ps": "V"
        },
        {
          "t": "開銷",
          "en": "overhead",
          "ps": "N"
        }
      ]
    }
  }
]