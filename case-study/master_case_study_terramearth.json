[
  {
    "no": "1",
    "level": "hard",
    "keywords": "Apigee, Legacy Modernization, API Management",
    "question": [
      {
        "t": "TerramEarth 的經銷商和合作夥伴需要存取儲存在地端私有資料中心內舊有庫存和物流系統中的數據。",
        "en": "TerramEarth’s dealers and partners require access to data stored in legacy inventory and logistics systems located in on-premises private data centers.",
        "wg": [
          { "t": "經銷商", "en": "dealers", "ps": "noun" },
          { "t": "舊有庫存", "en": "legacy inventory", "ps": "noun" },
          { "t": "地端", "en": "on-premises", "ps": "adjective" }
        ]
      },
      {
        "t": "作為業務需求的一部分，您需要建立一個新的抽象層，以便在不中斷營運的情況下逐步遷移到雲端，同時為合作夥伴提供安全且受控的存取權限。",
        "en": "As part of the business requirements, you need to create a new abstraction layer to enable a gradual move to the cloud without disrupting operations while providing secure and managed access for partners.",
        "wg": [
          { "t": "抽象層", "en": "abstraction layer", "ps": "noun" },
          { "t": "逐步遷移", "en": "gradual move", "ps": "noun" },
          { "t": "受控的存取權限", "en": "managed access", "ps": "noun" }
        ]
      },
      {
        "t": "您必須確保該解決方案支援配額管理、分析功能，並能隱藏後端舊有系統的複雜性。您應該採取哪種行動？",
        "en": "You must ensure the solution supports quota management, analytics, and hides the complexity of backend legacy systems. What action should you take?",
        "wg": [
          { "t": "配額管理", "en": "quota management", "ps": "noun" },
          { "t": "隱藏", "en": "hides", "ps": "verb" },
          { "t": "複雜性", "en": "complexity", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 Google Cloud 中部署 Cloud Endpoints，使用 OpenAPI 規範定義 API，並透過 Cloud VPN 將流量直接路由到地端伺服器。",
        "en": "(A) Deploy Cloud Endpoints in Google Cloud, define APIs using OpenAPI specifications, and route traffic directly to on-premises servers via Cloud VPN.",
        "wg": [
          { "t": "部署", "en": "Deploy", "ps": "verb" },
          { "t": "直接路由", "en": "route directly", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 將所有舊有數據一次性遷移到 Cloud Bigtable，並使用 Dataflow 建立即時 API 服務供合作夥伴查詢。",
        "en": "(B) Migrate all legacy data to Cloud Bigtable in a single lift-and-shift operation, and use Dataflow to build real-time API services for partners to query.",
        "wg": [
          { "t": "一次性", "en": "single lift-and-shift", "ps": "adjective" },
          { "t": "遷移", "en": "Migrate", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 實作 Apigee 作為 API 管理平台來建立 API 代理 (Proxies)，透過互連網路連接到舊有後端，並設定開發者入口網站。",
        "en": "(C) Implement Apigee as the API management platform to create API proxies that connect to the legacy backend via interconnects, and configure the developer portal.",
        "wg": [
          { "t": "實作", "en": "Implement", "ps": "verb" },
          { "t": "API 代理", "en": "API proxies", "ps": "noun" },
          { "t": "開發者入口網站", "en": "developer portal", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Compute Engine 執行個體建立一個自定義的 NGINX 反向代理叢集，並設定防火牆規則以允許合作夥伴 IP 存取。",
        "en": "(D) Create a custom NGINX reverse proxy cluster using Compute Engine instances, and configure firewall rules to allow partner IP access.",
        "wg": [
          { "t": "反向代理", "en": "reverse proxy", "ps": "noun" },
          { "t": "防火牆規則", "en": "firewall rules", "ps": "noun" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Apigee 是企業級 API 管理的最佳選擇，符合案例中「建立抽象層」、「合作夥伴生態系」以及「受控存取（配額、分析）」的需求。選項 A (Cloud Endpoints) 功能較簡單，較適合內部微服務；選項 B (Bigtable) 違反了「逐步遷移」且不中斷營運的要求；選項 D (NGINX) 缺乏原生的開發者門戶與進階變現/管理功能。",
      "en": "Apigee is the best choice for enterprise-grade API management, aligning with the requirements to 'create an abstraction layer', support a 'partner ecosystem', and provide 'managed access (quotas, analytics)'. Option A (Cloud Endpoints) is simpler and better suited for internal microservices; Option B (Bigtable) violates the requirement for a 'gradual move' without disruption; Option D (NGINX) lacks a native developer portal and advanced monetization/management features.",
      "wg": [
        { "t": "企業級", "en": "enterprise-grade", "ps": "adjective" },
        { "t": "符合", "en": "aligning with", "ps": "verb" }
      ]
    }
  },
  {
    "no": "2",
    "level": "hard",
    "keywords": "Data Ingestion, Pub/Sub, IoT",
    "question": [
      {
        "t": "TerramEarth 擁有 200 萬輛運行中的車輛，這些車輛會透過不穩定的行動網路連線傳輸關鍵的即時遙測數據。",
        "en": "TerramEarth has 2 million vehicles in operation that transmit critical real-time telemetry data over unstable cellular network connections.",
        "wg": [
          { "t": "不穩定的", "en": "unstable", "ps": "adjective" },
          { "t": "遙測數據", "en": "telemetry data", "ps": "noun" }
        ]
      },
      {
        "t": "您需要設計一個數據攝取架構，能夠處理來自數百萬個感測器的高吞吐量訊息，緩衝數據以應對流量峰值，並確保數據能被可靠地傳遞到後端進行即時車隊管理分析。",
        "en": "You need to design a data ingestion architecture capable of handling high-throughput messages from millions of sensors, buffering data to handle traffic spikes, and ensuring reliable delivery to the backend for real-time fleet management analytics.",
        "wg": [
          { "t": "數據攝取", "en": "data ingestion", "ps": "noun" },
          { "t": "流量峰值", "en": "traffic spikes", "ps": "noun" },
          { "t": "可靠地傳遞", "en": "reliable delivery", "ps": "noun" }
        ]
      },
      {
        "t": "該解決方案必須是全託管的，以最大限度地減少維運開銷。您應該怎麼做？",
        "en": "The solution must be fully managed to minimize operational overhead. What should you do?",
        "wg": [
          { "t": "全託管的", "en": "fully managed", "ps": "adjective" },
          { "t": "維運開銷", "en": "operational overhead", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 設定車輛使用 gRPC 直接寫入 Compute Engine 上的自定義應用程式，並將數據儲存在本地 SSD 中以獲得最高效能。",
        "en": "(A) Configure vehicles to write directly to a custom application on Compute Engine using gRPC, and store data on Local SSDs for maximum performance.",
        "wg": [
          { "t": "直接寫入", "en": "write directly", "ps": "verb" },
          { "t": "本地 SSD", "en": "Local SSDs", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 讓車輛將遙測數據發佈到 Cloud Pub/Sub 主題，並使用 Cloud Dataflow 訂閱該主題以處理數據並將其寫入 BigQuery。",
        "en": "(B) Have vehicles publish telemetry data to a Cloud Pub/Sub topic, and use Cloud Dataflow to subscribe to the topic to process and write data to BigQuery.",
        "wg": [
          { "t": "發佈", "en": "publish", "ps": "verb" },
          { "t": "訂閱", "en": "subscribe", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 Cloud IoT Core (註：若考試包含此舊產品) 或 MQTT 橋接器將數據直接串流傳輸到 Cloud Storage，然後觸發 Cloud Functions 進行處理。",
        "en": "(C) Stream data directly to Cloud Storage using an MQTT bridge, and then trigger Cloud Functions for processing.",
        "wg": [
          { "t": "串流傳輸", "en": "Stream", "ps": "verb" },
          { "t": "觸發", "en": "trigger", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 將數據直接寫入 Cloud SQL for PostgreSQL 資料庫，並配置自動擴展以處理高峰時段的連線數。",
        "en": "(D) Write data directly to a Cloud SQL for PostgreSQL database, and configure autoscaling to handle connection counts during peak hours.",
        "wg": [
          { "t": "資料庫", "en": "database", "ps": "noun" },
          { "t": "自動擴展", "en": "autoscaling", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Cloud Pub/Sub 是處理大規模 IoT 攝取、緩衝流量峰值以及解耦生產者與消費者的標準 GCP 解決方案。配合 Dataflow 與 BigQuery 可實現即時分析。選項 A 缺乏彈性且維運負擔高；選項 C 的 Cloud Storage 不適合低延遲即時分析的攝取點；選項 D 的關聯式資料庫難以處理 200 萬個並發連線。",
      "en": "Cloud Pub/Sub is the standard GCP solution for handling massive IoT ingestion, buffering traffic spikes, and decoupling producers from consumers. Pairing it with Dataflow and BigQuery enables real-time analytics. Option A lacks elasticity and has high operational overhead; Option C's Cloud Storage is not a suitable ingestion point for low-latency real-time analytics; Option D's relational database struggles to handle 2 million concurrent connections.",
      "wg": [
        { "t": "解耦", "en": "decoupling", "ps": "verb" },
        { "t": "緩衝", "en": "buffering", "ps": "verb" }
      ]
    }
  },
  {
    "no": "3",
    "level": "hard",
    "keywords": "Cost Optimization, Storage Lifecycle, BigQuery",
    "question": [
      {
        "t": "TerramEarth 每天從車輛收集 200 到 500 MB 的壓縮感測器數據。此數據主要用於歷史趨勢分析和訓練預測性維護模型。",
        "en": "TerramEarth collects 200 to 500 MB of compressed sensor data per vehicle daily. This data is primarily used for historical trend analysis and training predictive maintenance models.",
        "wg": [
          { "t": "壓縮", "en": "compressed", "ps": "adjective" },
          { "t": "歷史趨勢", "en": "historical trend", "ps": "noun" }
        ]
      },
      {
        "t": "由於數據量會隨著時間推移達到 PB 級別，您需要設計一個儲存策略，既能讓數據科學家透過 BigQuery 存取數據，又能將雲端儲存成本降至最低。",
        "en": "Since the data volume will reach petabyte scale over time, you need to design a storage strategy that allows data scientists to access data via BigQuery while minimizing cloud storage costs.",
        "wg": [
          { "t": "儲存策略", "en": "storage strategy", "ps": "noun" },
          { "t": "PB 級別", "en": "petabyte scale", "ps": "noun" }
        ]
      },
      {
        "t": "大多數查詢僅針對最近 30 天的數據。您應該採取什麼行動？",
        "en": "Most queries target only the last 30 days of data. What action should you take?",
        "wg": [
          { "t": "查詢", "en": "queries", "ps": "noun" },
          { "t": "最近 30 天", "en": "last 30 days", "ps": "noun" }
        ]
      },
      {
        "t": "(選擇最優解)",
        "en": "(Choose the best solution)",
        "wg": []
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將所有原始數據儲存在 BigQuery 原生儲存中，並使用分區表 (Partitioned Tables) 依據攝取時間進行分區。",
        "en": "(A) Store all raw data in BigQuery native storage, and use Partitioned Tables to partition based on ingestion time.",
        "wg": [
          { "t": "原生儲存", "en": "native storage", "ps": "noun" },
          { "t": "分區表", "en": "Partitioned Tables", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 將原始數據儲存在 Cloud Storage Nearline 儲存分桶中，並定期將所有數據匯入到 Cloud SQL 進行分析。",
        "en": "(B) Store raw data in Cloud Storage Nearline buckets, and periodically import all data into Cloud SQL for analysis.",
        "wg": [
          { "t": "儲存分桶", "en": "storage buckets", "ps": "noun" },
          { "t": "匯入", "en": "import", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 將數據儲存在 Persistent Disk 上，並掛載到高效能 Compute Engine 叢集上運行 Hadoop 進行批次處理。",
        "en": "(C) Store data on Persistent Disks mounted to a high-performance Compute Engine cluster running Hadoop for batch processing.",
        "wg": [
          { "t": "掛載", "en": "mounted", "ps": "verb" },
          { "t": "批次處理", "en": "batch processing", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 將原始檔案上傳到 Cloud Storage 標準級別，並設定生命週期策略在 30 天後將其轉移到 Coldline。使用 BigQuery 外部資料表 (External Tables) 或 Omni 來查詢數據。",
        "en": "(D) Upload raw files to Cloud Storage Standard class, and configure lifecycle policies to move them to Coldline after 30 days. Use BigQuery External Tables or Omni to query the data.",
        "wg": [
          { "t": "生命週期策略", "en": "lifecycle policies", "ps": "noun" },
          { "t": "外部資料表", "en": "External Tables", "ps": "noun" }
        ]
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "選項 D 利用物件生命週期管理 (Object Lifecycle Management) 自動將舊數據降級至更便宜的儲存類別 (Coldline)，這直接解決了「PB 級別」的成本問題，同時 BigQuery 外部資料表允許直接查詢 GCS 上的數據而無需支付雙重儲存費用。選項 A 雖然效能好但長期儲存大量原始日誌成本極高；選項 B 的 Cloud SQL 無法擴展至此規模；選項 C 使用 Persistent Disk 是最昂貴的儲存方式。",
      "en": "Option D leverages Object Lifecycle Management to automatically downgrade old data to cheaper storage classes (Coldline), directly addressing the 'petabyte scale' cost issue, while BigQuery External Tables allow querying data on GCS without double storage costs. Option A offers good performance but is cost-prohibitive for long-term raw log storage; Option B's Cloud SQL cannot scale to this volume; Option C using Persistent Disks is the most expensive storage method.",
      "wg": [
        { "t": "降級", "en": "downgrade", "ps": "verb" },
        { "t": "雙重儲存費用", "en": "double storage costs", "ps": "noun" }
      ]
    }
  },
  {
    "no": "4",
    "level": "hard",
    "keywords": "Security, Remote Access, IAP",
    "question": [
      {
        "t": "TerramEarth 的開發團隊分佈在全球各地。為了提高開發速度，他們需要能夠安全地存取位於 Google Cloud 私有網路 (VPC) 內的開發環境和內部儀表板。",
        "en": "TerramEarth's development team is distributed globally. To increase development speed, they need secure access to development environments and internal dashboards located within a Google Cloud Virtual Private Cloud (VPC).",
        "wg": [
          { "t": "分佈在全球各地", "en": "distributed globally", "ps": "adjective" },
          { "t": "私有網路", "en": "Virtual Private Cloud", "ps": "noun" }
        ]
      },
      {
        "t": "安全團隊要求不得將這些內部服務暴露在公共網際網路上，且必須根據使用者身分進行存取控制。同時，管理層希望避免維護傳統 VPN 基礎設施的複雜性。",
        "en": "The security team requires that these internal services must not be exposed to the public internet and access must be controlled based on user identity. Meanwhile, management wants to avoid the complexity of maintaining traditional VPN infrastructure.",
        "wg": [
          { "t": "暴露", "en": "exposed", "ps": "verb" },
          { "t": "身分", "en": "identity", "ps": "noun" },
          { "t": "複雜性", "en": "complexity", "ps": "noun" }
        ]
      },
      {
        "t": "您應該推薦哪種解決方案？",
        "en": "Which solution should you recommend?",
        "wg": [
          { "t": "推薦", "en": "recommend", "ps": "verb" },
          { "t": "解決方案", "en": "solution", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 設定 Identity-Aware Proxy (IAP) 來保護內部應用程式和 SSH/RDP 存取，並配置 IAM 政策以授予特定開發者存取權限。",
        "en": "(A) Configure Identity-Aware Proxy (IAP) to protect internal applications and SSH/RDP access, and configure IAM policies to grant access to specific developers.",
        "wg": [
          { "t": "保護", "en": "protect", "ps": "verb" },
          { "t": "授予", "en": "grant", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 為每個開發人員配置一個帶有公共 IP 位址的 Bastion Host (跳板機)，並使用防火牆規則將 SSH 存取限制為開發人員的家庭 IP。",
        "en": "(B) Provision a Bastion Host with a public IP address for each developer, and use firewall rules to restrict SSH access to the developers' home IPs.",
        "wg": [
          { "t": "跳板機", "en": "Bastion Host", "ps": "noun" },
          { "t": "限制", "en": "restrict", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 Cloud VPN 在每個開發人員的筆記型電腦和 Google Cloud VPC 之間建立加密通道。",
        "en": "(C) Use Cloud VPN to establish an encrypted tunnel between each developer's laptop and the Google Cloud VPC.",
        "wg": [
          { "t": "加密通道", "en": "encrypted tunnel", "ps": "noun" },
          { "t": "筆記型電腦", "en": "laptop", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 將內部應用程式部署在 App Engine 上，並使用防火牆規則允許來自所有 IP 位址的 HTTPS 流量。",
        "en": "(D) Deploy internal applications on App Engine and use firewall rules to allow HTTPS traffic from all IP addresses.",
        "wg": [
          { "t": "部署", "en": "Deploy", "ps": "verb" },
          { "t": "允許", "en": "allow", "ps": "verb" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Identity-Aware Proxy (IAP) 允許在不使用 VPN 的情況下對 VM 和應用程式進行零信任 (Zero Trust) 存取，完全符合「不暴露於公共網路」、「基於身分控制」以及「避免 VPN 維護」的需求。選項 B 的 Bastion Host 維護負擔大且依賴 IP 白名單（不靈活）；選項 C 違背了管理層避免 VPN 維護的要求；選項 D 將內部應用暴露給公網，違反安全規定。",
      "en": "Identity-Aware Proxy (IAP) enables Zero Trust access to VMs and applications without a VPN, perfectly aligning with the requirements to 'not expose to public internet', 'identity-based control', and 'avoid VPN maintenance'. Option B (Bastion Host) has high maintenance and relies on IP allowlisting (inflexible); Option C contradicts the management's desire to avoid VPN maintenance; Option D exposes internal apps to the public internet, violating security rules.",
      "wg": [
        { "t": "零信任", "en": "Zero Trust", "ps": "noun" },
        { "t": "違背", "en": "contradicts", "ps": "verb" }
      ]
    }
  },
  {
    "no": "5",
    "level": "hard",
    "keywords": "CI/CD, DevOps, Scalability, Autoscaling",
    "question": [
      {
        "t": "TerramEarth 希望將其應用程式部署流程現代化，並適應農業產業的季節性工作負載變化。目前的部署流程是手動的且容易出錯。",
        "en": "TerramEarth wants to modernize its application deployment process and adapt to the seasonal workload changes in the agricultural industry. The current deployment process is manual and error-prone.",
        "wg": [
          { "t": "現代化", "en": "modernize", "ps": "verb" },
          { "t": "季節性", "en": "seasonal", "ps": "adjective" }
        ]
      },
      {
        "t": "您需要設計一個 CI/CD 管道，允許開發人員在高度可擴展的環境中部署基於容器的工作負載。解決方案必須支援自動擴展以應對高峰需求，並在淡季減少資源使用以節省成本。",
        "en": "You need to design a CI/CD pipeline that allows developers to deploy container-based workloads in a highly scalable environment. The solution must support autoscaling to handle peak demand and reduce resource usage during the off-season to save costs.",
        "wg": [
          { "t": "容器", "en": "container", "ps": "noun" },
          { "t": "自動擴展", "en": "autoscaling", "ps": "noun" }
        ]
      },
      {
        "t": "您應該選擇哪兩個步驟？（請選擇兩項）",
        "en": "Which two steps should you choose? (Choose two)",
        "wg": [
          { "t": "步驟", "en": "steps", "ps": "noun" },
          { "t": "選擇", "en": "Choose", "ps": "verb" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 使用 Jenkins 在一組固定的 Compute Engine 虛擬機器上建置 Docker 映像檔，並使用 Ansible 腳本進行部署。",
        "en": "(A) Use Jenkins to build Docker images on a fixed set of Compute Engine virtual machines, and use Ansible scripts for deployment.",
        "wg": [
          { "t": "固定的", "en": "fixed", "ps": "adjective" },
          { "t": "腳本", "en": "scripts", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 實作 Cloud Build 管道，在程式碼提交時自動觸發測試、建置容器映像檔，並將其推送到 Artifact Registry。",
        "en": "(B) Implement a Cloud Build pipeline that automatically triggers tests, builds container images, and pushes them to Artifact Registry upon code commit.",
        "wg": [
          { "t": "觸發", "en": "triggers", "ps": "verb" },
          { "t": "推送", "en": "pushes", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 將應用程式部署到 App Engine Flexible 環境，並將最小執行個體數設定為預計的高峰負載量以確保效能。",
        "en": "(C) Deploy applications to App Engine Flexible environment, and set the minimum number of instances to the projected peak load to ensure performance.",
        "wg": [
          { "t": "最小執行個體數", "en": "minimum number of instances", "ps": "noun" },
          { "t": "高峰負載量", "en": "peak load", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 將應用程式部署到單一區域 (Zonal) 的 GKE 叢集，並停用叢集自動擴展器以保持預算可預測。",
        "en": "(D) Deploy applications to a single-zone (Zonal) GKE cluster, and disable the cluster autoscaler to keep the budget predictable.",
        "wg": [
          { "t": "單一區域", "en": "single-zone", "ps": "adjective" },
          { "t": "停用", "en": "disable", "ps": "verb" }
        ]
      },
      {
        "t": "(E) 配置 Google Kubernetes Engine (GKE) 叢集，啟用 Horizontal Pod Autoscaler (HPA) 和 Cluster Autoscaler，以根據 CPU/記憶體使用率動態調整資源。",
        "en": "(E) Configure a Google Kubernetes Engine (GKE) cluster with Horizontal Pod Autoscaler (HPA) and Cluster Autoscaler enabled to dynamically adjust resources based on CPU/memory usage.",
        "wg": [
          { "t": "啟用", "en": "enabled", "ps": "verb" },
          { "t": "動態調整", "en": "dynamically adjust", "ps": "verb" }
        ]
      }
    ],
    "answer": "(B), (E)",
    "why": {
      "t": "Cloud Build (選項 B) 是 Google 推薦的無伺服器 CI/CD 工具，能滿足「現代化」與「容器建置」的需求。GKE 配合 HPA 和 Cluster Autoscaler (選項 E) 是解決「季節性」和「高度可擴展」的最佳實踐，能確保在需求低時縮減節點以節省成本。選項 A 使用傳統 VM 和 Jenkins 維護成本高；選項 C 將最小實例設為高峰值違反了成本優化原則；選項 D 停用自動擴展無法適應季節性變化。",
      "en": "Cloud Build (Option B) is Google's recommended serverless CI/CD tool, meeting the 'modernization' and 'container build' needs. GKE with HPA and Cluster Autoscaler (Option E) is the best practice for addressing 'seasonality' and 'high scalability', ensuring nodes scale down during low demand to save costs. Option A uses traditional VMs/Jenkins with high maintenance; Option C sets minimum instances to peak load, violating cost optimization; Option D disabling autoscaling fails to adapt to seasonality.",
      "wg": [
        { "t": "無伺服器", "en": "serverless", "ps": "adjective" },
        { "t": "縮減", "en": "scale down", "ps": "verb" }
      ]
    }
  },
  {
    "no": "6",
    "level": "hard",
    "keywords": "Network, Hybrid Connectivity, High Availability, SLA",
    "question": [
      {
        "t": "TerramEarth 的兩個主要製造工廠需要將關鍵的即時車輛遙測數據傳輸到 Google Cloud 進行分析。目前的私有資料中心已配置了多條網路互連 (Network Interconnects)。",
        "en": "TerramEarth’s two main manufacturing plants need to transmit critical real-time vehicle telemetry data to Google Cloud for analysis. The private data centers are currently configured with multiple network interconnects.",
        "wg": [
          { "t": "製造工廠", "en": "manufacturing plants", "ps": "noun" },
          { "t": "網路互連", "en": "Network Interconnects", "ps": "noun" }
        ]
      },
      {
        "t": "為了滿足關鍵任務的可靠性要求，您需要確保混合連線架構符合 Google Cloud 的 99.99% 可用性服務層級協議 (SLA)。",
        "en": "To meet mission-critical reliability requirements, you need to ensure the hybrid connectivity architecture meets Google Cloud’s 99.99% Availability Service Level Agreement (SLA).",
        "wg": [
          { "t": "關鍵任務", "en": "mission-critical", "ps": "adjective" },
          { "t": "服務層級協議", "en": "Service Level Agreement", "ps": "noun" }
        ]
      },
      {
        "t": "您應該如何設計互連拓撲？",
        "en": "How should you design the interconnect topology?",
        "wg": [
          { "t": "拓撲", "en": "topology", "ps": "noun" },
          { "t": "設計", "en": "design", "ps": "verb" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在單一都會區 (Metro) 佈建兩條 Dedicated Interconnect 連線，並使用 Cloud VPN 作為備援路徑以確保連線不中斷。",
        "en": "(A) Provision two Dedicated Interconnect connections in a single metropolitan area (Metro), and use Cloud VPN as a backup path to ensure uninterrupted connectivity.",
        "wg": [
          { "t": "單一都會區", "en": "single metropolitan area", "ps": "noun" },
          { "t": "備援路徑", "en": "backup path", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 在兩個不同的都會區中，每個都會區各佈建兩條 Dedicated Interconnect 連線（總共 4 條連線），以實現地理備援。",
        "en": "(B) Provision two Dedicated Interconnect connections in each of two different metropolitan areas (total of 4 connections) to achieve geographic redundancy.",
        "wg": [
          { "t": "地理備援", "en": "geographic redundancy", "ps": "noun" },
          { "t": "總共", "en": "total of", "ps": "adjective" }
        ]
      },
      {
        "t": "(C) 使用 Partner Interconnect 連接到服務提供商，並請求提供商確保其網路骨幹具備 99.99% 的可用性保證。",
        "en": "(C) Use Partner Interconnect to connect to a service provider, and request the provider to ensure their network backbone has a 99.99% availability guarantee.",
        "wg": [
          { "t": "服務提供商", "en": "service provider", "ps": "noun" },
          { "t": "骨幹", "en": "backbone", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 配置兩條 Dedicated Interconnect 連線，分別連接到同一個區域 (Region) 內的不同區域 (Zones) 的 Cloud Router。",
        "en": "(D) Configure two Dedicated Interconnect connections, each connecting to Cloud Routers in different Zones within the same Region.",
        "wg": [
          { "t": "不同區域", "en": "different Zones", "ps": "noun" },
          { "t": "連接", "en": "connecting", "ps": "verb" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "根據 Google Cloud 架構指南，要獲得 99.99% 的 Dedicated Interconnect SLA，必須在兩個不同的都會區 (Metros) 各配置兩條連線（共 4 條），以防止單一設施維護或斷電導致的全面中斷。選項 A 和 D 僅能提供 99.9% 的 SLA（單一都會區）；選項 C 依賴合作夥伴的 SLA，而 Google 自身的 99.99% SLA 仍要求特定的多都會區拓撲配置。",
      "en": "According to Google Cloud architecture guides, to achieve a 99.99% Dedicated Interconnect SLA, you must provision two connections in each of two different metropolitan areas (4 total) to prevent total outages from single-facility maintenance or power failures. Options A and D only provide a 99.9% SLA (single metro); Option C relies on the partner's SLA, but Google's own 99.99% SLA still requires the specific multi-metro topology configuration.",
      "wg": [
        { "t": "都會區", "en": "Metros", "ps": "noun" },
        { "t": "全面中斷", "en": "total outages", "ps": "noun" }
      ]
    }
  },
  {
    "no": "7",
    "level": "hard",
    "keywords": "Analytics, BigQuery, Performance, BI Engine",
    "question": [
      {
        "t": "TerramEarth 的經銷商使用網頁前端存取庫存管理儀表板。該儀表板由 BigQuery 提供支援，數據量龐大且查詢頻繁。",
        "en": "TerramEarth dealers use a web frontend to access inventory management dashboards. The dashboards are backed by BigQuery, with massive data volumes and frequent queries.",
        "wg": [
          { "t": "儀表板", "en": "dashboards", "ps": "noun" },
          { "t": "由...提供支援", "en": "backed by", "ps": "verb" }
        ]
      },
      {
        "t": "經銷商投訴儀表板載入緩慢，影響了他們的日常營運。您需要優化架構以實現亞秒級 (Sub-second) 的查詢回應時間，同時支援高並發使用者，且無需大幅重寫 SQL 查詢。",
        "en": "Dealers are complaining about slow dashboard loading times, impacting their daily operations. You need to optimize the architecture to achieve sub-second query response times while supporting high concurrency, without significantly rewriting SQL queries.",
        "wg": [
          { "t": "亞秒級", "en": "Sub-second", "ps": "adjective" },
          { "t": "高並發", "en": "high concurrency", "ps": "noun" }
        ]
      },
      {
        "t": "您應該採取什麼行動？",
        "en": "What action should you take?",
        "wg": [
          { "t": "重寫", "en": "rewriting", "ps": "verb" },
          { "t": "行動", "en": "action", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將庫存數據匯出到 Cloud Bigtable，並修改前端應用程式以使用 Bigtable API 進行低延遲點查詢 (Point lookups)。",
        "en": "(A) Export inventory data to Cloud Bigtable, and modify the frontend application to use the Bigtable API for low-latency point lookups.",
        "wg": [
          { "t": "匯出", "en": "Export", "ps": "verb" },
          { "t": "點查詢", "en": "point lookups", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 啟用 BigQuery BI Engine，並配置足夠的記憶體保留容量來快取最常被查詢的庫存數據。",
        "en": "(B) Enable BigQuery BI Engine and configure sufficient memory reservation capacity to cache the most frequently queried inventory data.",
        "wg": [
          { "t": "啟用", "en": "Enable", "ps": "verb" },
          { "t": "記憶體保留", "en": "memory reservation", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Dataflow 將數據預聚合 (Pre-aggregate) 到新的 BigQuery 表中，並排程每小時更新一次。",
        "en": "(C) Use Cloud Dataflow to pre-aggregate data into new BigQuery tables, and schedule updates to occur every hour.",
        "wg": [
          { "t": "預聚合", "en": "pre-aggregate", "ps": "verb" },
          { "t": "排程", "en": "schedule", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 將 BigQuery 專案切換到固定費率 (Flat-rate) 定價模式，並購買額外的 Slots 以增加查詢處理能力。",
        "en": "(D) Switch the BigQuery project to flat-rate pricing and purchase additional Slots to increase query processing power.",
        "wg": [
          { "t": "固定費率", "en": "flat-rate", "ps": "adjective" },
          { "t": "處理能力", "en": "processing power", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "BigQuery BI Engine 是一個記憶體內分析服務，專為提供亞秒級查詢回應和高並發性而設計，且與 BI 工具（如 Looker Studio）無縫整合，無需重寫 SQL。選項 A 需要更改應用程式代碼（Bigtable API）；選項 C 雖然能提高效能但會犧牲數據即時性（每小時更新）；選項 D 增加 Slots 雖然能提升吞吐量，但通常無法達到記憶體內快取的亞秒級延遲。",
      "en": "BigQuery BI Engine is an in-memory analysis service designed to provide sub-second query responses and high concurrency, integrating seamlessly with BI tools without rewriting SQL. Option A requires application code changes (Bigtable API); Option C improves performance but sacrifices data freshness (hourly updates); Option D increasing Slots improves throughput but typically cannot achieve the sub-second latency of in-memory caching.",
      "wg": [
        { "t": "記憶體內", "en": "in-memory", "ps": "adjective" },
        { "t": "犧牲", "en": "sacrifices", "ps": "verb" }
      ]
    }
  },
  {
    "no": "8",
    "level": "hard",
    "keywords": "Security, IAM, Resource Hierarchy, Sandbox",
    "question": [
      {
        "t": "TerramEarth 的開發人員需要一個安全的環境來進行實驗和測試新功能，且不能犧牲安全性或違反治理要求。",
        "en": "TerramEarth developers need a secure environment to experiment and test new features without compromising security or violating governance requirements.",
        "wg": [
          { "t": "實驗", "en": "experiment", "ps": "verb" },
          { "t": "治理要求", "en": "governance requirements", "ps": "noun" }
        ]
      },
      {
        "t": "您希望為開發人員提供建立專案和資源的自主權，同時防止成本超支並確保與生產網路隔離。您應該如何建構資源階層？",
        "en": "You want to give developers autonomy to create projects and resources while preventing cost overruns and ensuring isolation from the production network. How should you structure the resource hierarchy?",
        "wg": [
          { "t": "自主權", "en": "autonomy", "ps": "noun" },
          { "t": "隔離", "en": "isolation", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 建立一個名為「Sandbox」的文件夾，並使用組織政策 (Organization Policies) 限制資源使用。授予開發人員在該文件夾內的 Project Creator 角色，並為該文件夾設定自動計費預算與警報。",
        "en": "(A) Create a folder named 'Sandbox' and use Organization Policies to restrict resource usage. Grant developers the Project Creator role on that folder, and set up automated billing budgets and alerts for the folder.",
        "wg": [
          { "t": "文件夾", "en": "folder", "ps": "noun" },
          { "t": "計費預算", "en": "billing budgets", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 為每個開發人員建立一個單獨的 VPC 網路，並使用防火牆規則封鎖所有外部流量。授予他們 Owner 角色以便完全控制。",
        "en": "(B) Create a separate VPC network for each developer and use firewall rules to block all external traffic. Grant them the Owner role for full control.",
        "wg": [
          { "t": "封鎖", "en": "block", "ps": "verb" },
          { "t": "外部流量", "en": "external traffic", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 允許開發人員使用他們的個人 Gmail 帳戶建立專案，並使用 Cloud Identity 將這些專案連結到公司組織。",
        "en": "(C) Allow developers to create projects using their personal Gmail accounts, and use Cloud Identity to link these projects to the corporate organization.",
        "wg": [
          { "t": "個人 Gmail 帳戶", "en": "personal Gmail accounts", "ps": "noun" },
          { "t": "連結", "en": "link", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 為開發團隊建立一個單一的共享專案，並使用 IAM 條件 (IAM Conditions) 限制每個開發人員只能存取特定的資源類型。",
        "en": "(D) Create a single shared project for the development team and use IAM Conditions to restrict each developer to accessing only specific resource types.",
        "wg": [
          { "t": "共享專案", "en": "shared project", "ps": "noun" },
          { "t": "限制", "en": "restrict", "ps": "verb" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "建立專用的 Sandbox 文件夾是隔離實驗環境的最佳實務。授予 Project Creator 角色能提供自主權，同時組織政策可防止創建昂貴或不合規的資源（例如：限制公網 IP），而計費預算可控管成本。選項 B 授予 Owner 角色過於寬鬆且難以治理；選項 C 使用個人帳戶會導致數據所有權問題（Shadow IT）；選項 D 在單一專案中混用會導致配額衝突與權限管理混亂。",
      "en": "Creating a dedicated Sandbox folder is the best practice for isolating experimental environments. Granting the Project Creator role provides autonomy, while Organization Policies prevent the creation of expensive or non-compliant resources (e.g., restricting public IPs), and billing budgets control costs. Option B granting Owner role is too broad and hard to govern; Option C using personal accounts leads to data ownership issues (Shadow IT); Option D mixing everyone in a single project leads to quota conflicts and messy permission management.",
      "wg": [
        { "t": "隔離", "en": "isolating", "ps": "verb" },
        { "t": "影子 IT", "en": "Shadow IT", "ps": "noun" }
      ]
    }
  },
  {
    "no": "9",
    "level": "hard",
    "keywords": "Security, Secret Manager, App Engine, Compliance",
    "question": [
      {
        "t": "作為現代化過程的一部分，TerramEarth 正在將舊有的 PHP 應用程式遷移到 App Engine。安全審核發現源代碼中硬編碼了資料庫密碼和第三方 API 金鑰。",
        "en": "As part of the modernization process, TerramEarth is migrating legacy PHP applications to App Engine. A security audit revealed that database passwords and third-party API keys are hardcoded in the source code.",
        "wg": [
          { "t": "硬編碼", "en": "hardcoded", "ps": "adjective" },
          { "t": "源代碼", "en": "source code", "ps": "noun" }
        ]
      },
      {
        "t": "您需要修復此漏洞，並確保開發人員無法存取生產環境的機密資訊 (Secrets)。解決方案必須支援自動化密碼輪替 (Rotation) 和集中審計。",
        "en": "You need to remediate this vulnerability and ensure developers cannot access production secrets. The solution must support automated password rotation and centralized auditing.",
        "wg": [
          { "t": "漏洞", "en": "vulnerability", "ps": "noun" },
          { "t": "密碼輪替", "en": "password rotation", "ps": "noun" },
          { "t": "集中審計", "en": "centralized auditing", "ps": "noun" }
        ]
      },
      {
        "t": "您應該怎麼做？",
        "en": "What should you do?",
        "wg": [
          { "t": "修復", "en": "remediate", "ps": "verb" },
          { "t": "應該", "en": "should", "ps": "verb" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud Key Management Service (Cloud KMS) 加密機密資訊，將加密後的字串儲存在環境變數中，並在應用程式啟動時解密。",
        "en": "(A) Use Cloud Key Management Service (Cloud KMS) to encrypt the secrets, store the encrypted strings in environment variables, and decrypt them upon application startup.",
        "wg": [
          { "t": "加密", "en": "encrypt", "ps": "verb" },
          { "t": "環境變數", "en": "environment variables", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 將機密資訊儲存在 Secret Manager 中。將應用程式配置為在執行時透過 Secret Manager API 存取機密，並設定 IAM 角色以限制開發人員的存取。",
        "en": "(B) Store secrets in Secret Manager. Configure the application to access secrets via the Secret Manager API at runtime, and set IAM roles to restrict developer access.",
        "wg": [
          { "t": "執行時", "en": "runtime", "ps": "noun" },
          { "t": "限制", "en": "restrict", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 將機密資訊儲存在受 ACL 保護的 Cloud Storage 存儲桶中的設定檔內，並讓 App Engine 服務帳戶讀取該檔案。",
        "en": "(C) Store secrets in a configuration file within an ACL-protected Cloud Storage bucket, and have the App Engine service account read the file.",
        "wg": [
          { "t": "設定檔", "en": "configuration file", "ps": "noun" },
          { "t": "讀取", "en": "read", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Build 在部署期間將機密資訊注入到應用程式的 `app.yaml` 檔案中，並使用 .gitignore 排除該檔案以避免提交到版本控制系統。",
        "en": "(D) Use Cloud Build to inject secrets into the application's `app.yaml` file during deployment, and use .gitignore to exclude the file from version control.",
        "wg": [
          { "t": "注入", "en": "inject", "ps": "verb" },
          { "t": "排除", "en": "exclude", "ps": "verb" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Secret Manager 是 Google Cloud 用於儲存 API 金鑰、密碼和證書的專用服務，它支援版本控制、自動輪替和細粒度的 IAM 存取控制，完美符合需求。選項 A 的 KMS 主要用於加密金鑰管理，而非直接儲存應用程式機密（雖然可行但不如 Secret Manager 方便且缺乏輪替功能）；選項 C 和 D 雖然將機密移出代碼，但缺乏原生的輪替、審計和版本管理功能。",
      "en": "Secret Manager is the dedicated Google Cloud service for storing API keys, passwords, and certificates. It supports versioning, automated rotation, and fine-grained IAM access control, perfectly fitting the requirements. Option A (KMS) is for encryption key management, not direct app secret storage (doable but less convenient/no rotation); Options C and D move secrets out of code but lack native rotation, auditing, and version management.",
      "wg": [
        { "t": "細粒度", "en": "fine-grained", "ps": "adjective" },
        { "t": "版本控制", "en": "versioning", "ps": "noun" }
      ]
    }
  },
  {
    "no": "10",
    "level": "hard",
    "keywords": "Operations, Logging, Monitoring, GKE",
    "question": [
      {
        "t": "TerramEarth 的開發人員在對部署在 GKE 叢集上的容器化應用程式進行故障排除時遇到困難。他們需要查看應用程式日誌和系統指標。",
        "en": "TerramEarth developers are struggling to troubleshoot containerized applications deployed on GKE clusters. They need to view application logs and system metrics.",
        "wg": [
          { "t": "故障排除", "en": "troubleshoot", "ps": "verb" },
          { "t": "系統指標", "en": "system metrics", "ps": "noun" }
        ]
      },
      {
        "t": "根據 Google Cloud 架構框架的「卓越營運 (Operational Excellence)」支柱，您應該實作哪些標準化工具來改進監控與故障排除？（請選擇兩項）",
        "en": "According to the 'Operational Excellence' pillar of the Google Cloud Architecture Framework, which standardized tools should you implement to improve monitoring and troubleshooting? (Choose two)",
        "wg": [
          { "t": "卓越營運", "en": "Operational Excellence", "ps": "noun" },
          { "t": "標準化工具", "en": "standardized tools", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 確保所有容器都將日誌寫入標準輸出 (STDOUT) 和標準錯誤 (STDERR)，以便 Cloud Logging 自動擷取。",
        "en": "(A) Ensure all containers write logs to standard output (STDOUT) and standard error (STDERR) so that Cloud Logging automatically captures them.",
        "wg": [
          { "t": "標準輸出", "en": "standard output", "ps": "noun" },
          { "t": "自動擷取", "en": "automatically captures", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 在每個節點上安裝 Prometheus 伺服器，並將指標儲存在本地 Persistent Disk 上供開發人員查詢。",
        "en": "(B) Install a Prometheus server on each node and store metrics on local Persistent Disks for developers to query.",
        "wg": [
          { "t": "安裝", "en": "Install", "ps": "verb" },
          { "t": "本地", "en": "local", "ps": "adjective" }
        ]
      },
      {
        "t": "(C) 使用 Sidecar 模式將日誌代理 (Log agent) 部署到每個 Pod 中，並將日誌轉發到自建的 Elasticsearch 叢集。",
        "en": "(C) Deploy a log agent to each Pod using the Sidecar pattern, and forward logs to a self-hosted Elasticsearch cluster.",
        "wg": [
          { "t": "轉發", "en": "forward", "ps": "verb" },
          { "t": "自建的", "en": "self-hosted", "ps": "adjective" }
        ]
      },
      {
        "t": "(D) 啟用 Google Cloud Managed Service for Prometheus 以收集和儲存 GKE 指標，並使用 Cloud Monitoring 儀表板進行視覺化。",
        "en": "(D) Enable Google Cloud Managed Service for Prometheus to collect and store GKE metrics, and use Cloud Monitoring dashboards for visualization.",
        "wg": [
          { "t": "收集", "en": "collect", "ps": "verb" },
          { "t": "視覺化", "en": "visualization", "ps": "noun" }
        ]
      },
      {
        "t": "(E) 配置防火牆規則以允許開發人員透過 SSH 連接到 GKE 工作節點，並使用 `journalctl` 查看日誌。",
        "en": "(E) Configure firewall rules to allow developers to SSH into GKE worker nodes and use `journalctl` to view logs.",
        "wg": [
          { "t": "工作節點", "en": "worker nodes", "ps": "noun" },
          { "t": "查看", "en": "view", "ps": "verb" }
        ]
      }
    ],
    "answer": "(A), (D)",
    "why": {
      "t": "根據 Google Cloud 最佳實務（以及 12-factor app 原則），容器應將日誌寫入 STDOUT/STDERR，以便 GKE 內建的 Fluentbit 代理將其串流傳輸到 Cloud Logging (選項 A)。對於指標，Managed Service for Prometheus (選項 D) 提供了與 GKE 整合的託管監控解決方案，無需維護本地伺服器。選項 B, C, E 增加了維運負擔（自建 ELK、Prometheus）或存在安全風險（SSH 到節點）。",
      "en": "According to Google Cloud best practices (and 12-factor app principles), containers should write logs to STDOUT/STDERR so the built-in GKE Fluentbit agent streams them to Cloud Logging (Option A). For metrics, Managed Service for Prometheus (Option D) provides an integrated, managed monitoring solution for GKE without maintaining local servers. Options B, C, and E increase operational overhead (self-hosted ELK, Prometheus) or pose security risks (SSH into nodes).",
      "wg": [
        { "t": "最佳實務", "en": "best practices", "ps": "noun" },
        { "t": "維運負擔", "en": "operational overhead", "ps": "noun" }
      ]
    }
  },
  {
    "no": "11",
    "level": "hard",
    "keywords": "MLOps, Vertex AI, Automation, Predictive Maintenance",
    "question": [
      {
        "t": "TerramEarth 的數據科學團隊已經在 BigQuery 中使用歷史遙測數據開發了一個預測性維護模型。該模型需要每週使用新攝取的數據進行重新訓練，以保持準確性。",
        "en": "TerramEarth's data science team has developed a predictive maintenance model using historical telemetry data in BigQuery. The model needs to be retrained weekly with newly ingested data to maintain accuracy.",
        "wg": [
          { "t": "重新訓練", "en": "retrained", "ps": "verb" },
          { "t": "準確性", "en": "accuracy", "ps": "noun" }
        ]
      },
      {
        "t": "目前的重新訓練過程涉及數據科學家手動執行一系列腳本，這既耗時又容易出錯。您需要設計一個自動化且受管的機器學習工作流程 (MLOps) 來解決這個問題。",
        "en": "The current retraining process involves data scientists manually running a series of scripts, which is time-consuming and error-prone. You need to design an automated and managed machine learning workflow (MLOps) to solve this problem.",
        "wg": [
          { "t": "自動化", "en": "automated", "ps": "adjective" },
          { "t": "工作流程", "en": "workflow", "ps": "noun" }
        ]
      },
      {
        "t": "該解決方案應提供端到端的譜系追蹤 (Lineage tracking) 和模型版本控制。您應該怎麼做？",
        "en": "The solution should provide end-to-end lineage tracking and model versioning. What should you do?",
        "wg": [
          { "t": "譜系追蹤", "en": "lineage tracking", "ps": "noun" },
          { "t": "模型版本控制", "en": "model versioning", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud Scheduler 觸發一個 Cloud Functions 函數，該函數會啟動 Compute Engine 虛擬機器來執行訓練腳本。",
        "en": "(A) Use Cloud Scheduler to trigger a Cloud Functions function that starts a Compute Engine virtual machine to execute the training scripts.",
        "wg": [
          { "t": "觸發", "en": "trigger", "ps": "verb" },
          { "t": "執行", "en": "execute", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 將訓練邏輯封裝在 Dataflow 作業中，並使用 cron 作業定期安排數據處理和模型更新。",
        "en": "(B) Encapsulate the training logic within a Dataflow job, and use cron jobs to schedule data processing and model updates periodically.",
        "wg": [
          { "t": "封裝", "en": "Encapsulate", "ps": "verb" },
          { "t": "定期", "en": "periodically", "ps": "adverb" }
        ]
      },
      {
        "t": "(C) 建立一個 Vertex AI Pipeline，定義數據提取、驗證、訓練和模型評估步驟。使用 Vertex AI Metadata 來追蹤譜系。",
        "en": "(C) Create a Vertex AI Pipeline that defines steps for data extraction, validation, training, and model evaluation. Use Vertex AI Metadata to track lineage.",
        "wg": [
          { "t": "驗證", "en": "validation", "ps": "noun" },
          { "t": "評估", "en": "evaluation", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 BigQuery ML 直接在資料倉儲內執行 SQL 查詢來重新訓練模型，並編寫腳本將模型匯出到 Cloud Storage。",
        "en": "(D) Use BigQuery ML to retrain the model by executing SQL queries directly within the data warehouse, and script the export of the model to Cloud Storage.",
        "wg": [
          { "t": "資料倉儲", "en": "data warehouse", "ps": "noun" },
          { "t": "匯出", "en": "export", "ps": "verb" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Vertex AI Pipelines 是 Google Cloud 上用於 MLOps 的標準全託管服務，它專門設計用於編排複雜的 ML 工作流，並透過 Vertex ML Metadata 原生支援「譜系追蹤」和「版本控制」。選項 A 和 B 缺乏原生的 ML 專屬功能（如模型評估可視化、元數據追蹤）；選項 D 的 BigQuery ML 雖然強大，但對於需要完整 MLOps 生命週期管理（包括驗證和部署）的複雜場景，Pipelines 是更全面的架構選擇。",
      "en": "Vertex AI Pipelines is the standard fully managed service for MLOps on Google Cloud, specifically designed to orchestrate complex ML workflows and natively supporting 'lineage tracking' and 'versioning' via Vertex ML Metadata. Options A and B lack native ML-specific features (like model evaluation visualization, metadata tracking); while Option D (BigQuery ML) is powerful, Pipelines is the more comprehensive architectural choice for complex scenarios requiring full MLOps lifecycle management (including validation and deployment).",
      "wg": [
        { "t": "編排", "en": "orchestrate", "ps": "verb" },
        { "t": "全託管", "en": "fully managed", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "12",
    "level": "hard",
    "keywords": "Global Load Balancing, CDN, Latency, Content Delivery",
    "question": [
      {
        "t": "TerramEarth 的 500 家經銷商分佈在 100 個國家，他們透過網頁前端下載大型韌體更新檔案和維修手冊（PDF）。",
        "en": "TerramEarth's 500 dealers are distributed across 100 countries and download large firmware update files and repair manuals (PDFs) via the web frontend.",
        "wg": [
          { "t": "經銷商", "en": "dealers", "ps": "noun" },
          { "t": "韌體更新", "en": "firmware update", "ps": "noun" }
        ]
      },
      {
        "t": "位於偏遠地區的經銷商報告下載速度極慢且經常連線逾時。您需要優化架構以改善全球下載效能，並減少後端伺服器的負載。",
        "en": "Dealers in remote regions report extremely slow download speeds and frequent connection timeouts. You need to optimize the architecture to improve global download performance and reduce the load on backend servers.",
        "wg": [
          { "t": "偏遠地區", "en": "remote regions", "ps": "noun" },
          { "t": "逾時", "en": "timeouts", "ps": "noun" }
        ]
      },
      {
        "t": "您希望盡量減少對現有應用程式代碼的更改。您應該採取什麼行動？",
        "en": "You want to minimize changes to existing application code. What action should you take?",
        "wg": [
          { "t": "減少", "en": "minimize", "ps": "verb" },
          { "t": "代碼", "en": "code", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將內容複製到多個區域的 Cloud Storage 儲存分桶中，並在應用程式中實作邏輯，根據使用者的 IP 位址將其重新導向到最近的儲存分桶。",
        "en": "(A) Replicate content to Cloud Storage buckets in multiple regions, and implement logic in the application to redirect users to the nearest bucket based on their IP address.",
        "wg": [
          { "t": "複製", "en": "Replicate", "ps": "verb" },
          { "t": "重新導向", "en": "redirect", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 增加後端 Compute Engine 執行個體的數量和規模，並使用 TCP Proxy 負載平衡器來加速 TCP 握手過程。",
        "en": "(B) Increase the number and size of backend Compute Engine instances, and use a TCP Proxy Load Balancer to accelerate the TCP handshake process.",
        "wg": [
          { "t": "規模", "en": "size", "ps": "noun" },
          { "t": "加速", "en": "accelerate", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 Cloud VPN 為每個經銷商據點建立專用連線，以確保有保證的頻寬通往 Google Cloud。",
        "en": "(C) Establish dedicated connections for each dealer site using Cloud VPN to ensure guaranteed bandwidth to Google Cloud.",
        "wg": [
          { "t": "專用連線", "en": "dedicated connections", "ps": "noun" },
          { "t": "保證的", "en": "guaranteed", "ps": "adjective" }
        ]
      },
      {
        "t": "(D) 配置全域外部 HTTP(S) 負載平衡器 (Global External HTTP(S) Load Balancer) 作為前端，並啟用 Cloud CDN (內容傳遞網路) 來快取靜態內容。",
        "en": "(D) Configure a Global External HTTP(S) Load Balancer as the frontend, and enable Cloud CDN (Content Delivery Network) to cache static content.",
        "wg": [
          { "t": "全域", "en": "Global", "ps": "adjective" },
          { "t": "快取", "en": "cache", "ps": "verb" }
        ]
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud CDN 透過將內容快取在 Google 的全球邊緣節點 (Edge Points of Presence)，讓使用者能從地理位置最近的節點下載，顯著降低延遲並減少後端負載。這是解決靜態大檔案（如韌體、PDF）分發問題的標準做法，且不需要更改應用程式代碼（只需配置負載平衡器）。選項 A 需要複雜的應用程式邏輯與數據同步；選項 B 無法解決長距離傳輸的延遲問題；選項 C 管理數百個 VPN 通道既昂貴又不切實際。",
      "en": "Cloud CDN caches content at Google's global Edge Points of Presence, allowing users to download from the geographically closest node, significantly reducing latency and backend load. This is the standard solution for distributing large static files (like firmware, PDFs) and requires no application code changes (just load balancer config). Option A requires complex app logic and data synchronization; Option B doesn't solve long-haul latency; Option C managing hundreds of VPN tunnels is expensive and impractical.",
      "wg": [
        { "t": "邊緣節點", "en": "Edge Points of Presence", "ps": "noun" },
        { "t": "長距離", "en": "long-haul", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "13",
    "level": "hard",
    "keywords": "Global Database, Consistency, Cloud Spanner, Relational",
    "question": [
      {
        "t": "TerramEarth 計劃推出一個新的全球經銷商入口網站，該網站需要一個集中式的關聯式資料庫來儲存庫存交易紀錄。",
        "en": "TerramEarth plans to launch a new global dealer portal that requires a centralized relational database to store inventory transaction records.",
        "wg": [
          { "t": "集中式的", "en": "centralized", "ps": "adjective" },
          { "t": "關聯式資料庫", "en": "relational database", "ps": "noun" }
        ]
      },
      {
        "t": "該資料庫必須提供強一致性 (Strong Consistency) 以防止庫存超賣，並且需要具備全域高可用性 (99.999% SLA) 和水平擴展能力，以支援來自世界各地的並發寫入。",
        "en": "The database must provide strong consistency to prevent inventory overselling, and requires global high availability (99.999% SLA) and horizontal scalability to support concurrent writes from around the world.",
        "wg": [
          { "t": "強一致性", "en": "strong consistency", "ps": "noun" },
          { "t": "水平擴展", "en": "horizontal scalability", "ps": "noun" }
        ]
      },
      {
        "t": "您應該選擇哪種資料庫服務？",
        "en": "Which database service should you choose?",
        "wg": [
          { "t": "選擇", "en": "choose", "ps": "verb" },
          { "t": "服務", "en": "service", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Spanner，配置為多重地區 (Multi-region) 執行個體。",
        "en": "(A) Cloud Spanner, configured as a multi-region instance.",
        "wg": [
          { "t": "多重地區", "en": "multi-region", "ps": "adjective" },
          { "t": "執行個體", "en": "instance", "ps": "noun" }
        ]
      },
      {
        "t": "(B) Cloud SQL for PostgreSQL，並在多個地區配置讀取複本 (Read Replicas)。",
        "en": "(B) Cloud SQL for PostgreSQL, with Read Replicas configured in multiple regions.",
        "wg": [
          { "t": "讀取複本", "en": "Read Replicas", "ps": "noun" },
          { "t": "配置", "en": "configured", "ps": "verb" }
        ]
      },
      {
        "t": "(C) Cloud Bigtable，設計 Row Key 以防止熱點 (Hotspotting)。",
        "en": "(C) Cloud Bigtable, designing the Row Key to prevent hotspotting.",
        "wg": [
          { "t": "熱點", "en": "hotspotting", "ps": "noun" },
          { "t": "設計", "en": "designing", "ps": "verb" }
        ]
      },
      {
        "t": "(D) Firestore 在原生模式下運行，並啟用多地區複製。",
        "en": "(D) Firestore running in Native mode, with multi-region replication enabled.",
        "wg": [
          { "t": "原生模式", "en": "Native mode", "ps": "noun" },
          { "t": "複製", "en": "replication", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Cloud Spanner 是 Google Cloud 唯一能提供全域強一致性、水平寫入擴展能力以及高達 99.999% SLA 的關聯式資料庫。這完全符合「庫存交易（需要 ACID 交易）」、「全球存取」和「強一致性」的需求。選項 B 的 Cloud SQL 僅支援單一寫入主節點，無法進行全域寫入擴展；選項 C 和 D 是 NoSQL 資料庫，雖然可擴展，但對於複雜的關聯式庫存交易模型來說，Spanner 是更直接且強大的選擇。",
      "en": "Cloud Spanner is the only relational database on Google Cloud that provides global strong consistency, horizontal write scalability, and up to 99.999% SLA. This perfectly aligns with the needs for 'inventory transactions (requiring ACID)', 'global access', and 'strong consistency'. Option B (Cloud SQL) only supports a single write primary, failing global write scalability; Options C and D are NoSQL databases, which, while scalable, are less suited for complex relational inventory transaction models than Spanner.",
      "wg": [
        { "t": "交易", "en": "transactions", "ps": "noun" },
        { "t": "主節點", "en": "primary", "ps": "noun" }
      ]
    }
  },
  {
    "no": "14",
    "level": "hard",
    "keywords": "Cost Optimization, Batch Processing, Spot VMs, Fault Tolerance",
    "question": [
      {
        "t": "TerramEarth 每天晚上需要處理從車輛上傳的大量批次數據檔案。這些作業主要是數據清理和格式轉換，屬於非關鍵任務，且可以容忍中斷。",
        "en": "TerramEarth needs to process massive batch data files uploaded from vehicles every night. These jobs are primarily data cleaning and format conversion, are non-critical, and can tolerate interruptions.",
        "wg": [
          { "t": "批次數據", "en": "batch data", "ps": "noun" },
          { "t": "容忍中斷", "en": "tolerate interruptions", "ps": "verb" }
        ]
      },
      {
        "t": "目前的處理叢集運行在標準的 Compute Engine 虛擬機器上，導致成本過高。您被要求在不影響作業最終完成的情況下，大幅降低運算成本。",
        "en": "The current processing cluster runs on standard Compute Engine virtual machines, resulting in excessive costs. You are asked to significantly reduce compute costs without affecting the eventual completion of the jobs.",
        "wg": [
          { "t": "成本過高", "en": "excessive costs", "ps": "adjective" },
          { "t": "大幅降低", "en": "significantly reduce", "ps": "verb" }
        ]
      },
      {
        "t": "您應該在受管執行個體群組 (MIG) 中使用哪種機器配置？",
        "en": "Which machine configuration should you use in the Managed Instance Group (MIG)?",
        "wg": [
          { "t": "受管執行個體群組", "en": "Managed Instance Group", "ps": "noun" },
          { "t": "配置", "en": "configuration", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用記憶體優化 (Memory-optimized) 的機器類型來加快處理速度，從而減少總運行時間。",
        "en": "(A) Use Memory-optimized machine types to speed up processing, thereby reducing total runtime.",
        "wg": [
          { "t": "記憶體優化", "en": "Memory-optimized", "ps": "adjective" },
          { "t": "加快", "en": "speed up", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 配置 Spot VM（Spot 虛擬機器）執行個體，並確保應用程式能夠處理檢查點 (Checkpoints) 以便在搶佔後恢復工作。",
        "en": "(B) Configure Spot VM instances, and ensure the application can handle checkpoints to resume work after preemption.",
        "wg": [
          { "t": "搶佔", "en": "preemption", "ps": "noun" },
          { "t": "恢復", "en": "resume", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 購買為期 3 年的承諾使用折扣 (Committed Use Discounts)，覆蓋 100% 的預計批次處理核心數。",
        "en": "(C) Purchase 3-year Committed Use Discounts covering 100% of the projected batch processing cores.",
        "wg": [
          { "t": "承諾使用折扣", "en": "Committed Use Discounts", "ps": "noun" },
          { "t": "覆蓋", "en": "covering", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用獨占節點 (Sole-tenant nodes) 來確保效能隔離，避免「吵雜鄰居」效應影響處理效率。",
        "en": "(D) Use Sole-tenant nodes to ensure performance isolation and avoid the 'noisy neighbor' effect affecting processing efficiency.",
        "wg": [
          { "t": "獨占節點", "en": "Sole-tenant nodes", "ps": "noun" },
          { "t": "隔離", "en": "isolation", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Spot VM 提供高達 60-91% 的價格折扣，非常適合「可容忍中斷」且「非關鍵」的批次處理工作負載。關鍵在於確保應用程式能處理中斷（透過 Checkpointing），這在選項 B 中已被提及。選項 A 和 D 會增加成本而非降低；選項 C 雖然能節省成本，但 Spot VM 對於這類彈性、無狀態或可恢復的批次作業通常能提供比 CUD 更深的折扣。",
      "en": "Spot VMs provide discounts of up to 60-91%, making them ideal for 'fault-tolerant' and 'non-critical' batch processing workloads. The key is ensuring the application can handle interruptions (via Checkpointing), which is addressed in Option B. Options A and D increase costs rather than reducing them; Option C saves money, but Spot VMs typically offer deeper discounts than CUDs for this type of elastic, stateless, or resumable batch job.",
      "wg": [
        { "t": "折扣", "en": "discounts", "ps": "noun" },
        { "t": "可恢復的", "en": "resumable", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "15",
    "level": "hard",
    "keywords": "High Availability, GKE, Resiliency, Scalability",
    "question": [
      {
        "t": "TerramEarth 的經銷商服務後端運行在 Google Kubernetes Engine (GKE) 上。隨著公司每年 20% 的增長，系統必須具備極高的彈性。",
        "en": "TerramEarth's dealer service backend runs on Google Kubernetes Engine (GKE). With the company's 20% yearly growth, the system must be extremely resilient.",
        "wg": [
          { "t": "彈性", "en": "resilient", "ps": "adjective" },
          { "t": "增長", "en": "growth", "ps": "noun" }
        ]
      },
      {
        "t": "您需要確保即使整個區域 (Zone) 發生故障，應用程式仍能繼續服務客戶。此外，系統必須能夠自動處理突發的流量增長。",
        "en": "You need to ensure that the application continues to serve customers even if an entire Zone fails. Additionally, the system must be able to automatically handle sudden traffic surges.",
        "wg": [
          { "t": "區域", "en": "Zone", "ps": "noun" },
          { "t": "突發的", "en": "sudden", "ps": "adjective" }
        ]
      },
      {
        "t": "您應該在 GKE 架構中實作哪兩項配置？（請選擇兩項）",
        "en": "Which two configurations should you implement in the GKE architecture? (Choose two)",
        "wg": [
          { "t": "實作", "en": "implement", "ps": "verb" },
          { "t": "配置", "en": "configurations", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 建立一個區域性叢集 (Regional Cluster)，並將控制平面 (Control Plane) 和節點分佈在多個區域 (Zones) 中。",
        "en": "(A) Create a Regional Cluster, distributing the Control Plane and nodes across multiple Zones.",
        "wg": [
          { "t": "區域性叢集", "en": "Regional Cluster", "ps": "noun" },
          { "t": "分佈", "en": "distributing", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 為 Deployment 配置 Horizontal Pod Autoscaler (HPA)，根據 CPU 或自定義指標自動增加 Pod 數量。",
        "en": "(B) Configure Horizontal Pod Autoscaler (HPA) for the Deployment to automatically increase the number of Pods based on CPU or custom metrics.",
        "wg": [
          { "t": "自動增加", "en": "automatically increase", "ps": "verb" },
          { "t": "指標", "en": "metrics", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用單一區域叢集 (Zonal Cluster)，並啟用節點自動修復 (Node Auto-Repair) 功能以快速替換故障節點。",
        "en": "(C) Use a Zonal Cluster and enable Node Auto-Repair to quickly replace failed nodes.",
        "wg": [
          { "t": "單一區域叢集", "en": "Zonal Cluster", "ps": "noun" },
          { "t": "替換", "en": "replace", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 配置 Vertical Pod Autoscaler (VPA) 以在流量增加時自動增加現有 Pod 的 CPU 和記憶體限制。",
        "en": "(D) Configure Vertical Pod Autoscaler (VPA) to automatically increase CPU and memory limits for existing Pods when traffic increases.",
        "wg": [
          { "t": "限制", "en": "limits", "ps": "noun" },
          { "t": "增加", "en": "increase", "ps": "verb" }
        ]
      },
      {
        "t": "(E) 使用先佔式節點 (Preemptible Nodes) 來運行所有生產工作負載，以確保資源始終可用。",
        "en": "(E) Use Preemptible Nodes to run all production workloads to ensure resources are always available.",
        "wg": [
          { "t": "先佔式節點", "en": "Preemptible Nodes", "ps": "noun" },
          { "t": "始終可用", "en": "always available", "ps": "adjective" }
        ]
      }
    ],
    "answer": "(A), (B)",
    "why": {
      "t": "區域性叢集 (Regional Cluster) 是防止單一區域 (Zone) 故障的標準架構，因為它將控制平面和工作節點複製到三個區域。Horizontal Pod Autoscaler (HPA) 是處理「突發流量增長」的正確機制，透過增加 Pod 數量來水平擴展服務。選項 C 的單一區域叢集在區域故障時會完全停機；選項 D 的 VPA 需要重啟 Pod 才能生效，不適合應對突發流量；選項 E 使用先佔式節點會導致頻繁中斷，不適合關鍵生產工作負載。",
      "en": "A Regional Cluster is the standard architecture for surviving a single Zone failure as it replicates the control plane and worker nodes across three zones. Horizontal Pod Autoscaler (HPA) is the correct mechanism for handling 'sudden traffic surges' by scaling the service horizontally (adding more Pods). Option C (Zonal Cluster) goes down completely during a zone outage; Option D (VPA) requires restarting Pods to apply changes, making it unsuitable for sudden surges; Option E (Preemptible Nodes) causes frequent interruptions and is risky for critical production workloads.",
      "wg": [
        { "t": "標準架構", "en": "standard architecture", "ps": "noun" },
        { "t": "停機", "en": "go down", "ps": "verb" }
      ]
    }
  }
]