[
  {
    "no": "1",
    "level": "hard",
    "keywords": "Hybrid Connectivity, Dedicated Interconnect, High Availability",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 目前在多個託管設施（Colocation facilities）中運行其軟體服務，其中一個資料中心的租約即將到期。該公司需要將其地端環境與 Google Cloud 建立連線，以確保能持續存取與保險提供商之間的遺留文件與 API 整合系統，這些系統短期內不會移動或升級。技術要求明確指出需要一個「安全且高效能」的連線，且必須能應對業務指數級增長帶來的流量。考慮到業務的高可用性需求與地端網路架構，您應該推薦哪種連線方案？",
        "en": "EHR Healthcare is currently running its software services across multiple colocation facilities, and the lease on one of these data centers is about to expire. The company needs to establish connectivity between its on-premises environment and Google Cloud to ensure continued access to legacy file- and API-based integrations with insurance providers that are not planned for migration or upgrade. Technical requirements explicitly specify a 'secure and high-performance' connection that must handle traffic from exponential business growth. Considering the requirements for high availability and the on-premises architecture, which connectivity solution should you recommend?",
        "wg": [
          {"t": "託管設施", "en": "colocation facilities", "ps": "N"},
          {"t": "租約到期", "en": "lease is about to expire", "ps": "Phrase"},
          {"t": "指數級增長", "en": "exponential growth", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在地端設施與最近的 Google Cloud 邊緣站點之間部署具備高可用性配置的 Dedicated Interconnect，提供 10 Gbps 或 100 Gbps 的鏈路來處理大流量，並確保符合技術要求中的高效能標準。",
        "en": "(A) Deploy a Dedicated Interconnect with a high availability configuration between the on-premises facility and the nearest Google Cloud edge location, providing 10 Gbps or 100 Gbps links to handle large traffic volumes and ensuring the high-performance standard mentioned in the technical requirements.",
        "wg": []
      },
      {
        "t": "(B) 設定具備高可用性（HA）的 Cloud VPN 隧道，透過公共網際網路連接地端系統與 Google Cloud VPC，這是一種低成本且快速部署的方案，能滿足租約即將到期的急迫性，同時提供加密保護。",
        "en": "(B) Set up a High Availability (HA) Cloud VPN tunnel to connect the on-premises systems to the Google Cloud VPC over the public internet, providing a low-cost and rapid deployment solution to address the urgency of the expiring lease while ensuring encrypted protection.",
        "wg": []
      },
      {
        "t": "(C) 使用 Partner Interconnect 透過支援的服務供應商建立連接，這對於無法直接在 Google 邊緣站點進行物理託管的環境最為理想，並根據目前的流量需求彈性調整頻寬大小。",
        "en": "(C) Use Partner Interconnect to establish a connection through a supported service provider, which is ideal for environments that cannot physically colocate at a Google edge location, and elastically scale the bandwidth based on current traffic demands.",
        "wg": []
      },
      {
        "t": "(D) 實施 Direct Peering 以建立地端網路與 Google 邊緣網路之間的直接路由交換，這能有效減少延遲並提供直接存取所有 Google 公用 API 的能力，同時降低雲端數據外洩的風險。",
        "en": "(D) Implement Direct Peering to establish direct routing exchange between the on-premises network and Google's edge network, effectively reducing latency and providing direct access to all Google public APIs while reducing the risk of cloud data exfiltration.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "案例明確要求「高效能」且需應對「指數級增長」的流量。Dedicated Interconnect 提供實體直接連線與最大頻寬（10/100 Gbps），且不經過公共網際網路，最符合安全與效能要求。Cloud VPN (B) 受限於網際網路不穩定性；Partner Interconnect (C) 通常用於頻寬需求較小的場景；Direct Peering (D) 並非專為連接私有 VPC 工作負載設計，且不提供服務等級協議 (SLA)。",
      "en": "The case study explicitly requires 'high-performance' and the ability to handle 'exponential growth' in traffic. Dedicated Interconnect provides a direct physical connection with maximum bandwidth (10/100 Gbps) without traversing the public internet, best meeting the security and performance requirements. Cloud VPN (B) is limited by internet instability; Partner Interconnect (C) is typically for smaller bandwidth needs; Direct Peering (D) is not designed for connecting private VPC workloads and does not provide an SLA.",
      "wg": [
        {"t": "實體直接連線", "en": "direct physical connection", "ps": "N"},
        {"t": "服務等級協議", "en": "Service Level Agreement (SLA)", "ps": "N"}
      ]
    }
  },
  {
    "no": "2",
    "level": "hard",
    "keywords": "GKE Enterprise, Anthos, Multi-cluster Management",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 面臨管理分散在不同環境（地端與雲端）的多個容器化應用程式的挑戰。目前的架構包含多個 Kubernetes 叢集，且過往曾發生因「系統配置錯誤」與「監控不一致」導致的停機。執行長聲明指出，需要一個能無縫跨越多個環境、具備彈性且可擴展的平台，並提供穩定且一致的使用者體驗。身為架構師，您應該建議哪種方案來滿足對多個容器環境進行「一致性管理」與「動態配置」的技術要求？",
        "en": "EHR Healthcare faces challenges managing multiple containerized applications dispersed across different environments (on-premises and cloud). The current architecture involves multiple Kubernetes clusters, and past outages have been caused by 'misconfigured systems' and 'inconsistent monitoring.' The executive statement emphasizes the need for a scalable, resilient platform that can span multiple environments seamlessly and provide a stable, consistent user experience. As an architect, which solution should you recommend to meet the technical requirements for 'consistent management' and 'dynamic provisioning' of multiple container environments?",
        "wg": [
          {"t": "系統配置錯誤", "en": "misconfigured systems", "ps": "N"},
          {"t": "無縫跨越", "en": "span seamlessly", "ps": "V"},
          {"t": "動態配置", "en": "dynamic provisioning", "ps": "N"}
    ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 實施 GKE Enterprise (Anthos)，利用其機隊管理（Fleet management）功能來統一地端與雲端叢集的治理，並配合 Anthos Config Management 自動同步配置，以防止人為錯誤導致的配置偏移。",
        "en": "(A) Implement GKE Enterprise (Anthos), leveraging its Fleet management capabilities to unify governance across on-premises and cloud clusters, and use Anthos Config Management to automatically synchronize configurations to prevent configuration drift caused by human error.",
        "wg": [
          {"t": "機隊管理", "en": "Fleet management", "ps": "N"},
          {"t": "配置偏移", "en": "configuration drift", "ps": "N"}
        ]
      },
      {
        "t": "(B) 將所有現有的地端 Kubernetes 叢集手動遷移到 Google Cloud 上的標準 GKE 叢集，並編寫自定義的 Python 腳本，透過 GKE API 進行批次配置更新，以減少跨環境管理的複雜性。",
        "en": "(B) Manually migrate all existing on-premises Kubernetes clusters to standard GKE clusters on Google Cloud and write custom Python scripts to perform batch configuration updates via the GKE API to reduce the complexity of cross-environment management.",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud Run 進行無伺服器容器部署以取代所有的 Kubernetes 叢集，這能消除底層基礎設施的管理負擔，並透過其內建的自動縮放功能應對流量激增，同時達成降低管理成本的目標。",
        "en": "(C) Use Cloud Run for serverless container deployment to replace all Kubernetes clusters, which eliminates the administrative burden of underlying infrastructure and handles traffic spikes via its built-in autoscaling to meet the goal of reduced administration costs.",
        "wg": []
      },
      {
        "t": "(D) 在 Google Cloud 上部署單一超大型的 GKE 叢集，並使用命名空間（Namespaces）與多承租戶（Multi-tenancy）政策來區分不同的應用程式環境，以此實現集中化的監控與單一配置來源。",
        "en": "(D) Deploy a single, extra-large GKE cluster on Google Cloud and use Namespaces and multi-tenancy policies to isolate different application environments, thereby achieving centralized monitoring and a single source of truth for configuration.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "EHR Healthcare 需要跨多個環境（地端與雲端）的一致管理，且需解決「配置錯誤」問題。GKE Enterprise (Anthos) 是專為多叢集、多環境設計的，其 Config Management 能確保所有叢集遵循同一配置，減少人為錯誤。單一叢集 (D) 無法解決地端環境管理需求；Cloud Run (C) 可能不符合遺留系統的架構約束；自研腳本 (B) 會大幅增加行政與維護負擔。",
      "en": "EHR Healthcare requires consistent management across multiple environments (on-premises and cloud) and needs to address 'misconfiguration' issues. GKE Enterprise (Anthos) is specifically designed for multi-cluster, multi-environment scenarios, and its Config Management ensures all clusters adhere to the same configuration, reducing human error. A single cluster (D) doesn't solve on-premises needs; Cloud Run (C) may not fit legacy architecture constraints; custom scripts (B) would significantly increase administrative and maintenance burdens.",
      "wg": [
        {"t": "人為錯誤", "en": "human error", "ps": "N"},
        {"t": "架構約束", "en": "architecture constraints", "ps": "N"}
      ]
    }
  },
  {
    "no": "3",
    "level": "hard",
    "keywords": "Cloud Spanner, Relational Database, Global Scalability, High Availability",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的業務正以每年倍增的速度成長，並為跨國醫療機構提供軟體即服務（SaaS）。目前其數據儲存在混合了關聯式（MySQL, MS SQL Server）與 NoSQL（Redis, MongoDB）的資料庫中。隨著用戶群體擴張到全球，公司需要調整其災難恢復（DR）計劃，確保客戶面臨系統的高可用性。技術要求中提到要「減少基礎設施管理成本」，同時要為未來增長奠定基礎。針對需要全球擴展且具備強一致性的關聯式數據，您推薦哪種遷移路徑？",
        "en": "EHR Healthcare's business is growing exponentially year-over-year, providing SaaS to multi-national medical offices. Currently, data is stored in a mixture of relational (MySQL, MS SQL Server) and NoSQL (Redis, MongoDB) databases. As the user base expands globally, the company needs to adapt its disaster recovery (DR) plan to ensure high availability for customer-facing systems. Technical requirements mention 'decreasing infrastructure administration costs' and positioning the platform for future growth. For relational data requiring global scalability and strong consistency, which migration path do you recommend?",
        "wg": [
          {"t": "軟體即服務", "en": "Software as a Service (SaaS)", "ps": "N"},
          {"t": "強一致性", "en": "strong consistency", "ps": "N"},
          {"t": "災難恢復", "en": "disaster recovery (DR)", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將關聯式資料庫遷移至 Cloud Spanner，利用其全託管的特性減少管理負擔，並透過其原生支持的全球級水平擴展與同步複製功能，確保多區域的高可用性與強一致性，滿足跨國業務需求。",
        "en": "(A) Migrate relational databases to Cloud Spanner, leveraging its fully managed nature to reduce administrative burden, and use its native support for global horizontal scaling and synchronous replication to ensure multi-region high availability and strong consistency for multi-national operations.",
        "wg": []
      },
      {
        "t": "(B) 將 MySQL 與 MS SQL Server 遷移到 Cloud SQL，並配置跨區域唯讀副本與故障轉移機制，這能快速實現從地端資料中心的搬遷，同時透過 Google Cloud 提供的自動化修補與備份功能降低行政成本。",
        "en": "(B) Migrate MySQL and MS SQL Server to Cloud SQL and configure cross-region read replicas and failover mechanisms, enabling rapid relocation from on-premises data centers while reducing administrative costs through Google Cloud's automated patching and backup features.",
        "wg": []
      },
      {
        "t": "(C) 在 Compute Engine 上使用託管實例組（Managed Instance Groups）自行部署 MySQL 叢集，並手動配置半同步複製機制，以保持對資料庫底層配置的完全控制，同時符合特定的醫療法規數據存放要求。",
        "en": "(C) Deploy self-managed MySQL clusters on Compute Engine using Managed Instance Groups and manually configure semi-synchronous replication to maintain full control over the database's underlying configuration while meeting specific healthcare regulatory data residency requirements.",
        "wg": []
      },
      {
        "t": "(D) 將所有關聯式數據轉換為非關聯式格式並儲存在 Cloud Bigtable 中，利用其針對大規模分析與低延遲讀寫的優勢，直接支持案例中提到的「提供醫療趨勢分析與預測」的業務驅動因素。",
        "en": "(D) Transform all relational data into non-relational formats and store it in Cloud Bigtable, taking advantage of its strengths in large-scale analytics and low-latency read/writes to directly support the business driver of 'providing healthcare trend insights and predictions.'",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "題目強調「跨國」、「全球擴展」與「強一致性」。Cloud Spanner 是 Google Cloud 唯一能同時提供水平擴展、強一致性與全球多區域分佈的關聯式資料庫，且為全託管服務，符合減少行政成本的目標。Cloud SQL (B) 在跨區域一致性與全球擴展性上不如 Spanner。Bigtable (D) 是 NoSQL，不適合需要強一致性的關聯式事務需求。自管 (C) 增加了行政成本。",
      "en": "The scenario emphasizes 'multi-national', 'global scalability', and 'strong consistency'. Cloud Spanner is the only relational database on Google Cloud that provides horizontal scaling, strong consistency, and global multi-region distribution simultaneously, and it is fully managed, aligning with the goal of reducing administrative costs. Cloud SQL (B) lacks the cross-region consistency and global scalability of Spanner. Bigtable (D) is NoSQL and unsuitable for relational transaction needs requiring strong consistency. Self-managed (C) increases administrative costs.",
      "wg": [
        {"t": "水平擴展", "en": "horizontal scaling", "ps": "N"},
        {"t": "全託管服務", "en": "fully managed service", "ps": "N"}
      ]
    }
  },
  {
    "no": "4",
    "level": "hard",
    "keywords": "VPC Service Controls, Compliance, HIPAA, Data Exfiltration",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 作為醫療軟體供應商，必須嚴格遵守 HIPAA 等監管合規性要求。為了保護敏感的電子健康紀錄，公司需要防止數據因內部誤操作或惡意行為從雲端環境中外洩（Data Exfiltration）。目前，雖然已實施了 Cloud IAM 權限控管，但執行長仍對跨環境的數據安全性表示擔憂。為了提供「安全」且符合「法規遵循」的架構，且不影響授權使用者的正常存取，您應該實施哪項關鍵安全功能？",
        "en": "As an EHR software provider, EHR Healthcare must strictly adhere to regulatory compliance requirements such as HIPAA. To protect sensitive electronic health records, the company needs to prevent data exfiltration from the cloud environment due to internal misconfiguration or malicious acts. Currently, although Cloud IAM permission controls are in place, the executive team remains concerned about cross-environment data security. To provide a 'secure' and 'compliant' architecture without impacting authorized users' access, which key security feature should you implement?",
        "wg": [
          {"t": "法規遵循", "en": "regulatory compliance", "ps": "N"},
          {"t": "誤操作", "en": "misconfiguration/misoperation", "ps": "N"},
          {"t": "惡意行為", "en": "malicious acts", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 配置 VPC Service Controls (VPC SC) 並建立服務周界（Service Perimeter），將敏感數據服務（如 BigQuery 與 Cloud Storage）包含在內，限制只有周界內的授權資源與網路能存取數據，防止數據被複製到外部專案。",
        "en": "(A) Configure VPC Service Controls (VPC SC) and establish a Service Perimeter to include sensitive data services (e.g., BigQuery and Cloud Storage), restricting access to data to only authorized resources and networks within the perimeter to prevent data from being copied to external projects.",
        "wg": [
          {"t": "服務周界", "en": "Service Perimeter", "ps": "N"}
        ]
      },
      {
        "t": "(B) 部署 Cloud Armor 並在負載平衡器層級啟用 Web 應用程式防火牆 (WAF) 功能，透過定義 IP 白名單與過濾 SQL 注入攻擊，確保面向客戶的網頁應用程式不會受到分佈式阻斷服務 (DDoS) 的威脅。",
        "en": "(B) Deploy Cloud Armor and enable Web Application Firewall (WAF) capabilities at the load balancer level, ensuring customer-facing web applications are protected from Distributed Denial of Service (DDoS) threats by defining IP whitelists and filtering SQL injection attacks.",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud Key Management Service (KMS) 來管理所有的數據加密金鑰，並實施客戶管理加密金鑰 (CMEK) 策略，確保所有存放在 Cloud Storage 的病患數據都經過最高層級的硬體加密保護。",
        "en": "(C) Use Cloud Key Management Service (KMS) to manage all data encryption keys and implement Customer-Managed Encryption Keys (CMEK) policies to ensure all patient data stored in Cloud Storage is protected by the highest level of hardware-backed encryption.",
        "wg": []
      },
      {
        "t": "(D) 啟用 Cloud Data Loss Prevention (DLP) API 對所有傳入與傳出的流量進行即時掃描，自動識別並遮蔽（Masking）個人識別資訊 (PII)，以符合 HIPAA 中關於保護病患隱私的去識別化要求。",
        "en": "(D) Enable the Cloud Data Loss Prevention (DLP) API to perform real-time scanning of all inbound and outbound traffic, automatically identifying and masking Personally Identifiable Information (PII) to meet HIPAA de-identification requirements for protecting patient privacy.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "雖然 IAM 能控制「誰」能存取，但無法防止有權限的人將數據移動到外部受控專案（數據外洩）。VPC SC 是 Google Cloud 專門用於防止數據外洩的「實體」周界防禦工具。Cloud Armor (B) 是防禦外部網路攻擊；KMS (C) 是加密；DLP (D) 是內容識別。只有 VPC SC 能直接解決案例中關於「數據外洩」與「法規遵循」的架構層級需求。",
      "en": "While IAM controls 'who' has access, it cannot prevent an authorized individual from moving data to an externally controlled project (data exfiltration). VPC SC is Google Cloud's specific 'physical' perimeter defense tool for preventing data exfiltration. Cloud Armor (B) defends against external network attacks; KMS (C) handles encryption; DLP (D) is for content discovery. Only VPC SC directly addresses the architectural requirements for 'data exfiltration' and 'compliance' in the case study.",
      "wg": [
        {"t": "數據外洩", "en": "data exfiltration", "ps": "N"},
        {"t": "內容識別", "en": "content discovery", "ps": "N"}
      ]
    }
  },
  {
    "no": "5",
    "level": "hard",
    "keywords": "Cloud Operations Suite, Monitoring, Proactive Alerting, SRE",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的執行長指出，公司目前的監控做法不一致，且許多停機事件是源於系統配置錯誤與無法處理流量激增。目前的警報通常透過電子郵件發送且常被忽視，導致回應速度緩慢。技術要求中強調需要「一致的日誌記錄、保留、監控與警報能力」。為了從「反應式（Reactive）」維運轉向「主動式（Proactive）」維運，並為未來增長提供穩定的使用者體驗，您應該如何利用 Google Cloud 解決方案來優化其運作？",
        "en": "EHR Healthcare's executive statement points out that current monitoring practices are inconsistent and many outages stem from misconfigured systems and the inability to handle traffic spikes. Current alerts are typically sent via email and often ignored, leading to slow response times. Technical requirements emphasize the need for 'consistent logging, retention, monitoring, and alerting capabilities.' To transition from 'reactive' to 'proactive' operations and provide a stable user experience for future growth, how should you leverage Google Cloud solutions to optimize their operations?",
        "wg": [
          {"t": "反應式", "en": "reactive", "ps": "Adj"},
          {"t": "主動式", "en": "proactive", "ps": "Adj"},
          {"t": "回應速度", "en": "response times", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 實施 Google Cloud Operations Suite，建立基於服務水準目標（SLO）的儀表板與警報，並配置多個通知管道（如 Slack 或 PagerDuty），同時透過 Cloud Monitoring 預測趨勢以主動處理潛在的流量激增。",
        "en": "(A) Implement Google Cloud Operations Suite, establish dashboards and alerts based on Service Level Objectives (SLOs), configure multiple notification channels (e.g., Slack or PagerDuty), and use Cloud Monitoring to predict trends for proactively managing potential traffic spikes.",
        "wg": [
          {"t": "服務水準目標", "en": "Service Level Objectives (SLOs)", "ps": "N"},
          {"t": "通知管道", "en": "notification channels", "ps": "N"}
        ]
      },
      {
        "t": "(B) 使用 Cloud Logging 將所有的日誌匯出到 BigQuery 進行回溯性分析，並聘請專門的資料分析師每週生成效能報告，以此作為改進系統配置與容量規劃的依據，解決過往停機次數過多的問題。",
        "en": "(B) Use Cloud Logging to export all logs to BigQuery for retrospective analysis and hire dedicated data analysts to generate weekly performance reports as a basis for improving system configuration and capacity planning to address the history of frequent outages.",
        "wg": []
      },
      {
        "t": "(C) 在地端環境保留目前的開源監控工具以減少培訓成本，並透過 Cloud Interconnect 將雲端資源的指標導回地端儀表板，達成執行長要求的「一致性管理」目標。",
        "en": "(C) Retain current open-source monitoring tools in the on-premises environment to reduce training costs and use Cloud Interconnect to route Google Cloud resource metrics back to on-premises dashboards, achieving the 'consistent management' goal requested by the executive.",
        "wg": []
      },
      {
        "t": "(D) 啟用 Error Reporting 功能自動捕捉應用程式崩潰，並設定雲端排程器（Cloud Scheduler）每小時自動重啟 GKE 節點，以防止由於記憶體洩漏或系統配置錯誤導致的非預期服務中斷。",
        "en": "(D) Enable Error Reporting to automatically capture application crashes and set up Cloud Scheduler to restart GKE nodes every hour to prevent unexpected service interruptions caused by memory leaks or system misconfigurations.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "案例強調要解決「監控不一致」與「反應緩慢」。選項 (A) 提供了一套現代化的 SRE（網站可靠性工程）做法，透過 SLO 與多元通知管道確保警報不再被忽視，並具備預測能力達成「主動式」維運。選項 (B) 是反應式的分析；選項 (C) 會增加技術債且不符合雲端原生的優勢；選項 (D) 則是治標不治本的粗暴作法，無法提供穩定的使用者體驗。",
      "en": "The case study emphasizes resolving 'inconsistent monitoring' and 'slow response.' Option (A) provides a modern SRE (Site Reliability Engineering) approach, using SLOs and multi-channel notifications to ensure alerts are no longer ignored and predictive capabilities to achieve 'proactive' operations. Option (B) is reactive analysis; Option (C) adds technical debt and fails to leverage cloud-native advantages; Option (D) is a crude workaround that does not address the root cause or provide a stable user experience.",
      "wg": [
        {"t": "網站可靠性工程", "en": "Site Reliability Engineering (SRE)", "ps": "N"},
        {"t": "技術債", "en": "technical debt", "ps": "N"}
      ]
    }
  },
  {
    "no": "6",
    "level": "hard",
    "keywords": "Cloud Identity, GCDS, Active Directory, SSO",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 目前使用 Microsoft Active Directory (AD) 來管理其內部員工與開發人員的身份驗證。隨著公司向 Google Cloud 遷移，技術團隊需要確保在雲端環境中維持一致的身份管理策略，並達成執行長所要求的「減少基礎設施管理成本」目標。公司希望員工能使用現有的地端憑證登入 Google Cloud 控制台與相關應用程式，且不希望進行繁瑣的手動帳號創建工作。考量到安全性與維運效率，作為架構師，您應該建議如何實施身份整合？",
        "en": "EHR Healthcare currently uses Microsoft Active Directory (AD) to manage identity authentication for its internal employees and developers. As the company migrates to Google Cloud, the technical team needs to ensure a consistent identity management policy in the cloud environment, aligning with the CEO's goal of 'decreasing infrastructure administration costs.' The company wants employees to use their existing on-premises credentials to log into the Google Cloud Console and related applications without manual account creation. Considering security and operational efficiency, how should you implement identity integration?",
        "wg": [
          {"t": "身份驗證", "en": "identity authentication", "ps": "N"},
          {"t": "地端憑證", "en": "on-premises credentials", "ps": "N"},
          {"t": "維運效率", "en": "operational efficiency", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 部署 Google Cloud Directory Sync (GCDS) 將地端 Active Directory 的使用者與群組單向同步至 Google Cloud Identity，並配置 SAML 2.0 單一登入 (SSO) 以便利用地端 AD 作為身份識別提供者 (IdP) 進行驗證。",
        "en": "(A) Deploy Google Cloud Directory Sync (GCDS) to perform a one-way synchronization of users and groups from on-premises Active Directory to Google Cloud Identity, and configure SAML 2.0 Single Sign-On (SSO) to leverage the on-premises AD as the Identity Provider (IdP) for authentication.",
        "wg": [
          {"t": "單向同步", "en": "one-way synchronization", "ps": "N"},
          {"t": "身份識別提供者", "en": "Identity Provider (IdP)", "ps": "N"}
        ]
      },
      {
        "t": "(B) 在 Google Cloud 的 Compute Engine 上部署一組新的唯讀網域控制器 (RODC)，並透過 Cloud VPN 與地端 AD 建立森林信任關係（Forest Trust），讓雲端資源能直接向地端 AD 請求身份驗證。",
        "en": "(B) Deploy a set of Read-Only Domain Controllers (RODC) on Compute Engine in Google Cloud and establish a Forest Trust with the on-premises AD via Cloud VPN, allowing cloud resources to request authentication directly from the on-premises AD.",
        "wg": []
      },
      {
        "t": "(C) 要求所有員工在 Cloud Identity 中重新註冊新的個人帳號，並強制執行多因素驗證 (MFA)，隨後編寫 Cloud Functions 定期掃描地端 AD 並透過 Admin SDK 自動更新雲端帳號的狀態，以確保同步性。",
        "en": "(C) Require all employees to register new individual accounts in Cloud Identity, enforce Multi-Factor Authentication (MFA), and then write Cloud Functions to periodically scan the on-premises AD and update cloud account statuses via the Admin SDK to ensure synchronization.",
        "wg": []
      },
      {
        "t": "(D) 使用 Managed Service for Microsoft Active Directory 在 Google Cloud 上建立一個完全託管的 AD 環境，並將所有地端使用者資料一次性匯出並匯入該環境，從此完全捨棄地端 AD 以降低混合雲管理的複雜性。",
        "en": "(D) Use Managed Service for Microsoft Active Directory to create a fully managed AD environment on Google Cloud, export all on-premises user data once and import it into the environment, and then completely decommission the on-premises AD to reduce hybrid cloud management complexity.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "GCDS 是 Google 官方推薦的標準工具，用於將地端 AD 同步至雲端，符合「減少管理成本」與「自動化」的需求。配合 SSO (SAML) 則能實現憑證不離開地端且統一登入的體驗。選項 (B) 增加了 VM 管理負擔；選項 (C) 涉及高度自定義開發，不符合最小化管理成本；選項 (D) 違反了案例中提到要維持與地端遺留系統連通性的現狀。",
      "en": "GCDS is the official Google-recommended tool for syncing on-premises AD to the cloud, aligning with the needs for 'reduced administration costs' and 'automation.' Pairing it with SSO (SAML) enables a unified login experience while keeping credentials on-premises. Option (B) increases VM management overhead; Option (C) involves highly custom development, failing the minimum management cost goal; Option (D) contradicts the case study's requirement to maintain connectivity with on-premises legacy systems.",
      "wg": [
        {"t": "管理負擔", "en": "management overhead", "ps": "N"},
        {"t": "遺留系統", "en": "legacy systems", "ps": "N"}
      ]
    }
  },
  {
    "no": "7",
    "level": "hard",
    "keywords": "Pub/Sub, Dataflow, Data Ingestion, Scalability",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 需要「建立介面以攝取並處理來自新提供商的數據」，且執行長特別提到目前的系統「不足以管理流量激增」。隨著新保險提供商的快速加入，系統必須能夠動態擴展以處理不可預測的數據負載，並確保數據在進入 BigQuery 進行分析前經過適當的清洗與轉換。同時，為了符合「減少基礎設施管理成本」的要求，該方案應盡可能採用無伺服器（Serverless）架構。針對此數據攝取與處理鏈，您應該推薦哪種架構？",
        "en": "EHR Healthcare needs to 'create interfaces to ingest and process data from new providers,' and the CEO specifically mentioned that current systems are 'inadequate to manage spikes in traffic.' With the rapid onboarding of new insurance providers, the system must dynamically scale to handle unpredictable data loads and ensure data is properly cleaned and transformed before entering BigQuery for analysis. To meet the 'decrease infrastructure administration costs' requirement, the solution should favor a serverless architecture. Which architecture should you recommend for this data ingestion and processing chain?",
        "wg": [
          {"t": "攝取", "en": "ingest", "ps": "V"},
          {"t": "流量激增", "en": "spikes in traffic", "ps": "N"},
          {"t": "無伺服器", "en": "Serverless", "ps": "Adj/N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud Pub/Sub 作為消息中間件來緩衝傳入的數據流，並結合 Cloud Dataflow 進行自動擴展的串流處理與轉換，最後將結構化數據寫入 BigQuery，這能提供極高的彈性以應對任何規模的流量激增。",
        "en": "(A) Use Cloud Pub/Sub as a message middleware to buffer incoming data streams, combined with Cloud Dataflow for auto-scaling stream processing and transformation, finally writing structured data to BigQuery, providing maximum elasticity to handle spikes of any scale.",
        "wg": [
          {"t": "中間件", "en": "middleware", "ps": "N"},
          {"t": "結構化數據", "en": "structured data", "ps": "N"}
        ]
      },
      {
        "t": "(B) 部署一組運行 Apache Kafka 與 Apache Flink 的 Compute Engine 託管實例組 (MIGs)，透過自定義的自動縮放腳本根據 CPU 使用率調整叢集大小，並將處理後的結果定期批量載入 BigQuery。",
        "en": "(B) Deploy a set of Compute Engine Managed Instance Groups (MIGs) running Apache Kafka and Apache Flink, using custom autoscaling scripts to adjust cluster size based on CPU utilization and periodically batch loading processed results into BigQuery.",
        "wg": []
      },
      {
        "t": "(C) 讓保險提供商直接透過 SFTP 將 CSV 檔案上傳到 Cloud Storage，並觸發 Cloud Functions 進行數據解析，若數據量過大，則將資料暫存在 Cloud SQL 中，等待非高峰時段再匯入數據倉庫。",
        "en": "(C) Have insurance providers upload CSV files directly via SFTP to Cloud Storage, triggering Cloud Functions for data parsing; if data volume is too large, temporarily store data in Cloud SQL and wait for off-peak hours to import into the data warehouse.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud Tasks 排程數據抓取作業，從提供商的 API 接口拉取數據，並在 Google Kubernetes Engine (GKE) 上執行一組專門的微服務來處理 ETL 任務，以確保數據處理的細粒度控制與隔離性。",
        "en": "(D) Use Cloud Tasks to schedule data scraping jobs, pulling data from provider API endpoints and running a dedicated set of microservices on Google Kubernetes Engine (GKE) to handle ETL tasks, ensuring fine-grained control and isolation of data processing.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "根據案例，核心痛點是「流量激增」與「行政成本」。Pub/Sub + Dataflow 是 Google Cloud 上標準的 Serverless 串流處理方案，能自動應對任意規模的負載且無需管理伺服器，完全符合需求。選項 (B) 需要大量手動管理與維運；選項 (C) 的 Cloud Functions 在處理極大規模激增時可能面臨配額與超時限制；選項 (D) 的 GKE 雖然可擴展，但相比 Dataflow，其維運與自動縮放配置更為複雜。",
      "en": "Based on the case study, core pain points are 'spikes in traffic' and 'administration costs.' Pub/Sub + Dataflow is the standard Serverless stream processing solution on Google Cloud, automatically handling loads of any scale without managing servers, perfectly meeting requirements. Option (B) requires significant manual management; Option (C)'s Cloud Functions may face quota and timeout limits during massive spikes; Option (D)'s GKE is scalable but its operations and autoscaling configuration are more complex compared to Dataflow.",
      "wg": [
        {"t": "串流處理", "en": "stream processing", "ps": "N"},
        {"t": "維運", "en": "operations", "ps": "N"}
      ]
    }
  },
  {
    "no": "8",
    "level": "hard",
    "keywords": "Apigee, API Management, Legacy Interfaces",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 目前維護著多個與保險提供商對接的「遺留文件與 API 介面」，這些系統短期內不會升級且仍運行在地端。隨著公司將核心業務遷移至雲端，他們希望提供一個現代化的外層，以便在不更改地端遺留系統代碼的前提下，對外開放更安全、可監控且具備流量限制（Rate Limiting）能力的 API 服務。此外，公司還希望獲得 API 使用情況的分析洞察。作為架構師，您應該推薦哪項產品來滿足這些 API 管理需求？",
        "en": "EHR Healthcare currently maintains multiple 'legacy file- and API-based integrations' with insurance providers, which will not be upgraded in the short term and still run on-premises. As the company migrates core business to the cloud, they want to provide a modern outer layer to expose safer, monitorable API services with rate-limiting capabilities without changing legacy on-premises code. Additionally, the company wants analytical insights into API usage. As an architect, which product should you recommend to meet these API management requirements?",
        "wg": [
          {"t": "外層", "en": "outer layer/facade", "ps": "N"},
          {"t": "流量限制", "en": "Rate Limiting", "ps": "N"},
          {"t": "分析洞察", "en": "analytical insights", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 部署 Apigee API 管理平台，利用其 API 代理（Proxy）功能將地端遺留介面封裝成 RESTful API，並實施 OAuth 2.0 驗證、流量配額管理以及利用其內建的分析儀表板來追蹤提供商的調用行為。",
        "en": "(A) Deploy the Apigee API management platform, using its API Proxy features to encapsulate legacy on-premises interfaces as RESTful APIs, and implement OAuth 2.0 authentication, quota management, and its built-in analytics dashboards to track provider invocation patterns.",
        "wg": [
          {"t": "封裝", "en": "encapsulate", "ps": "V"},
          {"t": "調用行為", "en": "invocation patterns/behaviors", "ps": "N"}
        ]
      },
      {
        "t": "(B) 使用 Cloud Endpoints 配合 ESPv2 部署在 GKE 叢集中，並撰寫 OpenAPI 規範文檔來描述地端介面，利用其輕量級的特性來處理 API 驗證，並將所有分析數據手動匯出至 BigQuery 進行分析。",
        "en": "(B) Use Cloud Endpoints with ESPv2 deployed in a GKE cluster, write OpenAPI specifications to describe on-premises interfaces, leverage its lightweight nature for API authentication, and manually export all analytics data to BigQuery for analysis.",
        "wg": []
      },
      {
        "t": "(C) 在地端環境安裝 NGINX 作為反向代理伺服器，並配置防火牆規則來限制流量，同時將 NGINX 日誌透過 Cloud Logging 代理程式傳送到 Google Cloud，並建立自定義的 Cloud Monitoring 儀表板。",
        "en": "(C) Install NGINX as a reverse proxy on-premises, configure firewall rules for rate limiting, and send NGINX logs to Google Cloud via the Cloud Logging agent to build custom Cloud Monitoring dashboards.",
        "wg": []
      },
      {
        "t": "(D) 實施 VPC Service Controls 並配合內部負載平衡器 (ILB)，將地端 API 流量封閉在私有網路內，並使用 Cloud IAM 權限來嚴格控制誰能調用地端遺留介面，以確保最高層級的安全性。",
        "en": "(D) Implement VPC Service Controls combined with Internal Load Balancers (ILB) to keep on-premises API traffic within a private network, and use Cloud IAM permissions to strictly control who can invoke legacy on-premises interfaces to ensure the highest security level.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Apigee 是 Google Cloud 提供的企業級 API 管理工具，特別適合「封裝遺留系統」與提供強大的分析功能。它能提供流量控制（Rate Limiting）與現代化驗證，且無需修改後端遺留系統，完全符合 EHR 的目標。Cloud Endpoints (B) 雖然輕量，但主要針對雲端原生開發，且分析功能不如 Apigee 豐富；選項 (C) 增加了地端管理的負擔；選項 (D) 無法解決 API 管理、現代化封裝與流量分析的需求。",
      "en": "Apigee is Google Cloud's enterprise-grade API management tool, ideal for 'encapsulating legacy systems' and providing robust analytics. It offers rate limiting and modern authentication without modifying backend legacy systems, perfectly matching EHR's objectives. Cloud Endpoints (B) is lightweight but targeted more at cloud-native development and lacks Apigee's rich analytics; Option (C) increases on-premises management burden; Option (D) does not address API management, modernization, or usage analytics.",
      "wg": [
        {"t": "企業級", "en": "enterprise-grade", "ps": "Adj"},
        {"t": "雲端原生", "en": "cloud-native", "ps": "Adj/N"}
      ]
    }
  },
  {
    "no": "9",
    "level": "hard",
    "keywords": "BigQuery ML, Industry Trends, Machine Learning, SQL",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的高層在業務驅動因素中強調要「提升提供醫療趨勢洞察的能力」以及「根據提供商數據進行行業趨勢預測」。目前數據量正在指數級增長，分佈在 MySQL 與 MongoDB 中。公司希望其資料分析團隊能夠利用現有的 SQL 技能快速建立預測模型，而不需要投入大量資源來學習複雜的機器學習框架或管理專門的 AI 基礎設施。考慮到「減少行政成本」的目標，您應該推薦哪種方案來實現「行業趨勢預測」？",
        "en": "EHR Healthcare leadership emphasizes 'increasing ability to provide insights into healthcare trends' and 'making predictions on industry trends based on provider data' as business drivers. Data volume is growing exponentially across MySQL and MongoDB. The company wants its data analytics team to leverage existing SQL skills to rapidly build predictive models without investing significant resources in learning complex ML frameworks or managing specialized AI infrastructure. Considering the goal of 'decreasing infrastructure administration costs,' which solution should you recommend for 'industry trend forecasting'?",
        "wg": [
          {"t": "洞察", "en": "insights", "ps": "N"},
          {"t": "指數級", "en": "exponential", "ps": "Adj"},
          {"t": "預測模型", "en": "predictive models", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將數據載入 BigQuery 後，直接使用 BigQuery ML。透過標準 SQL 語法訓練線性回歸（Linear Regression）或預測模型，這能讓分析師在不移動數據且不管理底層運算資源的情況下實現快速開發。",
        "en": "(A) After loading data into BigQuery, use BigQuery ML directly. Training Linear Regression or forecasting models via standard SQL syntax allows analysts to achieve rapid development without moving data or managing underlying compute resources.",
        "wg": [
          {"t": "線性回歸", "en": "Linear Regression", "ps": "N"},
          {"t": "預測", "en": "forecasting/predicting", "ps": "N/V"}
        ]
      },
      {
        "t": "(B) 使用 Vertex AI 建立自定義的 TensorFlow 訓練作業，並利用 Vertex AI Pipelines 進行自動化的模型訓練與部署，雖然需要 Python 技能，但能提供最高精確度的趨勢預測結果。",
        "en": "(B) Use Vertex AI to build custom TensorFlow training jobs and leverage Vertex AI Pipelines for automated model training and deployment. Although this requires Python skills, it provides the highest accuracy for trend prediction results.",
        "wg": []
      },
      {
        "t": "(C) 部署一個大規模的 Dataproc 叢集並安裝 Spark MLlib，讓開發團隊使用 Scala 或 Java 編寫分散式機器學習演算法，以處理來自 MongoDB 的海量非結構化數據並生成報告。",
        "en": "(C) Deploy a large-scale Dataproc cluster and install Spark MLlib, allowing the development team to use Scala or Java to write distributed machine learning algorithms for processing massive unstructured data from MongoDB and generating reports.",
        "wg": []
      },
      {
        "t": "(D) 利用 Cloud SQL 的內建分析功能配合連接外部分析軟體（如 Tableau），透過手動調整數據透視表與簡單的統計公式來推估行業趨勢，以最大化利用現有的關係型數據資產。",
        "en": "(D) Leverage Cloud SQL's built-in analytical features paired with external BI software (like Tableau), using manual pivot tables and simple statistical formulas to estimate industry trends, maximizing existing relational data assets.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "EHR 的關鍵要求是「利用 SQL 技能」、「快速實現」且「不管理 AI 基礎設施」。BigQuery ML 完全符合這些條件，它讓 SQL 分析師能直接在數據倉庫中建立模型，且是 Serverless 架構，極大地降低了行政成本。Vertex AI (B) 與 Dataproc (C) 都需要更專業的技術背景（Python/Java/Infrastructure），不符合「利用現有 SQL 技能」且會增加成本；選項 (D) 無法處理大數據規模且不具備真正的機器學習預測能力。",
      "en": "EHR's key requirements are 'leveraging SQL skills,' 'rapid implementation,' and 'not managing AI infrastructure.' BigQuery ML fits perfectly, allowing SQL analysts to build models directly in the data warehouse with a Serverless architecture, significantly reducing administration costs. Vertex AI (B) and Dataproc (C) require more specialized technical backgrounds (Python/Java/Infrastructure), contradicting the 'leverage SQL' goal; Option (D) cannot handle big data scales and lacks true ML predictive power.",
      "wg": [
        {"t": "數據倉庫", "en": "data warehouse", "ps": "N"},
        {"t": "技術背景", "en": "technical backgrounds", "ps": "N"}
      ]
    }
  },
  {
    "no": "10",
    "level": "hard",
    "keywords": "Infrastructure as Code, Terraform, Misconfiguration, SRE",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的執行長在聲明中坦承，過往許多停機事件是源於「系統配置錯誤」與「對相似但不同的環境進行手動管理」。公司現在需要「動態地擴展並配置新環境」，同時確保所有環境（開發、測試、生產）的一致性。技術團隊希望透過自動化手段來減少人為干擾，並能快速恢復因錯誤配置導致的故障。作為架構師，您應該推薦哪項 DevOps 實踐與技術來解決配置錯誤導致的停機問題？",
        "en": "EHR Healthcare's CEO admitted in the statement that many past outages resulted from 'misconfigured systems' and 'manual management of similar but separate environments.' The company now needs to 'dynamically scale and provision new environments' while ensuring consistency across all environments (Dev, Test, Prod). The technical team wants to use automation to reduce human intervention and rapidly recover from failures caused by misconfigurations. As an architect, which DevOps practice and technology should you recommend to address outages caused by system misconfigurations?",
        "wg": [
          {"t": "人為干擾", "en": "human intervention", "ps": "N"},
          {"t": "一致性", "en": "consistency", "ps": "N"},
          {"t": "故障", "en": "failures", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 採用基礎設施即程式碼 (IaC) 並使用 Terraform。將所有的雲端資源定義在版本控制系統（如 Git）中的聲明式配置檔案中，並透過 CI/CD 流水線自動執行部署，以確保環境的冪等性（Idempotency）與可重複性。",
        "en": "(A) Adopt Infrastructure as Code (IaC) using Terraform. Define all cloud resources in declarative configuration files within a version control system (like Git) and automate deployments via CI/CD pipelines to ensure idempotency and repeatability across environments.",
        "wg": [
          {"t": "基礎設施即程式碼", "en": "Infrastructure as Code (IaC)", "ps": "N"},
          {"t": "冪等性", "en": "Idempotency", "ps": "N"},
          {"t": "可重複性", "en": "repeatability", "ps": "N"}
        ]
      },
      {
        "t": "(B) 建立一套詳盡的標準作業程序 (SOP) 手冊，並要求維運工程師在每次修改環境後更新手冊，同時使用 Google Cloud 控制台中的「複製」功能來手動建立新環境，以確保配置細節與現有系統一致。",
        "en": "(B) Create a detailed set of Standard Operating Procedures (SOPs) and require operations engineers to update them after every change, while using the 'Clone' feature in the Google Cloud Console to manually create new environments, ensuring configuration details match existing systems.",
        "wg": []
      },
      {
        "t": "(C) 使用 Compute Engine 的自定義映像檔 (Custom Images) 功能，將配置好的系統封裝成映像檔，當需要擴展時，直接從這些映像檔啟動新的 VM 實例，以避免手動安裝軟體時可能產生的配置差異。",
        "en": "(C) Use Compute Engine's Custom Images feature to package pre-configured systems into images. When scaling is needed, start new VM instances directly from these images to avoid potential configuration discrepancies that occur during manual software installation.",
        "wg": []
      },
      {
        "t": "(D) 部署 Cloud Identity-Aware Proxy (IAP) 來嚴格控制管理員對 VM 的存取權限，並啟用日誌稽核功能來追蹤是誰進行了錯誤配置，從而透過強化問責制（Accountability）來減少系統停機的風險。",
        "en": "(D) Deploy Cloud Identity-Aware Proxy (IAP) to strictly control administrative access to VMs and enable audit logging to track who made a misconfiguration, thereby reducing downtime risk through strengthened accountability.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "案例明確指出「系統配置錯誤」是停機主因。IaC (Terraform) 是解決此問題的最佳實務，它能將環境定義代碼化，透過 CI/CD 確保部署是自動化、版本化且一致的，消除了手動管理的風險。選項 (B) 依然依賴手動，無法解決「人為干擾」；選項 (C) 雖然解決了軟體層級一致性，但無法管理網路、資料庫等基礎設施層級的配置；選項 (D) 雖然能追蹤錯誤，但無法從根本上「預防」配置錯誤或「動態配置」新環境。",
      "en": "The case study clearly identifies 'system misconfiguration' as the primary cause of outages. IaC (Terraform) is the best practice for solving this, as it codifies environment definitions and ensures deployments are automated, versioned, and consistent through CI/CD, eliminating manual risks. Option (B) still relies on manual work, failing to address 'human intervention'; Option (C) handles software consistency but cannot manage infrastructure-level configs like networks or databases; Option (D) tracks errors but doesn't fundamentally 'prevent' them or 'dynamically provision' new environments.",
      "wg": [
        {"t": "代碼化", "en": "codified", "ps": "V"},
        {"t": "根本上", "en": "fundamentally", "ps": "Adv"}
      ]
    }
  },
  {
    "no": "11",
    "level": "hard",
    "keywords": "Continuous Deployment, GKE, Cloud Build, Binary Authorization",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的執行長聲明中提到，公司需要「推出新的持續部署能力，以便快速更新軟體」，同時也指出過往許多停機是由於「系統配置錯誤」所致。目前的環境包含多個 GKE 叢集。為了建立一個既能確保部署速度，又能透過自動化流程減少人為配置錯誤，並在生產環境中僅運行經過驗證的代碼的架構，身為架構師，您應該建議哪種 CI/CD 與安全組合方案？",
        "en": "EHR Healthcare's executive statement mentions the need to 'roll out new continuous deployment capabilities to update their software at a fast pace,' while noting that past outages were often caused by 'misconfigured systems.' Their environment includes multiple GKE clusters. To establish an architecture that ensures deployment speed, reduces human configuration errors via automation, and ensures only verified code runs in production, which CI/CD and security combination should you suggest?",
        "wg": [
          {"t": "持續部署", "en": "continuous deployment", "ps": "N"},
          {"t": "配置錯誤", "en": "misconfigured systems", "ps": "N"},
          {"t": "人為干擾", "en": "human intervention/error", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud Build 建立自動化流水線，將容器映像檔推送到 Artifact Registry，並實施 Binary Authorization 策略，確保只有經過 Cloud Build 簽署的映像檔才能部署到生產環境的 GKE 叢集中。",
        "en": "(A) Use Cloud Build to create automated pipelines that push container images to Artifact Registry, and implement a Binary Authorization policy to ensure only images signed by Cloud Build can be deployed to the production GKE clusters.",
        "wg": [
          {"t": "映像檔", "en": "container images", "ps": "N"},
          {"t": "二進位授權", "en": "Binary Authorization", "ps": "N"}
        ]
      },
      {
        "t": "(B) 在 Compute Engine 上自行部署 Jenkins 伺服器，透過腳本手動調用 kubectl apply 來更新 GKE 部署，並在部署後由維運團隊手動稽核日誌，以確保符合「減少行政成本」的業務目標。",
        "en": "(B) Deploy a self-managed Jenkins server on Compute Engine, manually invoke 'kubectl apply' via scripts to update GKE deployments, and have the operations team manually audit logs post-deployment to meet the 'decrease administration costs' business goal.",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud Deploy 進行多環境的編排，並配合 Cloud Source Repositories 進行版本控制，當代碼提交時自動更新 GKE 的 ConfigMap，但不實施任何外部簽署機制以保持部署流程的最低延遲。",
        "en": "(C) Use Cloud Deploy for multi-environment orchestration combined with Cloud Source Repositories for version control, automatically updating GKE ConfigMaps on code commit without implementing external signing mechanisms to maintain minimum deployment latency.",
        "wg": []
      },
      {
        "t": "(D) 建立一套以 GitHub Actions 為核心的流水線，並使用 Terraform 管理 GKE 資源，透過在每個節點上安裝第三方監控代理程式來即時修正配置偏移，以達成「主動式維運」的要求。",
        "en": "(D) Build a GitHub Actions-based pipeline and use Terraform to manage GKE resources, installing third-party monitoring agents on each node to fix configuration drift in real-time to meet the 'proactive operations' requirement.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Cloud Build 配合 Binary Authorization 是 Google Cloud 實現安全持續部署的最佳實務。它能自動化流程（減少人為錯誤）並確保軟體供應鏈安全（只運行簽署過的代碼）。選項 (B) 增加了管理負擔；選項 (C) 缺乏安全性驗證；選項 (D) 雖然使用 IaC，但在「確保只有驗證代碼運行」這一點上不如 Binary Authorization 直接有效。",
      "en": "Cloud Build paired with Binary Authorization is the Google Cloud best practice for secure continuous deployment. It automates processes (reducing human error) and secures the software supply chain (running only signed code). Option (B) increases management burden; Option (C) lacks security verification; Option (D) uses IaC but is less effective than Binary Authorization for ensuring only verified code runs.",
      "wg": [
        {"t": "最佳實務", "en": "best practice", "ps": "N"},
        {"t": "軟體供應鏈", "en": "software supply chain", "ps": "N"}
      ]
    }
  },
  {
    "no": "12",
    "level": "hard",
    "keywords": "Identity-Aware Proxy (IAP), Zero Trust, Secure Access",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 為全球跨國醫療機構提供服務，員工分佈於不同區域。為了存取其內部的客戶管理應用程式與遺留系統，目前主要依賴於傳統的 Client VPN 連線。然而，這種方式增加了管理複雜性（如憑證分發與連線不穩），且執行長希望透過轉向 Google Cloud 來實現「無縫且一致的使用者體驗」。考慮到「安全性」與「減少維運負擔」的技術要求，您應該建議哪種方案來取代 VPN，以提供對受保護資源的遠端存取？",
        "en": "EHR Healthcare serves multi-national medical offices with employees distributed globally. To access internal customer management applications and legacy systems, they currently rely on traditional Client VPN connections. However, this increases management complexity (e.g., certificate distribution and connection instability), and the CEO wants to move to Google Cloud for a 'seamless and stable user experience.' Considering the requirements for 'security' and 'decreasing administration costs,' which solution should you recommend to replace VPN for remote access to protected resources?",
        "wg": [
          {"t": "跨國", "en": "multi-national", "ps": "Adj"},
          {"t": "維運負擔", "en": "administration costs/burden", "ps": "N"},
          {"t": "連線不穩", "en": "connection instability", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 實施 Identity-Aware Proxy (IAP)，透過驗證使用者身份與請求上下文（如 IP 或設備狀態）來控制對應用的存取。這不需要客戶端安裝 VPN 軟體，且能直接在 Google 網路上實現細粒度的存取控制，降低維管負擔。",
        "en": "(A) Implement Identity-Aware Proxy (IAP) to control access to applications by verifying user identity and request context (e.g., IP or device status). This eliminates the need for VPN software on client devices and enables fine-grained access control on Google's network, reducing management burden.",
        "wg": [
          {"t": "身份感知代理", "en": "Identity-Aware Proxy (IAP)", "ps": "N"},
          {"t": "細粒度", "en": "fine-grained", "ps": "Adj"}
        ]
      },
      {
        "t": "(B) 部署全域外部 HTTP(S) 負載平衡器，並在所有內部應用程式前配置強大的防火牆規則，僅允許來自公司辦公室固定的 IP 範圍進行存取，同時使用 Cloud Armor 來防禦惡意流量。",
        "en": "(B) Deploy a Global External HTTP(S) Load Balancer and configure strict firewall rules in front of all internal applications, allowing access only from fixed company office IP ranges, while using Cloud Armor to defend against malicious traffic.",
        "wg": []
      },
      {
        "t": "(C) 為每位遠端員工建立專屬的 Bastion Host（堡壘機），並使用 OS Login 功能進行管理。員工必須先透過 SSH 隧道連接到堡壘機，再跳轉至內部遺留系統，以確保所有存取行為都被日誌記錄。",
        "en": "(C) Create a dedicated Bastion Host for each remote employee and manage them using OS Login. Employees must first connect via SSH tunnel to the Bastion Host and then jump to internal legacy systems, ensuring all access is logged.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud Interconnect 建立地端資料中心與 Google Cloud 之間的專用線路，並要求所有遠端員工先撥號回公司地端 VPN 網關，再透過專線存取雲端資源，以維持既有的安全策略。",
        "en": "(D) Use Cloud Interconnect to establish a private line between on-premises data centers and Google Cloud, requiring all remote employees to dial back to the company's on-premises VPN gateway first before accessing cloud resources to maintain existing security policies.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "IAP 是實現「零信任（Zero Trust）」安全模型的關鍵，它移除了對 VPN 的依賴，解決了管理複雜性並提升了使用者體驗，完全符合案例中「無縫跨環境」與「減少管理成本」的需求。選項 (B) 無法應對移動辦公的需求；選項 (C) 增加了極大的基礎設施維護成本；選項 (D) 增加了延遲且未利用雲端原生的安全優勢。",
      "en": "IAP is key to implementing a 'Zero Trust' security model, removing VPN dependency, solving management complexity, and improving user experience—perfectly aligning with the 'seamless cross-environment' and 'reduce administration costs' goals. Option (B) fails to support mobile work; Option (C) adds significant infrastructure maintenance; Option (D) increases latency and ignores cloud-native security advantages.",
      "wg": [
        {"t": "零信任", "en": "Zero Trust", "ps": "N"},
        {"t": "移動辦公", "en": "mobile work/remote work", "ps": "N"}
      ]
    }
  },
  {
    "no": "13",
    "level": "hard",
    "keywords": "Cloud DLP, PII, HIPAA, Data Privacy",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 在業務驅動因素中強調要「維持法規遵循（Regulatory Compliance）」，特別是針對病患數據的隱私保護。公司需要對存儲在 Google Cloud（如 BigQuery 與 Cloud Storage）中的海量電子健康紀錄進行掃描，以自動識別個人識別資訊 (PII)，並在將數據用於「行業趨勢分析與預測」之前進行遮蔽或去識別化處理。為了以自動化且可擴展的方式達成此目標並降低合規風險，您應該推薦哪種解決方案？",
        "en": "EHR Healthcare emphasizes 'Regulatory Compliance' as a business driver, particularly regarding patient data privacy. The company needs to scan massive electronic health records stored in Google Cloud (e.g., BigQuery and Cloud Storage) to automatically identify Personally Identifiable Information (PII) and perform masking or de-identification before using the data for 'industry trend insights and predictions.' Which solution should you recommend to achieve this in an automated, scalable way and reduce compliance risks?",
        "wg": [
          {"t": "去識別化", "en": "de-identification", "ps": "N/V"},
          {"t": "個人識別資訊", "en": "Personally Identifiable Information (PII)", "ps": "N"},
          {"t": "合規風險", "en": "compliance risks", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 實施 Cloud Data Loss Prevention (DLP)，配置檢查工作（Inspection Jobs）自動發現敏感數據，並應用去識別化轉換（如遮蔽、K-匿名化或偽名化），確保進入分析環境的數據符合 HIPAA 的隱私標準。",
        "en": "(A) Implement Cloud Data Loss Prevention (DLP), configure inspection jobs to automatically discover sensitive data, and apply de-identification transformations (e.g., masking, K-anonymity, or pseudonymization) to ensure data entering analysis environments meets HIPAA privacy standards.",
        "wg": [
          {"t": "檢查工作", "en": "Inspection Jobs", "ps": "N"},
          {"t": "偽名化", "en": "pseudonymization", "ps": "N"}
        ]
      },
      {
        "t": "(B) 僅使用 BigQuery 的資料列與資料欄等級權限控管 (IAM)，限制只有特定的資料科學家能存取包含病患姓名與 ID 的欄位，並要求其在分析前手動於代碼中執行數據過濾與遮蔽邏輯。",
        "en": "(B) Use only BigQuery row- and column-level IAM controls to restrict specific data scientists from accessing columns containing patient names and IDs, and require them to manually perform data filtering and masking in code before analysis.",
        "wg": []
      },
      {
        "t": "(C) 將所有的病患紀錄存放在加密的 Cloud Storage Bucket 中，並定期將數據匯出到地端環境進行手動稽核，確認無敏感資訊外洩後再重新載入 BigQuery 進行行業趨勢預測。",
        "en": "(C) Store all patient records in encrypted Cloud Storage buckets and periodically export data to an on-premises environment for manual auditing, re-loading it into BigQuery for trend forecasting only after confirming no sensitive info exfiltration.",
        "wg": []
      },
      {
        "t": "(D) 部署 Cloud Armor 的內容過濾規則，在數據從應用程式傳輸到資料庫的過程中攔截並攔阻任何包含社會安全號碼或病患電話格式的封包，以此作為主要的防護手段。",
        "en": "(D) Deploy Cloud Armor content filtering rules to intercept and block any packets containing Social Security Number or patient phone formats as data travels from applications to the database as the primary protection measure.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Cloud DLP 是專為自動識別與保護敏感數據設計的產品，支持去識別化技術（如遮蔽、K-匿名化），能直接處理存儲在 BigQuery/GCS 中的大規模數據，完美契合 EHR 關於 HIPAA 合規與趨勢預測的需求。選項 (B) 依賴人為操作，風險極高；選項 (C) 違反了減少行政成本與快速獲取洞察的目標；選項 (D) 主要是邊緣防護，無法對存儲中的靜態數據進行內容掃描與轉換。",
      "en": "Cloud DLP is specifically designed to automatically identify and protect sensitive data, supporting de-identification (e.g., masking, K-anonymity) for large-scale data in BigQuery/GCS, perfectly fitting EHR's HIPAA compliance and trend forecasting needs. Option (B) relies on human operation, which is high-risk; Option (C) contradicts goals for reduced admin costs and rapid insights; Option (D) is edge defense and cannot scan or transform data at rest in storage.",
      "wg": [
        {"t": "靜態數據", "en": "data at rest", "ps": "N"},
        {"t": "邊緣防護", "en": "edge defense", "ps": "N"}
      ]
    }
  },
  {
    "no": "14",
    "level": "hard",
    "keywords": "GKE, Autoscaling, HPA, VPA, Cluster Autoscaler",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的執行長指出，過往的停機事件有很大一部分是源於「處理流量激增的能力不足」。目前其客戶端應用程式已遷移至容器化環境，但仍面臨在負載波動時響應緩慢的問題。技術要求中明確提到要「動態地擴展並配置新環境」。為了確保 GKE 上的應用程式能夠自動應對從少數使用者到全球規模流量的劇烈波動，並提供穩定且一致的使用者體驗，您應該如何配置 GKE 的自動縮放機制？",
        "en": "EHR Healthcare's CEO noted that many past outages stemmed from an 'inadequate capacity to manage spikes in traffic.' Their customer-facing applications have moved to containerized environments but still face slow responses during load fluctuations. Technical requirements explicitly state the need to 'dynamically scale and provision new environments.' To ensure GKE applications can automatically handle drastic fluctuations from a few users to global-scale traffic while providing a stable, consistent user experience, how should you configure GKE's autoscaling mechanisms?",
        "wg": [
          {"t": "響應緩慢", "en": "slow responses", "ps": "N"},
          {"t": "流量劇烈波動", "en": "drastic fluctuations in traffic", "ps": "N"},
          {"t": "自動縮放機制", "en": "autoscaling mechanisms", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 同時啟用水平 Pod 自動縮放 (HPA) 以應對流量增加導致的副本數需求，以及集群自動縮放 (Cluster Autoscaler) 以在節點資源耗盡時自動增加底層 VM，並根據需要啟用垂直 Pod 自動縮放 (VPA) 優化資源預留。",
        "en": "(A) Simultaneously enable Horizontal Pod Autoscaler (HPA) to handle replica needs from increased traffic, and Cluster Autoscaler to automatically add underlying VMs when node resources are exhausted, enabling Vertical Pod Autoscaler (VPA) as needed to optimize resource reservations.",
        "wg": [
          {"t": "水平 Pod 自動縮放", "en": "Horizontal Pod Autoscaler (HPA)", "ps": "N"},
          {"t": "集群自動縮放", "en": "Cluster Autoscaler", "ps": "N"}
        ]
      },
      {
        "t": "(B) 根據歷史流量數據預估最大峰值，並將 GKE 叢集的大小固定在該峰值水平，以確保系統始終有足夠餘力（Headroom）處理突發流量，從而避免因自動縮放延遲而導致的用戶體驗下降。",
        "en": "(B) Estimate the maximum peak based on historical traffic data and fix the GKE cluster size at that peak level to ensure the system always has sufficient headroom to handle bursts, thereby avoiding user experience degradation caused by autoscaling latency.",
        "wg": []
      },
      {
        "t": "(C) 僅實施單一區域的 GKE 自動縮放，並使用 Cloud Scheduler 每小時執行腳本來檢查負載，若負載過高則手動增加節點池（Node Pool）的大小，以符合「減少管理成本」的目標並保持對基礎設施的完全控制。",
        "en": "(C) Implement single-zone GKE autoscaling only and use Cloud Scheduler to run hourly scripts to check load; if load is high, manually increase the Node Pool size to meet 'decrease administration costs' while maintaining full infrastructure control.",
        "wg": []
      },
      {
        "t": "(D) 將所有 GKE 負載遷移至 Cloud Run 服務，利用其全託管的縮放特性實現從零到幾千個實例的秒級伸縮，完全消除對 Kubernetes 叢集、節點池與底層虛擬機資源的管理需求。",
        "en": "(D) Migrate all GKE workloads to Cloud Run services, leveraging its fully managed scaling properties to achieve second-level elasticity from zero to thousands of instances, completely eliminating management needs for Kubernetes clusters, node pools, and underlying VM resources.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "針對「流量激增」與「穩定體驗」，(A) 是 GKE 的標準自動化解決方案，HPA 處理應用程式層，Cluster Autoscaler 處理基礎設施層，兩者配合能實現真正的動態擴展。選項 (B) 浪費成本且不具備動態性；選項 (C) 依然依賴手動干預且反應太慢；選項 (D) 雖然在縮放上極強，但對於 EHR 已有的大型 Kubernetes 生態系統與複雜配置（如多個容器環境管理）來說，遷移成本與架構變更過大，且不符合維持 GKE 叢集管理的需求。",
      "en": "For 'traffic spikes' and 'stable experience,' (A) is the standard GKE automation solution; HPA handles the app layer while Cluster Autoscaler handles the infra layer—together they provide true dynamic scaling. Option (B) wastes cost and lacks dynamics; Option (C) still relies on manual intervention and is too slow; Option (D) has excellent scaling but, given EHR's existing large Kubernetes ecosystem and complex management needs, would involve excessive migration costs and architectural changes that ignore the need to manage GKE clusters.",
      "wg": [
        {"t": "手動干預", "en": "manual intervention", "ps": "N"},
        {"t": "秒級伸縮", "en": "second-level elasticity", "ps": "N"}
      ]
    }
  },
  {
    "no": "15",
    "level": "hard",
    "keywords": "Database Migration Service (DMS), Cloud SQL, Relational Database, Minimal Downtime",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 目前將數據存儲在混合了 MySQL、MS SQL Server 等關聯式資料庫中，且其中一個資料中心的租約即將到期。技術團隊需要將這些資料庫遷移到 Cloud SQL 以「減少基礎設施管理成本」，並確保在遷移過程中對 24/7 全天候運行的醫療軟體服務造成的停機時間（Downtime）最小化。同時，公司希望在遷移後能利用 Google Cloud 的原生工具進行一致的監控。為了達成「快速、安全且低風險」的資料庫遷移，您應該推薦哪種技術路徑？",
        "en": "EHR Healthcare stores data in a mixture of relational databases like MySQL and MS SQL Server, and the lease on one of their data centers is about to expire. The technical team needs to migrate these databases to Cloud SQL to 'decrease infrastructure administration costs,' ensuring minimal downtime for their 24/7 software services during the process. Post-migration, they want to use native Google Cloud tools for consistent monitoring. For a 'fast, secure, and low-risk' database migration, which technical path should you recommend?",
        "wg": [
          {"t": "停機時間", "en": "Downtime", "ps": "N"},
          {"t": "資料庫遷移服務", "en": "Database Migration Service (DMS)", "ps": "N"},
          {"t": "原生工具", "en": "native tools", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Database Migration Service (DMS) 進行持續遷移，將地端資料庫設為來源並透過 Cloud VPN 或 Interconnect 連接，利用其基於變更數據捕獲 (CDC) 的機制實現與 Cloud SQL 的實時同步，並在最終切換（Cutover）時將停機時間降至最低。",
        "en": "(A) Use Database Migration Service (DMS) for continuous migration, setting the on-premises database as the source and connecting via Cloud VPN or Interconnect. Leverage its Change Data Capture (CDC) mechanism for real-time synchronization with Cloud SQL, minimizing downtime during the final cutover.",
        "wg": [
          {"t": "變更數據捕獲", "en": "Change Data Capture (CDC)", "ps": "N"},
          {"t": "最終切換", "en": "Cutover", "ps": "N"}
        ]
      },
      {
        "t": "(B) 執行一次性的 mysqldump 或 SQL Server 備份匯出，將備份檔案上傳到 Cloud Storage 後，再手動將其匯入新的 Cloud SQL 實例。在匯入期間停止所有應用程式寫入，以確保數據的一致性與安全性。",
        "en": "(B) Perform a one-time mysqldump or SQL Server backup export, upload the backup files to Cloud Storage, and then manually import them into a new Cloud SQL instance. Stop all application writes during the import to ensure data consistency and security.",
        "wg": []
      },
      {
        "t": "(C) 在 GKE 叢集內部署一組運行 MySQL 與 MS SQL Server 的 Pods，並使用持久化硬碟 (Persistent Disks) 存儲數據，透過在地端與雲端之間配置手動的應用層級數據複製流程，以維持對資料庫版本與配置的完全控制。",
        "en": "(C) Deploy a set of Pods running MySQL and MS SQL Server within GKE clusters using Persistent Disks for storage. Manually configure an application-level data replication process between on-premises and the cloud to maintain full control over database versions and configurations.",
        "wg": []
      },
      {
        "t": "(D) 使用 Storage Transfer Service 將地端的資料庫實體數據庫檔案直接搬移到 Google Cloud 虛擬機的磁碟上，然後在 Compute Engine 上重新啟動資料庫服務，這能提供最快的遷移速度並避開繁瑣的 API 轉換流程。",
        "en": "(D) Use Storage Transfer Service to move on-premises database physical files directly to disks on Google Cloud VMs, then restart database services on Compute Engine. This provides the fastest migration speed and avoids complex API transformation processes.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "DMS 是 Google 提供的全託管、易於使用的遷移工具，特別針對 Cloud SQL 設計，支持「最小停機時間」的持續同步，最符合 EHR 的業務需求。選項 (B) 的一次性匯出會導致長時間停機，不符合 24/7 運作要求；選項 (C) 增加了大量的行政管理成本，違反了業務目標；選項 (D) 雖然快，但屬於 Rehost，無法實現向 Cloud SQL（全託管）遷移以減少管理成本的目標。",
      "en": "DMS is Google's fully managed, easy-to-use migration tool designed specifically for Cloud SQL, supporting continuous synchronization for 'minimal downtime'—perfect for EHR's business needs. Option (B)'s one-time export causes long downtime, failing 24/7 requirements; Option (C) increases massive administrative costs, contradicting business goals; Option (D) is a Rehost and fails to achieve the goal of migrating to Cloud SQL (fully managed) to reduce management costs.",
      "wg": [
        {"t": "全託管", "en": "fully managed", "ps": "Adj"},
        {"t": "最小停機時間", "en": "minimal downtime", "ps": "N"}
      ]
    }
  },
  {
    "no": "16",
    "level": "hard",
    "keywords": "Disaster Recovery, RTO/RPO, Multi-region, Cloud Storage",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的執行長強調需要「調整其災難恢復（DR）計劃」以因應業務的指數級增長。目前，該公司正將其 Web 應用程式遷移至 Google Cloud。技術團隊的目標是確保在發生區域性故障（Regional Failure）時，能夠在幾分鐘內恢復服務（低 RTO），且數據損失接近於零（低 RPO）。考慮到公司提供的是全球性的 SaaS 服務且需滿足 HIPAA 合規性中的數據可用性要求，您應該推薦哪種架構來優化其在 Google Cloud 上的災難恢復能力？",
        "en": "EHR Healthcare's CEO emphasizes the need to 'adapt their disaster recovery (DR) plan' to account for exponential business growth. Currently, the company is migrating its web-based applications to Google Cloud. The technical team's goal is to ensure services can be recovered within minutes (low RTO) and with near-zero data loss (low RPO) in the event of a regional failure. Given that the company provides global SaaS services and must meet data availability requirements under HIPAA compliance, which architecture should you recommend to optimize their DR capabilities on Google Cloud?",
        "wg": [
          {"t": "區域性故障", "en": "regional failure", "ps": "N"},
          {"t": "恢復時間目標", "en": "Recovery Time Objective (RTO)", "ps": "N"},
          {"t": "數據損失接近於零", "en": "near-zero data loss", "ps": "Phrase"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 部署多區域（Multi-region）配置的 Cloud Spanner 作為數據庫層，並結合分佈在多個區域的 GKE 叢集，利用全域外部 HTTP(S) 負載平衡器進行流量分發，確保在單一區域完全失效時能自動切換至其他可用區域。",
        "en": "(A) Deploy a multi-region configuration of Cloud Spanner for the database layer combined with GKE clusters distributed across multiple regions, leveraging a Global External HTTP(S) Load Balancer for traffic distribution to ensure automatic failover to other available regions if a single region fails entirely.",
        "wg": []
      },
      {
        "t": "(B) 在單一區域內使用多可用區（Multi-zonal）部署 GKE 與 Cloud SQL，並定期將數據庫快照備份到不同區域的冷存儲（Coldline Storage）中，當區域故障發生時，透過 Terraform 手動在另一個區域重建整個基礎設施。",
        "en": "(B) Use a multi-zonal deployment of GKE and Cloud SQL within a single region and periodically back up database snapshots to Coldline Storage in a different region. When a regional failure occurs, use Terraform to manually reconstruct the entire infrastructure in another region.",
        "wg": []
      },
      {
        "t": "(C) 實施雙主動（Active-Active）混合雲架構，將數據即時同步回地端資料中心。在 Google Cloud 發生區域性停機時，透過修改 DNS 記錄將全球流量導向地端的遺留系統，直到雲端環境修復為止，以維持業務連續性。",
        "en": "(C) Implement an Active-Active hybrid cloud architecture that synchronizes data in real-time back to on-premises data centers. During a Google Cloud regional outage, redirect global traffic to the on-premises legacy systems by modifying DNS records until the cloud environment is restored to maintain business continuity.",
        "wg": []
      },
      {
        "t": "(D) 使用 Cloud DNS 的加權輪詢策略將請求分發至兩個不同的 Google Cloud 區域，並在每個區域內部署獨立的 MySQL 叢集，利用應用程式層級的異步複製來同步數據，平衡全球客戶的存取延遲與可用性需求。",
        "en": "(D) Use Cloud DNS weighted round-robin policies to distribute requests across two different Google Cloud regions, deploying independent MySQL clusters in each region and using application-level asynchronous replication to synchronize data, balancing access latency and availability for global customers.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "案例要求處理「指數級增長」並實現「低 RTO/RPO」。多區域 Spanner 提供同步複製與 99.999% 的可用性，配合全域負載平衡器能實現幾乎透明的自動切換，最符合 SaaS 全球擴張需求。選項 (B) 的手動重建 RTO 太高；選項 (C) 依賴即將過期的地端設施，違反了「更換託管設施」的決策；選項 (D) 使用異步複製會導致數據不一致，無法滿足低 RPO 的要求。",
      "en": "The scenario requires handling 'exponential growth' and achieving 'low RTO/RPO.' Multi-region Spanner offers synchronous replication and 99.999% availability, which, combined with a Global Load Balancer, enables near-transparent automatic failover—ideal for global SaaS expansion. Option (B)'s manual reconstruction has an RTO that is too high; Option (C) relies on expiring on-premises facilities, contradicting the decision to 'replace colocation facilities'; Option (D)'s asynchronous replication leads to data inconsistency, failing the low RPO requirement.",
      "wg": [
        {"t": "同步複製", "en": "synchronous replication", "ps": "N"},
        {"t": "業務連續性", "en": "business continuity", "ps": "N"}
      ]
    }
  },
  {
    "no": "17",
    "level": "hard",
    "keywords": "Organization Policy, Compliance, Governance, Data Residency",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 希望在將工作負載遷移至 Google Cloud 的同時，「維持法規遵循」並「減少基礎設施管理成本」。公司擔心開發團隊在未經授權的情況下，在不符合 HIPAA 規定的地理區域內啟動資源。為了確保所有新創立的專案都自動遵循公司的數據存放政策（Data Residency），且不需要安全團隊對每個專案進行手動檢查或編寫複雜的自定義監控腳本，您應該在組織層級實施哪種治理機制？",
        "en": "EHR Healthcare aims to 'maintain regulatory compliance' and 'decrease infrastructure administration costs' while migrating workloads to Google Cloud. The company is concerned that development teams might unauthorizedly launch resources in geographic regions that do not comply with HIPAA regulations. To ensure all newly created projects automatically adhere to the company's data residency policies without requiring manual inspection by the security team or writing complex custom monitoring scripts, which governance mechanism should you implement at the organization level?",
        "wg": [
          {"t": "數據存放政策", "en": "data residency policies", "ps": "N"},
          {"t": "地理區域", "en": "geographic regions", "ps": "N"},
          {"t": "治理機制", "en": "governance mechanism", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在資源階層的組織或資料夾層級定義「限制資源使用位置（Resource Location Restriction）」的組織策略 (Organization Policy)，明確指定允許部署資源的 Google Cloud 區域清單，強制所有下層專案遵守。",
        "en": "(A) Define an Organization Policy with the 'Resource Location Restriction' constraint at the Organization or Folder level of the resource hierarchy, explicitly specifying the list of allowed Google Cloud regions for resource deployment and enforcing it across all child projects.",
        "wg": [
          {"t": "組織策略", "en": "Organization Policy", "ps": "N"},
          {"t": "資源階層", "en": "resource hierarchy", "ps": "N"}
        ]
      },
      {
        "t": "(B) 建立一個自定義的 Cloud IAM 角色，僅授予編寫者權限給特定的區域 API，並將此角色分配給所有開發人員，同時在每個專案中手動刪除不符合合規要求的區域之默認網路配置。",
        "en": "(B) Create a custom Cloud IAM role that grants editor permissions only to specific regional APIs, assign this role to all developers, and manually delete default network configurations for non-compliant regions in every project.",
        "wg": []
      },
      {
        "t": "(C) 啟用 Cloud Asset Inventory 的即時通知功能，每當檢測到在禁止區域創建資源時，自動觸發 Cloud Functions 腳本來刪除該資源，並向安全團隊發送電子郵件告警，以達成合規目標。",
        "en": "(C) Enable Cloud Asset Inventory real-time notifications to trigger a Cloud Functions script whenever a resource creation is detected in a forbidden region to delete that resource and send an email alert to the security team to achieve compliance goals.",
        "wg": []
      },
      {
        "t": "(D) 實施 VPC Service Controls 並將所有的專案納入同一個服務周界，透過定義存取層級（Access Levels）來限制只有來自公司總部 IP 範圍的請求才能調用 Compute Engine 的 API。",
        "en": "(D) Implement VPC Service Controls and include all projects within a single service perimeter, defining Access Levels to restrict Compute Engine API calls only to requests originating from the company headquarters' IP range.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "組織策略 (Organization Policy) 是 Google Cloud 提供的一種聲明式治理工具，能直接在根層級限制資源位置，這比 IAM (B) 更具強制性且管理成本更低，也比基於偵測後反應的腳本 (C) 更具預防性。VPC SC (D) 主要防止數據外洩，而非直接限制資源創建的區域。這完全符合「減少行政成本」與「自動化合規」的要求。",
      "en": "Organization Policy is a declarative governance tool provided by Google Cloud that allows direct restriction of resource locations at the root level. This is more enforceable and lower-cost than IAM (B) and more preventative than detection-based scripts (C). VPC SC (D) primarily prevents data exfiltration rather than directly restricting resource creation regions. This perfectly aligns with the requirements for 'decreased administration costs' and 'automated compliance.'",
      "wg": [
        {"t": "聲明式", "en": "declarative", "ps": "Adj"},
        {"t": "預防性", "en": "preventative", "ps": "Adj"}
      ]
    }
  },
  {
    "no": "18",
    "level": "hard",
    "keywords": "BigQuery, Data Insights, Hybrid Data Analysis, Cloud Storage",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的業務驅動因素之一是「提升提供醫療趨勢洞察的能力」。目前數據分散在多個系統中：關聯式數據（MySQL, MS SQL）位於 Google Cloud，而部分 NoSQL 數據（MongoDB）與遺留文件仍在地端託管設施。公司希望分析團隊能對所有這些數據源進行聯合查詢（Federated Queries），以生成行業趨勢報告，同時要盡可能減少數據移動帶來的成本與複雜性。考慮到執行長提到的「不一致的監控與管理」問題，您推薦哪種數據分析架構？",
        "en": "One of EHR Healthcare's business drivers is to 'increase ability to provide insights into healthcare trends.' Currently, data is scattered across multiple systems: relational data (MySQL, MS SQL) in Google Cloud, while some NoSQL data (MongoDB) and legacy files remain in on-premises colocation facilities. The company wants its analytics team to perform federated queries across all these data sources to generate industry trend reports while minimizing costs and complexity associated with data movement. Considering the 'inconsistent monitoring and management' issues mentioned by the CEO, which data analytics architecture do you recommend?",
        "wg": [
          {"t": "聯合查詢", "en": "Federated Queries", "ps": "N"},
          {"t": "數據移動", "en": "data movement", "ps": "N"},
          {"t": "分析團隊", "en": "analytics team", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 BigQuery 作為核心分析平台。透過 Cloud SQL 聯合查詢直接存取雲端關聯式數據，並利用 BigQuery Omni 或將地端數據轉存至 Cloud Storage 後使用外部表格功能進行查詢，實現單一界面下的跨源數據分析。",
        "en": "(A) Use BigQuery as the core analytics platform. Access cloud relational data via Cloud SQL Federated Queries and leverage BigQuery Omni or transfer on-premises data to Cloud Storage to use External Tables, achieving cross-source data analysis within a single interface.",
        "wg": [
          {"t": "核心分析平台", "en": "core analytics platform", "ps": "N"},
          {"t": "外部表格", "en": "External Tables", "ps": "N"}
        ]
      },
      {
        "t": "(B) 在 Google Kubernetes Engine (GKE) 上部署一個大規模的 Presto 叢集，手動建立連接器以對接地端 MongoDB 與雲端 MySQL，並編寫自定義的數據聚合邏輯來處理跨環境的雜湊連接（Hash Joins）。",
        "en": "(B) Deploy a large-scale Presto cluster on Google Kubernetes Engine (GKE), manually build connectors to interface with on-premises MongoDB and cloud MySQL, and write custom data aggregation logic to handle cross-environment hash joins.",
        "wg": []
      },
      {
        "t": "(C) 要求地端維運團隊每晚將所有 MongoDB 數據與遺留文件導出為加密的 CSV 檔案，並透過專線手動上傳至 BigQuery 進行全面載入，以確保分析時擁有最高的查詢性能與數據一致性。",
        "en": "(C) Require the on-premises operations team to export all MongoDB data and legacy files as encrypted CSV files nightly and manually upload them via a dedicated line to BigQuery for a full load, ensuring maximum query performance and data consistency during analysis.",
        "wg": []
      },
      {
        "t": "(D) 利用 Looker 建立數據建模層，直接對接地端資料庫與雲端資料庫。透過 Looker 的內建緩存機制來緩解地端連線延遲問題，並向管理層提供即時的醫療趨勢儀表板，無需進行任何 ETL 過程。",
        "en": "(D) Utilize Looker to create a data modeling layer that connects directly to both on-premises and cloud databases. Use Looker's built-in caching mechanism to mitigate on-premises connection latency and provide real-time healthcare trend dashboards to management without any ETL processes.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "BigQuery 是推薦的 Serverless 分析解決方案，其聯合查詢功能允許分析師在不移動大量數據的情況下整合 Cloud SQL 數據，這符合「減少行政成本」的目標。使用外部表格或 BigQuery Omni 能有效處理混合雲場景。選項 (B) 增加了維運 GKE 叢集與 Presto 的負擔；選項 (C) 涉及過多手動操作且延遲高；選項 (D) 在處理大規模複雜趨勢分析時，直接連接地端遺留系統會嚴重受限於頻寬與系統效能。",
      "en": "BigQuery is the recommended Serverless analytics solution. Its federated query capability allows analysts to integrate Cloud SQL data without massive data movement, aligning with the 'decrease administration costs' goal. Using External Tables or BigQuery Omni effectively handles hybrid cloud scenarios. Option (B) increases the burden of operating GKE clusters and Presto; Option (C) involves excessive manual work and high latency; Option (D) would be severely limited by bandwidth and system performance when performing large-scale complex trend analysis directly against legacy on-premises systems.",
      "wg": [
        {"t": "雜湊連接", "en": "Hash Joins", "ps": "N"},
        {"t": "緩解", "en": "mitigate", "ps": "V"}
      ]
    }
  },
  {
    "no": "19",
    "level": "hard",
    "keywords": "Cloud Router, BGP, High Availability, Hybrid Connectivity",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的技術要求中包含「在地端系統與 Google Cloud 之間提供安全且高效能的連線」。公司已決定使用 Dedicated Interconnect。為了因應「業務指數級增長」並避免過往發生的「系統配置錯誤」導致的路由中斷，架構師需要實施一種能動態學習並發佈路由的機制，以便在地端網路拓撲變更時，雲端環境能自動更新路由表而無需手動干預。為了達成高可用性與自動化維運，您應該如何配置網路連接？",
        "en": "EHR Healthcare's technical requirements include providing a 'secure and high-performance connection between on-premises systems and Google Cloud.' The company has decided to use Dedicated Interconnect. To accommodate 'exponential business growth' and avoid routing outages caused by 'misconfigured systems' as seen in the past, the architect needs to implement a mechanism that dynamically learns and advertises routes. This ensures the cloud environment automatically updates routing tables without manual intervention when on-premises network topologies change. For high availability and automated operations, how should you configure the network connectivity?",
        "wg": [
          {"t": "動態學習", "en": "dynamically learn", "ps": "V"},
          {"t": "路由中斷", "en": "routing outages", "ps": "N"},
          {"t": "手動干預", "en": "manual intervention", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 部署 Cloud Router 並與地端邊緣路由器建立邊界網關協定 (BGP) 會期。配置動態路由模式為「全域（Global）」，以便所有區域的 VPC 都能動態獲取地端路由，並在地端線路故障時自動重新計算路徑。",
        "en": "(A) Deploy Cloud Router and establish Border Gateway Protocol (BGP) sessions with on-premises edge routers. Configure the dynamic routing mode to 'Global' so that VPCs in all regions can dynamically acquire on-premises routes and automatically recalculate paths if an on-premises line fails.",
        "wg": [
          {"t": "邊界網關協定", "en": "Border Gateway Protocol (BGP)", "ps": "N"},
          {"t": "全域動態路由", "en": "Global dynamic routing", "ps": "N"}
        ]
      },
      {
        "t": "(B) 在 Google Cloud 控制台中手動建立靜態路由（Static Routes），並將地端網段指向雲端互連（Cloud Interconnect）的 VLAN 附件，同時編寫一個自定義的 Python 監控程序，每當偵測到連線中斷時自動刪除並重建路由條目。",
        "en": "(B) Manually create static routes in the Google Cloud Console, pointing on-premises subnets to the Cloud Interconnect VLAN attachments, and write a custom Python monitoring program to automatically delete and reconstruct routing entries whenever a connection loss is detected.",
        "wg": []
      },
      {
        "t": "(C) 使用 Cloud DNS 轉發區域（Forwarding Zones）來解析地端服務的域名，並配置雲端負載平衡器的後端服務直接指向地端伺服器的公用 IP 地址，以此繞過複雜的 BGP 路由配置並簡化混合雲網路管理。",
        "en": "(C) Use Cloud DNS Forwarding Zones to resolve on-premises service domain names and configure Cloud Load Balancing backend services to point directly to the public IP addresses of on-premises servers to bypass complex BGP routing and simplify hybrid cloud network management.",
        "wg": []
      },
      {
        "t": "(D) 在每個 Google Cloud 區域部署一個虛擬網路設備（如 Cisco CSR），並與地端設備建立多個點對點的 IPsec VPN 隧道作為 Dedicated Interconnect 的主備援，透過手動調整路由優先級來控制流量權重。",
        "en": "(D) Deploy a virtual network appliance (e.g., Cisco CSR) in each Google Cloud region and establish multiple point-to-point IPsec VPN tunnels with on-premises devices as the primary backup for Dedicated Interconnect, controlling traffic weights by manually adjusting route priorities.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "根據案例，EHR 希望減少「配置錯誤」與「行政成本」。Cloud Router 配合 BGP 是 Google Cloud 上動態路由的標準做法，能自動處理路由更新與失效切換，無需手動干預 (B)。全域動態路由模式允許跨區域存取地端資源，符合跨國業務需求。選項 (C) 無法處理私有網路連線；選項 (D) 增加了大量的第三方設備管理成本與手動配置複雜性。",
      "en": "According to the case study, EHR wants to reduce 'misconfigurations' and 'administration costs.' Cloud Router with BGP is the standard for dynamic routing on Google Cloud, automatically handling route updates and failovers without manual intervention (B). The Global dynamic routing mode allows cross-region access to on-premises resources, meeting multi-national business needs. Option (C) cannot handle private network connectivity; Option (D) adds significant third-party appliance management costs and manual configuration complexity.",
      "wg": [
        {"t": "失效切換", "en": "failover", "ps": "N"},
        {"t": "靜態路由", "en": "static routes", "ps": "N"}
      ]
    }
  },
  {
    "no": "20",
    "level": "hard",
    "keywords": "GKE Release Channels, Maintenance Windows, SRE, Operational Excellence",
    "parentNo": null,
    "images": null,
    "question": [
      {
        "t": "EHR Healthcare 的執行長在聲明中指出，過往許多停機是由於「不一致的監控與維護做法」以及「系統配置錯誤」導致的。公司正致力於在 GKE 上實現維運卓越（Operational Excellence），並希望確保生產環境的叢集始終運行在穩定的 Kubernetes 版本上，同時能自動接收安全修補程式而不干擾 24/7 的醫療服務。為了在「穩定性」與「自動化維護」之間取得平衡，並減少運維人員的手動負擔，您應該如何配置 GKE 叢集？",
        "en": "EHR Healthcare's CEO states that many past outages were due to 'inconsistent monitoring and maintenance practices' and 'misconfigured systems.' The company is striving for Operational Excellence on GKE and wants to ensure production clusters always run on a stable Kubernetes version while automatically receiving security patches without disrupting 24/7 healthcare services. To balance 'stability' and 'automated maintenance' and reduce the manual burden on ops staff, how should you configure the GKE clusters?",
        "wg": [
          {"t": "維運卓越", "en": "Operational Excellence", "ps": "N"},
          {"t": "安全修補程式", "en": "security patches", "ps": "N"},
          {"t": "維護時間窗", "en": "maintenance windows", "ps": "N"}
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將生產環境叢集加入 GKE「穩定（Stable）」發佈通道，並配置「維護時間窗（Maintenance Windows）」與「排除時間（Exclusions）」，以確保自動更新僅在業務低峰期發生，且能避開關鍵的業務交付時段。",
        "en": "(A) Enroll production clusters in the GKE 'Stable' Release Channel and configure 'Maintenance Windows' and 'Exclusions' to ensure automatic updates occur only during off-peak hours and avoid critical business delivery periods.",
        "wg": [
          {"t": "發佈通道", "en": "Release Channel", "ps": "N"},
          {"t": "業務低峰期", "en": "off-peak hours", "ps": "N"}
        ]
      },
      {
        "t": "(B) 禁用 GKE 的所有自動更新功能，由維運團隊每月手動執行一次叢集升級。在升級前，先在測試環境中手動運行所有自動化測試，以防止新版本導致的系統不相容或配置錯誤。",
        "en": "(B) Disable all GKE automatic update features and have the ops team manually perform cluster upgrades once a month. Before upgrading, manually run all automated tests in a test environment to prevent system incompatibilities or misconfigurations caused by new versions.",
        "wg": []
      },
      {
        "t": "(C) 將所有叢集設定為「快速（Rapid）」發佈通道，以便第一時間獲得最新的 Kubernetes 功能與安全修補，並在每個區域部署一組專門的待命（On-call）工程師，隨時應對自動更新可能引發的系統崩潰。",
        "en": "(C) Set all clusters to the 'Rapid' Release Channel to get the latest Kubernetes features and security patches immediately, and deploy a team of on-call engineers in each region to respond to system crashes that may be triggered by automatic updates.",
        "wg": []
      },
      {
        "t": "(D) 採用完全自管的 Kubernetes 叢集部署在 Compute Engine 虛擬機上，並使用自定義的 Ansible 腳本來精確控制每個組件的升級順序，以實現執行長要求的「對環境進行細粒度管理」目標。",
        "en": "(D) Adopt a fully self-managed Kubernetes cluster deployed on Compute Engine VMs and use custom Ansible scripts to precisely control the upgrade sequence of each component to achieve the CEO's goal of 'fine-grained management of environments.'",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "EHR 需要「減少行政成本」並「減少配置錯誤引起的停機」。GKE 發佈通道（特別是 Stable）提供經過驗證的版本，配合維護時間窗能實現自動化維護而不干擾業務運作。選項 (B) 增加了行政負擔並依賴手動；選項 (C) 的快速通道對醫療生產環境來說風險過高；選項 (D) 則是回到了案例中提到的「需要大量投資時間與金錢培訓團隊」的自管系統舊路，違反業務目標。",
      "en": "EHR needs to 'decrease administration costs' and 'reduce outages from misconfigurations.' GKE Release Channels (specifically Stable) provide validated versions, which, combined with maintenance windows, enable automated maintenance without disrupting business operations. Option (B) increases administrative burden and relies on manual work; Option (C)'s Rapid channel is too high-risk for a healthcare production environment; Option (D) reverts to the self-managed systems mentioned in the case study that 'required a major investment of time and money,' contradicting business goals.",
      "wg": [
        {"t": "待命工程師", "en": "on-call engineers", "ps": "N"},
        {"t": "不相容", "en": "incompatibilities", "ps": "N"}
      ]
    }
  }
]