[
  {
    "no": "1",
    "level": "medium",
    "keywords": "Shared Responsibility Model, IaaS, Operating System",
    "question": [
      {
        "t": "在這種雲端運作模式中，客戶需負責維護作業系統。",
        "en": "In which cloud operating model is a customer responsible for maintaining the Operating System?",
        "wg": [
          { "t": "雲端運作模式", "en": "cloud operating model", "ps": "n" },
          { "t": "負責", "en": "responsible for", "ps": "adj" },
          { "t": "維護", "en": "maintaining", "ps": "v" },
          { "t": "作業系統", "en": "Operating System", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) SaaS (軟體即服務)",
        "en": "(A) SaaS",
        "wg": []
      },
      {
        "t": "(B) CaaS (容器即服務)",
        "en": "(B) CaaS",
        "wg": []
      },
      {
        "t": "(C) PaaS (平台即服務)",
        "en": "(C) PaaS",
        "wg": []
      },
      {
        "t": "(D) IaaS (基礎設施即服務)",
        "en": "(D) IaaS",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "在 IaaS (如 Compute Engine) 模式下，雲端供應商僅提供硬體虛擬化，客戶擁有虛擬機的完全控制權，包括作業系統的修補與更新。相較之下，PaaS (如 App Engine) 與 SaaS (如 Google Workspace) 的作業系統皆由供應商管理。CaaS 雖涉及容器，但在某些託管模式下 (如 GKE Autopilot)，底層 OS 管理責任也可能被抽象化。",
      "en": "In the IaaS (Infrastructure as a Service) model, such as Compute Engine, the provider offers hardware virtualization, but the customer retains full control over the virtual machine, including OS patching and updates. In contrast, for PaaS (like App Engine) and SaaS (like Google Workspace), the OS is managed by the provider. While CaaS involves containers, the underlying OS responsibility can sometimes be abstracted away depending on the managed service level (e.g., GKE Autopilot).",
      "wg": [
        { "t": "硬體虛擬化", "en": "hardware virtualization", "ps": "n" },
        { "t": "完全控制權", "en": "full control", "ps": "n" },
        { "t": "修補", "en": "patching", "ps": "v" }
      ]
    }
  },
  {
    "no": "2",
    "level": "hard",
    "keywords": "Risk Management, Vendor Lock-out, Cloud Strategy",
    "question": [
      {
        "t": "雲端供應商可能倒閉，導致客戶無法復原資料的風險被稱為什麼？",
        "en": "The risk that a cloud provider might go out of business and the customers might not be able to recover data is known as:",
        "wg": [
          { "t": "倒閉", "en": "go out of business", "ps": "v" },
          { "t": "復原資料", "en": "recover data", "ps": "v" },
          { "t": "風險", "en": "risk", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 供應商倒閉 (Vendor closure)",
        "en": "(A) Vendor closure",
        "wg": []
      },
      {
        "t": "(B) 供應商鎖定 (Vendor lock-in)",
        "en": "(B) Vendor lock-in",
        "wg": []
      },
      {
        "t": "(C) 供應商封鎖 (Vendor lock-out)",
        "en": "(C) Vendor lock-out",
        "wg": []
      },
      {
        "t": "(D) 自動販賣機 (Vending machine)",
        "en": "(D) Vending machine",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "此題的正確術語為 'Vendor lock-out'。這指的是由於供應商破產、服務終止或災難性故障，導致客戶無法存取其數據或服務的情況。'Vendor lock-in' (供應商鎖定) 是指轉換供應商的成本過高或技術困難，而非供應商倒閉。'Vendor closure' 僅描述事件本身，而非風險類型的專有名詞。",
      "en": "The correct term here is 'Vendor lock-out'. This refers to a situation where a customer loses access to their data or services because the provider goes bankrupt, terminates service, or suffers a catastrophic failure. 'Vendor lock-in' refers to the difficulty or high cost of switching providers due to proprietary technology, not the provider going out of business. 'Vendor closure' describes the event but is not the standard terminology for the risk scenario.",
      "wg": [
        { "t": "破產", "en": "bankrupt", "ps": "adj" },
        { "t": "服務終止", "en": "terminates service", "ps": "v" },
        { "t": "專有技術", "en": "proprietary technology", "ps": "n" }
      ]
    }
  },
  {
    "no": "3",
    "level": "medium",
    "keywords": "Dedicated Interconnect, Hybrid Connectivity, Colocation",
    "question": [
      {
        "t": "使用 Dedicated Interconnect (專用互連) 時，您可以在哪裡透過實體網路連接到 GCP？",
        "en": "Where can you connect to GCP with your physical network using Dedicated Interconnect?",
        "wg": [
          { "t": "實體網路", "en": "physical network", "ps": "n" },
          { "t": "連接", "en": "connect", "ps": "v" },
          { "t": "專用互連", "en": "Dedicated Interconnect", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 選定的 GCP 地區 (Region)",
        "en": "(A) Chosen GCP Region",
        "wg": []
      },
      {
        "t": "(B) 選定地區內的 GCP 區域 (Zone)",
        "en": "(B) Chosen GCP Zone within a Region",
        "wg": []
      },
      {
        "t": "(C) 主機代管設施 (Colocation Facilities)",
        "en": "(C) Colocation Facilities",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Dedicated Interconnect 需要在 Google 的網路邊緣位置 (PoP) 進行實體佈線連接。這些連接點位於特定的主機代管設施 (Colocation Facilities)，而非直接位於 Google 的資料中心內部 (即 Zone 或 Region)。客戶的路由器需位於這些代管設施中，才能透過光纖交叉連接到 Google 的邊緣路由器。",
      "en": "Dedicated Interconnect requires a physical cabling connection at Google's network edge (PoP). These connection points are located in specific Colocation Facilities, not directly inside Google's data centers (which correspond to Zones or Regions). The customer's router must be in these facilities to cross-connect via fiber to Google's edge routers.",
      "wg": [
        { "t": "網路邊緣位置", "en": "network edge", "ps": "n" },
        { "t": "實體佈線", "en": "physical cabling", "ps": "n" },
        { "t": "交叉連接", "en": "cross-connect", "ps": "v" }
      ]
    }
  },
  {
    "no": "4",
    "level": "easy",
    "keywords": "Resource Hierarchy, Project, Core Concepts",
    "question": [
      {
        "t": "所有 GCP 資源都與什麼相關聯？",
        "en": "All GCP resources are associated with *",
        "wg": [
          { "t": "資源", "en": "resources", "ps": "n" },
          { "t": "相關聯", "en": "associated with", "ps": "adj" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 帳單帳戶 (a billing account)",
        "en": "(A) a billing account",
        "wg": []
      },
      {
        "t": "(B) 專案 (a project)",
        "en": "(B) a project",
        "wg": []
      },
      {
        "t": "(C) 服務帳戶 (a service account)",
        "en": "(C) a service account",
        "wg": []
      },
      {
        "t": "(D) 使用者 (a user)",
        "en": "(D) a user",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "在 Google Cloud 的資源階層中，'專案' (Project) 是建立與使用所有資源 (如 VM、儲存空間) 的基本容器。雖然專案必須連結到帳單帳戶才能運作，但資源本身是直接隸屬於專案的。服務帳戶和使用者是用於存取控制的身分，而非資源的容器。",
      "en": "In the Google Cloud resource hierarchy, a 'Project' is the fundamental container where all resources (like VMs, storage) are created and live. Although a project must be linked to a billing account to function, the resources themselves are directly parented by the project. Service accounts and users are identities for access control, not containers for resources.",
      "wg": [
        { "t": "資源階層", "en": "resource hierarchy", "ps": "n" },
        { "t": "基本容器", "en": "fundamental container", "ps": "n" },
        { "t": "隸屬於", "en": "parented by", "ps": "v" }
      ]
    }
  },
  {
    "no": "5",
    "level": "medium",
    "keywords": "Billing, Networking, Egress Cost, Zones",
    "question": [
      {
        "t": "在單一區域 (Zone) 部署解決方案與分散在多個區域或地區 (Region) 部署相比，GCP 每月帳單成本的顯著差異為何？",
        "en": "What's the notable difference in monthly billing costs of GCP usage between deploying solution in a single zone vs spreading them throughout zones or regions?",
        "wg": [
          { "t": "部署", "en": "deploying", "ps": "v" },
          { "t": "顯著差異", "en": "notable difference", "ps": "n" },
          { "t": "分散", "en": "spreading", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 沒有大差異，因為我們只需為使用的資源付費。",
        "en": "(A) There is no big difference, since we're just paying for the resources we use.",
        "wg": []
      },
      {
        "t": "(B) 存在所謂的輸出流量 (Egress) 成本差異，當數據在不同位置交換時，這筆費用可能高得多。",
        "en": "(B) There is a difference is so-called egress costs, which might be much higher when data is exchanged between different locations.",
        "wg": [
          { "t": "輸出流量成本", "en": "egress costs", "ps": "n" },
          { "t": "交換", "en": "exchanged", "ps": "v" }
        ]
      },
      {
        "t": "(C) 多區域和多地區解決方案應該更便宜，因為流量平均分配。",
        "en": "(C) Multi-zone and multi-region solutions should be cheaper, since the traffic is equally distributed between the locations.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "雖然為了高可用性 (HA) 建議跨區域部署，但這會產生網路成本。在同一區域 (Zone) 內的內部流量通常是免費的，但跨區域 (Cross-zone) 或跨地區 (Cross-region) 的流量交換會產生每 GB 的 'Egress' (輸出) 費用。因此，分散式架構會增加網路傳輸成本。",
      "en": "While deploying across zones is recommended for High Availability (HA), it incurs networking costs. Internal traffic within a single Zone is typically free, but data exchange across different Zones (Cross-zone) or Regions (Cross-region) incurs 'Egress' charges per GB. Therefore, a distributed architecture increases network transfer costs.",
      "wg": [
        { "t": "高可用性", "en": "High Availability", "ps": "n" },
        { "t": "跨區域", "en": "Cross-zone", "ps": "adj" },
        { "t": "網路傳輸成本", "en": "network transfer costs", "ps": "n" }
      ]
    }
  },{
    "no": "6",
    "level": "hard",
    "keywords": "Global Resources, VPC, Load Balancing",
    "question": [
      {
        "t": "哪些是 GCP 全球性資源的例子？(選擇兩項)",
        "en": "What are examples of global GCP resources? (choose two)",
        "wg": [
          { "t": "全球性資源", "en": "global resources", "ps": "n" },
          { "t": "例子", "en": "examples", "ps": "n" }
        ]
      }
    ],
    "type": "多選題",
    "options": [
      {
        "t": "(A) 全球永久磁碟 (Global Persistent Disks)",
        "en": "(A) Global Persistent Disks",
        "wg": []
      },
      {
        "t": "(B) 子網段 (Subnets)",
        "en": "(B) Subnets",
        "wg": []
      },
      {
        "t": "(C) 部分負載平衡器 (some Load Balancers)",
        "en": "(C) some Load Balancers",
        "wg": []
      },
      {
        "t": "(D) Cloud SQL",
        "en": "(D) Cloud SQL",
        "wg": []
      },
      {
        "t": "(E) 全球 GCS 儲存桶 (Global GCS Buckets)",
        "en": "(E) Global GCS Buckets",
        "wg": []
      },
      {
        "t": "(F) VPC 網路 (VPCs)",
        "en": "(F) VPCs",
        "wg": []
      },
      {
        "t": "(G) Anthos GKE 叢集",
        "en": "(G) Anthos GKE Clusters",
        "wg": []
      }
    ],
    "answer": "(C), (F)",
    "why": {
      "t": "在 Google Cloud 中，VPC 網路是全球性的資源，這意味著一個 VPC 可以橫跨所有可用的 GCP 地區。同樣地，特定的負載平衡器 (如 HTTP(S), SSL Proxy, TCP Proxy) 也是全球性資源，擁有單一的 Anycast IP。相對地，子網段 (Subnets) 是地區性 (Regional) 的，而虛擬機實例和永久磁碟通常是區域性 (Zonal) 的。",
      "en": "In Google Cloud, VPC networks are global resources, meaning a single VPC can span all available GCP regions. Similarly, specific Load Balancers (like HTTP(S), SSL Proxy, TCP Proxy) are global resources with a single Anycast IP. In contrast, Subnets are Regional, while VM instances and persistent disks are typically Zonal.",
      "wg": [
        { "t": "橫跨", "en": "span", "ps": "v" },
        { "t": "單一 Anycast IP", "en": "single Anycast IP", "ps": "n" },
        { "t": "區域性", "en": "Zonal", "ps": "adj" }
      ]
    }
  },
  {
    "no": "7",
    "level": "medium",
    "keywords": "Regional Resources, Managed Instance Groups, Persistent Disks",
    "question": [
      {
        "t": "哪些是 GCP 地區性 (Regional) 資源的例子？(選擇兩項)",
        "en": "What are examples of regional GCP resources? (choose two)",
        "wg": [
          { "t": "地區性資源", "en": "regional resources", "ps": "n" },
          { "t": "例子", "en": "examples", "ps": "n" }
        ]
      }
    ],
    "type": "多選題",
    "options": [
      {
        "t": "(A) GCE 實例 (GCE Instances)",
        "en": "(A) GCE Instances",
        "wg": []
      },
      {
        "t": "(B) IP 位址 (IP Addresses)",
        "en": "(B) IP Addresses",
        "wg": []
      },
      {
        "t": "(C) 所有永久磁碟 (All Persistent Disks)",
        "en": "(C) All Persistent Disks",
        "wg": []
      },
      {
        "t": "(D) 地區性永久磁碟 (Regional Persistent Disks)",
        "en": "(D) Regional Persistent Disks",
        "wg": []
      },
      {
        "t": "(E) 地區性託管實例群組 (Regional MIGs)",
        "en": "(E) Regional MIGs",
        "wg": []
      },
      {
        "t": "(F) 區域性 GKE 叢集 (Zonal GKE clusters)",
        "en": "(F) Zonal GKE clusters",
        "wg": []
      }
    ],
    "answer": "(D), (E)",
    "why": {
      "t": "標準的 GCE 實例和標準永久磁碟是區域性 (Zonal) 資源，它們位於特定區域內。然而，'地區性永久磁碟' 會在同一地區的兩個區域間複製數據，屬於地區性資源。'地區性 MIGs' (託管實例群組) 則將實例分佈在同一地區的多個區域中，因此也是地區性資源。",
      "en": "Standard GCE instances and standard persistent disks are Zonal resources, living within a specific zone. However, 'Regional Persistent Disks' replicate data across two zones in the same region, making them Regional resources. 'Regional MIGs' (Managed Instance Groups) distribute instances across multiple zones within a single region, also making them Regional.",
      "wg": [
        { "t": "複製數據", "en": "replicate data", "ps": "v" },
        { "t": "分佈", "en": "distribute", "ps": "v" },
        { "t": "託管實例群組", "en": "Managed Instance Groups", "ps": "n" }
      ]
    }
  },
  {
    "no": "8",
    "level": "easy",
    "keywords": "VPC, Subnet, Scope",
    "question": [
      {
        "t": "虛擬私有雲 (VPC) 的子網段 (Subnet) 是屬於什麼範圍？",
        "en": "A Virtual Private Cloud subnet is *",
        "wg": [
          { "t": "子網段", "en": "subnet", "ps": "n" },
          { "t": "範圍", "en": "scope", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 區域性 (zonal)",
        "en": "(A) zonal",
        "wg": []
      },
      {
        "t": "(B) 多地區性 (multi-regional)",
        "en": "(B) multi-regional",
        "wg": []
      },
      {
        "t": "(C) 全球性 (global)",
        "en": "(C) global",
        "wg": []
      },
      {
        "t": "(D) 地區性 (regional)",
        "en": "(D) regional",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "雖然 VPC 網路本身是全球性的，但子網段 (Subnets) 是定義在特定地區 (Region) 內的。一個子網段可以跨越該地區內的所有區域 (Zones)，但不能跨越地區。",
      "en": "While the VPC network itself is global, Subnets are defined within a specific Region. A single subnet spans all the Zones within that Region, but cannot span across multiple Regions.",
      "wg": [
        { "t": "定義在", "en": "defined within", "ps": "v" },
        { "t": "跨越", "en": "span", "ps": "v" },
        { "t": "特定地區", "en": "specific Region", "ps": "n" }
      ]
    }
  },
  {
    "no": "9",
    "level": "easy",
    "keywords": "VM, IP Address, Internal IP",
    "question": [
      {
        "t": "在 Google Cloud 中，一台虛擬機 (VM) 最少可以擁有多少個 IP？",
        "en": "In Google Cloud, what is the minimum number of IPs that a VM can have?",
        "wg": [
          { "t": "最少", "en": "minimum", "ps": "adj" },
          { "t": "IP 位址", "en": "IPs", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 一個：僅一個內部 IP 位址",
        "en": "(A) One: Only an internal IP address",
        "wg": []
      },
      {
        "t": "(B) 兩個：一個內部和一個外部 IP 位址",
        "en": "(B) Two: One internal and one external IP address",
        "wg": []
      },
      {
        "t": "(C) 三個：一個內部、一個外部和一個別名 IP 位址",
        "en": "(C) Three: One internal, one external and one alias IP address",
        "wg": []
      },
      {
        "t": "(D) 不需要 IP 位址",
        "en": "(D) No IP address is required",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "每台 GCE 虛擬機必須至少分配一個內部 IP 位址，以便在 VPC 網路內進行通訊。外部 IP 是可選的，如果不需從網際網路直接存取，可以不配置外部 IP。",
      "en": "Every GCE virtual machine must be assigned at least one internal IP address to communicate within the VPC network. An external IP address is optional; if direct internet access is not required, the VM can be provisioned without one.",
      "wg": [
        { "t": "分配", "en": "assigned", "ps": "v" },
        { "t": "可選的", "en": "optional", "ps": "adj" },
        { "t": "配置", "en": "provisioned", "ps": "v" }
      ]
    }
  },
  {
    "no": "10",
    "level": "hard",
    "keywords": "GCE, Network Interface, NIC, Multiple VPCs",
    "question": [
      {
        "t": "一個 GCE 實例擁有多少個網路介面 (network interfaces)？",
        "en": "How many network interfaces does a GCE instance have?",
        "wg": [
          { "t": "網路介面", "en": "network interfaces", "ps": "n" },
          { "t": "實例", "en": "instance", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 只有一個",
        "en": "(A) Only one.",
        "wg": []
      },
      {
        "t": "(B) 如果只有內部 IP 則為一個，若有內部和外部 IP 則為兩個",
        "en": "(B) One if it has an Internal IP only, two if it has Internal and External IP",
        "wg": []
      },
      {
        "t": "(C) 取決於 NIC_NUMBER metadata 的值",
        "en": "(C) It depends on NIC_NUMBER metadata value.",
        "wg": []
      },
      {
        "t": "(D) 一個，除非它部署在多個 VPC 中",
        "en": "(D) One, unless it's deployed in multiple VPCs.",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "預設情況下，每個 GCE 實例有一個網路介面 (nic0)。如果您需要將實例連接到多個 VPC 網路 (例如用於網路隔離或管理流量分離)，您可以配置多個網路介面 (最多 8 個，取決於機器類型)。每個網路介面必須連接到不同的 VPC。",
      "en": "By default, every GCE instance has one network interface (nic0). If you need to connect the instance to multiple VPC networks (e.g., for network isolation or separation of management traffic), you can configure multiple network interfaces (up to 8, depending on the machine type). Each network interface must be attached to a different VPC.",
      "wg": [
        { "t": "預設情況下", "en": "By default", "ps": "adv" },
        { "t": "網路隔離", "en": "network isolation", "ps": "n" },
        { "t": "連接", "en": "attached to", "ps": "v" }
      ]
    }
  },{
    "no": "11",
    "level": "medium",
    "keywords": "IAM, Service Account, Authentication",
    "question": [
      {
        "t": "服務帳戶主要用於提供什麼功能？",
        "en": "Service accounts are used to provide *",
        "wg": [
          { "t": "服務帳戶", "en": "Service accounts", "ps": "n" },
          { "t": "提供", "en": "provide", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 服務之間的驗證",
        "en": "(A) authentication between services",
        "wg": []
      },
      {
        "t": "(B) 服務之間的流量路由",
        "en": "(B) traffic routing between services",
        "wg": []
      },
      {
        "t": "(C) VM 的管理存取權限",
        "en": "(C) administrative access to VMs",
        "wg": []
      },
      {
        "t": "(D) 部署的自動化",
        "en": "(D) automation for deployments",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "服務帳戶是一種特殊的 Google 帳戶，屬於應用程式或虛擬機 (VM)，而非單個終端使用者。其主要用途是讓應用程式在呼叫 Google Cloud API 時進行身份驗證 (Authentication) 和授權，而無需人為介入。",
      "en": "A service account is a special type of Google account intended to represent a non-human user, such as an application or a virtual machine (VM). Its primary use case is to handle authentication and authorization between services when they call Google Cloud APIs, without human intervention.",
      "wg": [
        { "t": "應用程式", "en": "application", "ps": "n" },
        { "t": "身份驗證", "en": "authentication", "ps": "n" },
        { "t": "無需人為介入", "en": "without human intervention", "ps": "adv" }
      ]
    }
  },
  {
    "no": "12",
    "level": "hard",
    "keywords": "Networking, SSH, IAP, Bastion Host, VPN",
    "question": [
      {
        "t": "有哪些選項可以用來連接沒有外部 IP 的 Linux GCE 實例？(選擇三項)",
        "en": "What are the options to connect to Linux-based GCE instances that have no external IP? (choose three)",
        "wg": [
          { "t": "連接", "en": "connect", "ps": "v" },
          { "t": "沒有外部 IP", "en": "no external IP", "ps": "adj" }
        ]
      }
    ],
    "type": "多選題",
    "options": [
      {
        "t": "(A) 從您的 Organization 節點連接，因為它擁有對所有其他資源的權限。",
        "en": "(A) Connect from your Organization node since it has privileges to all the other resources.",
        "wg": []
      },
      {
        "t": "(B) 使用 IAP (Identity-Aware Proxy)。",
        "en": "(B) Use IAP (Identity-Aware Proxy).",
        "wg": []
      },
      {
        "t": "(C) 透過跳板機 (Bastion Host) 登入。",
        "en": "(C) Login via a bastion host.",
        "wg": []
      },
      {
        "t": "(D) 直接從 Cloud Shell 使用 'ssh' 命令連接，因為它可以看到所有專案實例。",
        "en": "(D) Directly connect with 'ssh' command from Cloud Shell, since it has the visibility into all project instances.",
        "wg": []
      },
      {
        "t": "(E) 使用具有 GCP 資源本地可見性的 Cloud VPN。",
        "en": "(E) Use Cloud VPN with local visibility of GCP-based resources.",
        "wg": []
      }
    ],
    "answer": "(B), (C), (E)",
    "why": {
      "t": "沒有外部 IP 的 VM 無法直接從網際網路存取。解決方案包括：1. IAP：透過 HTTPS 通道轉發 SSH 流量，無需外部 IP。2. Bastion Host：透過一台有外部 IP 的跳板機轉發流量。3. Cloud VPN/Interconnect：將 GCP 網路延伸至本地網路，允許透過私有 IP 存取。Cloud Shell 雖然位於 Google 網路內，但無法直接路由到沒有外部 IP 的 VM (除非透過 IAP)。",
      "en": "VMs without external IPs cannot be accessed directly from the internet. Solutions include: 1. IAP: Tunnels SSH traffic via HTTPS, requiring no external IP on the VM. 2. Bastion Host: Jumps through an intermediary VM that has an external IP. 3. Cloud VPN/Interconnect: Extends the on-prem network to GCP, allowing access via private IPs. Cloud Shell cannot directly route to private IPs without IAP.",
      "wg": [
        { "t": "轉發", "en": "forward", "ps": "v" },
        { "t": "跳板機", "en": "Bastion Host", "ps": "n" },
        { "t": "私有 IP", "en": "private IPs", "ps": "n" }
      ]
    }
  },
  {
    "no": "13",
    "level": "medium",
    "keywords": "Cost Optimization, Sustained Use Discount, VM Pricing",
    "question": [
      {
        "t": "哪項功能每個月最多可節省約 30% 的 VM 成本？",
        "en": "Which feature can save up to ~30% of a VM's cost over a month?",
        "wg": [
          { "t": "節省", "en": "save", "ps": "v" },
          { "t": "成本", "en": "cost", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 先佔式折扣 (Pre-emptible discount)",
        "en": "(A) Pre-emptible discount",
        "wg": []
      },
      {
        "t": "(B) 持續使用折扣 (Sustained use discount)",
        "en": "(B) Sustained use discount",
        "wg": []
      },
      {
        "t": "(C) 承諾使用折扣 (Committed use discount)",
        "en": "(C) Committed use discount",
        "wg": []
      },
      {
        "t": "(D) 自訂機器類型 (Custom machine types)",
        "en": "(D) Custom machine types",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "持續使用折扣 (SUD) 是針對特定機器類型 (如 N1) 的自動折扣機制，當 VM 在一個月內運行的時間越長，折扣越多，最高可達約 30%。先佔式 (Preemptible) 折扣通常高達 60-80%，而承諾使用折扣 (CUD) 需要簽訂合約。",
      "en": "Sustained Use Discounts (SUD) are automatic discounts for specific machine types (like N1) that apply as you run a VM for a larger portion of the billing month. The maximum savings typically reach around 30%. Preemptible discounts are much higher (60-80%), and Committed Use Discounts (CUD) require a contract.",
      "wg": [
        { "t": "自動折扣機制", "en": "automatic discount mechanism", "ps": "n" },
        { "t": "運行時間", "en": "running time", "ps": "n" },
        { "t": "合約", "en": "contract", "ps": "n" }
      ]
    }
  },
  {
    "no": "14",
    "level": "medium",
    "keywords": "Cost Optimization, Preemptible VM, Spot VM",
    "question": [
      {
        "t": "哪項功能最多可節省約 80% 的 VM 成本？",
        "en": "Which feature can save up to ~80% of a VM's cost?",
        "wg": [
          { "t": "功能", "en": "feature", "ps": "n" },
          { "t": "節省", "en": "save", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 承諾使用折扣 (Committed use discount)",
        "en": "(A) Committed use discount",
        "wg": []
      },
      {
        "t": "(B) 自訂機器類型 (Custom machine types)",
        "en": "(B) Custom machine types",
        "wg": []
      },
      {
        "t": "(C) 先佔式折扣 (Pre-emptible discount)",
        "en": "(C) Pre-emptible discount",
        "wg": []
      },
      {
        "t": "(D) 持續使用折扣 (Sustained use discount)",
        "en": "(D) Sustained use discount",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "先佔式實例 (Preemptible Instances) 或現貨實例 (Spot VMs) 提供最高的折扣 (相較於標準定價可省下 60-91%)，代價是 Google 可以在需要產能時隨時終止這些實例。這適合容錯率高或批次處理的工作負載。",
      "en": "Preemptible Instances (or Spot VMs) offer the highest discounts (saving 60-91% off standard pricing) in exchange for the risk that Google can terminate the instances at any time when capacity is needed. This is suitable for fault-tolerant or batch processing workloads.",
      "wg": [
        { "t": "最高折扣", "en": "highest discounts", "ps": "n" },
        { "t": "終止", "en": "terminate", "ps": "v" },
        { "t": "容錯率高", "en": "fault-tolerant", "ps": "adj" }
      ]
    }
  },
  {
    "no": "15",
    "level": "hard",
    "keywords": "Cost Optimization, Committed Use Discount, Flexibility",
    "question": [
      {
        "t": "您想透過購買 3 年承諾來優化基礎設施成本，但不確定需求是否會變動，且可能被迫更改 GCE 實例的數量和大小。您應該怎麼做？",
        "en": "You would like to optimize the infrastructure costs by buying 3-year commitment for a specific requirement. However, you're not sure if your requirements do not change during this time and you might be forced to change the number and size of the GCE instances. What should you do?",
        "wg": [
          { "t": "優化", "en": "optimize", "ps": "v" },
          { "t": "承諾", "en": "commitment", "ps": "n" },
          { "t": "變動", "en": "change", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 購買 1 年承諾以節省部分成本，並接受停止/調整特定 VM 後不再享有優惠的事實。",
        "en": "(A) Buy a 1-year commitment to save some costs and accept the fact that when you stop / resize specific VM, you no longer benefit from the commitment.",
        "wg": []
      },
      {
        "t": "(B) 購買 3 年承諾，並勾選「允許提前退出」選項 (此為虛構選項)。",
        "en": "(B) Buy a 3-year commitment, checking option 'early opt-out possible' that allows you to cancel the commitment earlier with a small penalty.",
        "wg": []
      },
      {
        "t": "(C) 購買 3 年承諾，並隨著需求變更將其用於不同數量和大小的 VM 實例。",
        "en": "(C) Buy a 3-year commitment and use it for different number and sizes of VM instances as your requirements change during this period.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Google Cloud 的「承諾使用折扣」(Committed Use Discounts, CUDs) 特別是基於資源的 CUD (Resource-based CUDs)，是購買特定區域內一定數量的 vCPU 和記憶體，而非特定的 VM 實例。因此，只要總使用量符合承諾的 vCPU/記憶體數量，您可以自由更改 VM 的大小或數量。",
      "en": "Google Cloud's Committed Use Discounts (CUDs), specifically Resource-based CUDs, involve purchasing a specific amount of vCPU and memory in a region, rather than specific VM instances. Therefore, you are free to change the size or number of VMs as long as the aggregate usage matches the committed vCPU/memory amount.",
      "wg": [
        { "t": "基於資源", "en": "Resource-based", "ps": "adj" },
        { "t": "自由更改", "en": "free to change", "ps": "v" },
        { "t": "總使用量", "en": "aggregate usage", "ps": "n" }
      ]
    }
  },{
    "no": "16",
    "level": "medium",
    "keywords": "GPU, Quota, Region, Availability",
    "question": [
      {
        "t": "您想在本地地區 (Region) 部署一個附加 GPU 的 GCE 實例，但 Cloud Console 顯示此選項無法使用。您該如何部署這樣的 VM？",
        "en": "You would like to deploy a GCE instance with a GPU attached in your local region, but Cloud Console says this option is not available. How do you deploy such a VM?",
        "wg": [
          { "t": "附加 GPU", "en": "GPU attached", "ps": "adj" },
          { "t": "無法使用", "en": "not available", "ps": "adj" },
          { "t": "部署", "en": "deploy", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 您需要使用命令列工具，執行 'gcloud compute instances create'。",
        "en": "(A) You need to to it from command line, using 'gcloud compute instances create'",
        "wg": []
      },
      {
        "t": "(B) 您需要聯繫 GCP 支援以在專案中啟用 GPU，因為它們通常是隱藏的。",
        "en": "(B) You need to contact GCP support to enable GPUs in your projects, since they're normally hidden.",
        "wg": []
      },
      {
        "t": "(C) 您需要選擇另一個區域 (Zone) 或地區 (Region)，因為 GPU 並非在每個位置都可用。",
        "en": "(C) You need to choose another zone or region, since GPUs are not available in every location.",
        "wg": []
      },
      {
        "t": "(D) 您需要先購買承諾 (Commitment) 才能部署 GPU。",
        "en": "(D) You need to purchase a commitment first to deploy GPUs.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "GPU 加速器並非在每個 Google Cloud 地區或區域都可用。如果 Console 顯示不可用，通常意味著該特定區域不支援您選擇的 GPU 類型，或者該區域的資源已暫時耗盡。解決方案是檢查 GPU 區域可用性表，並嘗試在支援該硬體的不同區域或地區進行部署。",
      "en": "GPU accelerators are not available in every Google Cloud region or zone. If the Console indicates unavailability, it typically means the specific zone does not support the GPU type you selected. The solution is to check the GPU regional availability documentation and try deploying in a different zone or region where the hardware is supported.",
      "wg": [
        { "t": "加速器", "en": "accelerators", "ps": "n" },
        { "t": "區域可用性", "en": "regional availability", "ps": "n" },
        { "t": "支援", "en": "support", "ps": "v" }
      ]
    }
  },
  {
    "no": "17",
    "level": "medium",
    "keywords": "Cost Optimization, Storage, Snapshot, Lifecycle",
    "question": [
      {
        "t": "一位客戶擁有一些在可預見的未來不需要的非生產性 GCE 實例。為了停止實例和附加磁碟的計費，同時不遺失永久磁碟 (PDs) 上的數據，您會採取什麼行動？",
        "en": "A customer has some non-productive GCE instances that will not be needed for foreseeable future. What actions would you make in order to stop billing for instances and attached disks, without loosing data kept on PDs?",
        "wg": [
          { "t": "非生產性", "en": "non-productive", "ps": "adj" },
          { "t": "停止計費", "en": "stop billing", "ps": "v" },
          { "t": "永久磁碟", "en": "PDs", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 暫時停止 VM，直到再次需要它們。",
        "en": "(A) Stop the VMs for the time being, until they are needed again.",
        "wg": []
      },
      {
        "t": "(B) 刪除 VM 和 PD，並在需要時重新建立。",
        "en": "(B) Drop VMs with PDs and rebuild them when needed.",
        "wg": []
      },
      {
        "t": "(C) 停止 VM，為附加的 PD 製作快照，然後刪除 VM 和 PD。",
        "en": "(C) Stop VMs, Make snapshots from PDs attached and delete both VMs and PDs.",
        "wg": []
      },
      {
        "t": "(D) 使用 'gcloud compute freeze <gce_name> including disks' 命令。",
        "en": "(D) Use 'gcloud compute freeze <gce_name> including disks' command.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "僅停止 VM (選項 A) 只會停止運算費用的計費，但附加的永久磁碟 (Persistent Disk) 仍會繼續產生儲存費用。為了完全停止計費並保留數據，最具成本效益的方法是建立磁碟快照 (Snapshot) — 其儲存成本通常低於標準永久磁碟 — 然後刪除原始磁碟和實例。",
      "en": "Simply stopping the VM (Option A) halts compute billing but the attached Persistent Disks continue to incur storage charges. To stop all billing while preserving data, the most cost-effective method is to create a Snapshot of the disks—which typically has lower storage costs than standard PDs—and then delete both the original disks and the instances.",
      "wg": [
        { "t": "運算費用", "en": "compute billing", "ps": "n" },
        { "t": "最具成本效益", "en": "most cost-effective", "ps": "adj" },
        { "t": "保留數據", "en": "preserving data", "ps": "v" }
      ]
    }
  },
  {
    "no": "18",
    "level": "easy",
    "keywords": "Automation, Instance Schedule, Operations",
    "question": [
      {
        "t": "自動化 GCE 實例啟動和關閉排程的最簡單方法是什麼？",
        "en": "What's the easiest way to automate GCE instance startup and shutdown schedule?",
        "wg": [
          { "t": "自動化", "en": "automate", "ps": "v" },
          { "t": "啟動和關閉排程", "en": "startup and shutdown schedule", "ps": "n" },
          { "t": "最簡單方法", "en": "easiest way", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在每個實例的 crontab 中排程這些活動。",
        "en": "(A) Schedule those activities in crontab of each instance.",
        "wg": []
      },
      {
        "t": "(B) 使用 Cloud Workflows 觸發所選 VM 的啟動和關閉腳本。",
        "en": "(B) Use Cloud Workflows to trigger startup and shutdown scripts on selected VMs.",
        "wg": []
      },
      {
        "t": "(C) 建立實例排程 (Instance Schedule) 並將專案中的所選實例加入。",
        "en": "(C) Create Instance Schedule and add selected instances from the project.",
        "wg": []
      },
      {
        "t": "(D) 實作第三方任務排程系統以觸發 GCE 實例的 REST API。",
        "en": "(D) Implement a 3rd party task scheduling system to trigger REST API to GCE instance.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Google Compute Engine 提供了一項名為 '實例排程' (Instance Schedules) 的原生功能，允許使用者定義自動啟動和停止 VM 的策略，並將其附加到實例上。這是管理預定運作時間 (例如僅在辦公時間運行) 的最簡單且完全託管的方法，無需編寫腳本或維護額外的排程器。",
      "en": "Google Compute Engine offers a native feature called 'Instance Schedules' which allows users to define policies for automatically starting and stopping VMs and attach them to instances. This is the easiest, fully managed method for handling scheduled uptime (e.g., running only during office hours) without writing scripts or maintaining external schedulers.",
      "wg": [
        { "t": "原生功能", "en": "native feature", "ps": "n" },
        { "t": "完全託管", "en": "fully managed", "ps": "adj" },
        { "t": "排程器", "en": "schedulers", "ps": "n" }
      ]
    }
  },
  {
    "no": "19",
    "level": "medium",
    "keywords": "Backup, Restore, Snapshot, Disaster Recovery",
    "question": [
      {
        "t": "作為備份計畫的一部分，您希望能夠使用快照還原 Compute Engine 實例。如何使用最少的步驟完成此操作？",
        "en": "As part of your backup plan, you want to be able to restore Compute Engine instances using snapshots. How would you do it using fewest steps possible?",
        "wg": [
          { "t": "還原", "en": "restore", "ps": "v" },
          { "t": "最少的步驟", "en": "fewest steps", "ps": "n" },
          { "t": "備份計畫", "en": "backup plan", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將快照匯出到 Cloud Storage。從匯出的快照檔案建立磁碟。從新磁碟建立映像檔。",
        "en": "(A) Export the snapshots to Cloud Storage. Create disks from the exported snapshot files. Create images from the new disks.",
        "wg": []
      },
      {
        "t": "(B) 將快照匯出到 Cloud Storage。從匯出的快照檔案建立映像檔。",
        "en": "(B) Export the snapshots to Cloud Storage. Create images from the exported snapshot files.",
        "wg": []
      },
      {
        "t": "(C) 使用快照建立替換磁碟。根據需要使用磁碟建立實例。",
        "en": "(C) Use the snapshots to create replacement disks. Use the disks to create instances as needed.",
        "wg": []
      },
      {
        "t": "(D) 根據需要使用快照建立替換實例。",
        "en": "(D) Use the snapshots to create replacement instances as needed.",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "在 GCP 中，您可以直接從快照建立新的 VM 實例 (在建立實例時，於開機磁碟選項中選擇 '快照')。這比先手動將快照還原為磁碟，再從磁碟建立實例的步驟更少且更直接。不需要將快照匯出到 Cloud Storage，因為快照本身已經儲存在那裡 (由 Google 管理)。",
      "en": "In GCP, you can create a new VM instance directly from a snapshot (by selecting 'Snapshot' in the boot disk options during instance creation). This involves fewer steps than manually restoring a snapshot to a disk first and then creating an instance from that disk. Exporting to Cloud Storage is unnecessary as snapshots are already stored there (managed by Google).",
      "wg": [
        { "t": "直接", "en": "directly", "ps": "adv" },
        { "t": "開機磁碟", "en": "boot disk", "ps": "n" },
        { "t": "手動還原", "en": "manually restoring", "ps": "v" }
      ]
    }
  },
  {
    "no": "20",
    "level": "hard",
    "keywords": "Architecture, High Availability, Latency, Zonal Failure",
    "question": [
      {
        "t": "您將如何設計一個對延遲敏感且即使整個 GCP 區域 (Zone) 無法存取也能確保業務連續性的 GCE 系統？",
        "en": "How would you design a GCE-based system that is latency-sensitive and should ensure business continuity even if a whole GCP zone was not accessible?",
        "wg": [
          { "t": "對延遲敏感", "en": "latency-sensitive", "ps": "adj" },
          { "t": "業務連續性", "en": "business continuity", "ps": "n" },
          { "t": "區域", "en": "zone", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在同一區域 (Zone) 部署，但使用多個 GCE 實例以防其中一個故障。",
        "en": "(A) Deploy in the same zone, but using multiple GCE instances in case one of them fails.",
        "wg": []
      },
      {
        "t": "(B) 在同一地區 (Region) 的不同區域 (Zone) 部署多個 VM。",
        "en": "(B) Deploy multiple VMs in separate zones in the same region.",
        "wg": []
      },
      {
        "t": "(C) 在不同地區 (Region) 部署多個 VM。",
        "en": "(C) Deploy multiple VMs in separate regions.",
        "wg": []
      },
      {
        "t": "(D) 部署單個 VM 並安排快照，以便在發生故障時還原到另一個區域。",
        "en": "(D) Deploy a single VM and schedule snapshots that can be restored to another zone in case of failure.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "為了滿足 '業務連續性' (應對區域故障) 的需求，必須跨多個區域 (Zones) 部署。為了滿足 '延遲敏感' 的需求，應保持在同一個地理地區 (Region) 內，因為跨地區 (Cross-Region) 的網路延遲明顯高於跨區域 (Cross-Zone)。因此，同一地區內的多區域部署是最佳平衡。",
      "en": "To meet the requirement of 'business continuity' (surviving a zonal failure), deployment must span multiple zones. To meet the 'latency-sensitive' requirement, resources should remain within the same geographic Region, as Cross-Region network latency is significantly higher than Cross-Zone latency. Therefore, multi-zone deployment within a single region is the optimal balance.",
      "wg": [
        { "t": "跨地區", "en": "Cross-Region", "ps": "adj" },
        { "t": "網路延遲", "en": "network latency", "ps": "n" },
        { "t": "最佳平衡", "en": "optimal balance", "ps": "n" }
      ]
    }
  },{
    "no": "21",
    "level": "hard",
    "keywords": "Compute Engine, Disk Performance, IOPS, Throughput",
    "question": [
      {
        "t": "您注意到其中一台機器的 I/O 吞吐量有問題。這是一台 n2-standard-2，您剛剛將其 SSD 大小從 500GB 增加到 1TB，但仍然沒有幫助。您可以做什麼來快速解決這個問題？",
        "en": "You notice that there are problems with I/O throughput on one your machines. It's an n2-standard-2 and you've just increased it's SSD size from 500GB to 1TB, but it still did not help. What can you do to quickly address this issue?",
        "wg": [
          { "t": "I/O 吞吐量", "en": "I/O throughput", "ps": "n" },
          { "t": "增加", "en": "increased", "ps": "v" },
          { "t": "解決", "en": "address", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 新增一顆性能更快的 Extreme SSD 磁碟。",
        "en": "(A) Add an Extreme SSD disk that performs even faster.",
        "wg": []
      },
      {
        "t": "(B) 將 GCE 實例重新調整大小為 n2-standard-8。",
        "en": "(B) Re-size the GCE instance to n2-standard-8.",
        "wg": []
      },
      {
        "t": "(C) 將處理模式從較小的檔案更改為較大的檔案。",
        "en": "(C) Change the processing pattern from smaller to larger file sizes.",
        "wg": []
      },
      {
        "t": "(D) 檢查開機磁碟是否太小。",
        "en": "(D) Check if boot disk is not too small.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "在 Compute Engine 中，磁碟的 I/O 性能 (IOPS 和吞吐量) 不僅取決於磁碟大小和類型，還受到虛擬機實例 (VM) 的 vCPU 數量的限制。n2-standard-2 只有 2 個 vCPU，其網路和磁碟 I/O 上限較低。即使增加了磁碟大小，如果達到了實例層級的吞吐量上限，性能也不會提升。升級到 n2-standard-8 (8 個 vCPU) 會顯著提高這個上限。",
      "en": "In Compute Engine, disk I/O performance (IOPS and throughput) is not only determined by the disk size and type but is also capped by the number of vCPUs of the VM instance. An n2-standard-2 has only 2 vCPUs and a relatively low cap on network and disk I/O. Even if the disk size is increased, performance won't improve if the instance-level throughput cap is hit. Upgrading to n2-standard-8 (8 vCPUs) significantly raises this cap.",
      "wg": [
        { "t": "vCPU 數量", "en": "number of vCPUs", "ps": "n" },
        { "t": "實例層級", "en": "instance-level", "ps": "adj" },
        { "t": "上限", "en": "cap", "ps": "n" }
      ]
    }
  },
  {
    "no": "22",
    "level": "medium",
    "keywords": "Troubleshooting, Serial Console, Boot Failure",
    "question": [
      {
        "t": "其中一台 Linux GCE 實例無法正常開機。您可以採取哪些行動來驗證錯誤？(選擇兩項)",
        "en": "One of the linux GCE instances is not booting properly. What actions can you take to validate the errors? (choose two).",
        "wg": [
          { "t": "無法正常開機", "en": "not booting properly", "ps": "v" },
          { "t": "驗證錯誤", "en": "validate the errors", "ps": "v" }
        ]
      }
    ],
    "type": "多選題",
    "options": [
      {
        "t": "(A) 啟用序列埠主控台 (Serial Console) 連線並從那裡連接。",
        "en": "(A) Enable Serial Console connectivity and connect from there.",
        "wg": []
      },
      {
        "t": "(B) 將 VM 調整為更大的尺寸。",
        "en": "(B) Resize the VM to a larger size.",
        "wg": []
      },
      {
        "t": "(C) 透過身份感知代理 (IAP) 連接，而不是 ssh。",
        "en": "(C) Connect via Identity-Aware Proxy (IAP) instead of ssh.",
        "wg": []
      },
      {
        "t": "(D) 從故障機器卸載開機磁碟，將其作為非開機磁碟連接到另一台機器，並驗證磁碟內容。",
        "en": "(D) Unmount the boot disk from the failing machine, attach it to a different one as non-boot disk and validate the contents of the disk.",
        "wg": []
      }
    ],
    "answer": "(A), (D)",
    "why": {
      "t": "當 VM 無法開機時，標準的 SSH (包括 IAP) 通常無法運作，因為 SSH 服務可能未啟動。啟用序列埠主控台允許您查看核心開機日誌和錯誤訊息，這對於診斷開機失敗至關重要。另一種標準方法是將磁碟掛載到另一台健康的 VM 上進行鑑識分析，檢查日誌檔 (如 /var/log/syslog) 或修復配置錯誤。",
      "en": "When a VM fails to boot, standard SSH (including IAP) usually won't work because the SSH service might not be running. Enabling the Serial Console allows you to see kernel boot logs and error messages, which is crucial for diagnosing boot failures. The other standard approach is to mount the disk on another healthy VM for forensic analysis, allowing you to inspect log files (like /var/log/syslog) or fix configuration errors.",
      "wg": [
        { "t": "序列埠主控台", "en": "Serial Console", "ps": "n" },
        { "t": "核心開機日誌", "en": "kernel boot logs", "ps": "n" },
        { "t": "鑑識分析", "en": "forensic analysis", "ps": "n" }
      ]
    }
  },
  {
    "no": "23",
    "level": "medium",
    "keywords": "Deployment, Automation, Custom Image, Startup Script",
    "question": [
      {
        "t": "您有哪些選項可以自動部署已經包含特定軟體和配置的 GCE 實例？(選擇三項)",
        "en": "What are your options to automatically deploy a GCE instance that already contain specific software and configuration? (choose three).",
        "wg": [
          { "t": "自動部署", "en": "automatically deploy", "ps": "v" },
          { "t": "特定軟體", "en": "specific software", "ps": "n" },
          { "t": "配置", "en": "configuration", "ps": "n" }
        ]
      }
    ],
    "type": "多選題",
    "options": [
      {
        "t": "(A) 建立一個安裝了所有軟體的自訂作業系統映像檔 (Custom OS image)，並使用此映像檔部署 GCE 實例。",
        "en": "(A) Create a custom OS image with all the software installed and deploy a GCE instance using this image.",
        "wg": []
      },
      {
        "t": "(B) 部署帶有公共 OS 映像檔的 VM，SSH 進入並從腳本觸發配置。",
        "en": "(B) Deploy a VM with a public OS image, ssh into it and trigger the configuration from a script.",
        "wg": []
      },
      {
        "t": "(C) 部署帶有公共 OS 映像檔的 VM，並使用啟動腳本 (startup scripts) 安裝/配置軟體。",
        "en": "(C) Deploy a VM with a public OS image and use startup scripts to install/configure the software.",
        "wg": []
      },
      {
        "t": "(D) 使用特定的 GCP Marketplace 解決方案。",
        "en": "(D) Use a specific GCP Marketplace solution.",
        "wg": []
      }
    ],
    "answer": "(A), (C), (D)",
    "why": {
      "t": "選項 A (自訂映像檔) 將軟體預先打包，啟動即用。選項 C (啟動腳本) 利用 GCP 原生功能在開機時自動執行安裝指令。選項 D (Marketplace) 提供合作夥伴或 Google 預先配置好的解決方案，可一鍵部署。選項 B 涉及手動或外部觸發的 SSH 步驟，嚴格來說不算是在部署實例時 '包含' 配置的自動化原生方法。",
      "en": "Option A (Custom Image) pre-bakes software so it's ready on boot. Option C (Startup Scripts) uses a native GCP feature to automatically run installation commands at boot time. Option D (Marketplace) offers pre-configured solutions from partners or Google that can be deployed with one click. Option B involves manual or externally triggered SSH steps, which is not strictly an automated native method where the instance 'contains' the configuration upon deployment.",
      "wg": [
        { "t": "預先打包", "en": "pre-bakes", "ps": "v" },
        { "t": "一鍵部署", "en": "deployed with one click", "ps": "v" },
        { "t": "原生方法", "en": "native method", "ps": "n" }
      ]
    }
  },
  {
    "no": "24",
    "level": "medium",
    "keywords": "Cost Optimization, Billing, Infrastructure",
    "question": [
      {
        "t": "您如何優化 VM 的基礎設施成本？(選擇五項)",
        "en": "How can you optimize the infrastructure costs for your VMs? (choose five)",
        "wg": [
          { "t": "優化", "en": "optimize", "ps": "v" },
          { "t": "基礎設施成本", "en": "infrastructure costs", "ps": "n" }
        ]
      }
    ],
    "type": "多選題",
    "options": [
      {
        "t": "(A) 使用承諾使用折扣 (Committed Use Discounts)。",
        "en": "(A) Use Committed Use Discounts.",
        "wg": []
      },
      {
        "t": "(B) 自動化關機和開機以減少 VM 運行時間。",
        "en": "(B) Automate shutdowns and startups to reduce the time VMs are up.",
        "wg": []
      },
      {
        "t": "(C) 遵循 GCP 的 VM 大小調整建議 (Recommendations)。",
        "en": "(C) Follow GCP Recommendations for the VM sizing.",
        "wg": []
      },
      {
        "t": "(D) 限制可以登入 VM 的授權使用者數量。",
        "en": "(D) Limit the number of Licenced Users that can login to VMs.",
        "wg": []
      },
      {
        "t": "(E) 使用先佔式實例 (Preemptible Instances)。",
        "en": "(E) Use Preemptible Instances.",
        "wg": []
      },
      {
        "t": "(F) 在較便宜的地區部署 VM。",
        "en": "(F) Deploy VMs in cheaper regions.",
        "wg": []
      }
    ],
    "answer": "(A), (B), (C), (E), (F)",
    "why": {
      "t": "優化雲端成本的五大支柱包括：1. 財務承諾 (CUDs)；2. 減少閒置資源 (自動開關機)；3. 調整資源規模 (Right-sizing 建議)；4. 使用低成本資源類型 (先佔式/Spot)；5. 地理位置套利 (選擇價格較低的地區)。限制登入使用者數量 (選項 D) 通常與軟體授權有關，與基礎設施 (運算/儲存) 成本無直接關係。",
      "en": "The five pillars of optimizing cloud costs include: 1. Financial commitments (CUDs); 2. Reducing idle resources (Automate shutdowns); 3. Right-sizing resources (Recommendations); 4. Using lower-cost resource types (Preemptible/Spot); 5. Geographic arbitrage (Deploying in cheaper regions). Limiting the number of login users (Option D) is typically related to software licensing, not directly to infrastructure (compute/storage) costs.",
      "wg": [
        { "t": "財務承諾", "en": "Financial commitments", "ps": "n" },
        { "t": "調整資源規模", "en": "Right-sizing resources", "ps": "n" },
        { "t": "地理位置套利", "en": "Geographic arbitrage", "ps": "n" }
      ]
    }
  },
  {
    "no": "25",
    "level": "hard",
    "keywords": "Storage, Regional Persistent Disk, High Availability, Replication",
    "question": [
      {
        "t": "您希望確保所選永久磁碟 (Persistent Disk) 的內容被複製到另一個區域 (Zone)，以便在發生區域故障時，您能夠快速將其掛載到另一個區域的不同 VM，而不會遺失任何數據。您的最佳選擇是什麼？",
        "en": "You'd like to ensure that contents of a chosen Persistent Disk are replicated to another zone so that in the event of a zonal failure, you're able to quickly mount it to a different VM in another zone, without loosing any data. What is your best option?",
        "wg": [
          { "t": "複製", "en": "replicated", "ps": "v" },
          { "t": "區域故障", "en": "zonal failure", "ps": "n" },
          { "t": "掛載", "en": "mount", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 排程頻繁的快照，以便在停機時用於在第二個區域建立 PD。",
        "en": "(A) Schedule frequent snapshots that can be used to create a PD in the second zone in case of outage.",
        "wg": []
      },
      {
        "t": "(B) 建立一個地區性永久磁碟 (Regional PD)，並在停機時將其強制掛載到另一個區域的 GCE 實例。",
        "en": "(B) Create a regional PD and forcefully mount it to a GCE instance in another zone in case of outage.",
        "wg": []
      },
      {
        "t": "(C) 建立兩個獨立的區域性 PD，並在它們之間建立基於 rsync 的複製。",
        "en": "(C) Create two separate zonal PDs and create an rsync-based replication between them.",
        "wg": []
      },
      {
        "t": "(D) 您不需要做任何事情。PD 會自動在區域之間複製以實現彈性。",
        "en": "(D) You don't need to do anything. PDs are automatically replicated between zones for resiliency.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "地區性永久磁碟 (Regional Persistent Disk) 專為高可用性 (HA) 設計，它會同步將數據複製到同一地區的兩個區域 (Zones)。如果主區域發生故障，您可以強制將該磁碟掛載到次要區域的 VM 上，且 RPO (復原點目標) 為零 (無數據遺失)。快照是異步的，會有數據遺失。標準 PD 是區域性的，不會跨區域複製。",
      "en": "Regional Persistent Disks are designed for High Availability (HA) by synchronously replicating data across two zones within the same region. In the event of a zonal failure, you can forcefully attach the disk to a VM in the secondary zone with an RPO (Recovery Point Objective) of zero (no data loss). Snapshots are asynchronous and imply some data loss. Standard PDs are zonal and not replicated across zones.",
      "wg": [
        { "t": "同步複製", "en": "synchronously replicating", "ps": "v" },
        { "t": "高可用性", "en": "High Availability", "ps": "n" },
        { "t": "強制掛載", "en": "forcefully attach", "ps": "v" }
      ]
    }
  },{
    "no": "26",
    "level": "hard",
    "keywords": "Cloud SQL, VPC Peering, Networking, Transitive Peering",
    "question": [
      {
        "t": "一位客戶聯絡您，表示他們在其中一個專案中佈建了 Cloud SQL 實例，但無法從另一個專案連接到此實例，儘管這兩個專案的 VPC 之間已配置了 VPC 對等互連 (VPC peering)。最可能的原因是什麼？",
        "en": "A customer contacted you saying that they provisioned a Cloud SQL instance in one of the projects, but he can't connect to this instance from another project, despite VPC peering is configured between VPCs in those two projects. What's the most likely reason?",
        "wg": [
          { "t": "佈建", "en": "provisioned", "ps": "v" },
          { "t": "無法連接", "en": "can't connect", "ps": "v" },
          { "t": "VPC 對等互連", "en": "VPC peering", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 連接可能是透過 Cloud SQL 實例名稱進行的；應改用 IP 位址連接。",
        "en": "(A) The connection are probably done via Cloud SQL instance name; connecting via IP address should be used instead.",
        "wg": []
      },
      {
        "t": "(B) 缺少適當的 Cloud SQL 角色；新增 'Cloud SQL viewer' 角色後應可建立連接。",
        "en": "(B) Appropriate Cloud SQL roles are missing; connectivity should be established after adding 'Cloud SQL viewer' role.",
        "wg": []
      },
      {
        "t": "(C) Cloud SQL 會自動建立 VPC 對等互連，因此任何來自另一個對等 VPC 的登入嘗試都將無法運作。",
        "en": "(C) Cloud SQL automatically creates a VPC peering, so any attempts to login from another peered VPC will not work.",
        "wg": []
      },
      {
        "t": "(D) Cloud SQL 需要在 Cloud Console 中註冊才能啟用連接。",
        "en": "(D) Cloud SQL needs to be registered in Cloud Console in order for the connectivity to be enabled.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud SQL 使用私有 IP 時，是透過與 Google 管理的服務生產者網路進行 VPC 對等互連 (VPC Peering) 來實現的。VPC 對等互連具有「不可傳遞性」(Non-transitive)。這意味著如果專案 A 的 VPC 與專案 B 的 VPC 對等互連，且專案 A 的 VPC 與 Cloud SQL (生產者網路) 對等互連，專案 B 無法透過專案 A「跳板」存取 Cloud SQL。這就是所謂的傳遞性對等互連限制。",
      "en": "When using Private IP, Cloud SQL works via VPC Peering with a Google-managed producer network. VPC Peering is 'non-transitive'. This means if Project A's VPC is peered with Project B's VPC, and Project A's VPC is peered with Cloud SQL (the producer network), Project B cannot access Cloud SQL by 'hopping' through Project A. This is the transitive peering limitation.",
      "wg": [
        { "t": "不可傳遞性", "en": "Non-transitive", "ps": "adj" },
        { "t": "生產者網路", "en": "producer network", "ps": "n" },
        { "t": "限制", "en": "limitation", "ps": "n" }
      ]
    }
  },
  {
    "no": "27",
    "level": "medium",
    "keywords": "Sole-tenant nodes, Compliance, Compute Engine, Dedicated Host",
    "question": [
      {
        "t": "YourHealth 公司希望將其工作負載遷移到 GCP，但他們有嚴格的合規要求，不允許與其他客戶共享實體運算基礎設施。他們如何仍然能夠使用 GCE 實例？",
        "en": "YourHealth company would like to migrate their workloads to GCP, but they have strict compliance requirements that don't allow them to share physical compute infrastructure with other customers. How would they still be able to use GCE instances?",
        "wg": [
          { "t": "合規要求", "en": "compliance requirements", "ps": "n" },
          { "t": "共享", "en": "share", "ps": "v" },
          { "t": "實體運算基礎設施", "en": "physical compute infrastructure", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 他們不能；建立 GCE VM 時，必須接受共享模式，底層沒有專屬的實體機器。",
        "en": "(A) They can't; when creating a GCE VM, you have to accept shared model and not having your own, dedicated physical machine underneath.",
        "wg": []
      },
      {
        "t": "(B) 他們可以使用單一租戶節點 (sole-tenant nodes)。",
        "en": "(B) They can use sole-tenant nodes.",
        "wg": []
      },
      {
        "t": "(C) 他們可以部署大小與底層實體機器完全相同的 GCE VM。",
        "en": "(C) They can deploy GCE VMs of exactly the size of a physical machine underneath.",
        "wg": []
      },
      {
        "t": "(D) 他們可以在部署所有 GCE VM 時查詢 GCP metadata 以取得實體機器的 ID 並使用此 ID。",
        "en": "(D) They can query GCP metadata for the ID of physical machine and use this ID when deploying all their GCE VMs.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "單一租戶節點 (Sole-tenant nodes) 是 Google Compute Engine 提供的實體 Compute Engine 伺服器，專供特定專案使用。這讓客戶能夠擁有專屬的實體硬體，滿足隔離性、合規性或授權 (BYOL) 的需求，避免與其他客戶共享同一台實體主機。",
      "en": "Sole-tenant nodes are physical Compute Engine servers dedicated exclusively to your project. This allows customers to have dedicated physical hardware, meeting requirements for isolation, compliance, or licensing (BYOL), avoiding sharing the same physical host with other customers.",
      "wg": [
        { "t": "單一租戶節點", "en": "Sole-tenant nodes", "ps": "n" },
        { "t": "專供", "en": "dedicated exclusively", "ps": "adv" },
        { "t": "隔離性", "en": "isolation", "ps": "n" }
      ]
    }
  },
  {
    "no": "28",
    "level": "easy",
    "keywords": "Security, Encryption, Data at Rest, All Services",
    "question": [
      {
        "t": "BizBank 有一項要求，即只能使用確保資料加密的資料服務。他們可以考慮 GCP 中的哪些服務？",
        "en": "BizBank has a requirement to only use data services that ensure data encryption. Which services in GCP can they consider?",
        "wg": [
          { "t": "資料加密", "en": "data encryption", "ps": "n" },
          { "t": "考慮", "en": "consider", "ps": "v" }
        ]
      }
    ],
    "type": "多選題",
    "options": [
      {
        "t": "(A) GCS",
        "en": "(A) GCS",
        "wg": []
      },
      {
        "t": "(B) Cloud Spanner",
        "en": "(B) Cloud Spanner",
        "wg": []
      },
      {
        "t": "(C) Bigtable",
        "en": "(C) Bigtable",
        "wg": []
      },
      {
        "t": "(D) Firestore",
        "en": "(D) Firestore",
        "wg": []
      },
      {
        "t": "(E) 永久磁碟 (Persistent Disks)",
        "en": "(E) Persistent Disks",
        "wg": []
      }
    ],
    "answer": "(A), (B), (C), (D), (E)",
    "why": {
      "t": "Google Cloud 預設會加密所有儲存的靜態資料 (Data at rest)，無需使用者採取任何行動。這適用於 GCS、Cloud Spanner、Bigtable、Firestore 和 Persistent Disks 等所有資料服務。因此，所有列出的服務都符合 BizBank 的加密要求。",
      "en": "Google Cloud encrypts all data at rest by default, without any action required from the user. This applies to all data services including GCS, Cloud Spanner, Bigtable, Firestore, and Persistent Disks. Therefore, all listed services meet BizBank's encryption requirement.",
      "wg": [
        { "t": "靜態資料", "en": "Data at rest", "ps": "n" },
        { "t": "預設", "en": "by default", "ps": "adv" },
        { "t": "無需", "en": "without any action", "ps": "adv" }
      ]
    }
  },
  {
    "no": "29",
    "level": "medium",
    "keywords": "Logging, Audit Logs, Data Access, Security",
    "question": [
      {
        "t": "MyCompany 希望知道何時有人存取了其中一個關鍵專案中 GCS 儲存桶內的資料。他們該如何配置？",
        "en": "MyCompany would like to know whenever someone accesses data stored in GCS bucket in one of the critical projects. How can they configure it?",
        "wg": [
          { "t": "存取", "en": "accesses", "ps": "v" },
          { "t": "資料", "en": "data", "ps": "n" },
          { "t": "配置", "en": "configure", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 他們不必做任何事 - 稽核日誌在 GCP 中預設為開啟。",
        "en": "(A) They don't have to - audit logs are on by default in GCP.",
        "wg": []
      },
      {
        "t": "(B) 他們需要聯絡 Google 支援以提供此資料。",
        "en": "(B) They need to reach out to Google support to provide this data.",
        "wg": []
      },
      {
        "t": "(C) 他們可以為 GCS 啟用資料存取稽核記錄 (Data Access audit logging)。",
        "en": "(C) They can activate data access audit logging for GCS.",
        "wg": []
      },
      {
        "t": "(D) 他們必須啟用 'Audit Data' API。",
        "en": "(D) They have to activate 'Audit Data' API.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "在 Google Cloud 中，'管理活動' (Admin Activity) 稽核記錄預設為開啟，記錄修改資源配置的行為。然而，'資料存取' (Data Access) 稽核記錄（記錄讀取或寫入使用者資料的 API 呼叫，如讀取 GCS 檔案）除了 BigQuery 外，預設是停用的，因為資料量可能非常大。使用者必須明確啟用它們。",
      "en": "In Google Cloud, 'Admin Activity' audit logs are on by default, recording actions that modify resource configurations. However, 'Data Access' audit logs (which record API calls that read or write user data, like reading a GCS file) are disabled by default (except for BigQuery) because they can be very voluminous. Users must explicitly enable them.",
      "wg": [
        { "t": "管理活動", "en": "Admin Activity", "ps": "n" },
        { "t": "資料存取", "en": "Data Access", "ps": "n" },
        { "t": "明確啟用", "en": "explicitly enable", "ps": "v" }
      ]
    }
  },
  {
    "no": "30",
    "level": "hard",
    "keywords": "Security, Encryption, CSEK, Key Recovery",
    "question": [
      {
        "t": "建立永久磁碟 (PD) 時，您選擇了 CSEK 模式來管理 KEK 金鑰。不幸的是，您將加密金鑰儲存在被盜的公司筆記型電腦上。您如何復原解密 PD 上儲存的資料所需的遺失金鑰？",
        "en": "When creating a PD, you chose a CSEK model to manage KEK keys. Unfortunately, you stored the encryption key on a company laptop that was stolen from you. How can you recover the lost key needed to decrypt the data stored on PD?",
        "wg": [
          { "t": "CSEK 模式", "en": "CSEK model", "ps": "n" },
          { "t": "加密金鑰", "en": "encryption key", "ps": "n" },
          { "t": "復原", "en": "recover", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 您需要聯絡 Google 支援並啟動金鑰復原程序。",
        "en": "(A) You need to reach out to Google support and initiate Key Recovery procedure.",
        "wg": []
      },
      {
        "t": "(B) 您不必這樣做；Google 仍將 DEK 金鑰儲存在 GCP 中，這足以解密資料。",
        "en": "(B) You don't have to; Google still stores DEK keys in GCP, which are enough to decrypt the data.",
        "wg": []
      },
      {
        "t": "(C) 您可以產生另一個加密金鑰並改用這一個。",
        "en": "(C) You can generate another encryption key and use this one instead.",
        "wg": []
      },
      {
        "t": "(D) Google 無法協助您復原金鑰，因為 Google 不會永久儲存該金鑰。",
        "en": "(D) Google can't help you recover the key, since it's not stored permanently by Google.",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "在使用客戶提供的加密金鑰 (Customer-Supplied Encryption Keys, CSEK) 模式時，Google 僅在處理請求時短暫地將金鑰保存在記憶體中，絕不會將其永久儲存在磁碟或資料庫中。如果您遺失了金鑰，Google 無法復原它，這意味著該磁碟上的資料將永久無法存取 (Cryptographic Erase)。",
      "en": "With the Customer-Supplied Encryption Keys (CSEK) model, Google only holds the key transiently in memory to process requests and never stores it permanently on disk or database. If you lose the key, Google cannot recover it, meaning the data on that disk is permanently inaccessible (effectively cryptographically erased).",
      "wg": [
        { "t": "客戶提供的加密金鑰", "en": "Customer-Supplied Encryption Keys", "ps": "n" },
        { "t": "永久儲存", "en": "stores it permanently", "ps": "v" },
        { "t": "無法存取", "en": "inaccessible", "ps": "adj" }
      ]
    }
  },
  {
    "no": "31",
    "level": "hard",
    "keywords": "Database Migration, Cloud Spanner, MySQL, Schema Conversion",
    "question": [
      {
        "t": "GamersFirst 有一個 MySQL 資料庫，近年來增長顯著，必須在一天中最繁忙的時間支援每秒 8000 個請求。他們已經實施了各種技術來優化目前的解決方案，並且正在考慮遷移到 Cloud Spanner。他們如何執行這樣的遷移？",
        "en": "GamersFirst has a MySQL database that grew significantly in recent years and has to support 8000 requests per second in busiest time of the day. They already implemented various techniques to optimize the current solution and they're thinking of migrating to Cloud Spanner. How can they execute such a migration?",
        "wg": [
          { "t": "遷移", "en": "migration", "ps": "n" },
          { "t": "執行", "en": "execute", "ps": "v" },
          { "t": "優化", "en": "optimize", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 執行 MySQL 資料庫匯出並將其匯入 Spanner。",
        "en": "(A) Perform MySQL database export and import it into Spanner.",
        "wg": []
      },
      {
        "t": "(B) 使用 GCP 提供的資料庫遷移服務 (Database Migration Service)。",
        "en": "(B) Use Database Migration Service that GCP provides.",
        "wg": []
      },
      {
        "t": "(C) 資料庫結構描述 (Schemas) 需要轉換，使用資料庫的應用程式需要修改，並且必須進行資料的批次匯出/匯入。",
        "en": "(C) Database schemas needs to be converted, application using the database needs to be modified and bulk export/import of data has to be done.",
        "wg": []
      },
      {
        "t": "(D) 與其遷移到 Spanner，他們只需新增另一個 MySQL 唯讀複本 (Read Replica)，因為 MySQL 會隨著節點數量線性擴展。",
        "en": "(D) Instead of migrating to Spanner, they can just add another MySQL Read Replica, since MySQL scales linearly with the number of nodes.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Spanner 是一個分散式關聯資料庫，雖然它支援 SQL，但其架構與傳統 MySQL 不同。它不完全相容 MySQL 協定 (與 Cloud SQL 不同)。因此，不能簡單地使用 'dump and restore' 或標準的 DMS (通常用於同構遷移)。遷移到 Spanner 通常需要：1. 重新設計或轉換 Schema 以符合 Spanner 的最佳實踐 (如主鍵設計)；2. 修改應用程式程式碼以使用 Spanner Client Library；3. 執行資料的批次匯入 (使用 Dataflow 或類似工具)。",
      "en": "Cloud Spanner is a distributed relational database. While it supports SQL, its architecture differs from traditional MySQL, and it is not wire-compatible with MySQL (unlike Cloud SQL). Therefore, you cannot simply use 'dump and restore' or standard DMS (which is often for homogeneous migrations). Migrating to Spanner typically requires: 1. Converting schemas to fit Spanner best practices (e.g., primary key design); 2. Modifying application code to use Spanner client libraries; 3. Performing a bulk data export/import.",
      "wg": [
        { "t": "資料庫結構描述", "en": "Database schemas", "ps": "n" },
        { "t": "修改", "en": "modified", "ps": "v" },
        { "t": "批次匯出/匯入", "en": "bulk export/import", "ps": "n" }
      ]
    }
  },
  {
    "no": "1",
    "level": "medium",
    "keywords": "Cloud Storage, Lifecycle Management, Storage Class",
    "question": [
      {
        "t": "在 Cloud Storage 中，您將如何儲存每個月存取不超過一次且五年後不再需要的資料？",
        "en": "In Cloud Storage, how would you store data to be accessed not more than once a month and not needed after five years?",
        "wg": [
          { "t": "儲存", "en": "store", "ps": "v" },
          { "t": "存取", "en": "accessed", "ps": "v" },
          { "t": "五年後不再需要", "en": "not needed after five years", "ps": "adj" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Nearline 類別，生命週期政策在 5 年後更改為 Coldline",
        "en": "(A) Nearline class, lifecycle policy change to Coldline after 5 years",
        "wg": []
      },
      {
        "t": "(B) Nearline 類別，生命週期政策在 5 年後刪除",
        "en": "(B) Nearline class, lifecycle policy to delete after 5 years",
        "wg": []
      },
      {
        "t": "(C) Standard Storage 類別，生命週期政策在 5 年後更改為 Coldline",
        "en": "(C) Standard Storage class, lifecycle policy change to Coldline after 5 years",
        "wg": []
      },
      {
        "t": "(D) Standard Storage 類別，生命週期政策在 5 年後刪除",
        "en": "(D) Standard Storage class, lifecycle policy to delete after 5 years",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Nearline Storage 專為平均每個月存取不到一次的資料而設計 (30 天最小儲存期限)，符合題目「每個月存取不超過一次」的描述。Standard 適合頻繁存取，而 Coldline/Archive 適合更低頻率 (每季/每年)。題目還指出資料「五年後不再需要」，因此正確的生命週期動作應為「刪除」(Delete)，而非轉換類別。",
      "en": "Nearline Storage is designed for data accessed less than once a month on average (30-day minimum storage duration), matching the 'not more than once a month' requirement. Standard is for frequent access, while Coldline/Archive are for lower frequency (quarterly/yearly). Since the data is 'not needed after five years', the correct lifecycle action is to 'delete' it, not change its class.",
      "wg": [
        { "t": "生命週期動作", "en": "lifecycle action", "ps": "n" },
        { "t": "轉換類別", "en": "change its class", "ps": "v" },
        { "t": "最小儲存期限", "en": "minimum storage duration", "ps": "n" }
      ]
    }
  },
  {
    "no": "2",
    "level": "medium",
    "keywords": "BigQuery, Analytics, SQL, Petabyte-scale",
    "question": [
      {
        "t": "哪種服務最適合只懂 SQL 的分析師使用的多 PB (multi-petabyte) 資料庫？",
        "en": "Which service is best for a multi-petabyte database for analysts that only know SQL? The database must be available 24 x 7",
        "wg": [
          { "t": "多 PB", "en": "multi-petabyte", "ps": "adj" },
          { "t": "只懂 SQL", "en": "only know SQL", "ps": "adj" },
          { "t": "全天候可用", "en": "available 24 x 7", "ps": "adj" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) BigQuery",
        "en": "(A) BigQuery",
        "wg": []
      },
      {
        "t": "(B) Firebase",
        "en": "(B) Firebase",
        "wg": []
      },
      {
        "t": "(C) Cloud Storage",
        "en": "(C) Cloud Storage",
        "wg": []
      },
      {
        "t": "(D) Cloud SQL",
        "en": "(D) Cloud SQL",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "BigQuery 是 Google Cloud 的無伺服器、高度可擴展的企業資料倉儲，專為使用 SQL 進行 PB 級 (Petabyte-scale) 分析而設計。Cloud SQL 雖然支援 SQL，但在處理多 PB 資料時擴展性不如 BigQuery。Firebase 是 NoSQL 移動後端，Cloud Storage 是物件儲存，不直接提供 SQL 介面給分析師。",
      "en": "BigQuery is Google Cloud's serverless, highly scalable enterprise data warehouse, explicitly designed for petabyte-scale analytics using SQL. While Cloud SQL supports SQL, it is not as easily scalable to multi-petabyte ranges for analytics compared to BigQuery. Firebase is a NoSQL mobile backend, and Cloud Storage is object storage, not directly offering a SQL interface for analysts.",
      "wg": [
        { "t": "企業資料倉儲", "en": "enterprise data warehouse", "ps": "n" },
        { "t": "無伺服器", "en": "serverless", "ps": "adj" },
        { "t": "擴展性", "en": "scalability", "ps": "n" }
      ]
    }
  },
  {
    "no": "3",
    "level": "hard",
    "keywords": "IAM, Roles, Security Auditor, Organization",
    "question": [
      {
        "t": "您會為需要查看所有專案權限的資安稽核員指派哪些 Cloud IAM 角色？",
        "en": "Which Cloud IAM roles would you assign for security auditors requiring visibility across all projects?",
        "wg": [
          { "t": "資安稽核員", "en": "security auditors", "ps": "n" },
          { "t": "查看", "en": "visibility", "ps": "n" },
          { "t": "所有專案", "en": "across all projects", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Org viewer, project viewer",
        "en": "(A) Org viewer, project viewer",
        "wg": []
      },
      {
        "t": "(B) Org viewer, project owner",
        "en": "(B) Org viewer, project owner",
        "wg": []
      },
      {
        "t": "(C) Project owner, network admin",
        "en": "(C) Project owner, network admin",
        "wg": []
      },
      {
        "t": "(D) Org admin, project browser",
        "en": "(D) Org admin, project browser",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "稽核員通常需要唯讀權限。在組織層級 (Organization level) 指派 'Org Viewer' 可讓他們查看組織的配置和階層結構。在組織層級指派 'Project Viewer' (或是透過 'Org Viewer' 結合各專案的繼承權限) 可確保他們對組織下的所有專案擁有讀取權限，這符合「查看所有專案」的需求，且不給予過多的修改權限 (如 Owner 或 Admin)。",
      "en": "Auditors typically require read-only access. Assigning 'Org Viewer' at the Organization level allows them to view the organization's configuration and hierarchy. Assigning 'Project Viewer' (inherited from the Org level) ensures they have read access to all projects under the organization, meeting the requirement for 'visibility across all projects' without granting excessive modification rights like Owner or Admin.",
      "wg": [
        { "t": "唯讀權限", "en": "read-only access", "ps": "n" },
        { "t": "繼承權限", "en": "inherited permissions", "ps": "n" },
        { "t": "組織層級", "en": "Organization level", "ps": "n" }
      ]
    }
  },
  {
    "no": "4",
    "level": "easy",
    "keywords": "Cloud Storage, Cost Optimization, Storage Classes",
    "question": [
      {
        "t": "Google Cloud 提供每位元組最便宜的儲存服務是什麼？",
        "en": "What is the cheapest per-byte storage offered by Google Cloud?",
        "wg": [
          { "t": "最便宜", "en": "cheapest", "ps": "adj" },
          { "t": "每位元組", "en": "per-byte", "ps": "n" },
          { "t": "儲存服務", "en": "storage", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud BigTable",
        "en": "(A) Cloud BigTable",
        "wg": []
      },
      {
        "t": "(B) Cloud Firestore",
        "en": "(B) Cloud Firestore",
        "wg": []
      },
      {
        "t": "(C) Cloud SQL",
        "en": "(C) Cloud SQL",
        "wg": []
      },
      {
        "t": "(D) Cloud Storage",
        "en": "(D) Cloud Storage",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud Storage (特別是 Archive Storage 類別) 提供了 Google Cloud 所有服務中最低的靜態資料儲存成本。相比之下，區塊儲存 (Block Storage) 和託管資料庫 (如 Cloud SQL, Bigtable) 的每 GB 成本都顯著較高，因為它們包含額外的運算和效能特性。",
      "en": "Cloud Storage (specifically the Archive Storage class) offers the lowest cost for data at rest among all Google Cloud services. In comparison, Block Storage and managed databases (like Cloud SQL, Bigtable) have significantly higher costs per GB as they include additional compute and performance features.",
      "wg": [
        { "t": "最低成本", "en": "lowest cost", "ps": "n" },
        { "t": "靜態資料", "en": "data at rest", "ps": "n" },
        { "t": "託管資料庫", "en": "managed databases", "ps": "n" }
      ]
    }
  },
  {
    "no": "5",
    "level": "medium",
    "keywords": "IAM, Roles, Permissions, Concepts",
    "question": [
      {
        "t": "在 Cloud IAM 中，使用哪種抽象概念來管理使用者存取？",
        "en": "Which abstraction is use to administer user access in Cloud IAM?",
        "wg": [
          { "t": "抽象概念", "en": "abstraction", "ps": "n" },
          { "t": "管理", "en": "administer", "ps": "v" },
          { "t": "使用者存取", "en": "user access", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 租賃 (Leases)，定期權利的抽象",
        "en": "(A) Leases, an abstraction of periodic entitlements",
        "wg": []
      },
      {
        "t": "(B) 特權 (Privileges)，存取權限的抽象",
        "en": "(B) Privileges, an abstraction of access rights",
        "wg": []
      },
      {
        "t": "(C) 角色 (Roles)，工作角色的抽象",
        "en": "(C) Roles, an abstraction of job roles",
        "wg": []
      },
      {
        "t": "(D) 憑證 (Credentials)，授權權杖的抽象",
        "en": "(D) Credentials, an abstraction of an authorization token",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "在 Cloud IAM 中，權限 (Permissions) 不會直接指派給使用者。相反，權限被分組到「角色」(Roles) 中，這些角色代表特定的工作職能 (如 Viewer, Editor, Admin)。然後將這些角色授予給使用者 (Members)。這簡化了存取管理。",
      "en": "In Cloud IAM, permissions are not assigned directly to users. Instead, permissions are grouped into 'Roles', which represent specific job functions (like Viewer, Editor, Admin). These Roles are then granted to users (Members). This simplifies access management.",
      "wg": [
        { "t": "直接指派", "en": "assigned directly", "ps": "v" },
        { "t": "工作職能", "en": "job functions", "ps": "n" },
        { "t": "授予", "en": "granted", "ps": "v" }
      ]
    }
  },{
    "no": "6",
    "level": "easy",
    "keywords": "Security, Encryption, Compliance, Storage",
    "question": [
      {
        "t": "法規要求加密靜態資料。可以使用哪些 Google Cloud 服務？",
        "en": "Regulations require encrypting data at rest. Which Google Cloud services can be used?",
        "wg": [
          { "t": "法規", "en": "Regulations", "ps": "n" },
          { "t": "加密靜態資料", "en": "encrypting data at rest", "ps": "n" },
          { "t": "可以使用", "en": "can be used", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 除 BigQuery 之外的任何託管資料庫",
        "en": "(A) Any of the managed databases except BigQuery",
        "wg": []
      },
      {
        "t": "(B) 除 Cloud Filestore 之外的任何 GCP 儲存服務",
        "en": "(B) Any GCP storage service except Cloud Filestore",
        "wg": []
      },
      {
        "t": "(C) 任何託管資料庫",
        "en": "(C) Any of the managed databases",
        "wg": []
      },
      {
        "t": "(D) 任何 GCP 儲存服務",
        "en": "(D) Any GCP storage service",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Google Cloud 的一項基本安全承諾是：所有 Google Cloud 服務中儲存的靜態資料都會使用 AES-256 或更高等級的加密標準自動進行加密。這適用於所有儲存服務 (如 GCS, Filestore, Persistent Disk) 和所有託管資料庫 (如 BigQuery, Cloud SQL, Spanner)。因此，任何 GCP 儲存服務皆符合要求。",
      "en": "A fundamental security commitment of Google Cloud is that all data stored at rest in any Google Cloud service is automatically encrypted using AES-256 or better. This applies to all storage services (like GCS, Filestore, Persistent Disk) and all managed databases (like BigQuery, Cloud SQL, Spanner). Therefore, any GCP storage service meets the requirement.",
      "wg": [
        { "t": "基本安全承諾", "en": "fundamental security commitment", "ps": "n" },
        { "t": "自動加密", "en": "automatically encrypted", "ps": "v" },
        { "t": "符合要求", "en": "meets the requirement", "ps": "v" }
      ]
    }
  },
  {
    "no": "7",
    "level": "medium",
    "keywords": "Storage, Video, Large Files, Object Storage",
    "question": [
      {
        "t": "您會使用哪個儲存服務來儲存大型影片檔案？",
        "en": "Which storage service would you use to store large video files?",
        "wg": [
          { "t": "儲存服務", "en": "storage service", "ps": "n" },
          { "t": "大型影片檔案", "en": "large video files", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) BigQuery",
        "en": "(A) BigQuery",
        "wg": []
      },
      {
        "t": "(B) Cloud Bigtable",
        "en": "(B) Cloud Bigtable",
        "wg": []
      },
      {
        "t": "(C) Cloud Storage",
        "en": "(C) Cloud Storage",
        "wg": []
      },
      {
        "t": "(D) Cloud Firestore",
        "en": "(D) Cloud Firestore",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Storage 是物件儲存服務 (Object Storage)，專為儲存非結構化資料 (Unstructured Data) 而設計，例如影片、圖像和備份檔案。它具有極高的擴展性和耐用性。相比之下，BigQuery 是用於分析的資料倉儲，Bigtable 是寬欄位 NoSQL 資料庫，Firestore 是文件型 NoSQL 資料庫，它們都不適合直接儲存大型二進位檔案 (BLOBs)。",
      "en": "Cloud Storage is an object storage service designed for storing unstructured data, such as videos, images, and backups. It is highly scalable and durable. In contrast, BigQuery is a data warehouse for analytics, Bigtable is a wide-column NoSQL database, and Firestore is a document NoSQL database; none of these are optimized for directly storing large binary files (BLOBs).",
      "wg": [
        { "t": "物件儲存服務", "en": "Object Storage service", "ps": "n" },
        { "t": "非結構化資料", "en": "unstructured data", "ps": "n" },
        { "t": "極高的擴展性", "en": "highly scalable", "ps": "adj" }
      ]
    }
  },
  {
    "no": "8",
    "level": "medium",
    "keywords": "Cloud Storage, Storage Class, Coldline, Forensics",
    "question": [
      {
        "t": "應該使用哪個儲存類別來儲存鑑識日誌，這些日誌每季最多被存取一次？",
        "en": "Which storage class should be used to save logs for forensics, which will be accessed at most once a quarter.",
        "wg": [
          { "t": "儲存類別", "en": "storage class", "ps": "n" },
          { "t": "鑑識日誌", "en": "logs for forensics", "ps": "n" },
          { "t": "每季最多一次", "en": "at most once a quarter", "ps": "adv" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Archive",
        "en": "(A) Archive",
        "wg": []
      },
      {
        "t": "(B) Coldline",
        "en": "(B) Coldline",
        "wg": []
      },
      {
        "t": "(C) Nearline",
        "en": "(C) Nearline",
        "wg": []
      },
      {
        "t": "(D) Standard",
        "en": "(D) Standard",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Coldline Storage 的設計目標是存取頻率極低的資料 (如每季一次)，其最小儲存期限為 90 天。這完全符合「每季最多存取一次」的使用情境。Archive Storage 適用於每年不到一次的存取 (365 天最小期限)，而 Nearline 適用於每月一次 (30 天最小期限)。",
      "en": "Coldline Storage is designed for data that is accessed very infrequently (e.g., once a quarter), with a minimum storage duration of 90 days. This fits the scenario of 'accessed at most once a quarter' perfectly. Archive Storage is for access less than once a year (365 days min), and Nearline is for once a month (30 days min).",
      "wg": [
        { "t": "存取頻率", "en": "access frequency", "ps": "n" },
        { "t": "最小儲存期限", "en": "minimum storage duration", "ps": "n" },
        { "t": "使用情境", "en": "usage scenario", "ps": "n" }
      ]
    }
  },
  {
    "no": "9",
    "level": "medium",
    "keywords": "Operations Suite, Latency, App Engine, Trace",
    "question": [
      {
        "t": "在 App Engine 中，Operations Suite 的哪個工具可用來查看 Web 應用程式的請求延遲？",
        "en": "What is the Operations Suite tool to see the latency of requests for a web application in App Engine?",
        "wg": [
          { "t": "查看", "en": "see", "ps": "v" },
          { "t": "請求延遲", "en": "latency of requests", "ps": "n" },
          { "t": "Web 應用程式", "en": "web application", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Debugger",
        "en": "(A) Debugger",
        "wg": []
      },
      {
        "t": "(B) Error Reporting",
        "en": "(B) Error Reporting",
        "wg": []
      },
      {
        "t": "(C) Trace",
        "en": "(C) Trace",
        "wg": []
      },
      {
        "t": "(D) Profiler",
        "en": "(D) Profiler",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Trace 是一個分散式追蹤系統，可以收集應用程式發出的請求延遲資料，並以視覺化方式呈現請求在各個微服務間的傳播路徑與耗時。這對於診斷效能瓶頸至關重要。Profiler 用於分析 CPU/記憶體使用，Debugger 用於除錯程式碼，Error Reporting 用於追蹤錯誤崩潰。",
      "en": "Cloud Trace is a distributed tracing system that collects latency data for requests served by your application and visualizes how requests propagate through your microservices. It is essential for diagnosing performance bottlenecks. Profiler is for CPU/memory analysis, Debugger is for code debugging, and Error Reporting is for tracking crashes.",
      "wg": [
        { "t": "分散式追蹤系統", "en": "distributed tracing system", "ps": "n" },
        { "t": "視覺化呈現", "en": "visualizes", "ps": "v" },
        { "t": "效能瓶頸", "en": "performance bottlenecks", "ps": "n" }
      ]
    }
  },
  {
    "no": "10",
    "level": "hard",
    "keywords": "Data Migration, Storage Transfer Service, Transfer Appliance, Cost",
    "question": [
      {
        "t": "如何安排將 100-TB 的檔案伺服器低成本、單向且一次性地遷移到 Google Cloud？資料將在單一地區頻繁存取。",
        "en": "How to arrange a low-cost, one-way and one-time migration a 100-TB file server to Google Cloud? Data will be frequently accessed from a single region.",
        "wg": [
          { "t": "低成本", "en": "low-cost", "ps": "adj" },
          { "t": "一次性遷移", "en": "one-time migration", "ps": "n" },
          { "t": "頻繁存取", "en": "frequently accessed", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Transfer Appliance。轉移到 Cloud Storage Standard 儲存桶。",
        "en": "(A) Use Transfer Appliance. Transfer to a Cloud Storage Standard bucket.",
        "wg": []
      },
      {
        "t": "(B) 使用 Transfer Appliance。轉移到 Cloud Storage Nearline 儲存桶。",
        "en": "(B) Use Transfer Appliance. Transfer to a Cloud Storage Nearline bucket.",
        "wg": []
      },
      {
        "t": "(C) 使用 Storage Transfer Service。轉移到 Cloud Storage Standard 儲存桶。",
        "en": "(C) Use Storage Transfer Service. Transfer to a Cloud Storage Standard bucket.",
        "wg": []
      },
      {
        "t": "(D) 使用 Storage Transfer Service。轉移到 Cloud Storage Coldline 儲存桶。",
        "en": "(D) Use Storage Transfer Service. Transfer to a Cloud Storage Coldline bucket.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "對於 100TB 的數據量，如果具備合理的上傳頻寬 (例如 1Gbps)，線上傳輸通常比實體設備 (Transfer Appliance) 更快且更便宜 (考慮到設備租賃和運輸時間)。Storage Transfer Service 是線上傳輸的理想工具。由於資料將被「頻繁存取」，Standard Storage 是最具成本效益的選擇 (避免存取費用)。",
      "en": "For 100TB of data, if reasonable upload bandwidth is available (e.g., 1Gbps), online transfer is often faster and cheaper than physical appliances (considering rental and shipping time of Transfer Appliance). Storage Transfer Service is the tool for online transfers. Since the data will be 'frequently accessed', Standard Storage is the most cost-effective class (avoiding access fees).",
      "wg": [
        { "t": "線上傳輸", "en": "online transfer", "ps": "n" },
        { "t": "上傳頻寬", "en": "upload bandwidth", "ps": "n" },
        { "t": "最具成本效益", "en": "most cost-effective", "ps": "adj" }
      ]
    }
  },{
    "no": "11",
    "level": "medium",
    "keywords": "Backup, Disaster Recovery, Storage Transfer Service, Nearline",
    "question": [
      {
        "t": "客戶希望安排從另一個雲端將多 TB 的資料庫定期備份到 Google Cloud，包括每月的災難復原 (DR) 演練。應該使用哪些服務？",
        "en": "Customer would like to arrange regular backups of multi-TB databases from another cloud to Google Cloud, including monthly DR drills. What services should be used?",
        "wg": [
          { "t": "定期備份", "en": "regular backups", "ps": "n" },
          { "t": "災難復原演練", "en": "disaster recovery drills", "ps": "n" },
          { "t": "服務", "en": "services", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Transfer Appliance。轉移到 Cloud Storage Nearline 儲存桶。",
        "en": "(A) Use Transfer Appliance. Transfer to Cloud Storage Nearline bucket.",
        "wg": []
      },
      {
        "t": "(B) 使用 Transfer Appliance。轉移到 Cloud Storage Coldline 儲存桶。",
        "en": "(B) Use Transfer Appliance. Transfer to Cloud Storage Coldline bucket.",
        "wg": []
      },
      {
        "t": "(C) 使用 Storage Transfer Service。轉移到 Cloud Storage Nearline 儲存桶。",
        "en": "(C) Use Storage Transfer Service. Transfer to Cloud Storage Nearline bucket.",
        "wg": []
      },
      {
        "t": "(D) 使用 Storage Transfer Service。轉移到 Cloud Storage Coldline 儲存桶。",
        "en": "(D) Use Storage Transfer Service. Transfer to Cloud Storage Coldline bucket.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "由於是「定期」且持續的資料傳輸，Storage Transfer Service 是正確的自動化工具 (Transfer Appliance 適用於一次性大規模遷移)。對於每月的 DR 演練，資料將每個月被存取一次，這使得 Nearline Storage (適合月度存取) 比 Coldline (適合季度存取) 更具成本效益，因為 Coldline 的資料擷取費用較高且最短儲存期較長。",
      "en": "Since this involves 'regular', ongoing data transfers, Storage Transfer Service is the correct automation tool (Transfer Appliance is for one-time bulk migration). For monthly DR drills, data will be accessed once a month, making Nearline Storage (monthly access) more cost-effective than Coldline (quarterly access) due to Coldline's higher retrieval fees and longer minimum retention period.",
      "wg": [
        { "t": "持續的資料傳輸", "en": "ongoing data transfers", "ps": "n" },
        { "t": "自動化工具", "en": "automation tool", "ps": "n" },
        { "t": "資料擷取費用", "en": "retrieval fees", "ps": "n" }
      ]
    }
  },
  {
    "no": "12",
    "level": "medium",
    "keywords": "Cloud SQL, Transactional, Strong Consistency, Data Size",
    "question": [
      {
        "t": "某應用程式具有以下資料需求：1. 需要強一致性的交易。2. 資料總量將小於 500 GB。3. 資料不需要是串流或即時的。哪種資料技術符合這些要求？",
        "en": "An application has the following data requirements. 1. It requires strongly consistent transactions. 2. Total data will be less than 500 GB. 3. The data does not need to be streaming or real time. Which data technology would fit these requirements?",
        "wg": [
          { "t": "強一致性", "en": "strongly consistent", "ps": "adj" },
          { "t": "交易", "en": "transactions", "ps": "n" },
          { "t": "資料技術", "en": "data technology", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) BigQuery",
        "en": "(A) BigQuery",
        "wg": []
      },
      {
        "t": "(B) Cloud Bigtable",
        "en": "(B) Cloud Bigtable",
        "wg": []
      },
      {
        "t": "(C) Cloud SQL",
        "en": "(C) Cloud SQL",
        "wg": []
      },
      {
        "t": "(D) Memorystore",
        "en": "(D) Memorystore",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud SQL 是一個完全託管的關聯式資料庫 (MySQL, PostgreSQL, SQL Server)，原生支援 ACID 交易和強一致性，非常適合 OLTP (線上交易處理)。500GB 的資料量完全在 Cloud SQL 的處理能力範圍內 (最高可達數十 TB)。BigQuery 適合分析 (OLAP)，Bigtable 是 NoSQL (最終一致性模型較常見)，Memorystore 是快取。",
      "en": "Cloud SQL is a fully managed relational database (MySQL, PostgreSQL, SQL Server) that natively supports ACID transactions and strong consistency, making it ideal for OLTP. The 500GB data size is well within Cloud SQL's capabilities (which scale to tens of TB). BigQuery is for analytics (OLAP), Bigtable is NoSQL, and Memorystore is for caching.",
      "wg": [
        { "t": "關聯式資料庫", "en": "relational database", "ps": "n" },
        { "t": "ACID 交易", "en": "ACID transactions", "ps": "n" },
        { "t": "完全託管", "en": "fully managed", "ps": "adj" }
      ]
    }
  },
  {
    "no": "13",
    "level": "medium",
    "keywords": "Bigtable, Time-series, IoT, High Throughput",
    "question": [
      {
        "t": "一家公司需要一個靈活的儲存解決方案，用於儲存將從數百萬個連網裝置擷取的大量時間序列資料。您會推薦哪種 GCP 服務？",
        "en": "A company needs a flexible storage solution for a vast amount of time-series data that will be ingested from millions of connected devices. What GCP service would you recommend?",
        "wg": [
          { "t": "靈活的儲存解決方案", "en": "flexible storage solution", "ps": "n" },
          { "t": "時間序列資料", "en": "time-series data", "ps": "n" },
          { "t": "連網裝置", "en": "connected devices", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Storage",
        "en": "(A) Cloud Storage",
        "wg": []
      },
      {
        "t": "(B) Cloud Spanner",
        "en": "(B) Cloud Spanner",
        "wg": []
      },
      {
        "t": "(C) Bigtable",
        "en": "(C) BigTable",
        "wg": []
      },
      {
        "t": "(D) Memorystore",
        "en": "(D) Memorystore",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Bigtable 是 Google 的高效能 NoSQL 寬欄位資料庫，專為高吞吐量寫入和低延遲讀取而設計。它是儲存 IoT (物聯網) 時間序列資料的理想選擇，因為它能夠處理每秒數百萬次的寫入操作，並且能夠橫向擴展到 PB 級別。這與「數百萬個連網裝置」和「大量資料」的需求完美匹配。",
      "en": "Cloud Bigtable is Google's high-performance NoSQL wide-column database, designed for high throughput writes and low latency reads. It is the ideal choice for storing IoT time-series data as it can handle millions of writes per second and scales horizontally to petabytes. This matches perfectly with 'millions of connected devices' and 'vast amount of data'.",
      "wg": [
        { "t": "高吞吐量寫入", "en": "high throughput writes", "ps": "n" },
        { "t": "橫向擴展", "en": "scales horizontally", "ps": "v" },
        { "t": "寬欄位資料庫", "en": "wide-column database", "ps": "n" }
      ]
    }
  },
  {
    "no": "14",
    "level": "hard",
    "keywords": "Cloud Spanner, Petabyte-scale, Relational, OLTP",
    "question": [
      {
        "t": "GlobalBank 想要建立一個需要 PB 級 (petabyte-scale) 資料的線上交易處理 (OLTP) 應用程式的關聯式資料庫。他們應該選擇哪種 GCP 儲存服務？",
        "en": "GlobalBank wants to build an online transactional processing application that requires a relational database with petabyte-scale data. What GCS storage service should they choose?",
        "wg": [
          { "t": "線上交易處理", "en": "online transactional processing", "ps": "n" },
          { "t": "關聯式資料庫", "en": "relational database", "ps": "n" },
          { "t": "PB 級", "en": "petabyte-scale", "ps": "adj" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud SQL",
        "en": "(A) Cloud SQL",
        "wg": []
      },
      {
        "t": "(B) BigTable",
        "en": "(B) BigTable",
        "wg": []
      },
      {
        "t": "(C) BigQuery",
        "en": "(C) BigQuery",
        "wg": []
      },
      {
        "t": "(D) Cloud Spanner",
        "en": "(D) Cloud Spanner",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud Spanner 是唯一能同時滿足「關聯式資料庫 (SQL, ACID, 強一致性)」和「PB 級全球水平擴展」這兩個條件的服務。Cloud SQL 雖然是關聯式的，但無法擴展到 PB 級寫入。Bigtable 是 PB 級的，但它是 NoSQL，不是關聯式。BigQuery 是 PB 級的，但它是 OLAP (分析)，不是 OLTP (交易)。",
      "en": "Cloud Spanner is the only service that meets both criteria: 'Relational Database (SQL, ACID, Strong Consistency)' and 'Petabyte-scale global horizontal scaling'. Cloud SQL is relational but cannot scale to petabyte-level writes. Bigtable is petabyte-scale but is NoSQL, not relational. BigQuery is petabyte-scale but is for OLAP (analytics), not OLTP (transactional).",
      "wg": [
        { "t": "水平擴展", "en": "horizontal scaling", "ps": "n" },
        { "t": "滿足條件", "en": "meets criteria", "ps": "v" },
        { "t": "分析", "en": "analytics", "ps": "n" }
      ]
    }
  },
  {
    "no": "15",
    "level": "medium",
    "keywords": "Cloud Storage, Availability, Multi-region, Replication",
    "question": [
      {
        "t": "您被要求在多個地區之間分發和同步 GCS 儲存桶以提高可用性。最簡單的方法是什麼？",
        "en": "You're requested to distribute and synchronize a GCS storage bucket between multiple regions for increased availability. What's the easiest way to do it?",
        "wg": [
          { "t": "分發", "en": "distribute", "ps": "v" },
          { "t": "同步", "en": "synchronize", "ps": "v" },
          { "t": "提高可用性", "en": "increased availability", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在不同地區部署單獨的儲存桶，並使用「儲存桶對儲存桶」複製功能。",
        "en": "(A) Deploy separate buckets in different regions and use 'bucket-to-bucket' replication functionality.",
        "wg": []
      },
      {
        "t": "(B) 在不同地區部署單獨的儲存桶，並在它們之間安排 rsync 程序。",
        "en": "(B) Deploy separate buckets in different regions and schedule an rsync process between them.",
        "wg": []
      },
      {
        "t": "(C) 部署單個雙地區 (dual-region) 或多地區 (multi-region) 儲存桶。",
        "en": "(C) Deploy a single dual or multi-region bucket.",
        "wg": []
      },
      {
        "t": "(D) 在不同地區部署單獨的儲存桶，然後在它們之間安排備份和還原工作。",
        "en": "(D) Deploy separate buckets in different regions, then schedule backup and restore job between them.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Google Cloud Storage 原生支援「多地區」(Multi-Region) 和「雙地區」(Dual-Region) 儲存桶類別。當您選擇這些選項時，Google 會自動在多個地理位置之間複製您的資料，以確保最高的可用性和地理備援，而無需您手動設定任何同步機制或管理多個儲存桶。這是最簡單且完全託管的解決方案。",
      "en": "Google Cloud Storage natively supports 'Multi-Region' and 'Dual-Region' bucket classes. When you select these options, Google automatically replicates your data across multiple geographic locations to ensure maximum availability and geo-redundancy, without requiring you to manually configure synchronization mechanisms or manage multiple buckets. This is the easiest and fully managed solution.",
      "wg": [
        { "t": "原生支援", "en": "natively supports", "ps": "v" },
        { "t": "地理備援", "en": "geo-redundancy", "ps": "n" },
        { "t": "完全託管", "en": "fully managed", "ps": "adj" }
      ]
    }
  },{
    "no": "16",
    "level": "hard",
    "keywords": "Cloud Storage, Compliance, Retention Policy, Bucket Lock, WORM",
    "question": [
      {
        "t": "為了滿足合規性要求，您在其中一個 GCS 儲存桶上定義了保留政策 (retention policy)，並執行了 'gsutil retention lock gs://BUCKET_NAME' 命令。您現在需要修改儲存桶中尚未過期的一些物件，但出現錯誤。您該如何解決？",
        "en": "In order to fulfill a compliance requirement, you defined a retention policy on one of GCS buckets and you executed 'gsutil retention lock gs://BUCKET_NAME' command. You now need to modify some objects from the bucket that did not expire yet and you get an error. How do you resolve it?",
        "wg": [
          { "t": "保留政策", "en": "retention policy", "ps": "n" },
          { "t": "執行", "en": "executed", "ps": "v" },
          { "t": "尚未過期", "en": "did not expire yet", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 您需要手動從儲存桶中移除鎖定並更新政策，以便可以修改物件。",
        "en": "(A) You need to manually remove the lock from the bucket and update the policy so that the object can be modified.",
        "wg": []
      },
      {
        "t": "(B) 您需要聯絡 GCP 支援為您移除鎖定。",
        "en": "(B) You need to contact the GCP support to remove the lock for you.",
        "wg": []
      },
      {
        "t": "(C) 您無法移除物件，直到它們滿足過期政策為止。",
        "en": "(C) You can't remove the object until they fulfill the expiration policy.",
        "wg": []
      },
      {
        "t": "(D) 執行 'gsutil rm' 命令時需要使用 --force 參數。",
        "en": "(D) You need to use --force parameter when executing the 'gsutil rm' command.",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Storage 的保留政策一旦被「鎖定」(Locked)，就進入了合規模式 (類似 WORM - Write Once, Read Many)。這意味著在物件達到保留期限之前，沒有任何人 (包括專案擁有者或 Google 支援) 可以覆寫或刪除該物件。這是為了滿足嚴格的監管要求 (如 FINRA, SEC)。",
      "en": "Once a retention policy is 'Locked' in Cloud Storage, it enters a compliance mode (similar to WORM - Write Once, Read Many). This means that absolutely no one (including Project Owners or Google Support) can overwrite or delete the object until the retention period has passed. This is designed to meet strict regulatory requirements (like FINRA, SEC).",
      "wg": [
        { "t": "合規模式", "en": "compliance mode", "ps": "n" },
        { "t": "覆寫", "en": "overwrite", "ps": "v" },
        { "t": "監管要求", "en": "regulatory requirements", "ps": "n" }
      ]
    }
  },
  {
    "no": "17",
    "level": "medium",
    "keywords": "Dataflow, Templates, Pipeline, Reusability",
    "question": [
      {
        "t": "Dataflow 範本 (Template) 的用途是什麼？",
        "en": "What is a Dataflow template used for?",
        "wg": [
          { "t": "範本", "en": "template", "ps": "n" },
          { "t": "用途", "en": "used for", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 定義一個可以使用不同參數執行多次的管線。",
        "en": "(A) To define a pipeline that can be executed multiple times with different parameters",
        "wg": []
      },
      {
        "t": "(B) 在處理之前儲存和組織資料來源。",
        "en": "(B) To store and organize data sources before processing",
        "wg": []
      },
      {
        "t": "(C) 直接將資料匯出到 Cloud Storage。",
        "en": "(C) To export data directly to Cloud Storage",
        "wg": []
      },
      {
        "t": "(D) 提供一組預定義轉換的版本控制集。",
        "en": "(D) To provide a versioned set of predefined transformations",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Dataflow 範本允許您將管線 (Pipeline) 打包並分發，使非開發人員 (如資料分析師或操作員) 能夠執行該管線，而無需設定開發環境或編寫程式碼。使用者在執行範本時可以傳入執行參數 (如輸入/輸出路徑、視窗大小等)，從而實現重複使用。",
      "en": "Dataflow Templates allow you to package and stage your pipelines so that non-developers (like data analysts or operators) can execute them without needing to set up a development environment or write code. Users can pass execution parameters (like input/output paths, window sizes) when running the template, enabling reusability.",
      "wg": [
        { "t": "打包", "en": "package", "ps": "v" },
        { "t": "非開發人員", "en": "non-developers", "ps": "n" },
        { "t": "執行參數", "en": "execution parameters", "ps": "n" }
      ]
    }
  },
  {
    "no": "18",
    "level": "hard",
    "keywords": "Dataflow, Shuffle, Optimization, Streaming",
    "question": [
      {
        "t": "Dataflow 的洗牌優化 (shuffle optimization) 功能的目的是什麼？",
        "en": "What is the purpose of Dataflow’s shuffle optimization feature?",
        "wg": [
          { "t": "洗牌優化", "en": "shuffle optimization", "ps": "n" },
          { "t": "目的", "en": "purpose", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 將大型輸入資料拆分為較小的區塊進行處理。",
        "en": "(A) To split large input data into smaller chunks for processing",
        "wg": []
      },
      {
        "t": "(B) 透過最小化資料洗牌的需求來減少串流處理的延遲。",
        "en": "(B) To reduce latency in stream processing by minimizing the need for data shuffling",
        "wg": []
      },
      {
        "t": "(C) 提高批次處理管線中聚合的準確性。",
        "en": "(C) To improve the accuracy of aggregations in batch pipelines",
        "wg": []
      },
      {
        "t": "(D) 對儲存在 BigQuery 中的資料進行分區。",
        "en": "(D) To partition data for storage in BigQuery",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "此題指的是將 Shuffle 操作從 Worker VM 中卸載到專用的服務後端。對於串流處理 (Streaming Engine)，這可以顯著減少延遲並提高自動擴展的響應速度，因為 Worker 不需要儲存洗牌狀態。註：雖然 Google 區分 'Dataflow Shuffle' (用於批次) 和 'Streaming Engine' (用於串流)，但此題將此概念統稱為洗牌優化功能並強調其減少延遲的優點。",
      "en": "This refers to offloading the Shuffle operation from Worker VMs to a dedicated service backend. For stream processing (Streaming Engine), this significantly reduces latency and improves autoscaling responsiveness because workers don't need to store shuffle state locally. Note: While Google technically distinguishes between 'Dataflow Shuffle' (for Batch) and 'Streaming Engine' (for Streaming), this question groups the concept under shuffle optimization features, highlighting the latency reduction benefit.",
      "wg": [
        { "t": "卸載", "en": "offloading", "ps": "v" },
        { "t": "串流處理", "en": "stream processing", "ps": "n" },
        { "t": "洗牌狀態", "en": "shuffle state", "ps": "n" }
      ]
    }
  },{
    "no": "1",
    "level": "easy",
    "keywords": "NoSQL, Relational Database, Schema",
    "question": [
      {
        "t": "哪一個是 NoSQL 具備但關聯式資料庫沒有的特性？",
        "en": "What is a NoSQL feature that is not available in relational databases?",
        "wg": [
          { "t": "NoSQL 特性", "en": "NoSQL feature", "ps": "n" },
          { "t": "關聯式資料庫", "en": "relational databases", "ps": "n" },
          { "t": "特性", "en": "feature", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 固定結構 (Fixed schemas)",
        "en": "(A) Fixed schemas",
        "wg": []
      },
      {
        "t": "(B) 彈性結構 (Flexible schemas)",
        "en": "(B) Flexible schemas",
        "wg": []
      },
      {
        "t": "(C) ACID 交易 (ACID transactions)",
        "en": "(C) ACID transactions",
        "wg": []
      },
      {
        "t": "(D) 索引 (Indexes)",
        "en": "(D) Indexes",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "關聯式資料庫 (RDBMS) 需要預先定義固定的 Schema (資料表結構)。NoSQL 資料庫的主要優勢之一是其結構的靈活性 (Schema-less 或 Flexible schema)，允許在不修改整個資料庫結構的情況下儲存不同格式的資料。索引和 ACID 交易在許多 RDBMS 中都是核心功能。",
      "en": "Relational databases (RDBMS) require a pre-defined, fixed schema. One of the primary features of NoSQL databases is their schema flexibility (schema-less or flexible schema), allowing data of different formats to be stored without modifying the database structure. Indexes and ACID transactions are core features available in RDBMS.",
      "wg": [
        { "t": "預先定義", "en": "pre-defined", "ps": "v" },
        { "t": "靈活性", "en": "flexibility", "ps": "n" },
        { "t": "核心功能", "en": "core features", "ps": "n" }
      ]
    }
  },
  {
    "no": "2",
    "level": "easy",
    "keywords": "Hadoop, Spark, Dataproc, Managed Service",
    "question": [
      {
        "t": "哪個產品提供託管的 Hadoop 叢集？",
        "en": "Which product provides a managed Hadoop cluster?",
        "wg": [
          { "t": "託管", "en": "managed", "ps": "adj" },
          { "t": "Hadoop 叢集", "en": "Hadoop cluster", "ps": "n" },
          { "t": "產品", "en": "product", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Pub/Sub",
        "en": "(A) Cloud Pub/Sub",
        "wg": []
      },
      {
        "t": "(B) BigQuery",
        "en": "(B) BigQuery",
        "wg": []
      },
      {
        "t": "(C) Cloud Dataproc",
        "en": "(C) Cloud Dataproc",
        "wg": []
      },
      {
        "t": "(D) Cloud Dataflow",
        "en": "(D) Cloud Dataflow",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Dataproc 是 Google Cloud 上的全託管 Spark 和 Hadoop 服務，允許使用者快速建立和管理叢集以處理大數據。Cloud Dataflow 是用於串流和批次處理的服務 (基於 Apache Beam)，BigQuery 是資料倉儲，Pub/Sub 是訊息傳遞服務。",
      "en": "Cloud Dataproc is the fully managed Spark and Hadoop service on Google Cloud, allowing users to quickly create and manage clusters for big data processing. Cloud Dataflow is for stream and batch processing (Apache Beam based), BigQuery is a data warehouse, and Pub/Sub is a messaging service.",
      "wg": [
        { "t": "全託管", "en": "fully managed", "ps": "adj" },
        { "t": "處理大數據", "en": "processing big data", "ps": "v" },
        { "t": "訊息傳遞服務", "en": "messaging service", "ps": "n" }
      ]
    }
  },
  {
    "no": "3",
    "level": "medium",
    "keywords": "Load Balancing, WebSockets, Migration",
    "question": [
      {
        "t": "現有的應用程式使用 WebSocket。為了協助將應用程式遷移到雲端，您應該怎麼做？",
        "en": "An existing application uses websockets. To help migrate the application to cloud you should:",
        "wg": [
          { "t": "WebSocket", "en": "websockets", "ps": "n" },
          { "t": "遷移", "en": "migrate", "ps": "v" },
          { "t": "應用程式", "en": "application", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 對應用程式不做任何更動。HTTP(S) 負載平衡原生支援 WebSocket 代理。",
        "en": "(A) Do nothing to the application. HTTP(S) load balancing natively supports websocket proxying.",
        "wg": [
          { "t": "原生支援", "en": "natively supports", "ps": "v" },
          { "t": "代理", "en": "proxying", "ps": "n" }
        ]
      },
      {
        "t": "(B) 重新設計應用程式以使用 HTTP 串流。",
        "en": "(B) Redesign the application to use HTTP streaming.",
        "wg": []
      },
      {
        "t": "(C) 與安全團隊審查 WebSocket 加密需求。",
        "en": "(C) Review websocket encryption requirements with the security team.",
        "wg": []
      },
      {
        "t": "(D) 重新設計應用程式以使用分散式工作階段代替 WebSocket。",
        "en": "(D) Redesign the application to use distributed sessions instead of websockets.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Google Cloud 的 HTTP(S) 負載平衡器原生支援 WebSocket 協定。當用戶端發送 HTTP Upgrade 請求時，負載平衡器可以建立並維護與後端實例的 WebSocket 連接，因此通常不需要為了遷移而更改應用程式架構。",
      "en": "Google Cloud's HTTP(S) Load Balancers natively support the WebSocket protocol. When a client sends an HTTP Upgrade request, the load balancer can establish and maintain the WebSocket connection to the backend instances, so typically no architectural changes to the application are required for migration.",
      "wg": [
        { "t": "原生支援", "en": "natively support", "ps": "v" },
        { "t": "協定", "en": "protocol", "ps": "n" },
        { "t": "架構", "en": "architectural", "ps": "adj" }
      ]
    }
  },
  {
    "no": "4",
    "level": "hard",
    "keywords": "Security, SSH, IAM, Operations",
    "question": [
      {
        "t": "安全團隊已經鎖定了對生產環境 VM 的 SSH 存取權限。維運團隊在無法 SSH 進入這些機器的情況下，如何仍然能夠管理 VM？",
        "en": "The security team has locked out SSH access to production VMs. How can operations still manage the VMs, without being able to ssh into those machines?",
        "wg": [
          { "t": "鎖定", "en": "locked out", "ps": "v" },
          { "t": "SSH 存取權限", "en": "SSH access", "ps": "n" },
          { "t": "管理", "en": "manage", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 授予維運團隊適當的 IAM 角色，以便使用 gcloud 命令管理 VM。",
        "en": "(A) Grant operations team appropriate IAM roles to manage VMs with gcloud commands",
        "wg": [
          { "t": "授予", "en": "Grant", "ps": "v" },
          { "t": "IAM 角色", "en": "IAM roles", "ps": "n" }
        ]
      },
      {
        "t": "(B) 設定 VPN 以允許 SSH 存取 VM。",
        "en": "(B) Configure a VPN to allow SSH access to VMs",
        "wg": []
      },
      {
        "t": "(C) 開發一個 Cloud API 應用程式來執行所有維運操作。",
        "en": "(C) Develop a Cloud API application for all operations actions",
        "wg": []
      },
      {
        "t": "(D) 開發一個授予臨時 SSH 存取權限的應用程式。",
        "en": "(D) Develop an application that grants temporary SSH access",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "許多 VM 管理任務 (如啟動、停止、調整大小、修改中繼資料) 是透過呼叫 Google Cloud API 完成的，而不是透過 SSH 進入作業系統內部。`gcloud compute` 命令行工具使用 Cloud API。因此，只要使用者擁有適當的 IAM 角色 (如 Compute Instance Admin)，即使無法 SSH 登入，他們仍然可以管理 VM 的基礎設施層面。",
      "en": "Many VM management tasks (like starting, stopping, resizing, modifying metadata) are performed by calling Google Cloud APIs, not by SSHing into the OS. The `gcloud compute` command-line tool uses Cloud APIs. Therefore, as long as users have the appropriate IAM roles (like Compute Instance Admin), they can still manage the infrastructure aspect of the VMs even without SSH access.",
      "wg": [
        { "t": "管理任務", "en": "management tasks", "ps": "n" },
        { "t": "基礎設施層面", "en": "infrastructure aspect", "ps": "n" },
        { "t": "呼叫", "en": "calling", "ps": "v" }
      ]
    }
  },
  {
    "no": "5",
    "level": "medium",
    "keywords": "Shared VPC, Networking, RFC1918, Cross-project",
    "question": [
      {
        "t": "由不同專案團隊擁有的應用程式部分，如何透過 RFC1918 (私有) 位址進行通訊？",
        "en": "How can application parts, owned by different project teams, communicate over RFC1918 addresses?",
        "wg": [
          { "t": "不同專案團隊", "en": "different project teams", "ps": "n" },
          { "t": "RFC1918 位址", "en": "RFC1918 addresses", "ps": "n" },
          { "t": "通訊", "en": "communicate", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 單一專案，同一個 VPC。",
        "en": "(A) Single project, same VPC",
        "wg": []
      },
      {
        "t": "(B) 透過全球負載平衡器通訊，每個專案一個。",
        "en": "(B) Communicate over global load balancers, one per project",
        "wg": []
      },
      {
        "t": "(C) 各部分使用 HTTPS 進行通訊。",
        "en": "(C) Parts communicate using HTTPS",
        "wg": []
      },
      {
        "t": "(D) 共用 VPC (Shared VPC)，每個團隊的專案都是共用 VPC 專案的服務專案。",
        "en": "(D) Shared VPC, each team's project a service of the Shared VPC project",
        "wg": [
          { "t": "共用 VPC", "en": "Shared VPC", "ps": "n" },
          { "t": "服務專案", "en": "service of", "ps": "n" }
        ]
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "共用 VPC (Shared VPC) 允許組織將多個專案 (稱為服務專案) 連接到一個共同的 VPC 網路 (位於宿主專案中)。這使得不同專案中的資源可以使用內部 IP (RFC1918) 安全且高效地相互通訊，同時保持專案間的管理隔離 (如由不同團隊擁有)。",
      "en": "Shared VPC allows an organization to connect multiple projects (called Service Projects) to a common VPC network (hosted in a Host Project). This enables resources in different projects to communicate with each other securely and efficiently using internal IPs (RFC1918), while maintaining administrative isolation between projects (owned by different teams).",
      "wg": [
        { "t": "共用 VPC", "en": "Shared VPC", "ps": "n" },
        { "t": "內部 IP", "en": "internal IPs", "ps": "n" },
        { "t": "管理隔離", "en": "administrative isolation", "ps": "n" }
      ]
    }
  },{
    "no": "6",
    "level": "medium",
    "keywords": "Cloud Spanner, RDBMS, Scalability, Consistency",
    "question": [
      {
        "t": "哪種儲存服務提供全球一致、可水平擴展的 RDBMS？",
        "en": "Which storage service provides a globally consistent, horizontally scalable RDBMS?",
        "wg": [
          { "t": "全球一致", "en": "globally consistent", "ps": "adj" },
          { "t": "可水平擴展", "en": "horizontally scalable", "ps": "adj" },
          { "t": "RDBMS", "en": "RDBMS", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Firestore",
        "en": "(A) Cloud Firestore",
        "wg": []
      },
      {
        "t": "(B) Cloud Bigtable",
        "en": "(B) Cloud Bigtable",
        "wg": []
      },
      {
        "t": "(C) Cloud Spanner",
        "en": "(C) Cloud Spanner",
        "wg": []
      },
      {
        "t": "(D) BigQuery",
        "en": "(D) BigQuery",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Spanner 是 Google Cloud 獨有的資料庫服務，它結合了關聯式資料庫 (RDBMS) 的特性 (如 SQL、ACID 交易、強一致性) 與 NoSQL 資料庫的可擴展性 (如全球分佈、水平擴展)。這是唯一符合「全球一致性」且「可水平擴展」的 RDBMS 選項。",
      "en": "Cloud Spanner is a unique database service on Google Cloud that combines the features of a relational database (RDBMS) (like SQL, ACID transactions, strong consistency) with the scalability of a NoSQL database (like global distribution, horizontal scaling). It is the only option that fits 'globally consistent' and 'horizontally scalable' RDBMS.",
      "wg": [
        { "t": "獨有的", "en": "unique", "ps": "adj" },
        { "t": "結合", "en": "combines", "ps": "v" },
        { "t": "特性", "en": "features", "ps": "n" }
      ]
    }
  },
  {
    "no": "7",
    "level": "hard",
    "keywords": "Autoscaling, Managed Instance Group, Thrashing, Stabilization",
    "question": [
      {
        "t": "一個託管實例群組 (MIG) 正在發生震盪 (Thrashing)：它不斷增加更多 VM，然後將其關閉。VM 運作正常。您該如何修復？",
        "en": "A managed instance group is thrashing: it keeps adding more VMs, and then shutting them down. The VMs are working properly. How would you fix it?",
        "wg": [
          { "t": "震盪", "en": "thrashing", "ps": "v" },
          { "t": "託管實例群組", "en": "managed instance group", "ps": "n" },
          { "t": "修復", "en": "fix", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 增加自動縮放器在做出決定時考慮的時間 (冷卻時間)。",
        "en": "(A) By increasing the time autoscalers consider when making decisions",
        "wg": [
          { "t": "增加", "en": "increasing", "ps": "v" },
          { "t": "做出決定", "en": "making decisions", "ps": "v" }
        ]
      },
      {
        "t": "(B) 減少實例群組中的最小 VM 數量。",
        "en": "(B) By decreasing the minimum number of VMs in the instance group",
        "wg": []
      },
      {
        "t": "(C) 增加實例群組中的最大 VM 數量。",
        "en": "(C) By increasing the maximum number of VMs in the instance group",
        "wg": []
      },
      {
        "t": "(D) 減少自動縮放器在做出決定時考慮的時間。",
        "en": "(D) By decreasing the time autoscalers consider when making decisions",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "「震盪」(Thrashing) 通常是因為自動縮放器 (Autoscaler) 對負載波動反應過度敏感，導致頻繁的擴展 (Scale-out) 和縮減 (Scale-in)。增加「冷卻時間」(Cool-down period) 或決策考慮的時間視窗，可以讓縮放器等待更長的時間來確認負載變化是否持續，從而平滑擴縮操作並穩定群組大小。",
      "en": "'Thrashing' usually occurs when the Autoscaler is too sensitive to load fluctuations, causing frequent scale-out and scale-in actions. Increasing the 'cool-down period' or the time window considered for decisions allows the scaler to wait longer to verify if the load change is sustained, thereby smoothing out scaling operations and stabilizing the group size.",
      "wg": [
        { "t": "反應過度敏感", "en": "too sensitive", "ps": "adj" },
        { "t": "負載波動", "en": "load fluctuations", "ps": "n" },
        { "t": "平滑", "en": "smoothing out", "ps": "v" }
      ]
    }
  },
  {
    "no": "8",
    "level": "hard",
    "keywords": "Logging, Monitoring, Alerting, Microservices",
    "question": [
      {
        "t": "一個微服務有間歇性問題，會導致日誌爆發。您如何能在問題發生時準確捕捉到時機來分析日誌？",
        "en": "A microservice has intermittent problems that bursts logs. How can you spot the right time to analyze the logs as issues happen?",
        "wg": [
          { "t": "間歇性問題", "en": "intermittent problems", "ps": "n" },
          { "t": "日誌爆發", "en": "bursts logs", "ps": "v" },
          { "t": "分析", "en": "analyze", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 登入運行微服務的機器並等待日誌訊息。",
        "en": "(A) Log into the machine running the microservice and wait for the log messages.",
        "wg": []
      },
      {
        "t": "(B) 在 Error Reporting 儀表板中尋找錯誤。",
        "en": "(B) Look for error in Error Reporting dashboard.",
        "wg": []
      },
      {
        "t": "(C) 配置微服務將追蹤傳送到 Cloud Trace。",
        "en": "(C) Configure microservice to send traces to Cloud Trace.",
        "wg": []
      },
      {
        "t": "(D) 在 Cloud Logging 中設定日誌指標 (Log Metric)，並針對超過閾值的情況發出警報。",
        "en": "(D) Set a log metric in Cloud Logging, and alert on it past a threshold.",
        "wg": [
          { "t": "日誌指標", "en": "log metric", "ps": "n" },
          { "t": "閾值", "en": "threshold", "ps": "n" },
          { "t": "警報", "en": "alert", "ps": "v" }
        ]
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "對於間歇性且會導致日誌量激增 (Burst) 的問題，被動等待或手動檢查通常效率低下。最佳做法是建立一個「以日誌為基礎的指標」(Log-based Metric) 來計算特定錯誤日誌的出現次數，然後在 Cloud Monitoring 中設定一個警報政策 (Alerting Policy)。當錯誤率超過設定的閾值時，系統會自動通知您，讓您能即時介入分析。",
      "en": "For intermittent problems that cause log bursts, passive waiting or manual checking is inefficient. The best practice is to create a 'Log-based Metric' that counts the occurrences of specific error logs, and then set an Alerting Policy in Cloud Monitoring. When the error rate exceeds a threshold, the system automatically notifies you, allowing for timely analysis.",
      "wg": [
        { "t": "最佳做法", "en": "best practice", "ps": "n" },
        { "t": "計算", "en": "counts", "ps": "v" },
        { "t": "即時介入", "en": "timely intervention", "ps": "n" }
      ]
    }
  },
  {
    "no": "9",
    "level": "medium",
    "keywords": "Decoupling, Microservices, Pub/Sub, Asynchronous",
    "question": [
      {
        "t": "一個應用程式在微服務之間進行同步通訊。哪種方法可以解耦 (Decouple) 這些微服務？",
        "en": "An application synchronously communicates between microservices. Which approach will decouple the microservices?",
        "wg": [
          { "t": "同步通訊", "en": "synchronously communicates", "ps": "v" },
          { "t": "解耦", "en": "decouple", "ps": "v" },
          { "t": "微服務", "en": "microservices", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 建立一個 Bigtable 資料庫，發送者寫入，接收者讀取。",
        "en": "(A) Create a Bigtable database that sender writes and receiver reads",
        "wg": []
      },
      {
        "t": "(B) 建立一個 Pub/Sub 主題，發送者寫入，接收者讀取。",
        "en": "(B) Create a Pub/Sub topic that sender writes and receiver reads",
        "wg": [
          { "t": "Pub/Sub 主題", "en": "Pub/Sub topic", "ps": "n" },
          { "t": "發送者", "en": "sender", "ps": "n" },
          { "t": "接收者", "en": "receiver", "ps": "n" }
        ]
      },
      {
        "t": "(C) 建立一個 Cloud Storage 儲存桶，發送者寫入，接收者讀取。",
        "en": "(C) Create a Cloud Storage bucket that sender writes and receiver reads",
        "wg": []
      },
      {
        "t": "(D) 讓發送者寫入本地磁碟；接收者唯讀掛載該磁碟。",
        "en": "(D) Have sender write to local drives; receiver mounts drives read-only",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "要將同步通訊轉換為非同步通訊以實現解耦，訊息佇列 (Message Queue) 或發布/訂閱 (Pub/Sub) 模式是標準解決方案。Cloud Pub/Sub 允許發送服務將訊息發佈到主題，而接收服務訂閱該主題。這樣發送者不需要等待接收者處理完畢，甚至不需要知道接收者是否存在。",
      "en": "To convert synchronous communication to asynchronous communication for decoupling, a Message Queue or Pub/Sub pattern is the standard solution. Cloud Pub/Sub allows the sending service to publish messages to a topic, and the receiving service to subscribe to it. This way, the sender doesn't need to wait for the receiver to process, or even know if the receiver exists.",
      "wg": [
        { "t": "非同步通訊", "en": "asynchronous communication", "ps": "n" },
        { "t": "發布/訂閱", "en": "Pub/Sub", "ps": "n" },
        { "t": "標準解決方案", "en": "standard solution", "ps": "n" }
      ]
    }
  },
  {
    "no": "10",
    "level": "medium",
    "keywords": "Migration, SQL Server, Cloud SQL, Database",
    "question": [
      {
        "t": "將 SQL Server 應用程式遷移到 GCP 時，哪個 DBMS 服務可能是最容易遷移的目標？",
        "en": "When migrating a SQL Server application to GCP, which DBMS service may be easiest to move to?",
        "wg": [
          { "t": "遷移", "en": "migrating", "ps": "v" },
          { "t": "SQL Server 應用程式", "en": "SQL Server application", "ps": "n" },
          { "t": "最容易", "en": "easiest", "ps": "adj" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Dataproc",
        "en": "(A) Cloud Dataproc",
        "wg": []
      },
      {
        "t": "(B) Cloud Bigtable",
        "en": "(B) Cloud Bigtable",
        "wg": []
      },
      {
        "t": "(C) Cloud PostgreSQL",
        "en": "(C) Cloud PostgreSQL",
        "wg": []
      },
      {
        "t": "(D) Cloud SQL",
        "en": "(D) Cloud SQL",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud SQL 是一項全託管服務，支援 MySQL、PostgreSQL 和 **SQL Server**。因此，對於現有的 Microsoft SQL Server 應用程式，直接遷移到 Cloud SQL for SQL Server 通常是阻力最小的路徑，因為它提供了高度的相容性，且無需更改應用程式程式碼或資料庫引擎。",
      "en": "Cloud SQL is a fully managed service that supports MySQL, PostgreSQL, and **SQL Server**. Therefore, for an existing Microsoft SQL Server application, migrating directly to Cloud SQL for SQL Server is typically the path of least resistance (\"lift and shift\"), as it provides high compatibility without needing to change application code or the database engine.",
      "wg": [
        { "t": "全託管服務", "en": "fully managed service", "ps": "n" },
        { "t": "阻力最小的路徑", "en": "path of least resistance", "ps": "n" },
        { "t": "相容性", "en": "compatibility", "ps": "n" }
      ]
    }
  },{
    "no": "11",
    "level": "medium",
    "keywords": "ETL, Dataflow, Apache Beam, Transformation",
    "question": [
      {
        "t": "哪一個產品使用 Apache Beam API 來提供 ETL 服務中的轉換 (Transformation) 部分？",
        "en": "Which product uses the Apache Beam API to provide transformation part in ETL services?",
        "wg": [
          { "t": "Apache Beam API", "en": "Apache Beam API", "ps": "n" },
          { "t": "轉換", "en": "transformation", "ps": "n" },
          { "t": "ETL 服務", "en": "ETL services", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Pub/Sub",
        "en": "(A) Cloud Pub/Sub",
        "wg": []
      },
      {
        "t": "(B) Cloud Dataproc",
        "en": "(B) Cloud Dataproc",
        "wg": []
      },
      {
        "t": "(C) Cloud Dataflow",
        "en": "(C) Cloud Dataflow",
        "wg": []
      },
      {
        "t": "(D) BigQuery",
        "en": "(D) BigQuery",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Dataflow 是 Google 針對 Apache Beam SDK 的全託管執行引擎。Apache Beam 是一個統一的程式設計模型，用於定義批次和串流資料處理管線。ETL 中的 'T' (Transformation，轉換) 正是 Dataflow 的核心功能，它負責執行 Beam 定義的邏輯來處理資料。",
      "en": "Cloud Dataflow is Google's fully managed execution engine for the Apache Beam SDK. Apache Beam is a unified programming model for defining both batch and streaming data processing pipelines. The 'T' (Transformation) in ETL is the core function of Dataflow, which executes the logic defined in Beam to process the data.",
      "wg": [
        { "t": "全託管執行引擎", "en": "fully managed execution engine", "ps": "n" },
        { "t": "統一的程式設計模型", "en": "unified programming model", "ps": "n" },
        { "t": "核心功能", "en": "core function", "ps": "n" }
      ]
    }
  },
  {
    "no": "12",
    "level": "medium",
    "keywords": "Kafka, Pub/Sub, Managed Service, Messaging",
    "question": [
      {
        "t": "哪一個原生 GCP 服務提供了 Apache Kafka 服務的託管替代方案？",
        "en": "Which native GCP service provides a managed alternative to Apache Kafka service?",
        "wg": [
          { "t": "原生", "en": "native", "ps": "adj" },
          { "t": "託管替代方案", "en": "managed alternative", "ps": "n" },
          { "t": "Apache Kafka", "en": "Apache Kafka", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Pub/Sub",
        "en": "(A) Cloud Pub/Sub",
        "wg": []
      },
      {
        "t": "(B) BigQuery",
        "en": "(B) BigQuery",
        "wg": []
      },
      {
        "t": "(C) Cloud Dataflow",
        "en": "(C) Cloud Dataflow",
        "wg": []
      },
      {
        "t": "(D) Cloud Dataproc",
        "en": "(D) Cloud Dataproc",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Apache Kafka 是一個流行的開源分散式事件串流平台。Google Cloud Pub/Sub 是一個全球性、全託管的即時訊息傳遞服務，它解決了與 Kafka 類似的問題 (大規模資料擷取、解耦系統)，並且是無伺服器的 (Serverless)，無需像管理 Kafka 叢集那樣維護基礎設施。因此，它是 Kafka 在 GCP 上的主要託管替代方案。",
      "en": "Apache Kafka is a popular open-source distributed event streaming platform. Google Cloud Pub/Sub is a global, fully managed real-time messaging service that solves similar problems (ingesting data at scale, decoupling systems) and is serverless, meaning you don't need to maintain infrastructure like you would with a Kafka cluster. Thus, it is the primary managed alternative on GCP.",
      "wg": [
        { "t": "分散式事件串流", "en": "distributed event streaming", "ps": "n" },
        { "t": "全託管", "en": "fully managed", "ps": "adj" },
        { "t": "無伺服器的", "en": "Serverless", "ps": "adj" }
      ]
    }
  },
  {
    "no": "13",
    "level": "hard",
    "keywords": "Compute Engine, Network Bandwidth, vCPUs, Performance",
    "question": [
      {
        "t": "對於預設 VPC 上具有 2 個 vCPU 和 8 GB 記憶體的虛擬機，哪種變更會增加其網路頻寬？",
        "en": "Which change would increase network bandwidth for a virtual machine with 2 vCPUs and 8 GB memory on the default VPC?",
        "wg": [
          { "t": "增加", "en": "increase", "ps": "v" },
          { "t": "網路頻寬", "en": "network bandwidth", "ps": "n" },
          { "t": "變更", "en": "change", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 指派自訂機器類型 (Custom Machine Type)。",
        "en": "(A) Assign a Custom Machine Type",
        "wg": []
      },
      {
        "t": "(B) 指派 32 GB 記憶體。",
        "en": "(B) Assign 32 GB Memory",
        "wg": []
      },
      {
        "t": "(C) 指派 4 個網路介面。",
        "en": "(C) Assign 4 Network Interfaces",
        "wg": []
      },
      {
        "t": "(D) 指派 16 個 vCPU。",
        "en": "(D) Assign 16 vCPUs",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "在 Google Compute Engine 中，虛擬機的最大出站網路頻寬 (Egress bandwidth) 與其 vCPU 數量成正比。每個 vCPU 提供 2 Gbps 的頻寬，直到達到該機器類型的理論上限 (例如 N1/N2 等級通常最高 32 Gbps)。因此，從 2 vCPU 增加到 16 vCPU 會顯著增加可用的網路吞吐量。",
      "en": "In Google Compute Engine, a VM's maximum egress network bandwidth is directly proportional to its number of vCPUs. Each vCPU provides 2 Gbps of bandwidth, up to a theoretical maximum for the machine type (e.g., typically 32 Gbps for N1/N2). Therefore, increasing from 2 vCPUs to 16 vCPUs will significantly increase the available network throughput.",
      "wg": [
        { "t": "成正比", "en": "directly proportional", "ps": "adj" },
        { "t": "理論上限", "en": "theoretical maximum", "ps": "n" },
        { "t": "吞吐量", "en": "throughput", "ps": "n" }
      ]
    }
  },
  {
    "no": "14",
    "level": "hard",
    "keywords": "Pub/Sub, Decoupling, Workload Spikes, Architecture",
    "question": [
      {
        "t": "如何在不增加 VM 數量的情況下，避免在工作負載高峰期間遺失傳入的資料？",
        "en": "How to avoid dropped incoming data during workload spikes - without increasing the number of VMs?",
        "wg": [
          { "t": "避免遺失", "en": "avoid dropped", "ps": "v" },
          { "t": "工作負載高峰", "en": "workload spikes", "ps": "n" },
          { "t": "不增加 VM", "en": "without increasing VMs", "ps": "adv" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 為 VM 增加記憶體。",
        "en": "(A) Add memory to the VMs",
        "wg": []
      },
      {
        "t": "(B) 寫入 Cloud Pub/Sub，並讓 VM 從佇列中讀取。",
        "en": "(B) Write to Cloud Pub/Sub and have VMs read from queue",
        "wg": [
          { "t": "佇列", "en": "queue", "ps": "n" },
          { "t": "寫入", "en": "Write to", "ps": "v" }
        ]
      },
      {
        "t": "(C) 寫入 Cloud Memorystore，並讓 VM 從快取中讀取。",
        "en": "(C) Write to Cloud Memorystore and have VMs read from cache",
        "wg": []
      },
      {
        "t": "(D) 在 VM 上使用本地 SSD。",
        "en": "(D) Use local SSDs on VMs",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "使用 Cloud Pub/Sub 引入了「緩衝區」(Buffer) 機制。在流量高峰期間，Pub/Sub 可以攝取並持久化儲存大量的傳入訊息，而無需後端 VM 立即處理。VM 可以按照自己的處理能力 (Pull 或 Push 速率) 從 Pub/Sub 中消費訊息，從而「削減峰值」(Peak shaving)，防止因後端過載而導致資料遺失。",
      "en": "Using Cloud Pub/Sub introduces a 'buffer' mechanism. During traffic spikes, Pub/Sub can ingest and durably store a massive volume of incoming messages without requiring immediate processing by backend VMs. The VMs can then consume messages from Pub/Sub at their own pace, effectively 'shaving the peak' and preventing data loss due to backend overload.",
      "wg": [
        { "t": "緩衝區", "en": "buffer", "ps": "n" },
        { "t": "持久化儲存", "en": "durably store", "ps": "v" },
        { "t": "削減峰值", "en": "Peak shaving", "ps": "n" }
      ]
    }
  },
  {
    "no": "15",
    "level": "medium",
    "keywords": "Managed Instance Group, Health Check, Troubleshooting, Lifecycle",
    "question": [
      {
        "t": "一個應用程式運行在託管實例群組 (MIG) 上，但無法服務傳入的請求。什麼可能是最可能的原因 (從下列選項中)？",
        "en": "An application is running on a managed instance group, but it is not able to serve the incoming requests. What might be the most probable reason (out of those listed below)?",
        "wg": [
          { "t": "無法服務", "en": "not able to serve", "ps": "v" },
          { "t": "託管實例群組", "en": "managed instance group", "ps": "n" },
          { "t": "最可能的原因", "en": "most probable reason", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 當健康檢查失敗時，VM 關閉並啟動新的 VM。",
        "en": "(A) VM shuts down when the health check fails & a new VM starts",
        "wg": []
      },
      {
        "t": "(B) 當實例群組的生存時間 (TTL) 到期時，應用程式關閉。",
        "en": "(B) The application shuts down when the instance group time-to-live expires",
        "wg": []
      },
      {
        "t": "(C) 當健康檢查失敗時，應用程式關閉。",
        "en": "(C) The application shuts down when the health check fails",
        "wg": []
      },
      {
        "t": "(D) 當實例群組生存時間到期時，VM 關閉；新的 VM 啟動。",
        "en": "(D) VM shuts down when instance group time-to-live expires; a new VM starts",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "MIG 依賴健康檢查 (Health Check) 來監控 VM 的狀態。如果健康檢查偵測到應用程式無回應 (例如因為應用程式崩潰或過載)，MIG 會將該 VM 標記為不健康，並自動啟動「自動修復」(Auto-healing) 過程：終止不健康的 VM 並重新建立一個新的 VM。在新 VM 準備好之前，請求無法被服務。",
      "en": "MIGs rely on Health Checks to monitor the status of VMs. If the health check detects that the application is unresponsive (e.g., crashed or overloaded), the MIG marks the VM as unhealthy and automatically initiates the 'Auto-healing' process: terminating the unhealthy VM and recreating a new one. During this cycle, requests cannot be served until the new VM is ready.",
      "wg": [
        { "t": "健康檢查", "en": "Health Check", "ps": "n" },
        { "t": "自動修復", "en": "Auto-healing", "ps": "n" },
        { "t": "終止", "en": "terminating", "ps": "v" }
      ]
    }
  },{
    "no": "16",
    "level": "medium",
    "keywords": "CDN, Performance, Latency, Static Content",
    "question": [
      {
        "t": "其他地區的使用者載入靜態網頁資料的速度很慢。您如何能最有效地改善效能？",
        "en": "Static web data loads slowly for users in other regions. How can you best improve peformance?",
        "wg": [
          { "t": "靜態網頁資料", "en": "Static web data", "ps": "n" },
          { "t": "改善效能", "en": "improve peformance", "ps": "v" },
          { "t": "其他地區", "en": "other regions", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud CDN 分發資料。",
        "en": "(A) Distribute data using Cloud CDN",
        "wg": []
      },
      {
        "t": "(B) 擴大 VM 的規模。",
        "en": "(B) Scale up the size of the VMs",
        "wg": []
      },
      {
        "t": "(C) 為 VM 使用 Premium Network。",
        "en": "(C) Use Premium Network for VMs",
        "wg": []
      },
      {
        "t": "(D) 將 VM 移動到離使用者更近的位置。",
        "en": "(D) Move the VMs to a location nearer the users",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "對於靜態內容 (如圖片、CSS、JS)，最佳的解決方案是使用內容傳遞網路 (CDN)。Cloud CDN 會將這些內容快取到 Google 的全球邊緣節點 (Edge Points)，讓使用者能從最近的地理位置獲取資料，從而顯著降低延遲並減輕後端伺服器的負載。這比移動 VM 或擴充規格更有效且成本更低。",
      "en": "For static content (images, CSS, JS), the best solution is to use a Content Delivery Network (CDN). Cloud CDN caches this content at Google's global edge points, allowing users to fetch data from the geographically closest location, significantly reducing latency and offloading the backend servers. This is more effective and cost-efficient than moving VMs or scaling them up.",
      "wg": [
        { "t": "內容傳遞網路", "en": "Content Delivery Network", "ps": "n" },
        { "t": "快取", "en": "caches", "ps": "v" },
        { "t": "邊緣節點", "en": "edge points", "ps": "n" }
      ]
    }
  },
  {
    "no": "17",
    "level": "easy",
    "keywords": "NoSQL, Document Store, JSON, Firestore",
    "question": [
      {
        "t": "您會選擇什麼作為 JSON 文件的託管資料庫？",
        "en": "What is your choice for a managed database for JSON documents?",
        "wg": [
          { "t": "託管資料庫", "en": "managed database", "ps": "n" },
          { "t": "JSON 文件", "en": "JSON documents", "ps": "n" },
          { "t": "選擇", "en": "choice", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Bigtable",
        "en": "(A) Cloud Bigtable",
        "wg": []
      },
      {
        "t": "(B) Cloud Spanner",
        "en": "(B) Cloud Spanner",
        "wg": []
      },
      {
        "t": "(C) Cloud Filestore",
        "en": "(C) Cloud Filestore",
        "wg": []
      },
      {
        "t": "(D) Cloud Firestore",
        "en": "(D) Cloud Firestore",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud Firestore 是 Google 的無伺服器、雲端原生 NoSQL 文件資料庫，專門設計用於儲存、同步和查詢 JSON 格式的文件資料。它支援靈活的 Schema 和強大的查詢功能。Bigtable 是寬欄位儲存，Filestore 是檔案儲存，Spanner 是關聯式資料庫。",
      "en": "Cloud Firestore is Google's serverless, cloud-native NoSQL document database, specifically designed to store, sync, and query data in JSON-like documents. It supports flexible schemas and powerful queries. Bigtable is wide-column, Filestore is file storage, and Spanner is relational.",
      "wg": [
        { "t": "文件資料庫", "en": "document database", "ps": "n" },
        { "t": "無伺服器", "en": "serverless", "ps": "adj" },
        { "t": "查詢", "en": "query", "ps": "v" }
      ]
    }
  },
  {
    "no": "18",
    "level": "medium",
    "keywords": "Hybrid Connectivity, Interconnect, VPN, Cost",
    "question": [
      {
        "t": "您需要在 GCP 專案和地端資料中心之間建立一條私有的 1 Gbps 連線。從成本角度來看，最佳選擇是什麼？",
        "en": "You need a private 1 Gbps connection between your GCP project and on-premises datacenter. The optimal choice from cost perspective is:",
        "wg": [
          { "t": "私有連線", "en": "private connection", "ps": "n" },
          { "t": "成本角度", "en": "cost perspective", "ps": "n" },
          { "t": "最佳選擇", "en": "optimal choice", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Dedicated Interconnect",
        "en": "(A) Dedicated Interconnect",
        "wg": []
      },
      {
        "t": "(B) Partner Interconnect",
        "en": "(B) Partner Interconnect",
        "wg": []
      },
      {
        "t": "(C) Cloud VPN",
        "en": "(C) Cloud VPN",
        "wg": []
      },
      {
        "t": "(D) Hybrid Interconnect",
        "en": "(D) Hybrid Interconnect",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "雖然 Cloud VPN 最便宜，但它使用公共網際網路，題目要求「私有」連線 (通常指避開公網的專線)。Dedicated Interconnect 提供 10 Gbps 或 100 Gbps 的連線，對於 1 Gbps 的需求來說過大且昂貴。Partner Interconnect 允許您從服務供應商處購買較小的頻寬 (如 50 Mbps 到 10 Gbps)，因此對於 1 Gbps 的私有連線需求，它是最具成本效益的選擇。",
      "en": "While Cloud VPN is the cheapest, it goes over the public internet, and the question implies a 'private' link (often meaning a dedicated circuit avoiding public internet). Dedicated Interconnect comes in 10 Gbps or 100 Gbps chunks, which is overkill and expensive for 1 Gbps. Partner Interconnect allows you to purchase smaller bandwidth capacities (from 50 Mbps up to 10 Gbps) from a service provider, making it the most cost-effective choice for a 1 Gbps private connection.",
      "wg": [
        { "t": "過大且昂貴", "en": "overkill and expensive", "ps": "adj" },
        { "t": "服務供應商", "en": "service provider", "ps": "n" },
        { "t": "頻寬", "en": "bandwidth", "ps": "n" }
      ]
    }
  },
  {
    "no": "19",
    "level": "medium",
    "keywords": "Load Balancing, Global, Anycast IP, Networking",
    "question": [
      {
        "t": "您正在從美國擴展到歐洲。哪個選項會將使用者路由到最近的健康伺服器？",
        "en": "You are expanding from US to Europe. Which option routes users to the nearest healthy server?",
        "wg": [
          { "t": "擴展", "en": "expanding", "ps": "v" },
          { "t": "路由", "en": "routes", "ps": "v" },
          { "t": "最近的健康伺服器", "en": "nearest healthy server", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 內容傳遞網路 (Content delivery network)",
        "en": "(A) Content delivery network",
        "wg": []
      },
      {
        "t": "(B) 簡單網路管理通訊協定 (SNMP)",
        "en": "(B) Simple network management protocol",
        "wg": []
      },
      {
        "t": "(C) VPN",
        "en": "(C) VPN",
        "wg": []
      },
      {
        "t": "(D) 全球負載平衡 (Global load balancing)",
        "en": "(D) Global load balancing",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Google Cloud 的 HTTP(S) 全球負載平衡器使用 Anycast IP 位址。它會自動將使用者的請求路由到網路延遲最低 (通常是地理位置最近) 且通過健康檢查的後端實例。這是實現跨地區流量管理和全球擴展的核心機制。",
      "en": "Google Cloud's HTTP(S) Global Load Balancer uses a single Anycast IP address. It automatically routes user requests to the backend instances that are closest in terms of network latency (geographically nearest) and are healthy. This is the core mechanism for cross-region traffic management and global scaling.",
      "wg": [
        { "t": "全球負載平衡器", "en": "Global Load Balancer", "ps": "n" },
        { "t": "Anycast IP 位址", "en": "Anycast IP address", "ps": "n" },
        { "t": "延遲最低", "en": "lowest latency", "ps": "adj" }
      ]
    }
  },
  {
    "no": "20",
    "level": "easy",
    "keywords": "Load Balancing, Multi-region, HTTP, True/False",
    "question": [
      {
        "t": "Google Cloud Load Balancing 能否跨多個地區平衡 HTTP 流量？",
        "en": "Can Google Cloud Load Balancing balance HTTP traffic across multiple regions?",
        "wg": [
          { "t": "平衡", "en": "balance", "ps": "v" },
          { "t": "HTTP 流量", "en": "HTTP traffic", "ps": "n" },
          { "t": "多個地區", "en": "multiple regions", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 是 (True)",
        "en": "(A) True",
        "wg": []
      },
      {
        "t": "(B) 否 (False)",
        "en": "(B) False",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "是的，Google Cloud 的外部 HTTP(S) 負載平衡器是全球性的。它使用單一的全球 IP 位址，並可以將流量分發到位於全球不同地區 (Regions) 的後端服務，從而實現跨地區的負載平衡。",
      "en": "Yes, Google Cloud's External HTTP(S) Load Balancer is a global resource. It uses a single global IP address and can distribute traffic to backend services located in multiple regions around the world, enabling cross-region load balancing.",
      "wg": [
        { "t": "全球性的", "en": "global", "ps": "adj" },
        { "t": "分發", "en": "distribute", "ps": "v" },
        { "t": "後端服務", "en": "backend services", "ps": "n" }
      ]
    }
  },{
    "no": "21",
    "level": "medium",
    "keywords": "Load Balancing, CDN, Static Content, Global",
    "question": [
      {
        "t": "對於擁有大量靜態資料的大型全球網站應用程式，哪種負載平衡選項是最佳選擇？",
        "en": "Which load-balancing option is best for a large-scale, world-wide web app with a lot of static data?",
        "wg": [
          { "t": "靜態資料", "en": "static data", "ps": "n" },
          { "t": "全球網站應用程式", "en": "world-wide web app", "ps": "n" },
          { "t": "最佳選擇", "en": "best", "ps": "adj" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 具有 SSL 和 CDN 的 HTTP/S 負載平衡器",
        "en": "(A) HTTP/S load balancer with SSL and CDN",
        "wg": []
      },
      {
        "t": "(B) 具有 SSL 和 CDN 的 TCP 負載平衡器",
        "en": "(B) TCP load balancer with SSL and CDN",
        "wg": []
      },
      {
        "t": "(C) 具有 SSL 的 HTTP/S 負載平衡器",
        "en": "(C) HTTP/S load balancer with SSL",
        "wg": []
      },
      {
        "t": "(D) 具有 SSL 的 TCP 負載平衡器",
        "en": "(D) TCP load balancer with SSL",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "對於全球性的 Web 應用程式，HTTP(S) 負載平衡器是最佳選擇，因為它是全球性的第 7 層負載平衡器。關鍵字「大量靜態資料」表明需要快取功能。Cloud CDN (內容傳遞網路) 僅能與 HTTP(S) 負載平衡器整合，而不能直接與 TCP 負載平衡器整合。因此，選項 (A) 結合了全球負載平衡和 CDN 快取，是效能最佳化的正確配置。",
      "en": "For a global web application, the HTTP(S) Load Balancer is the best choice as it is a global Layer 7 load balancer. The keyword 'lot of static data' indicates a need for caching. Cloud CDN (Content Delivery Network) integrates only with HTTP(S) Load Balancers, not directly with TCP Load Balancers. Therefore, option (A) combining global load balancing with CDN caching is the correct configuration for performance optimization.",
      "wg": [
        { "t": "快取功能", "en": "caching capabilities", "ps": "n" },
        { "t": "整合", "en": "integrates", "ps": "v" },
        { "t": "效能最佳化", "en": "performance optimization", "ps": "n" }
      ]
    }
  },
  {
    "no": "22",
    "level": "hard",
    "keywords": "VPC, Firewall Rules, Security, Networking",
    "question": [
      {
        "t": "VPC 防火牆規則適用於什麼樣的流量？",
        "en": "VPC firewall rules are applied to traffic that is *",
        "wg": [
          { "t": "VPC 防火牆規則", "en": "VPC firewall rules", "ps": "n" },
          { "t": "適用於", "en": "applied to", "ps": "v" },
          { "t": "流量", "en": "traffic", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 進入 VM 的流量，無論來源為何",
        "en": "(A) entering a VM regardless of origin",
        "wg": []
      },
      {
        "t": "(B) 從 VPC 子網段外部進入 VM 的流量",
        "en": "(B) entering a VM from outside the VPC subnet",
        "wg": []
      },
      {
        "t": "(C) 從 VPC 網路外部進入 VM 的流量",
        "en": "(C) entering a VM from outside the VPC network",
        "wg": []
      },
      {
        "t": "(D) 從專案外部進入 VM 的流量",
        "en": "(D) entering a VM from outside its project",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "在 Google Cloud 中，VPC 防火牆規則是分散式的，並在每個虛擬機 (VM) 的虛擬網路介面卡層級強制執行。這意味著防火牆規則會評估所有嘗試進入 VM 的流量，無論這些流量是來自網際網路、同一個 VPC 網路、甚至同一個子網段內的另一個 VM。沒有「隱式允許」讓同一子網段內的 VM 可以繞過防火牆規則 (除非有預設規則允許)。",
      "en": "In Google Cloud, VPC firewall rules are distributed and enforced at the virtual network interface level of each VM. This means firewall rules evaluate all traffic attempting to enter a VM, regardless of whether that traffic originates from the internet, another VPC network, or even another VM within the same subnet. There is no 'implicit allow' that bypasses firewall evaluation for traffic within the same subnet (unless a default rule permits it).",
      "wg": [
        { "t": "分散式的", "en": "distributed", "ps": "adj" },
        { "t": "強制執行", "en": "enforced", "ps": "v" },
        { "t": "評估", "en": "evaluate", "ps": "v" }
      ]
    }
  },
  {
    "no": "23",
    "level": "medium",
    "keywords": "VPC Peering, Networking, Cross-project Connectivity",
    "question": [
      {
        "t": "要連接相同或不同組織中的 GCP 專案之間的網路，您應該使用：",
        "en": "To connect networks between GCP projects in the same or different organizations, you should use:",
        "wg": [
          { "t": "連接網路", "en": "connect networks", "ps": "v" },
          { "t": "不同組織", "en": "different organizations", "ps": "n" },
          { "t": "使用", "en": "use", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 專用互連 (Dedicated Interconnect)",
        "en": "(A) Dedicated Interconnect",
        "wg": []
      },
      {
        "t": "(B) 專用對等互連 (Dedicated Peering)",
        "en": "(B) Dedicated Peering",
        "wg": []
      },
      {
        "t": "(C) 營運商對等互連 (Carrier Peering)",
        "en": "(C) Carrier Peering",
        "wg": []
      },
      {
        "t": "(D) VPC 對等互連 (VPC Peering)",
        "en": "(D) VPC Peering",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "VPC 對等互連 (VPC Peering) 允許兩個 VPC 網路 (無論它們是否屬於同一個專案或同一個組織) 透過私有 IP 位址進行內部通訊。這是在 GCP 內部連接不同網路的標準且最簡單的方法。Interconnect 和 Peering (Dedicated/Carrier) 通常用於連接 GCP 與地端 (On-premises) 網路或外部網際網路。",
      "en": "VPC Peering allows two VPC networks (regardless of whether they belong to the same project or organization) to communicate internally using private IP addresses. This is the standard and easiest way to connect different networks within GCP. Interconnect and Peering (Dedicated/Carrier) are typically used for connecting GCP with on-premises networks or the public internet.",
      "wg": [
        { "t": "內部通訊", "en": "communicate internally", "ps": "v" },
        { "t": "私有 IP 位址", "en": "private IP addresses", "ps": "n" },
        { "t": "地端", "en": "On-premises", "ps": "adj" }
      ]
    }
  },
  {
    "no": "24",
    "level": "easy",
    "keywords": "Load Balancer, Health Check, Availability",
    "question": [
      {
        "t": "為了確保負載平衡器僅將請求發送到正常運作的虛擬機，您會使用：",
        "en": "To ensure that a load balancer only sends requests to virtual machines that are working, you would use",
        "wg": [
          { "t": "負載平衡器", "en": "load balancer", "ps": "n" },
          { "t": "正常運作", "en": "working", "ps": "v" },
          { "t": "使用", "en": "use", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 健康檢查 (Health check)",
        "en": "(A) Health check",
        "wg": []
      },
      {
        "t": "(B) 運行時間檢查 (Uptime check)",
        "en": "(B) Uptime check",
        "wg": []
      },
      {
        "t": "(C) 存活探針 (Liveness probe)",
        "en": "(C) Liveness probe",
        "wg": []
      },
      {
        "t": "(D) 就緒探針 (Readiness probe)",
        "en": "(D) Readiness probe",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "負載平衡器使用「健康檢查」來定期輪詢後端實例。如果實例未能回應健康檢查，負載平衡器會將其標記為不健康，並停止向其發送新請求。Uptime check 是 Cloud Monitoring 用於從外部檢查服務可用性的工具。Liveness/Readiness probes 是 Kubernetes 的概念，雖然類似，但在此上下文中，LB 使用的是 Health Check。",
      "en": "Load balancers use 'Health checks' to periodically poll backend instances. If an instance fails to respond to the health check, the load balancer marks it as unhealthy and stops sending new requests to it. Uptime checks are a Cloud Monitoring tool for checking service availability from the outside. Liveness/Readiness probes are Kubernetes concepts; while similar, in this context, the LB uses Health Checks.",
      "wg": [
        { "t": "定期輪詢", "en": "periodically poll", "ps": "v" },
        { "t": "標記為不健康", "en": "marks it as unhealthy", "ps": "v" },
        { "t": "上下文", "en": "context", "ps": "n" }
      ]
    }
  },
  {
    "no": "25",
    "level": "medium",
    "keywords": "Monitoring, Alerting, Uptime Check, Operations",
    "question": [
      {
        "t": "您希望在應用程式當機時收到通知。哪種工具可以作為警報的基礎？",
        "en": "You want to be notified if your application is down. Which tool can provide the basis for an alert?",
        "wg": [
          { "t": "通知", "en": "notified", "ps": "v" },
          { "t": "當機", "en": "down", "ps": "adj" },
          { "t": "警報的基礎", "en": "basis for an alert", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 存活探針 (Liveness probe)",
        "en": "(A) Liveness probe",
        "wg": []
      },
      {
        "t": "(B) 健康檢查 (Health check)",
        "en": "(B) Health check",
        "wg": []
      },
      {
        "t": "(C) 就緒探針 (Readiness probe)",
        "en": "(C) Readiness probe",
        "wg": []
      },
      {
        "t": "(D) 運行時間檢查 (Uptime check)",
        "en": "(D) Uptime check",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud Monitoring 的「運行時間檢查」(Uptime check) 會從全球多個位置向您的公開 URL 發送請求。如果服務無法存取，它可以觸發警報政策並發送通知 (如電子郵件、SMS)。雖然健康檢查也監控狀態，但它們主要用於 LB 的流量導向；Uptime check 專門設計用於外部可用性監控和警報。",
      "en": "Cloud Monitoring's 'Uptime check' sends requests to your public URL from multiple locations around the world. If the service is inaccessible, it can trigger an alerting policy and send notifications (e.g., email, SMS). While health checks also monitor status, they are primarily for LB traffic direction; Uptime checks are specifically designed for external availability monitoring and alerting.",
      "wg": [
        { "t": "公開 URL", "en": "public URL", "ps": "n" },
        { "t": "觸發警報", "en": "trigger an alerting policy", "ps": "v" },
        { "t": "可用性監控", "en": "availability monitoring", "ps": "n" }
      ]
    }
  },
  {
    "no": "26",
    "level": "medium",
    "keywords": "Dataproc, Migration, Spark, Hadoop",
    "question": [
      {
        "t": "客戶希望遷移到 GCP，但仍維持對現有 Apache Spark 程式碼資料管線的投資。他應該選擇哪種服務？",
        "en": "Customer wants to migrate to GCP, but still maintain investment in an existing Apache Spark code data pipeline. What service should he choose?",
        "wg": [
          { "t": "維持投資", "en": "maintain investment", "ps": "v" },
          { "t": "資料管線", "en": "data pipeline", "ps": "n" },
          { "t": "選擇", "en": "choose", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) BigQuery",
        "en": "(A) BigQuery",
        "wg": []
      },
      {
        "t": "(B) Dataflow",
        "en": "(B) Dataflow",
        "wg": []
      },
      {
        "t": "(C) Dataproc",
        "en": "(C) Dataproc",
        "wg": []
      },
      {
        "t": "(D) Dataprep",
        "en": "(D) Dataprep",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Dataproc 是 GCP 上的託管 Hadoop/Spark 服務。它允許客戶「搬移」(Lift and Shift) 現有的 Spark/Hadoop 工作負載，而無需重寫程式碼 (這與需要重寫為 Apache Beam 的 Dataflow 不同)。因此，這是保留現有 Spark 程式碼投資的最佳選擇。",
      "en": "Cloud Dataproc is the managed Hadoop/Spark service on GCP. It allows customers to 'Lift and Shift' existing Spark/Hadoop workloads without rewriting code (unlike Dataflow, which would require rewriting to Apache Beam). Therefore, it is the best choice for preserving existing investment in Spark code.",
      "wg": [
        { "t": "搬移", "en": "Lift and Shift", "ps": "v" },
        { "t": "重寫程式碼", "en": "rewriting code", "ps": "v" },
        { "t": "保留", "en": "preserving", "ps": "v" }
      ]
    }
  },
  {
    "no": "27",
    "level": "hard",
    "keywords": "Cloud SQL, Read Replicas, Performance, Geographic Expansion",
    "question": [
      {
        "t": "客戶使用 Cloud SQL 資料庫來服務不常變更的查找表 (lookup tables)，這些表託管應用程式使用的資料。應用程式不會修改這些表。隨著他們擴展到其他地理區域，他們希望確保良好的效能。您推薦什麼？",
        "en": "A client is using Cloud SQL database to serve infrequently changing lookup tables that host data used by applications. The applications will not modify the tables. As they expand into other geographic regions they want to ensure good performance. What do you recommend?",
        "wg": [
          { "t": "不常變更", "en": "infrequently changing", "ps": "adv" },
          { "t": "查找表", "en": "lookup tables", "ps": "n" },
          { "t": "擴展", "en": "expand", "ps": "v" },
          { "t": "效能", "en": "performance", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 遷移到 Cloud Spanner。",
        "en": "(A) Migrate to Cloud Spanner.",
        "wg": []
      },
      {
        "t": "(B) 讀取複本 (Read replicas)。",
        "en": "(B) Read replicas.",
        "wg": []
      },
      {
        "t": "(C) 實例高可用性配置。",
        "en": "(C) Instance high availability configuration.",
        "wg": []
      },
      {
        "t": "(D) 從外部伺服器複製。",
        "en": "(D) Replicate from an external server.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Cloud SQL 支援跨地區讀取複本 (Cross-Region Read Replicas)。由於資料不常變更且應用程式只進行讀取，在新的地理區域建立讀取複本可以讓應用程式從本地讀取資料，從而顯著降低讀取延遲並提高效能。這比遷移到 Spanner (成本較高且複雜) 更簡單且符合需求。",
      "en": "Cloud SQL supports Cross-Region Read Replicas. Since the data changes infrequently and the application performs only reads, creating read replicas in the new geographic regions allows applications to read data locally. This significantly reduces read latency and improves performance. This is simpler and more cost-effective than migrating to Spanner.",
      "wg": [
        { "t": "跨地區讀取複本", "en": "Cross-Region Read Replicas", "ps": "n" },
        { "t": "降低讀取延遲", "en": "reduces read latency", "ps": "v" },
        { "t": "符合需求", "en": "fits the requirements", "ps": "v" }
      ]
    }
  },{
    "no": "1",
    "level": "easy",
    "keywords": "CI/CD, Cloud Build, Pipeline, Diagram",
    "question": [
      {
        "t": "哪個服務完成了 CI/CD 管線？(參考圖表：Cloud Source Repositories -> [?] -> Container Registry -> Jenkins -> GCE/GKE)",
        "en": "Which service completes the CI/CD pipeline?",
        "wg": [
          { "t": "服務", "en": "service", "ps": "n" },
          { "t": "CI/CD 管線", "en": "CI/CD pipeline", "ps": "n" },
          { "t": "完成", "en": "completes", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Cloud Build",
        "en": "(A) Cloud Build",
        "wg": []
      },
      {
        "t": "(B) Pub/Sub",
        "en": "(B) Pub/Sub",
        "wg": []
      },
      {
        "t": "(C) Cloud Storage",
        "en": "(C) Cloud Storage",
        "wg": []
      },
      {
        "t": "(D) Cloud Deploy",
        "en": "(D) Cloud Deploy",
        "wg": []
      },
      {
        "t": "(E) Dataproc",
        "en": "(E) Dataproc",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "在圖示的 CI/CD 流程中，原始碼從儲存庫 (Repositories) 出來後，需要經過「建置」(Build) 階段才能產生容器映像檔並存入 Registry。Cloud Build 是 Google Cloud 的全託管持續整合/持續交付 (CI/CD) 平台，負責執行建置步驟 (如編譯程式碼、打包容器)。",
      "en": "In the illustrated CI/CD workflow, after source code is pulled from repositories, it must go through a 'Build' stage to generate container images for the Registry. Cloud Build is Google Cloud's fully managed continuous integration/continuous delivery (CI/CD) platform that handles the build steps (like compiling code and packaging containers).",
      "wg": [
        { "t": "建置階段", "en": "Build stage", "ps": "n" },
        { "t": "全託管", "en": "fully managed", "ps": "adj" },
        { "t": "容器映像檔", "en": "container images", "ps": "n" }
      ]
    }
  },
  {
    "no": "2",
    "level": "medium",
    "keywords": "App Engine, Canary Release, Traffic Splitting",
    "question": [
      {
        "t": "如何使用小部分的即時流量來測試 App Engine 應用程式的風險更新 (金絲雀發布)？",
        "en": "How to test a risky update to an App Engine application with some small percentage of live traffic (Canary Release)?",
        "wg": [
          { "t": "風險更新", "en": "risky update", "ps": "n" },
          { "t": "即時流量", "en": "live traffic", "ps": "n" },
          { "t": "金絲雀發布", "en": "Canary Release", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 部署新版本，使用流量分割 (traffic splitting) 來測試一定百分比。",
        "en": "(A) Deploy a new version, use traffic splitting to test a percentage.",
        "wg": [
          { "t": "流量分割", "en": "traffic splitting", "ps": "n" },
          { "t": "部署", "en": "Deploy", "ps": "v" }
        ]
      },
      {
        "t": "(B) 建立一個單獨的隔離測試專案並讓使用者加入。",
        "en": "(B) Create a separate isolated test project and onboard users.",
        "wg": []
      },
      {
        "t": "(C) 建立第二個 App Engine 專案，然後重新導向一部分使用者。",
        "en": "(C) Create a second App Engine project, then redirect a subset of users.",
        "wg": []
      },
      {
        "t": "(D) 暫時部署為預設版本，然後復原。",
        "en": "(D) Deploy as default temporarily, then roll it back.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "App Engine 原生支援「流量分割」(Traffic Splitting) 功能，允許您將傳入流量的特定百分比 (例如 1% 或 5%) 分配給應用程式的不同版本。這是實作金絲雀發布 (Canary Release) 的標準方法，可以在不影響所有使用者的情況下測試新功能。",
      "en": "App Engine natively supports 'Traffic Splitting', which allows you to distribute a specific percentage of incoming traffic (e.g., 1% or 5%) to different versions of your application. This is the standard method for implementing Canary Releases to test new features without affecting all users.",
      "wg": [
        { "t": "原生支援", "en": "natively supports", "ps": "v" },
        { "t": "分配", "en": "distribute", "ps": "v" },
        { "t": "標準方法", "en": "standard method", "ps": "n" }
      ]
    }
  },
  {
    "no": "3",
    "level": "hard",
    "keywords": "Security, Penetration Testing, Compliance",
    "question": [
      {
        "t": "貴公司希望執行滲透測試，從網際網路來源的終端使用者角度模擬對其入口網站的流量。您會採取什麼行動？",
        "en": "Your company wants to run penetration tests that simulate the traffic to their web portal from Internet-originating end user perspective. What action would you take?",
        "wg": [
          { "t": "滲透測試", "en": "penetration tests", "ps": "n" },
          { "t": "網際網路來源", "en": "Internet-originating", "ps": "adj" },
          { "t": "模擬", "en": "simulate", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 通知 Google 您將進行滲透測試。",
        "en": "(A) Notify Google you are going to run a penetration test.",
        "wg": []
      },
      {
        "t": "(B) 透過公共網際網路使用地端 (On-premises) 掃描器。",
        "en": "(B) Use on-premises scanners over public Internet.",
        "wg": []
      },
      {
        "t": "(C) 在雲端部署掃描器並從那裡進行測試。",
        "en": "(C) Deploy scanners in the cloud and test from there.",
        "wg": []
      },
      {
        "t": "(D) 透過 VPN 使用地端掃描器。",
        "en": "(D) Use on-premises scanners over VPN.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "為了最真實地模擬「網際網路來源」(Internet-originating) 的攻擊者或使用者，測試流量必須來自外部網路 (公共網際網路)，而非 Google Cloud 內部或 VPN 通道。雖然 Google 現在不再強制要求預先通知滲透測試 (只要遵守可接受使用政策)，但題目的重點在於「來源角度」。使用地端掃描器透過公網測試符合此要求。",
      "en": "To most accurately simulate an 'Internet-originating' attacker or user, the test traffic must come from an external network (the public Internet), not from within Google Cloud or via a VPN tunnel. While Google no longer strictly requires pre-notification for pen tests (as long as AUP is followed), the key here is the 'source perspective'. Using on-premises scanners over the public internet meets this requirement.",
      "wg": [
        { "t": "最真實地模擬", "en": "most accurately simulate", "ps": "adv" },
        { "t": "外部網路", "en": "external network", "ps": "n" },
        { "t": "可接受使用政策", "en": "Acceptable Use Policy", "ps": "n" }
      ]
    }
  },
  {
    "no": "4",
    "level": "medium",
    "keywords": "Microservices, Monolith, Architecture, Reliability",
    "question": [
      {
        "t": "Web 應用程式的發布失敗不斷導致 rollback。對 QA 流程的修復已將 rollback 減少了 80%。您可以採取哪些額外步驟？",
        "en": "Release failures keep causing rollbacks in a web application. Fixes to the QA process reduced rollbacks by 80%. What additional steps can you take?",
        "wg": [
          { "t": "發布失敗", "en": "Release failures", "ps": "n" },
          { "t": "rollback", "en": "rollbacks", "ps": "n" },
          { "t": "額外步驟", "en": "additional steps", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 移除平台對關聯式資料庫系統的依賴。",
        "en": "(A) Remove the platform's dependency on relational database systems.",
        "wg": []
      },
      {
        "t": "(B) 移除 QA 環境。開始執行金絲雀發布。",
        "en": "(B) Remove the QA environment. Start executing canary releases.",
        "wg": []
      },
      {
        "t": "(C) 用 NoSQL 資料庫取代平台的關聯式資料庫系統。",
        "en": "(C) Replace the platform's relational database systems with a NoSQL database.",
        "wg": []
      },
      {
        "t": "(D) 將單體 (Monolithic) 平台拆分為微服務。",
        "en": "(D) Fragment the monolithic platform into microservices.",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "單體架構 (Monolith) 的主要缺點之一是「爆炸半徑」大：一個小的變更失敗可能導致整個應用程式崩潰或需要完全 rollback。將單體拆分為微服務可以解耦系統元件，允許獨立部署和擴展。這樣，如果一個微服務的發布失敗，它只會影響該特定服務，而不是整個平台，從而進一步降低全面 rollback 的風險。",
      "en": "One of the main drawbacks of a Monolithic architecture is the large 'blast radius': a small failed change can crash the entire app or require a full rollback. Fragmenting the monolith into microservices decouples system components, allowing independent deployment and scaling. If a release fails for one microservice, it only impacts that specific service, not the entire platform, further reducing the risk of total rollbacks.",
      "wg": [
        { "t": "單體架構", "en": "Monolithic architecture", "ps": "n" },
        { "t": "爆炸半徑", "en": "blast radius", "ps": "n" },
        { "t": "解耦", "en": "decouples", "ps": "v" }
      ]
    }
  },
  {
    "no": "5",
    "level": "hard",
    "keywords": "Deployment Strategies, Blue-Green, Long-running Transactions",
    "question": [
      {
        "t": "一個租車系統擁有長時間執行的交易 (long-running transactions)。應該避免下列哪一種部署方法？",
        "en": "A car reservation system has long-running transactions. Which one of the following deployment methods should be avoided?",
        "wg": [
          { "t": "長時間執行的交易", "en": "long-running transactions", "ps": "n" },
          { "t": "部署方法", "en": "deployment methods", "ps": "n" },
          { "t": "避免", "en": "avoided", "ps": "v" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 引入藍綠部署 (Blue-Green) 模型。",
        "en": "(A) Introduce a blue-green deployment model.",
        "wg": []
      },
      {
        "t": "(B) 引入滾動部署 (Rolling) 模型。",
        "en": "(B) Introduce a rolling deployment model.",
        "wg": []
      },
      {
        "t": "(C) 執行金絲雀發布 (Canary releases)。",
        "en": "(C) Execute canary releases.",
        "wg": []
      },
      {
        "t": "(D) 引入管線部署模型。",
        "en": "(D) Introduce a pipeline deployment model.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "藍綠部署通常涉及將負載平衡器的指標從「綠色」(舊/當前) 環境瞬間切換到「藍色」(新) 環境。對於有長時間執行交易的系統，這種瞬間切換會切斷與舊環境的所有現有連線，導致交易中斷。相比之下，滾動部署可以配置為等待連線耗盡 (Connection Draining)，較適合此場景。",
      "en": "Blue-green deployment typically involves an instantaneous switch of the load balancer pointer from the 'green' (old/current) environment to the 'blue' (new) environment. For systems with long-running transactions, this hard switch cuts off all existing connections to the old environment, disrupting the transactions. In contrast, rolling deployments can be configured with connection draining, making them more suitable.",
      "wg": [
        { "t": "瞬間切換", "en": "instantaneous switch", "ps": "n" },
        { "t": "切斷", "en": "cuts off", "ps": "v" },
        { "t": "交易中斷", "en": "disrupting the transactions", "ps": "v" }
      ]
    }
  },
  {
    "no": "6",
    "level": "medium",
    "keywords": "Deployment, Rolling Update, Managed Instance Group, Rollback",
    "question": [
      {
        "t": "當網站有數百個 VM 且經常有重大更新時，如何實作復原 (back-out/rollback) 計畫？",
        "en": "How to implement back-out/rollback plan for website with 100s of VMs, when the site has frequent critical updates?",
        "wg": [
          { "t": "復原計畫", "en": "back-out/rollback plan", "ps": "n" },
          { "t": "經常有重大更新", "en": "frequent critical updates", "ps": "n" },
          { "t": "數百個 VM", "en": "100s of VMs", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟動滾動更新時，使用帶有 'update-instances' 命令的託管實例群組。",
        "en": "(A) Use managed instance groups with the 'update-instances' command when starting a rolling update.",
        "wg": []
      },
      {
        "t": "(B) 在更新之前為每個 VM 建立快照，以防失敗。",
        "en": "(B) Create a snapshot of each VM prior to update, in case of failure.",
        "wg": []
      },
      {
        "t": "(C) 僅使用 Deployment Manager 範本部署變更。",
        "en": "(C) Only deploy changes using Deployment Manager templates.",
        "wg": []
      },
      {
        "t": "(D) 在 Cloud Storage 中建立靜態資料的 Nearline 副本。",
        "en": "(D) Create a Nearline copy of static data in Cloud Storage.",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "託管實例群組 (MIG) 的滾動更新功能允許您指定新的實例範本，並以受控的速度逐步更新實例。如果發現問題，您可以透過發出另一個指向舊範本的更新命令來輕鬆執行復原 (Rollback)。為數百個 VM 手動建立快照 (B) 效率極低且成本高昂。",
      "en": "The Rolling Update feature of Managed Instance Groups (MIGs) allows you to specify a new Instance Template and update instances incrementally at a controlled rate. If issues are detected, you can easily execute a rollback by issuing another update command pointing back to the old template. Manually creating snapshots for hundreds of VMs (Option B) is extremely inefficient and costly.",
      "wg": [
        { "t": "滾動更新功能", "en": "Rolling Update feature", "ps": "n" },
        { "t": "逐步更新", "en": "update instances incrementally", "ps": "v" },
        { "t": "受控的速度", "en": "controlled rate", "ps": "n" }
      ]
    }
  },
  {
    "no": "7",
    "level": "hard",
    "keywords": "SRE, Postmortem, Root Cause Analysis, Failure Rate",
    "question": [
      {
        "t": "上週某地區的 Web 層級 VM 有 1% 的失敗率。您應該如何回應？",
        "en": "Last week a region had a 1% failure rate in web tier VMs. How should you respond?",
        "wg": [
          { "t": "失敗率", "en": "failure rate", "ps": "n" },
          { "t": "回應", "en": "respond", "ps": "v" },
          { "t": "Web 層級 VM", "en": "web tier VMs", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在地端複製應用程式以補償雲端的失敗。",
        "en": "(A) Duplicate the application on-premises to compensate for failures in the cloud",
        "wg": []
      },
      {
        "t": "(B) 執行根本原因分析 (RCA) 以防止未來發生類似失敗。",
        "en": "(B) Perform a root cause analysis to prevent similar failures in future.",
        "wg": []
      },
      {
        "t": "(C) 監控應用程式是否有 5% 的失敗率。",
        "en": "(C) Monitor the application for a 5% failure rate",
        "wg": []
      },
      {
        "t": "(D) 停止所有開發，直到找到並修復應用程式問題。",
        "en": "(D) Halt all development until the application issue can be found and fixed.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "根據 SRE (網站可靠性工程) 原則，當發生重大事件或服務水準指標 (SLI) 異常時 (如 1% 失敗率)，正確的做法是進行事後檢討 (Postmortem) 和根本原因分析 (RCA)。這有助於了解問題的成因並實施長期修復，以避免問題復發。停止所有開發 (D) 通常只在錯誤預算耗盡時才考慮。",
      "en": "According to SRE (Site Reliability Engineering) principles, when a significant incident or SLI anomaly occurs (like a 1% failure rate), the correct course of action is to conduct a Postmortem and Root Cause Analysis (RCA). This helps understand the origin of the problem and implement long-term fixes to prevent recurrence. Halting all development (Option D) is typically only considered when the Error Budget is exhausted.",
      "wg": [
        { "t": "事後檢討", "en": "Postmortem", "ps": "n" },
        { "t": "根本原因分析", "en": "Root Cause Analysis", "ps": "n" },
        { "t": "錯誤預算", "en": "Error Budget", "ps": "n" }
      ]
    }
  },
  {
    "no": "8",
    "level": "medium",
    "keywords": "Microservices, Decoupling, Pub/Sub, Asynchronous",
    "question": [
      {
        "t": "一個應用程式在微服務之間進行同步通訊。哪種方法可以解耦這些微服務？",
        "en": "An application communicates synchronously between microservices. Which approach will decouple the microservices?",
        "wg": [
          { "t": "同步通訊", "en": "synchronously", "ps": "adv" },
          { "t": "解耦", "en": "decouple", "ps": "v" },
          { "t": "微服務", "en": "microservices", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 建立一個 Pub/Sub 主題，發送者寫入，接收者讀取。",
        "en": "(A) Create a Pub/Sub topic that sender writes and receiver reads",
        "wg": []
      },
      {
        "t": "(B) 讓發送者寫入本地磁碟；接收者唯讀掛載該磁碟。",
        "en": "(B) Have sender write to local drives; receiver mounts drives read-only",
        "wg": []
      },
      {
        "t": "(C) 建立一個 Bigtable 資料庫，發送者寫入，接收者讀取。",
        "en": "(C) Create a Bigtable database that sender writes and receiver reads",
        "wg": []
      },
      {
        "t": "(D) 建立一個 Cloud Storage 儲存桶，發送者寫入，接收者讀取。",
        "en": "(D) Create a Cloud Storage bucket that sender writes and receiver reads",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "這是一個經典的解耦模式問題。使用 Cloud Pub/Sub 引入了非同步訊息傳遞。發送服務 (Publisher) 只需將訊息發送到主題，不需要關心接收服務 (Subscriber) 是否在線或何時處理。這消除了服務之間的直接相依性，實現了解耦。",
      "en": "This is a classic decoupling pattern question. Using Cloud Pub/Sub introduces asynchronous messaging. The sending service (Publisher) only needs to send messages to a topic, without caring if the receiving service (Subscriber) is online or when it processes the message. This removes the direct dependency between services, achieving decoupling.",
      "wg": [
        { "t": "非同步訊息傳遞", "en": "asynchronous messaging", "ps": "n" },
        { "t": "直接相依性", "en": "direct dependency", "ps": "n" },
        { "t": "消除", "en": "removes", "ps": "v" }
      ]
    }
  },
  {
    "no": "9",
    "level": "hard",
    "keywords": "Compute Engine, IOPS, Disk Performance, Resizing",
    "question": [
      {
        "t": "針對在 n1-standard-8 VM (配備 50 GB SSD) 上運行緩慢的 MySQL 資料庫，您的初始行動是什麼？",
        "en": "What would be your initial action to quickly address a MySQL dbms running slowly on an n1-standard-8 VM with 50 GB SSD?",
        "wg": [
          { "t": "運行緩慢", "en": "running slowly", "ps": "adv" },
          { "t": "初始行動", "en": "initial action", "ps": "n" },
          { "t": "配備", "en": "with", "ps": "prep" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 動態將 SSD 調整為 500 GB。",
        "en": "(A) Dynamically resize the SSD to 500 GB",
        "wg": []
      },
      {
        "t": "(B) 將資料庫遷移到 BigQuery。",
        "en": "(B) Migrate the database to BigQuery",
        "wg": []
      },
      {
        "t": "(C) 將 VM 的記憶體增加到 64 GB。",
        "en": "(C) Increase the VM's memory to 64 GB",
        "wg": []
      },
      {
        "t": "(D) 建立一個運行 PostgreSQL 的新 VM。",
        "en": "(D) Create a new VM running PostgreSQL",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "在 Google Cloud 中，永久磁碟 (Persistent Disk) 的效能 (IOPS 和吞吐量) 與磁碟大小成正比。50 GB 的 SSD 通常只有較低的 IOPS (例如 30 IOPS/GB * 50 = 1500 IOPS)。對於資料庫而言，這通常是瓶頸。將磁碟調整為 500 GB 會立即增加 IOPS 上限 (到約 15000 IOPS)，這是解決 I/O 瓶頸最快且侵入性最小的方法。",
      "en": "In Google Cloud, the performance (IOPS and throughput) of a Persistent Disk is directly proportional to its size. A 50 GB SSD typically has low IOPS (e.g., 30 IOPS/GB * 50 = 1500 IOPS). For a database, this is often a bottleneck. Resizing the disk to 500 GB immediately increases the IOPS cap (to ~15000 IOPS), which is the quickest and least invasive way to address I/O bottlenecks.",
      "wg": [
        { "t": "成正比", "en": "directly proportional", "ps": "adj" },
        { "t": "瓶頸", "en": "bottleneck", "ps": "n" },
        { "t": "侵入性最小", "en": "least invasive", "ps": "adj" }
      ]
    }
  },
  {
    "no": "10",
    "level": "medium",
    "keywords": "SRE, SLO, Concepts, Reliability",
    "question": [
      {
        "t": "哪項最能描述 SLO (服務水準目標)？",
        "en": "Which best describes an SLO?",
        "wg": [
          { "t": "描述", "en": "describes", "ps": "v" },
          { "t": "服務水準目標", "en": "SLO", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 應用程式功能的度量描述。",
        "en": "(A) a measurable description of an application feature",
        "wg": []
      },
      {
        "t": "(B) 您希望服務達到的目標測量值。",
        "en": "(B) a target measure you want your service to achieve",
        "wg": []
      },
      {
        "t": "(C) 微服務的可測量 KPI。",
        "en": "(C) a measurable KPI for your microservice",
        "wg": []
      },
      {
        "t": "(D) 與客戶保證服務品質的合約。",
        "en": "(D) a contract with customer that guarantees service quality",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "SLO (Service Level Objective) 是 SLI (Service Level Indicator，服務水準指標) 的目標值或範圍 (例如：99.9% 的請求需在 200ms 內完成)。SLA (Service Level Agreement) 才是與客戶簽訂的合約 (D)。KPI (C) 是更通用的術語。SLI 才是度量描述 (A)。",
      "en": "An SLO (Service Level Objective) is a target value or range of values for a service level that is measured by an SLI (Service Level Indicator) (e.g., 99.9% of requests must complete within 200ms). An SLA (Service Level Agreement) is the contract with the customer (D). KPI (C) is a more general term. SLI is the measurable description (A).",
      "wg": [
        { "t": "目標值", "en": "target value", "ps": "n" },
        { "t": "服務水準指標", "en": "SLI", "ps": "n" },
        { "t": "合約", "en": "contract", "ps": "n" }
      ]
    }
  },{
    "no": "11",
    "level": "easy",
    "keywords": "Kubernetes, Pod, Deployment Unit",
    "question": [
      {
        "t": "Kubernetes 中的基本部署單位是什麼？",
        "en": "The basic unit of deployment in Kubernetes is *",
        "wg": [
          { "t": "基本部署單位", "en": "basic unit of deployment", "ps": "n" },
          { "t": "Kubernetes", "en": "Kubernetes", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) Pod",
        "en": "(A) a pod",
        "wg": []
      },
      {
        "t": "(B) 容器 (Container)",
        "en": "(B) a container",
        "wg": []
      },
      {
        "t": "(C) 節點 (Node)",
        "en": "(C) a node",
        "wg": []
      },
      {
        "t": "(D) 服務 (Service)",
        "en": "(D) a service",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "在 Kubernetes 中，Pod 是您可以建立和管理的最小、最簡單的可部署物件。一個 Pod 代表叢集中運作的一個程序，它可以包含一個或多個容器 (如 Docker 容器)。雖然容器是實際執行程式碼的地方，但 Kubernetes 直接管理的是 Pod。",
      "en": "In Kubernetes, a Pod is the smallest and simplest unit in the Kubernetes object model that you create or deploy. A Pod represents a running process on your cluster and can contain one or more containers (such as Docker containers). While containers are where the code runs, Kubernetes manages Pods directly.",
      "wg": [
        { "t": "可部署物件", "en": "deployable object", "ps": "n" },
        { "t": "運作的程序", "en": "running process", "ps": "n" },
        { "t": "直接管理", "en": "manages directly", "ps": "v" }
      ]
    }
  },
  {
    "no": "12",
    "level": "medium",
    "keywords": "GKE, CLI, gcloud, Cluster Creation",
    "question": [
      {
        "t": "哪一個指令是用來建立 Kubernetes 叢集的？",
        "en": "Which command is used to create a Kubernetes cluster? *",
        "wg": [
          { "t": "指令", "en": "command", "ps": "n" },
          { "t": "建立", "en": "create", "ps": "v" },
          { "t": "Kubernetes 叢集", "en": "Kubernetes cluster", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) gcloud container clusters create",
        "en": "(A) gcloud container clusters create",
        "wg": []
      },
      {
        "t": "(B) kubectl node create",
        "en": "(B) kubectl node create",
        "wg": []
      },
      {
        "t": "(C) gcloud kubernetes clusters create",
        "en": "(C) gcloud kubernetes clusters create",
        "wg": []
      },
      {
        "t": "(D) kubectl cluster create",
        "en": "(D) kubectl cluster create",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "在 Google Cloud 中，管理 GKE (Google Kubernetes Engine) 叢集基礎設施的工具是 `gcloud` SDK。正確的指令群組是 `gcloud container clusters ...`。`kubectl` 是用來管理 Kubernetes 叢集 *內部* 資源 (如 Pods, Deployments) 的工具，而不是用來建立叢集本身的。",
      "en": "In Google Cloud, the tool for managing GKE (Google Kubernetes Engine) cluster infrastructure is the `gcloud` SDK. The correct command group is `gcloud container clusters ...`. `kubectl` is the tool used for managing resources *inside* a Kubernetes cluster (like Pods, Deployments), not for creating the cluster itself.",
      "wg": [
        { "t": "基礎設施", "en": "infrastructure", "ps": "n" },
        { "t": "指令群組", "en": "command group", "ps": "n" },
        { "t": "內部資源", "en": "internal resources", "ps": "n" }
      ]
    }
  },
  {
    "no": "13",
    "level": "medium",
    "keywords": "Kubernetes, kubectl, Deployment, Lifecycle",
    "question": [
      {
        "t": "哪一個指令會啟動選定數量的 Pod 並管理它們的生命週期？",
        "en": "Which command starts a selected number of pods and manages their lifecycle?",
        "wg": [
          { "t": "啟動", "en": "starts", "ps": "v" },
          { "t": "管理", "en": "manages", "ps": "v" },
          { "t": "生命週期", "en": "lifecycle", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) kubectl run",
        "en": "(A) kubectl run",
        "wg": []
      },
      {
        "t": "(B) kubectl exec",
        "en": "(B) kubectl exec",
        "wg": []
      },
      {
        "t": "(C) kubectl create deployment",
        "en": "(C) kubectl create deployment",
        "wg": []
      },
      {
        "t": "(D) kubectl create pod",
        "en": "(D) kubectl create pod",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "雖然 `kubectl run` 曾用於建立各種資源，但現在主要用於建立單個 Pod。要管理 Pod 的生命週期 (如複本數量、更新、Rollback)，正確的抽象層是 Deployment。因此，`kubectl create deployment` 是建立 Deployment 控制器的指令，該控制器會確保指定數量的 Pod 正在運行。",
      "en": "While `kubectl run` was historically used for various resources, it now primarily creates a single Pod. To manage the lifecycle of Pods (like replica counts, updates, rollbacks), the correct abstraction is a Deployment. Therefore, `kubectl create deployment` is the command to create a Deployment controller, which ensures the specified number of Pods are running.",
      "wg": [
        { "t": "抽象層", "en": "abstraction", "ps": "n" },
        { "t": "控制器", "en": "controller", "ps": "n" },
        { "t": "確保", "en": "ensures", "ps": "v" }
      ]
    }
  },
  {
    "no": "14",
    "level": "hard",
    "keywords": "Availability, Monitoring, Reliability, SRE",
    "question": [
      {
        "t": "為了提高可用性，除了冗餘和程式碼審查之外，您還選擇：",
        "en": "To improve availability, in addition to redundancy and code reviews, you choose to",
        "wg": [
          { "t": "提高可用性", "en": "improve availability", "ps": "v" },
          { "t": "冗餘", "en": "redundancy", "ps": "n" },
          { "t": "程式碼審查", "en": "code reviews", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用存取控制。",
        "en": "(A) Use access controls",
        "wg": []
      },
      {
        "t": "(B) 為所有運算需求使用託管服務。",
        "en": "(B) Use managed services for all compute requirements",
        "wg": []
      },
      {
        "t": "(C) 使用監控來針對應用程式效能的變化發出警報。",
        "en": "(C) Use monitoring to alert on changes in application performance",
        "wg": [
          { "t": "監控", "en": "monitoring", "ps": "n" },
          { "t": "警報", "en": "alert", "ps": "v" },
          { "t": "效能變化", "en": "changes in application performance", "ps": "n" }
        ]
      },
      {
        "t": "(D) 使用 Bigtable 收集應用程式效能數據。",
        "en": "(D) Use Bigtable to collect application performance data",
        "wg": []
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "可用性 (Availability) 不僅僅是防止失敗，還包括快速偵測和回應失敗。監控 (Monitoring) 和警報 (Alerting) 是 SRE 的基石。當效能指標 (如延遲或錯誤率) 惡化時及時發出警報，可以讓維運團隊在使用者受到嚴重影響之前介入，從而減少 MTTR (平均修復時間) 並提高整體可用性。",
      "en": "Availability is not just about preventing failures but also about detecting and responding to them quickly. Monitoring and Alerting are cornerstones of SRE. Alerting on performance degradation (like latency or error rates) allows operations teams to intervene before users are severely impacted, thereby reducing MTTR (Mean Time To Repair) and improving overall availability.",
      "wg": [
        { "t": "快速偵測", "en": "detecting quickly", "ps": "v" },
        { "t": "基石", "en": "cornerstones", "ps": "n" },
        { "t": "平均修復時間", "en": "Mean Time To Repair", "ps": "n" }
      ]
    }
  },
  {
    "no": "15",
    "level": "medium",
    "keywords": "Incident Management, SRE, Priority, Mitigation",
    "question": [
      {
        "t": "發生了事故。最高優先順序是什麼？",
        "en": "An incident has occurred. What is the highest priority? *",
        "wg": [
          { "t": "事故", "en": "incident", "ps": "n" },
          { "t": "最高優先順序", "en": "highest priority", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 開始緩解 (Start mitigation)",
        "en": "(A) Start mitigation",
        "wg": []
      },
      {
        "t": "(B) 識別根本原因 (Identify the root cause)",
        "en": "(B) Identify the root cause",
        "wg": []
      },
      {
        "t": "(C) 開始事後檢討 (Start a postmortem)",
        "en": "(C) Start a postmortem",
        "wg": []
      },
      {
        "t": "(D) 指派責任 (Assign blame)",
        "en": "(D) Assign blame",
        "wg": []
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "在事故管理 (Incident Management) 中，首要任務始終是恢復服務或減輕對使用者的影響 (Mitigation)。尋找根本原因 (RCA) 和撰寫事後檢討 (Postmortem) 是在服務穩定後才進行的後續步驟。指派責任 (Blame) 與 SRE 的「不指責文化」(Blameless culture) 相悖。",
      "en": "In Incident Management, the first priority is always to restore service or mitigate the impact on users (Mitigation). Finding the root cause (RCA) and writing a postmortem are subsequent steps taken after the service is stable. Assigning blame contradicts the 'Blameless culture' of SRE.",
      "wg": [
        { "t": "首要任務", "en": "first priority", "ps": "n" },
        { "t": "恢復服務", "en": "restore service", "ps": "v" },
        { "t": "不指責文化", "en": "Blameless culture", "ps": "n" }
      ]
    }
  },{
    "no": "16",
    "level": "hard",
    "keywords": "Security, Binary Authorization, Container Security, Supply Chain",
    "question": [
      {
        "t": "什麼是 Binary Authorization？",
        "en": "What is Binary Authorization?",
        "wg": [
          { "t": "Binary Authorization", "en": "Binary Authorization", "ps": "n" },
          { "t": "容器安全", "en": "Container Security", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用授權開發人員身分簽署容器的工具。",
        "en": "(A) Tool that signs containers with the identity of an authorized developer",
        "wg": []
      },
      {
        "t": "(B) 確保僅部署受信任容器的控制措施。",
        "en": "(B) Control that ensures only trusted containers are deployed",
        "wg": []
      },
      {
        "t": "(C) 確保 VM 開機堆疊有效性的安全套件。",
        "en": "(C) Security package that ensures validity of VM boot stack",
        "wg": []
      },
      {
        "t": "(D) 掃描容器登錄檔是否有漏洞的工具。",
        "en": "(D) Tool that scans container registry for vulnerabilities",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Binary Authorization 是一項 Google Cloud 服務，它提供了一種部署時的安全性控制 (Admission Controller)。它確保只有經過加密簽章和驗證 (即「受信任」) 的容器映像檔才能部署到 GKE 叢集。這有助於保護軟體供應鏈，防止未經授權或惡意的程式碼被部署。",
      "en": "Binary Authorization is a Google Cloud service that provides a deploy-time security control (Admission Controller). It ensures that only container images that have been cryptographically signed and verified (i.e., 'trusted') are allowed to be deployed to GKE clusters. This secures the software supply chain against unauthorized or malicious code.",
      "wg": [
        { "t": "部署時的安全性控制", "en": "deploy-time security control", "ps": "n" },
        { "t": "加密簽章", "en": "cryptographically signed", "ps": "v" },
        { "t": "軟體供應鏈", "en": "software supply chain", "ps": "n" }
      ]
    }
  },
  {
    "no": "17",
    "level": "medium",
    "keywords": "SRE, Reliability, System Feature, Philosophy",
    "question": [
      {
        "t": "根據 SRE 哲學，任何系統最重要的特性是什麼？",
        "en": "According to SRE philosophy, the most important feature of any system is *",
        "wg": [
          { "t": "SRE 哲學", "en": "SRE philosophy", "ps": "n" },
          { "t": "最重要的特性", "en": "most important feature", "ps": "n" },
          { "t": "系統", "en": "system", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 一致性 (Consistency)",
        "en": "(A) Consistency",
        "wg": []
      },
      {
        "t": "(B) 可靠性 (Reliability)",
        "en": "(B) Reliability",
        "wg": []
      },
      {
        "t": "(C) 準確性 (Accuracy)",
        "en": "(C) Accuracy",
        "wg": []
      },
      {
        "t": "(D) 效能 (Performance)",
        "en": "(D) Performance",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "這是 SRE (Site Reliability Engineering) 的核心原則之一：'Reliability is the most important feature of any system' (可靠性是任何系統最重要的特性)。如果系統不可用或不可靠，那麼無論它有多少功能、速度多快或多準確，對使用者來說都沒有價值。",
      "en": "This is a core tenet of SRE (Site Reliability Engineering): 'Reliability is the most important feature of any system'. If a system is unavailable or unreliable, it provides no value to its users, regardless of its feature set, speed, or accuracy.",
      "wg": [
        { "t": "核心原則", "en": "core tenet", "ps": "n" },
        { "t": "不可用", "en": "unavailable", "ps": "adj" },
        { "t": "沒有價值", "en": "no value", "ps": "n" }
      ]
    }
  },
  {
    "no": "18",
    "level": "hard",
    "keywords": "Hybrid Connectivity, Partner Interconnect, Oracle, SLA",
    "question": [
      {
        "t": "一家公司希望將雲端應用程式連接到其資料中心的 Oracle 資料庫。需求是最大 5 Gbps 的資料傳輸量和 99% 的端到端服務水準協議 (SLA)。",
        "en": "A company wants to connect cloud applications to an Oracle database in its data center. Requirements are a maximum of 5 Gbps of data and an end-to-end Service Level Agreement (SLA) of 99%.",
        "wg": [
          { "t": "連接", "en": "connect", "ps": "v" },
          { "t": "最大 5 Gbps", "en": "maximum of 5 Gbps", "ps": "n" },
          { "t": "SLA", "en": "SLA", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 實作高吞吐量的 Cloud VPN 連線。",
        "en": "(A) Implement a high-throughput Cloud VPN connection.",
        "wg": []
      },
      {
        "t": "(B) 使用 Cloud Router 的 VPN。",
        "en": "(B) Cloud Router with VPN.",
        "wg": []
      },
      {
        "t": "(C) 專用互連 (Dedicated Interconnect)。",
        "en": "(C) Dedicated Interconnect.",
        "wg": []
      },
      {
        "t": "(D) 合作夥伴互連 (Partner Interconnect)。",
        "en": "(D) Partner Interconnect.",
        "wg": []
      }
    ],
    "answer": "(D)",
    "why": {
      "t": "Cloud VPN 雖然便宜，但透過公共網際網路傳輸，無法提供嚴格的端到端頻寬保證或 SLA。Dedicated Interconnect 起步頻寬為 10 Gbps，對於 5 Gbps 的需求來說可能過度配置且成本較高。Partner Interconnect 允許透過服務供應商獲得各種頻寬選項 (從 50 Mbps 到 10 Gbps)，適合 5 Gbps 的需求，且當正確配置時 (如 VLAN 附件) Google 提供 SLA，服務供應商通常也提供其連線部分的 SLA。",
      "en": "Cloud VPN goes over the public internet and cannot provide strict end-to-end bandwidth guarantees or SLAs. Dedicated Interconnect starts at 10 Gbps, which is over-provisioned and more expensive for a 5 Gbps requirement. Partner Interconnect offers flexible bandwidth options (from 50 Mbps to 10 Gbps) via service providers, fitting the 5 Gbps need perfectly. Google provides an SLA for the GCP side, and service providers typically offer SLAs for their connectivity.",
      "wg": [
        { "t": "頻寬保證", "en": "bandwidth guarantees", "ps": "n" },
        { "t": "過度配置", "en": "over-provisioned", "ps": "adj" },
        { "t": "服務供應商", "en": "service provider", "ps": "n" }
      ]
    }
  },
  {
    "no": "19",
    "level": "medium",
    "keywords": "BigQuery, Cost Estimation, Pricing, Query Processing",
    "question": [
      {
        "t": "如何在觸發 BigQuery 查詢之前檢查其運行成本？",
        "en": "How to check the cost of running a BigQuery query before it's triggered?",
        "wg": [
          { "t": "觸發", "en": "triggered", "ps": "v" },
          { "t": "檢查成本", "en": "check the cost", "ps": "v" },
          { "t": "BigQuery 查詢", "en": "BigQuery query", "ps": "n" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在查詢末尾添加 'ESTIMATE' 子句。",
        "en": "(A) Add 'ESTIMATE' clause at the end of the query.",
        "wg": []
      },
      {
        "t": "(B) 檢查將處理多少資料，並將此數量提供給 GCP 計算器。",
        "en": "(B) Check how much data will be processed and provide this amount to GCP calculator.",
        "wg": []
      },
      {
        "t": "(C) 這無法做到 - 您只能在月底的帳單報告中看到。",
        "en": "(C) This can't be done - you will only see it in the billing report at the end of the month.",
        "wg": []
      },
      {
        "t": "(D) 在查詢中繼資料中搜尋 'price' 部分。",
        "en": "(D) Search for 'price' section in the query metadata.",
        "wg": []
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "BigQuery 的按需 (On-demand) 定價是基於查詢處理的位元組數。在執行查詢之前 (例如在 Cloud Console 中輸入查詢，或使用 `--dry-run` 標誌)，BigQuery 會驗證查詢語法並提供將要處理的位元組估計值 (例如 '此查詢將處理 2.5 GB')。您可以將此數據量輸入 GCP 定價計算器來估算具體成本。",
      "en": "BigQuery's On-demand pricing is based on the number of bytes processed. Before running a query (e.g., in the Cloud Console or using the `--dry-run` flag), BigQuery validates the syntax and provides an estimate of the bytes that will be processed (e.g., 'This query will process 2.5 GB'). You can then input this data volume into the GCP Pricing Calculator to estimate the specific cost.",
      "wg": [
        { "t": "按需定價", "en": "On-demand pricing", "ps": "n" },
        { "t": "位元組數", "en": "bytes", "ps": "n" },
        { "t": "估計值", "en": "estimate", "ps": "n" }
      ]
    }
  },
{
      "no": "1",
      "level": "medium",
      "keywords": "Cloud Functions, Pub/Sub, Event-driven architecture, Cloud Storage",
      "question": [
        {
          "t": "哪種解決方案可用於觸發 Cloud Function，使其能夠攝取並處理影像標記管道中的影像？",
          "en": "Which solution can be used to trigger a Cloud Function, so it can ingest and process an image in the image tagging pipeline?",
          "wg": [
            { "t": "觸發", "en": "trigger", "ps": "verb" },
            { "t": "攝取", "en": "ingest", "ps": "verb" },
            { "t": "影像標記管道", "en": "image tagging pipeline", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) Cloud Bigtable",
          "en": "(A) Cloud Bigtable",
          "wg": []
        },
        {
          "t": "(B) Pub/Sub",
          "en": "(B) Pub/Sub",
          "wg": [
            { "t": "發布/訂閱", "en": "Pub/Sub", "ps": "noun" }
          ]
        },
        {
          "t": "(C) Firestore",
          "en": "(C) Firestore",
          "wg": []
        },
        {
          "t": "(D) Dataflow",
          "en": "(D) Dataflow",
          "wg": []
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Pub/Sub 是 Google Cloud 中用於解耦服務和處理異步事件的標準訊息傳遞服務。在此架構中，當影像上傳至 Cloud Storage 時，會發送通知至 Pub/Sub 主題，進而觸發 Cloud Function 進行處理。這種模式確保了系統的可擴展性與鬆散耦合。Cloud Bigtable 和 Firestore 是資料庫，不適用於事件觸發；Dataflow 主要用於大規模資料處理管道，而非輕量級事件觸發。",
        "en": "Pub/Sub is the standard messaging service in Google Cloud for decoupling services and handling asynchronous events. In this architecture, an image upload to Cloud Storage sends a notification to a Pub/Sub topic, which in turn triggers the Cloud Function for processing. This pattern ensures scalability and loose coupling. Cloud Bigtable and Firestore are databases and not designed for event triggering; Dataflow is for large-scale data processing pipelines, not lightweight event triggers.",
        "wg": [
          { "t": "解耦", "en": "decoupling", "ps": "verb" },
          { "t": "異步事件", "en": "asynchronous events", "ps": "noun" },
          { "t": "可擴展性", "en": "scalability", "ps": "noun" }
        ]
      }
    },
    {
      "no": "2",
      "level": "hard",
      "keywords": "Cloud Storage, Security, ACLs, IAM, PII",
      "question": [
        {
          "t": "針對 Cloud Storage 上的 PII（個人身份資訊）數據，最佳實踐的安全策略是什麼？",
          "en": "What is the best-practice security strategy for PII data on Cloud Storage?",
          "wg": [
            { "t": "個人身份資訊", "en": "PII data", "ps": "noun" },
            { "t": "安全策略", "en": "security strategy", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 給予使用者唯讀權限，並在儲存桶上使用預設 ACL",
          "en": "(A) Read-only access to users, and default ACL on bucket",
          "wg": []
        },
        {
          "t": "(B) 使用具有過期時間的簽署 URL (Signed URL)",
          "en": "(B) Signed URL with expiration",
          "wg": [
            { "t": "簽署 URL", "en": "Signed URL", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 不給予使用者 Cloud IAM 角色，並在儲存桶上使用精細的 ACL",
          "en": "(C) No Cloud IAM roles to users, and granular ACLs on bucket",
          "wg": [
            { "t": "精細的 ACL", "en": "granular ACLs", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 公開存取，使用隨機名稱，並秘密分享 URL",
          "en": "(D) Public access, random names, and share URLs in confidence",
          "wg": []
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "根據題目提供的反饋，精細的 ACL 配合不給予使用者 IAM 角色被視為最嚴格的策略，因為它允許對單個物件進行特定的存取控制，而不是對整個儲存桶進行廣泛授權。簽署 URL 雖然安全，但如果洩漏則可能導致未經授權的存取。選項 D 的「隱匿式安全」(Security through obscurity) 並非真正的安全措施。",
        "en": "According to the feedback provided, granular ACLs combined with no Cloud IAM roles for users is considered the most restrictive policy, as it allows for specific access control on individual objects rather than broad permissions on the bucket. While Signed URLs are secure, they can be leaked. Option D, 'Security through obscurity', is not a valid security measure.",
        "wg": [
          { "t": "最嚴格的策略", "en": "most restrictive policy", "ps": "noun" },
          { "t": "隱匿式安全", "en": "Security through obscurity", "ps": "noun" }
        ]
      }
    },
    {
      "no": "3",
      "level": "medium",
      "keywords": "Cloud Storage, Cloud Functions, Event-driven, Performance",
      "question": [
        {
          "t": "一個 Cron job 每 10 分鐘檢查一次 Cloud Storage 儲存桶是否有新檔案。",
          "en": "A cron job checks a Cloud Storage bucket every 10 min for new files.",
          "wg": [
            { "t": "檢查", "en": "checks", "ps": "verb" },
            { "t": "儲存桶", "en": "bucket", "ps": "noun" }
          ]
        },
        {
          "t": "您可以透過以下哪種方式改善回應時間？",
          "en": "You can improve response time by:",
          "wg": [
            { "t": "改善", "en": "improve", "ps": "verb" },
            { "t": "回應時間", "en": "response time", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Function",
          "en": "(A) Using a Cloud Function",
          "wg": []
        },
        {
          "t": "(B) 使用 App Engine Flexible 應用程式",
          "en": "(B) Using an App Engine Flexible application",
          "wg": []
        },
        {
          "t": "(C) 使用 Kubernetes pod",
          "en": "(C) Using a Kubernetes pod",
          "wg": []
        },
        {
          "t": "(D) 每分鐘執行一次 Cron job",
          "en": "(D) Running the cron job every minute",
          "wg": []
        }
      ],
      "answer": "(A)",
      "why": {
        "t": "使用 Cloud Function 可以建立事件驅動 (Event-driven) 的架構。當檔案上傳至 Cloud Storage 時，會立即觸發 Cloud Function 執行，從而消除 Cron job 輪詢 (Polling) 造成的延遲（在此例中最多可達 10 分鐘）。這種方式不僅反應即時，也比持續運行的運算資源更具成本效益。",
        "en": "Using a Cloud Function enables an event-driven architecture. When a file is uploaded to Cloud Storage, the Cloud Function is triggered immediately, eliminating the latency caused by Cron job polling (which can be up to 10 minutes in this case). This approach is not only real-time but often more cost-effective than continuously running compute resources.",
        "wg": [
          { "t": "事件驅動", "en": "Event-driven", "ps": "adj" },
          { "t": "輪詢", "en": "Polling", "ps": "noun" },
          { "t": "延遲", "en": "latency", "ps": "noun" }
        ]
      }
    },
    {
      "no": "4",
      "level": "medium",
      "keywords": "Cloud Storage, Load Balancer, Static Website, Hosting",
      "question": [
        {
          "t": "在 GCP 中託管靜態網站最簡單的方法是什麼？",
          "en": "What's the easiest way to host a static web site in GCP?",
          "wg": [
            { "t": "託管", "en": "host", "ps": "verb" },
            { "t": "靜態網站", "en": "static web site", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 將其部署到 App Engine",
          "en": "(A) Deploy it to App Engine.",
          "wg": []
        },
        {
          "t": "(B) 使用 GCS 儲存桶進行儲存，並建立一個以 GCS 儲存桶為後端的全域負載平衡器",
          "en": "(B) Use GCS bucket for storage and create a global Load Balancer with GCS bucket as a backend.",
          "wg": [
            { "t": "全域負載平衡器", "en": "global Load Balancer", "ps": "noun" },
            { "t": "後端", "en": "backend", "ps": "noun" }
          ]
        },
        {
          "t": "(C) 使用 GCP Marketplace 部署 CMS，例如 Wordpress",
          "en": "(C) Use GCP Marketplace to deploy a CMS, eg. Wordpress.",
          "wg": []
        },
        {
          "t": "(D) 部署單個 VM 並在其中安裝網頁伺服器",
          "en": "(D) Deploy a single VM and install a web server there.",
          "wg": []
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "Cloud Storage (GCS) 原生支援靜態網站託管，這是最簡單且無伺服器 (Serverless) 的解決方案。結合 Cloud Load Balancing 可以提供 HTTPS 支援和全球內容交付 (CDN) 功能。使用 VM 或 App Engine 對於純靜態內容來說增加了不必要的管理開銷。",
        "en": "Cloud Storage (GCS) natively supports static website hosting, making it the simplest and serverless solution. Combining it with Cloud Load Balancing provides HTTPS support and global content delivery (CDN). Using VMs or App Engine adds unnecessary management overhead for purely static content.",
        "wg": [
          { "t": "無伺服器", "en": "Serverless", "ps": "adj" },
          { "t": "管理開銷", "en": "management overhead", "ps": "noun" }
        ]
      }
    },
    {
      "no": "5",
      "level": "medium",
      "keywords": "App Engine, Standard Environment, Flexible Environment, Scaling",
      "question": [
        {
          "t": "App Engine Standard 相較於 App Engine Flexible 的一個優勢是什麼？",
          "en": "Which is an advantage of App Engine Standard over App Engine Flexible?",
          "wg": [
            { "t": "優勢", "en": "advantage", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 縮減至零 (Scales to zero)",
          "en": "(A) Scales to zero",
          "wg": [
            { "t": "縮減至零", "en": "Scales to zero", "ps": "verb" }
          ]
        },
        {
          "t": "(B) SSH 存取",
          "en": "(B) SSH access",
          "wg": []
        },
        {
          "t": "(C) 允許暫存磁碟",
          "en": "(C) Allows ephemeral disk",
          "wg": []
        },
        {
          "t": "(D) 支援第三方二進位檔",
          "en": "(D) Supports 3rd party binaries",
          "wg": []
        }
      ],
      "answer": "(A)",
      "why": {
        "t": "App Engine Standard 環境可以完全縮減至零個實例（當沒有流量時），這意味著成本可以降至零。而 App Engine Flexible 運行在虛擬機上，通常至少需要一個實例運行以保持服務可用性，且啟動時間較慢。SSH 存取和支援第三方二進位檔實際上是 Flexible 環境的特點。",
        "en": "The App Engine Standard environment can scale completely down to zero instances (when there is no traffic), meaning costs can drop to zero. App Engine Flexible runs on VMs and typically requires at least one instance running for availability, with slower startup times. SSH access and support for 3rd party binaries are actually features of the Flexible environment.",
        "wg": [
          { "t": "實例", "en": "instances", "ps": "noun" },
          { "t": "啟動時間", "en": "startup times", "ps": "noun" }
        ]
      }
    },
{
      "no": "6",
      "level": "medium",
      "keywords": "Compute Engine, Persistent Disk, Performance, I/O",
      "question": [
        {
          "t": "如何在不重建虛擬機的情況下，為其掛接的永久磁碟提供更高的 I/O 效能？",
          "en": "How do you give a virtual machine greater I/O performance for its attached persistent disk without rebuilding the VM?",
          "wg": [
            { "t": "重建", "en": "rebuilding", "ps": "verb" },
            { "t": "永久磁碟", "en": "persistent disk", "ps": "noun" },
            { "t": "I/O 效能", "en": "I/O performance", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 將磁碟類型更改為本機 SSD",
          "en": "(A) Change the type of disk to local SSD",
          "wg": []
        },
        {
          "t": "(B) 更新磁碟中繼資料，包括標籤",
          "en": "(B) Update the disk metadata, including labels",
          "wg": []
        },
        {
          "t": "(C) 增加磁碟的大小",
          "en": "(C) Increase the size of the disk",
          "wg": [
            { "t": "增加", "en": "Increase", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 更改磁碟的存取控制",
          "en": "(D) Change the access controls of the disk",
          "wg": []
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "在 Google Cloud Compute Engine 中，永久磁碟 (Persistent Disk) 的效能（IOPS 和吞吐量）與磁碟大小成正比。因此，增加磁碟大小是提升 I/O 效能且無需重建 VM 的直接方法。本機 SSD 無法直接轉換，且需要重建或重新掛載流程。",
        "en": "In Google Cloud Compute Engine, the performance (IOPS and throughput) of a Persistent Disk scales linearly with the disk size. Therefore, increasing the disk size is the direct way to improve I/O performance without needing to rebuild the VM. Local SSDs cannot be converted directly and would require a rebuild or remount process.",
        "wg": [
          { "t": "成正比", "en": "scales linearly", "ps": "verb" },
          { "t": "吞吐量", "en": "throughput", "ps": "noun" }
        ]
      }
    },
    {
      "no": "7",
      "level": "medium",
      "keywords": "App Engine, Serverless, Python, Scaling",
      "question": [
        {
          "t": "您有一個新的無狀態 Python 網頁應用程式；您無法預測負載。",
          "en": "You have a new stateless Python web app; you can't predict the load.",
          "wg": [
            { "t": "無狀態", "en": "stateless", "ps": "adj" },
            { "t": "無法預測", "en": "can't predict", "ps": "verb" }
          ]
        },
        {
          "t": "哪種運算選項會是最佳的？",
          "en": "Which compute option would be optimal?",
          "wg": [
            { "t": "最佳的", "en": "optimal", "ps": "adj" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) App Engine",
          "en": "(A) App Engine",
          "wg": []
        },
        {
          "t": "(B) Cloud Functions",
          "en": "(B) Cloud Functions",
          "wg": []
        },
        {
          "t": "(C) Compute Engine",
          "en": "(C) Compute Engine",
          "wg": []
        },
        {
          "t": "(D) Kubernetes Engine",
          "en": "(D) Kubernetes Engine",
          "wg": []
        }
      ],
      "answer": "(A)",
      "why": {
        "t": "App Engine 是完全託管的無伺服器平台，專為網頁應用程式設計。它能根據不可預測的流量自動擴展（包括縮減至零），這對於無法預測負載的無狀態 Python 應用程式來說是最佳選擇。雖然 Cloud Functions 也是無伺服器的，但 App Engine 更適合完整的網頁應用程式架構。",
        "en": "App Engine is a fully managed serverless platform designed for web applications. It automatically scales based on unpredictable traffic (including scaling to zero), making it the optimal choice for a stateless Python app with unpredictable load. While Cloud Functions is also serverless, App Engine is better suited for full web application architectures.",
        "wg": [
          { "t": "完全託管", "en": "fully managed", "ps": "adj" },
          { "t": "自動擴展", "en": "automatically scales", "ps": "verb" }
        ]
      }
    },
    {
      "no": "8",
      "level": "medium",
      "keywords": "Migration, NFS, Storage, Cloud Filestore",
      "question": [
        {
          "t": "遷移至 Google Cloud：在當前的地端環境中，VM 掛載了 NFS 儲存裝置以存取共享儲存。",
          "en": "Migrating to Google Cloud: in the current on-premises environment, VMs have a NFS storage mounted for accessing shared storage.",
          "wg": [
            { "t": "地端環境", "en": "on-premises environment", "ps": "noun" },
            { "t": "共享儲存", "en": "shared storage", "ps": "noun" }
          ]
        },
        {
          "t": "哪種原生的 GCP 服務可用於此案例？",
          "en": "What native GCP service can be used for this use-case?",
          "wg": []
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) Cloud Storage",
          "en": "(A) Cloud Storage",
          "wg": []
        },
        {
          "t": "(B) 文件資料庫",
          "en": "(B) A document database",
          "wg": []
        },
        {
          "t": "(C) 關聯式資料庫",
          "en": "(C) A relational database",
          "wg": []
        },
        {
          "t": "(D) Cloud Filestore",
          "en": "(D) Cloud Filestore",
          "wg": []
        }
      ],
      "answer": "(D)",
      "why": {
        "t": "Cloud Filestore 是 Google Cloud 的託管檔案儲存服務，支援 NFSv3 協定。這使得它成為需要共享檔案系統且依賴 NFS 的既有應用程式進行遷移時的直接替代方案。",
        "en": "Cloud Filestore is Google Cloud's managed file storage service that supports the NFSv3 protocol. This makes it the direct replacement for migrating existing applications that require a shared filesystem and rely on NFS.",
        "wg": [
          { "t": "託管檔案儲存", "en": "managed file storage", "ps": "noun" },
          { "t": "協定", "en": "protocol", "ps": "noun" }
        ]
      }
    },
    {
      "no": "9",
      "level": "hard",
      "keywords": "Dataproc, Cost Optimization, Preemptible VMs, Spark",
      "question": [
        {
          "t": "在 Dataproc 上執行非關鍵性 Apache Spark 作業，具成本效益的方式是什麼？",
          "en": "What's a cost-effective way to run non-critical Apache Spark jobs on Dataproc?",
          "wg": [
            { "t": "具成本效益", "en": "cost-effective", "ps": "adj" },
            { "t": "非關鍵性", "en": "non-critical", "ps": "adj" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 設定高可用性模式叢集，使用高記憶體機器類型。增加 10 個額外的本機 SSD。",
          "en": "(A) Set up a cluster in high availability mode with high-memory machine types. Add 10 additional local SSDs.",
          "wg": []
        },
        {
          "t": "(B) 設定高可用性模式叢集，使用預設機器類型。增加 10 個額外的可搶佔工作節點。",
          "en": "(B) Set up a cluster in high availability mode with default machine types. Add 10 additional preemptible worker nodes.",
          "wg": []
        },
        {
          "t": "(C) 設定標準模式叢集，使用高記憶體機器類型。增加 10 個額外的可搶佔工作節點。",
          "en": "(C) Set up a cluster in standard mode with high-memory machine types. Add 10 additional preemptible worker nodes.",
          "wg": [
            { "t": "標準模式", "en": "standard mode", "ps": "noun" },
            { "t": "可搶佔工作節點", "en": "preemptible worker nodes", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 設定標準模式叢集，使用預設機器類型。增加 10 個額外的本機 SSD。",
          "en": "(D) Set up a cluster in standard mode with the default machine types. Add 10 additional local SSDs.",
          "wg": []
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "為了達到成本效益，應避免使用高可用性 (HA) 模式（因為 HA 需要 3 個主節點，成本較高）。對於非關鍵作業，使用標準模式（1 個主節點）並搭配可搶佔 (Preemptible) 節點是最省錢的策略，因為可搶佔 VM 比標準 VM 便宜許多。選項 C 結合了標準模式與可搶佔節點，符合成本效益與效能需求（高記憶體）。",
        "en": "For cost-effectiveness, High Availability (HA) mode should be avoided as it requires 3 master nodes, increasing cost. For non-critical jobs, using Standard mode (1 master) combined with Preemptible nodes is the most economical strategy, as Preemptible VMs are significantly cheaper. Option C combines Standard mode with Preemptible nodes, meeting both cost and potential performance (high-mem) needs.",
        "wg": [
          { "t": "高可用性", "en": "High Availability", "ps": "noun" },
          { "t": "主節點", "en": "master nodes", "ps": "noun" }
        ]
      }
    },
    {
      "no": "10",
      "level": "medium",
      "keywords": "Data Engineering, Streaming, Pub/Sub, Dataflow, ETL",
      "question": [
        {
          "t": "來源數據以突發方式串流傳輸，且必須在使用前進行轉換。",
          "en": "Source data is streamed in bursts and must be transformed before use.",
          "wg": [
            { "t": "突發方式", "en": "bursts", "ps": "noun" },
            { "t": "串流傳輸", "en": "streamed", "ps": "verb" },
            { "t": "轉換", "en": "transformed", "ps": "verb" }
          ]
        },
        {
          "t": "你會使用什麼服務？",
          "en": "What services would you use?",
          "wg": []
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 Cloud Bigtable 進行快速輸入，並使用 cbt 進行 ETL。",
          "en": "(A) Use Cloud Bigtable for fast input and cbt for ETL.",
          "wg": []
        },
        {
          "t": "(B) 將數據攝取至 Cloud Storage。使用 Dataproc 進行 ETL。",
          "en": "(B) Ingest data to Cloud Storage. Use Dataproc for ETL.",
          "wg": []
        },
        {
          "t": "(C) 使用 Pub/Sub 緩衝數據，然後使用 BigQuery 進行 ETL。",
          "en": "(C) Use Pub/Sub to buffer the data, and then use BigQuery for ETL.",
          "wg": []
        },
        {
          "t": "(D) 使用 Pub/Sub 緩衝數據，然後使用 Dataflow 進行 ETL。",
          "en": "(D) Use Pub/Sub to buffer the data, and then use Dataflow for ETL.",
          "wg": [
            { "t": "緩衝", "en": "buffer", "ps": "verb" }
          ]
        }
      ],
      "answer": "(D)",
      "why": {
        "t": "這是處理突發性串流數據的經典 GCP 架構。Pub/Sub 作為全域緩衝區，能夠吸收數據突發峰值，確保不會遺失訊息。Dataflow 則負責從 Pub/Sub 讀取數據並執行轉換邏輯 (ETL)。選項 C 雖使用了 Pub/Sub，但 BigQuery 主要用於分析，而非執行複雜的串流轉換管道。",
        "en": "This is the classic GCP architecture for handling bursty streaming data. Pub/Sub acts as a global buffer to absorb data spikes, ensuring no messages are lost. Dataflow then reads from Pub/Sub and executes the transformation logic (ETL). While Option C uses Pub/Sub, BigQuery is primarily for analysis, not for executing complex streaming transformation pipelines.",
        "wg": [
          { "t": "全域緩衝區", "en": "global buffer", "ps": "noun" },
          { "t": "吸收", "en": "absorb", "ps": "verb" },
          { "t": "峰值", "en": "spikes", "ps": "noun" }
        ]
      }
    },
{
      "no": "11",
      "level": "easy",
      "keywords": "Data Engineering, Pub/Sub, Dataflow, BigQuery",
      "question": [
        {
          "t": "哪三種 Google Cloud 服務常在數據工程解決方案中一起使用？",
          "en": "What are three Google Cloud services commonly used together in data engineering solutions?",
          "wg": [
            { "t": "數據工程解決方案", "en": "data engineering solutions", "ps": "noun" },
            { "t": "一起使用", "en": "used together", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) Dataproc, Cloud SQL, BigQuery.",
          "en": "(A) Dataproc, Cloud SQL, BigQuery.",
          "wg": []
        },
        {
          "t": "(B) Pub/Sub, Dataflow, BigQuery.",
          "en": "(B) Pub/Sub, Dataflow, BigQuery.",
          "wg": []
        },
        {
          "t": "(C) Pub/Sub, Google Kubernetes Engine, Cloud Spanner.",
          "en": "(C) Pub/Sub, Google Kubernetes Engine, Cloud Spanner.",
          "wg": []
        },
        {
          "t": "(D) Cloud Bigtable, Dataproc, Cloud Spanner.",
          "en": "(D) Cloud Bigtable, Dataproc, Cloud Spanner.",
          "wg": []
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "這是 GCP 數據處理的經典「黃金三角」架構：Pub/Sub 負責訊息攝取與緩衝（Messaging），Dataflow 負責 ETL 與數據轉換（Processing），BigQuery 負責分析與互動式查詢（Analysis）。這三者整合緊密，形成了強大的串流與批次處理管道。",
        "en": "This is the classic 'Golden Triangle' architecture for data processing on GCP: Pub/Sub handles message ingestion and buffering (Messaging), Dataflow handles ETL and data transformation (Processing), and BigQuery handles analysis and interactive queries (Analysis). These three integrate tightly to form powerful streaming and batch processing pipelines.",
        "wg": [
          { "t": "訊息攝取", "en": "message ingestion", "ps": "noun" },
          { "t": "互動式查詢", "en": "interactive queries", "ps": "noun" }
        ]
      }
    },
    {
      "no": "12",
      "level": "hard",
      "keywords": "Kubernetes Engine, Cloud SQL Proxy, Troubleshooting, Cloud Logging",
      "question": [
        {
          "t": "您將應用程式部署到 Kubernetes Engine，並使用 Cloud SQL Proxy 容器讓 Kubernetes 上的服務能夠存取 Cloud SQL 資料庫。",
          "en": "You have deployed an application to Kubernetes Engine, and are using the Cloud SQL proxy container to make the Cloud SQL database available to the services running on Kubernetes.",
          "wg": [
            { "t": "部署", "en": "deployed", "ps": "verb" },
            { "t": "代理容器", "en": "proxy container", "ps": "noun" }
          ]
        },
        {
          "t": "您收到通知說應用程式回報資料庫連線問題。公司政策要求進行事後檢討 (post-mortem)。您應該做什麼？",
          "en": "You are notified that the application is reporting database connection issues. Your company policies require a post-mortem. What should you do?",
          "wg": [
            { "t": "事後檢討", "en": "post-mortem", "ps": "noun" },
            { "t": "連線問題", "en": "connection issues", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 gcloud sql instances restart。",
          "en": "(A) Use gcloud sql instances restart.",
          "wg": []
        },
        {
          "t": "(B) 驗證 Cloud SQL Proxy 容器使用的服務帳戶是否仍具有 Cloud Build Editor 角色。",
          "en": "(B) Validate that the Service Account used by the Cloud SQL proxy container still has the Cloud Build Editor role.",
          "wg": []
        },
        {
          "t": "(C) 在 GCP 控制台中，導航至 Cloud Logging。查閱 Kubernetes Engine 和 Cloud SQL 的日誌。",
          "en": "(C) In the GCP Console, navigate to Cloud Logging. Consult logs for Kubernetes Engine and Cloud SQL.",
          "wg": [
            { "t": "查閱", "en": "Consult", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 在 GCP 控制台中，導航至 Cloud SQL。還原最新的備份。使用 kubectl 重啟所有 pod。",
          "en": "(D) In the GCP Console, navigate to Cloud SQL. Restore the latest backup. Use kubectl to restart all pods.",
          "wg": []
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "在進行故障排除（特別是為了事後檢討）時，第一步永遠是收集證據並了解發生了什麼事，而不是盲目重啟服務。Cloud Logging 集中了 GKE 容器日誌（包括 Sidecar proxy）和 Cloud SQL 實例日誌，是診斷連線問題根本原因的最佳位置。",
        "en": "When troubleshooting (especially for a post-mortem), the first step is always to gather evidence and understand what happened, rather than blindly restarting services. Cloud Logging aggregates GKE container logs (including the sidecar proxy) and Cloud SQL instance logs, making it the best place to diagnose the root cause of connection issues.",
        "wg": [
          { "t": "故障排除", "en": "troubleshooting", "ps": "verb" },
          { "t": "根本原因", "en": "root cause", "ps": "noun" }
        ]
      }
    },
    {
      "no": "13",
      "level": "hard",
      "keywords": "Compute Engine, Autoscaling, Instance Template, Custom Image",
      "question": [
        {
          "t": "貴公司正在 Compute Engine 實例上運行一個無狀態應用程式。用戶報告在高峰時段應用程式變慢。",
          "en": "Your company is running a stateless application on a Compute Engine instance. Users are reporting that the application is slow during peak hours.",
          "wg": [
            { "t": "高峰時段", "en": "peak hours", "ps": "noun" },
            { "t": "變慢", "en": "slow", "ps": "adj" }
          ]
        },
        {
          "t": "您需要優化應用程式的效能。您應該做什麼？",
          "en": "You need to optimize the application's performance. What should you do?",
          "wg": [
            { "t": "優化", "en": "optimize", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 為現有磁碟建立快照。從快照建立實例範本 (Instance Template)。從實例範本建立自動擴展的託管實例群組 (MIG)。",
          "en": "(A) Create a snapshot of the existing disk. Create an instance template from the snapshot. Create an autoscaled managed instance group from the instance template.",
          "wg": []
        },
        {
          "t": "(B) 為現有磁碟建立快照。從快照建立自訂映像檔 (Custom Image)。從自訂映像檔建立自動擴展的託管實例群組。",
          "en": "(B) Create a snapshot of the existing disk. Create a custom image from the snapshot. Create an autoscaled managed instance group from the custom image.",
          "wg": []
        },
        {
          "t": "(C) 從現有磁碟建立自訂映像檔。從自訂映像檔建立實例範本。從實例範本建立自動擴展的託管實例群組。",
          "en": "(C) Create a custom image from the existing disk. Create an instance template from the custom image. Create an autoscaled managed instance group from the instance template.",
          "wg": [
            { "t": "自訂映像檔", "en": "custom image", "ps": "noun" },
            { "t": "實例範本", "en": "instance template", "ps": "noun" }
          ]
        },
        {
          "t": "(D) 從現有磁碟建立實例範本。從實例範本建立自訂映像檔。從自訂映像檔建立自動擴展的託管實例群組。",
          "en": "(D) Create an instance template from the existing disk. Create a custom image from the instance template. Create an autoscaled managed instance group from the custom image.",
          "wg": []
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "正確的流程是：1. 將磁碟狀態保存為映像檔 (Image)（快照不能直接用於建立範本）。2. 使用該映像檔定義實例範本 (Instance Template)（這是 MIG 的藍圖）。3. 使用該範本建立託管實例群組 (MIG) 並開啟自動擴展。MIG 必須基於實例範本建立，而不能直接基於映像檔建立。",
        "en": "The correct workflow is: 1. Save the disk state as an Image (snapshots cannot be used directly to create a template). 2. Use that Image to define an Instance Template (this is the blueprint for the MIG). 3. Create a Managed Instance Group (MIG) using that template and enable autoscaling. A MIG must be created based on an Instance Template, not directly from an image.",
        "wg": [
          { "t": "藍圖", "en": "blueprint", "ps": "noun" },
          { "t": "託管實例群組", "en": "Managed Instance Group", "ps": "noun" }
        ]
      }
    },
    {
      "no": "14",
      "level": "medium",
      "keywords": "VPC, Networking, GCE, GKE, Serverless",
      "question": [
        {
          "t": "您建立了一個新專案，但由於組織政策限制，沒有建立 VPC。",
          "en": "You created a new project, but due to an org policy restrictions, no VPC was created.",
          "wg": [
            { "t": "組織政策", "en": "org policy", "ps": "noun" },
            { "t": "限制", "en": "restrictions", "ps": "noun" }
          ]
        },
        {
          "t": "這樣一個沒有 VPC 的專案會有什麼影響？（選擇 2 項）",
          "en": "What are the effects of such a project, without a VPC? (choose 2)",
          "wg": []
        }
      ],
      "type": "多選題",
      "options": [
        {
          "t": "(A) 您仍然可以正常建立所有 GCP 資源",
          "en": "(A) You can still create all GCP resources as normal",
          "wg": []
        },
        {
          "t": "(B) 您無法建立 GCE VM",
          "en": "(B) You can't create a GCE VM",
          "wg": []
        },
        {
          "t": "(C) 您無法建立 Cloud Function",
          "en": "(C) You cannot create a Cloud Function",
          "wg": []
        },
        {
          "t": "(D) 您無法建立 GCS 儲存桶",
          "en": "(D) You cannot create a GCS bucket",
          "wg": []
        },
        {
          "t": "(E) 您無法建立 GKE 叢集",
          "en": "(E) You cannot create a GKE cluster",
          "wg": []
        }
      ],
      "answer": "(B), (E)",
      "why": {
        "t": "VPC (虛擬私有雲) 是 IaaS 資源的網路基礎。Compute Engine (GCE) 虛擬機和 Kubernetes Engine (GKE) 叢集（其節點本身就是虛擬機）都必須依賴 VPC 網路介面才能運作。相反地，像 Cloud Storage (GCS) 和 Cloud Functions (Serverless) 等全域或無伺服器資源不一定需要 VPC 即可建立（除非有特定網路設定需求）。",
        "en": "A VPC (Virtual Private Cloud) is the networking foundation for IaaS resources. Compute Engine (GCE) VMs and Kubernetes Engine (GKE) clusters (whose nodes are VMs) essentially require a VPC network interface to function. Conversely, global or serverless resources like Cloud Storage (GCS) and Cloud Functions do not strictly require a VPC to be created (unless specific networking configurations are needed).",
        "wg": [
          { "t": "網路基礎", "en": "networking foundation", "ps": "noun" },
          { "t": "依賴", "en": "require", "ps": "verb" }
        ]
      }
    },
    {
      "no": "15",
      "level": "medium",
      "keywords": "Kubernetes Engine, Logging, Troubleshooting, Stdout",
      "question": [
        {
          "t": "您正在 Kubernetes Engine 上運行叢集以服務網頁應用程式。用戶報告應用程式的特定部分不再回應。您注意到所有 pod 每 2 秒重啟一次。",
          "en": "You are running a cluster on Kubernetes Engine to serve a web application. Users are reporting that a specific part of the application is not responding anymore. You notice that all pods of your deployment keep restarting after 2 seconds.",
          "wg": [
            { "t": "不再回應", "en": "not responding", "ps": "verb" },
            { "t": "重啟", "en": "restarting", "ps": "verb" }
          ]
        },
        {
          "t": "應用程式將日誌寫入標準輸出 (stdout)。您想檢查日誌以找出問題原因。您可以採取哪種方法？",
          "en": "The application writes logs to standard output. You want to inspect the logs to find the cause of the issue. Which approach can you take?",
          "wg": [
            { "t": "標準輸出", "en": "standard output", "ps": "noun" },
            { "t": "檢查", "en": "inspect", "ps": "verb" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 查閱作為叢集節點的每個 Compute Engine 實例的 Cloud Logging。",
          "en": "(A) Review the Cloud Logging for each Compute Engine instance that is serving as a node in the cluster.",
          "wg": []
        },
        {
          "t": "(B) 查閱服務應用程式無回應部分的特定 Kubernetes Engine 容器的 Cloud Logging。",
          "en": "(B) Review the Cloud Logging for the specific Kubernetes Engine container that is serving the unresponsive part of the application.",
          "wg": []
        },
        {
          "t": "(C) 使用 gcloud 憑證連接到叢集，並連接到其中一個 pod 中的容器以讀取日誌。",
          "en": "(C) Connect to the cluster using gcloud credentials and connect to a container in one of the pods to read the logs.",
          "wg": []
        },
        {
          "t": "(D) 查閱作為叢集節點的每個 Compute Engine 實例的序列埠 (Serial Port) 日誌。",
          "en": "(D) Review the Serial Port logs for each Compute Engine instance that is serving as a node in the cluster.",
          "wg": []
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "GKE 會自動收集容器寫入標準輸出 (stdout) 和標準錯誤 (stderr) 的日誌，並將其傳送至 Cloud Logging。由於 Pod 不斷重啟（CrashLoopBackOff），直接連接到 Pod (選項 C) 可能很困難且來不及查看。查看特定容器的 Cloud Logging 是最有效且持久的日誌檢視方式。",
        "en": "GKE automatically collects logs written to standard output (stdout) and standard error (stderr) by containers and sends them to Cloud Logging. Since the pods are constantly restarting (CrashLoopBackOff), connecting directly to the pod (Option C) would be difficult and transient. Reviewing Cloud Logging for the specific container is the most effective and persistent way to view these logs.",
        "wg": [
          { "t": "持久的", "en": "persistent", "ps": "adj" },
          { "t": "自動收集", "en": "automatically collects", "ps": "verb" }
        ]
      }
    },
{
      "no": "16",
      "level": "medium",
      "keywords": "GKE, Deployment, Infrastructure as Code, gcloud, kubectl",
      "question": [
        {
          "t": "開發團隊為您提供了一個 Kubernetes 佈署 (Deployment) 檔案。您目前還沒有任何基礎設施，且需要佈署該應用程式。",
          "en": "The development team has provided you with a Kubernetes Deployment file. You have no infrastructure yet and need to deploy the application.",
          "wg": [
            { "t": "佈署檔案", "en": "Deployment file", "ps": "noun" },
            { "t": "基礎設施", "en": "infrastructure", "ps": "noun" }
          ]
        },
        {
          "t": "您應該採取什麼行動？",
          "en": "What should you do?",
          "wg": []
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 使用 gcloud 建立 Kubernetes 叢集。使用 Deployment Manager 建立佈署。",
          "en": "(A) Use gcloud to create a Kubernetes cluster. Use Deployment Manager to create the deployment.",
          "wg": []
        },
        {
          "t": "(B) 使用 gcloud 建立 Kubernetes 叢集。使用 kubectl 建立佈署。",
          "en": "(B) Use gcloud to create a Kubernetes cluster. Use kubectl to create the deployment.",
          "wg": [
            { "t": "建立叢集", "en": "create a cluster", "ps": "verb" }
          ]
        },
        {
          "t": "(C) 使用 kubectl 建立 Kubernetes 叢集。使用 Deployment Manager 建立佈署。",
          "en": "(C) Use kubectl to create a Kubernetes cluster. Use Deployment Manager to create the deployment.",
          "wg": []
        },
        {
          "t": "(D) 使用 kubectl 建立 Kubernetes 叢集。使用 kubectl 建立佈署。",
          "en": "(D) Use kubectl to create a Kubernetes cluster. Use kubectl to create the deployment.",
          "wg": []
        }
      ],
      "answer": "(B)",
      "why": {
        "t": "在 GCP 中，建立基礎設施（如 GKE 叢集）應使用 Google Cloud SDK 命令 `gcloud`。一旦叢集建立完成，與 Kubernetes 內部的資源（如 Deployments, Pods）進行互動則應使用 Kubernetes 標準工具 `kubectl`。Deployment Manager 是用於 GCP 資源編排的，而不是用來解析 Kubernetes YAML 佈署檔案的。",
        "en": "In GCP, creating infrastructure (like a GKE cluster) should be done using the Google Cloud SDK command `gcloud`. Once the cluster is created, interacting with Kubernetes-internal resources (like Deployments, Pods) should be done using the standard Kubernetes tool `kubectl`. Deployment Manager is for orchestrating GCP resources, not for parsing Kubernetes YAML deployment files.",
        "wg": [
          { "t": "互動", "en": "interacting", "ps": "verb" },
          { "t": "資源編排", "en": "orchestrating", "ps": "verb" }
        ]
      }
    },
    {
      "no": "17",
      "level": "hard",
      "keywords": "IAM, Service Account, Datastore, Least Privilege, Cross-Project",
      "question": [
        {
          "t": "客戶希望部署一個新的 GCE 應用程式，該程式將使用部署在另一個獨立專案中的 Datastore 資料庫。",
          "en": "A customer wants to deploy a new GCE-based application that will use a Datastore database deployed in a separate project.",
          "wg": [
            { "t": "獨立專案", "en": "separate project", "ps": "noun" }
          ]
        },
        {
          "t": "遵循最小權限原則，您會建議哪種服務帳戶 (Service Account) 方法？",
          "en": "Following the least privilege approach, what approach to Service Accounts would you advise?",
          "wg": [
            { "t": "最小權限原則", "en": "least privilege approach", "ps": "noun" }
          ]
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) 在兩個專案中分別建立服務帳戶，並授予其對應專案的擁有者 (Owner) 角色。",
          "en": "(A) Create Service Accounts in both projects and assign them corresponding projects’ owner role.",
          "wg": []
        },
        {
          "t": "(B) 在新專案中建立服務帳戶，並授予其組織管理員 (Org Admin) 角色。",
          "en": "(B) Create a Service Account in the new project and grant it Org Admin role.",
          "wg": []
        },
        {
          "t": "(C) 在新專案中建立一個供應用程式使用的服務帳戶，並授予其在 Datastore 專案中的 roles/datastore.user 角色。",
          "en": "(C) Create a Service Account in the new project and grant it roles/datastore.user role in the Datastore project.",
          "wg": [
            { "t": "授予角色", "en": "grant role", "ps": "verb" }
          ]
        },
        {
          "t": "(D) 在舊有專案中建立服務帳戶，並授予其 roles/datastore.user 角色。",
          "en": "(D) Create a Service Account in the legacy project and grant it roles/datastore.user role.",
          "wg": []
        }
      ],
      "answer": "(C)",
      "why": {
        "t": "最佳實踐是在運行資源（GCE 實例）所在的專案中建立服務帳戶，然後在資源所在的專案（Datastore 專案）中為該帳戶授予所需的特定權限（datastore.user）。這符合「最小權限原則」，因為它只給予了存取資料庫所需的權限，而不是整個專案的擁有者或組織管理員角色。",
        "en": "The best practice is to create the Service Account in the project where the computing resource (GCE instance) resides, and then grant that account the specific required permission (datastore.user) in the project where the data resource (Datastore) resides. This adheres to the 'principle of least privilege' by giving only the necessary database access rather than broad Owner or Org Admin roles.",
        "wg": [
          { "t": "最佳實踐", "en": "best practice", "ps": "noun" },
          { "t": "權限", "en": "permission", "ps": "noun" }
        ]
      }
    },
    {
      "no": "18",
      "level": "medium",
      "keywords": "App Engine, Scaling, Cost, Serverless",
      "question": [
        {
          "t": "您正在建立一個新的測試環境。您希望該環境在沒有活動時自動「縮減至零」，以免產生費用。",
          "en": "You are creating a new test environment. You want the environment to automatically 'scale to zero' so you don't incur costs when there is no activity.",
          "wg": [
            { "t": "測試環境", "en": "test environment", "ps": "noun" },
            { "t": "縮減至零", "en": "scale to zero", "ps": "verb" }
          ]
        },
        {
          "t": "您應該選擇哪種主要的運算資源？",
          "en": "Which primary compute resource should you choose?",
          "wg": []
        }
      ],
      "type": "單選題",
      "options": [
        {
          "t": "(A) App Engine Standard",
          "en": "(A) App Engine Standard",
          "wg": []
        },
        {
          "t": "(B) App Engine Flexible",
          "en": "(B) App Engine Flexible",
          "wg": []
        },
        {
          "t": "(C) Compute Engine 託管實例群組",
          "en": "(C) Compute Engine Managed Instance Groups",
          "wg": []
        },
        {
          "t": "(D) Google Kubernetes Engine (Standard)",
          "en": "(D) Google Kubernetes Engine (Standard)",
          "wg": []
        }
      ],
      "answer": "(A)",
      "why": {
        "t": "App Engine Standard 環境最具備此特性，當沒有流量時，它可以將實例數量降至零，從而停止計費。App Engine Flexible 和 GKE Standard 通常需要至少一個實例或節點處於運行狀態（除非使用特定設定，但非預設行為且啟動慢），而 GCE 實例即時自動擴展也無法完全將基礎執行個體成本降為零。",
        "en": "The App Engine Standard environment is characterized by this feature: it can reduce the number of instances to zero when there is no traffic, thereby stopping billing. App Engine Flexible and GKE Standard usually require at least one instance or node to remain running (unless specific configurations are used, but it's not default and startup is slow), and GCE autoscaling cannot eliminate the base instance cost entirely to zero.",
        "wg": [
          { "t": "計費", "en": "billing", "ps": "noun" },
          { "t": "流量", "en": "traffic", "ps": "noun" }
        ]
      }
    }
  ]