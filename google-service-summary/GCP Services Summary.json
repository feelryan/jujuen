[
  {
    "no": "1",
    "level": "hard",
    "keywords": "Hybrid Connectivity, Dedicated Interconnect, SLA, High Availability",
    "question": [
      {
        "t": "您的客戶是一家跨國金融機構，正計劃將其地端的主要交易系統連接到 Google Cloud。該業務要求連線必須具備極高的可靠性，並明確要求 99.99% 的可用性服務水準協議 (SLA) 以符合監管機關的規範。",
        "en": "Your client, a multinational financial institution, is planning to connect their on-premises primary trading system to Google Cloud. The business requires the connection to have extremely high reliability and explicitly demands a 99.99% Availability Service Level Agreement (SLA) to comply with regulatory standards.",
        "wg": [
          { "t": "跨國金融機構", "en": "multinational financial institution", "ps": "noun" },
          { "t": "可用性服務水準協議", "en": "Availability Service Level Agreement (SLA)", "ps": "noun" }
        ]
      },
      {
        "t": "目前的網路架構顯示，客戶在兩個不同的都市區域 (Metropolitan Areas) 皆擁有資料中心。您需要設計一個 Dedicated Interconnect 架構來滿足此 SLA 要求，同時確保在單一設施故障時仍能維持連線。",
        "en": "The current network architecture shows that the client has data centers in two different Metropolitan Areas. You need to design a Dedicated Interconnect architecture to meet this SLA requirement while ensuring connectivity is maintained in the event of a single facility failure.",
        "wg": [
          { "t": "都市區域", "en": "Metropolitan Areas", "ps": "noun" },
          { "t": "單一設施故障", "en": "single facility failure", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在單一都市區域內配置兩條 Dedicated Interconnect 電路，並透過 Cloud VPN 建立備援通道作為故障轉移路徑，以降低成本並滿足 SLA。",
        "en": "(A) Provision two Dedicated Interconnect circuits within a single metropolitan area and establish a redundant tunnel via Cloud VPN as a failover path to reduce costs and meet the SLA.",
        "wg": [
          { "t": "備援通道", "en": "redundant tunnel", "ps": "noun" },
          { "t": "故障轉移路徑", "en": "failover path", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 在單一都市區域內配置四條 Dedicated Interconnect 電路，分別連接到兩個不同的 Google 邊緣可用區 (Edge Availability Domains)，以確保最高的吞吐量。",
        "en": "(B) Provision four Dedicated Interconnect circuits within a single metropolitan area, connecting to two different Google Edge Availability Domains respectively, to ensure maximum throughput.",
        "wg": [
          { "t": "邊緣可用區", "en": "Edge Availability Domains", "ps": "noun" },
          { "t": "吞吐量", "en": "throughput", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 在兩個不同的都市區域各配置兩條 Dedicated Interconnect 電路（總共四條），確保在每個都會區內連接到兩個不同的 Google 邊緣可用區，並啟用全球動態路由。",
        "en": "(C) Provision two Dedicated Interconnect circuits in each of two different metropolitan areas (four in total), ensuring connection to two different Google Edge Availability Domains within each metro, and enable global dynamic routing.",
        "wg": [
          { "t": "全球動態路由", "en": "global dynamic routing", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Partner Interconnect 連接，並要求服務供應商提供其 Layer 3 的 99.99% SLA 保證，這比直接管理 Dedicated Interconnect 更為簡單且責任轉嫁給供應商。",
        "en": "(D) Use Partner Interconnect connections and request the service provider to provide their Layer 3 99.99% SLA guarantee, which is simpler than directly managing Dedicated Interconnect and shifts liability to the provider.",
        "wg": [
          { "t": "責任轉嫁", "en": "shifts liability", "ps": "verb phrase" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "根據 Google Cloud 架構規範，要獲得 99.99% 的 SLA，必須在兩個不同的都市區域 (Metros) 各部署兩條連線（總共 4 條），以防止單一都會區發生災難性故障。(A) 選項混用 VPN 無法保證 Interconnect 等級的 SLA。(B) 選項集中在單一都會區只能提供 99.9% SLA。",
      "en": "According to Google Cloud architectural standards, to achieve a 99.99% SLA, you must deploy two connections in each of two different metropolitan areas (4 total) to protect against catastrophic failure in a single metro. Option (A) mixing VPN does not guarantee Interconnect-grade SLA. Option (B) concentrated in a single metro only provides 99.9% SLA.",
      "wg": [
        { "t": "災難性故障", "en": "catastrophic failure", "ps": "noun" }
      ]
    }
  },
  {
    "no": "2",
    "level": "hard",
    "keywords": "Migration, GCVE, VMware, Lift and Shift",
    "question": [
      {
        "t": "一家大型製造業客戶需要由地端資料中心撤出，並且面臨嚴格的 3 個月遷移期限。他們目前的環境高度依賴 VMware vSphere，且擁有數百個使用傳統 OS 的應用程式，這些應用程式的重構成本極高且風險未知。",
        "en": "A large manufacturing client needs to evacuate their on-premises data center and faces a strict 3-month migration deadline. Their current environment relies heavily on VMware vSphere and hosts hundreds of applications using legacy OSs, for which refactoring costs are extremely high and risks unknown.",
        "wg": [
          { "t": "撤出", "en": "evacuate", "ps": "verb" },
          { "t": "重構成本", "en": "refactoring costs", "ps": "noun" }
        ]
      },
      {
        "t": "客戶希望能保留現有的維運工具 (vCenter) 與流程，同時希望能利用 Google Cloud 的資料分析服務 (如 BigQuery)。您需要建議一個能在期限內完成且風險最低的遷移方案。",
        "en": "The client wishes to retain existing operational tools (vCenter) and processes while also leveraging Google Cloud data analytics services (like BigQuery). You need to recommend a migration plan that can be completed within the deadline with minimal risk.",
        "wg": [
          { "t": "維運工具", "en": "operational tools", "ps": "noun" },
          { "t": "期限", "en": "deadline", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Migrate for Compute Engine 將所有 VM 轉換為 Google Compute Engine 執行個體，並利用 Terraform 重新編寫基礎設施即程式碼 (IaC) 以現代化管理。",
        "en": "(A) Use Migrate for Compute Engine to convert all VMs into Google Compute Engine instances, and utilize Terraform to rewrite Infrastructure as Code (IaC) for modernized management.",
        "wg": [
          { "t": "轉換", "en": "convert", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 部署 Google Cloud VMware Engine (GCVE) 私有雲，透過 HCX 使用 vMotion 進行即時遷移，並配置 Private Service Access 以便 VM 能透過內部網路存取 BigQuery。",
        "en": "(B) Deploy a Google Cloud VMware Engine (GCVE) private cloud, use HCX to perform live migration via vMotion, and configure Private Service Access so VMs can access BigQuery over the internal network.",
        "wg": [
          { "t": "即時遷移", "en": "live migration", "ps": "noun" },
          { "t": "私有雲", "en": "private cloud", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Migrate for Anthos (Migrate to Containers) 將所有傳統 VM 自動容器化並部署至 GKE Autopilot，以消除作業系統維護的負擔。",
        "en": "(C) Use Migrate for Anthos (Migrate to Containers) to automatically containerize all legacy VMs and deploy them to GKE Autopilot to eliminate the burden of OS maintenance.",
        "wg": [
          { "t": "容器化", "en": "containerize", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 將 VM 匯出為 OVF 格式，上傳至 Cloud Storage，然後將其匯入為 Compute Engine 自定義映像檔，並手動重新配置網路設定。",
        "en": "(D) Export VMs as OVF format, upload to Cloud Storage, then import them as Compute Engine custom images, and manually reconfigure network settings.",
        "wg": [
          { "t": "匯出", "en": "export", "ps": "verb" },
          { "t": "匯入", "en": "import", "ps": "verb" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "題目強調「保留現有 vCenter 工具」、「期限緊迫」且「重構風險高」。GCVE 是唯一的解答，它允許直接使用 vMotion 遷移而無需轉換 VM 格式，且能透過專用連線存取 Google 原生服務。(A) 和 (D) 涉及格式轉換與工具變更，風險較高。(C) 容器化對於傳統 OS 應用程式來說過於激進且耗時。",
      "en": "The question emphasizes 'retaining existing vCenter tools', 'tight deadline', and 'high refactoring risk'. GCVE is the only answer that allows direct migration using vMotion without converting VM formats, while enabling access to Google native services via private connections. (A) and (D) involve format conversion and tool changes, carrying higher risk. (C) Containerization is too aggressive and time-consuming for legacy OS apps.",
      "wg": [
        { "t": "格式轉換", "en": "format conversion", "ps": "noun" },
        { "t": "激進", "en": "aggressive", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "3",
    "level": "hard",
    "keywords": "Storage, Compliance, Bucket Lock, Retention Policy",
    "question": [
      {
        "t": "您的公司是一家受嚴格監管的醫療機構，必須遵守法規要求將所有的病歷存取日誌保留至少 7 年。在此期間，這些日誌必須是不可變的 (Immutable)，即便是擁有最高權限的管理員也無法刪除或修改它們。",
        "en": "Your company is a strictly regulated healthcare institution that must comply with regulations to retain all medical record access logs for at least 7 years. During this period, these logs must be immutable, meaning even administrators with the highest privileges cannot delete or modify them.",
        "wg": [
          { "t": "不可變的", "en": "Immutable", "ps": "adjective" },
          { "t": "最高權限", "en": "highest privileges", "ps": "noun" }
        ]
      },
      {
        "t": "目前日誌是由應用程式寫入到 Cloud Storage 的。您需要配置一個儲存解決方案來滿足此合規性要求，同時最小化維護工作。",
        "en": "Currently, logs are written to Cloud Storage by the application. You need to configure a storage solution to meet this compliance requirement while minimizing maintenance effort.",
        "wg": [
          { "t": "合規性要求", "en": "compliance requirement", "ps": "noun" },
          { "t": "維護工作", "en": "maintenance effort", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用 Bucket Versioning，並設定 IAM 政策以拒絕所有使用者的 `storage.objects.delete` 權限。使用 Object Lifecycle Management 在 7 年後將舊版本設為過期。",
        "en": "(A) Enable Bucket Versioning and configure IAM policies to deny `storage.objects.delete` permission for all users. Use Object Lifecycle Management to expire old versions after 7 years.",
        "wg": [
          { "t": "拒絕", "en": "deny", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 設定 Bucket Retention Policy 為 7 年，並將該政策「鎖定」(Lock)。這將強制執行 WORM (Write Once, Read Many) 合規性，防止在保留期滿前刪除物件。",
        "en": "(B) Set a Bucket Retention Policy of 7 years and 'Lock' the policy. This enforces WORM (Write Once, Read Many) compliance, preventing object deletion before the retention period expires.",
        "wg": [
          { "t": "強制執行", "en": "enforces", "ps": "verb" },
          { "t": "鎖定", "en": "Lock", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 將日誌匯出到 BigQuery，並使用 `IAM roles/bigquery.dataViewer` 限制存取。設定資料集過期時間為 7 年，以確保資料自動清除。",
        "en": "(C) Export logs to BigQuery and restrict access using `IAM roles/bigquery.dataViewer`. Set the dataset expiration time to 7 years to ensure data is automatically purged.",
        "wg": [
          { "t": "資料集過期時間", "en": "dataset expiration time", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 對儲存日誌的 Bucket 應用 Legal Hold。在 7 年期限到達時，編寫一個 Cloud Function 觸發程序來移除 Legal Hold 並刪除資料。",
        "en": "(D) Apply a Legal Hold to the bucket storing the logs. When the 7-year term arrives, write a Cloud Function trigger to remove the Legal Hold and delete the data.",
        "wg": [
          { "t": "法律保留", "en": "Legal Hold", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Bucket Lock (鎖定的保留政策) 是實現 WORM 合規性的標準方法，它能防止包括管理員在內的任何人刪除資料，滿足「不可變」的要求。(A) 的 IAM 政策可以被管理員修改，不符合嚴格合規。(D) Legal Hold 是無限期的，且通常用於臨時的法律調查，並非自動化的生命週期管理工具。",
      "en": "Bucket Lock (Locked Retention Policy) is the standard method for achieving WORM compliance, preventing deletion by anyone including admins, satisfying the 'immutable' requirement. (A) IAM policies can be modified by admins, failing strict compliance. (D) Legal Hold is indefinite and typically used for temporary legal investigations, not automated lifecycle management.",
      "wg": [
        { "t": "標準方法", "en": "standard method", "ps": "noun" },
        { "t": "無限期", "en": "indefinite", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "4",
    "level": "hard",
    "keywords": "Compute, GKE, Security, Network Policy, Autopilot",
    "question": [
      {
        "t": "您正在設計一個多租戶 (Multi-tenant) 的 SaaS 平台，該平台將在 Google Kubernetes Engine (GKE) 上運行。每個租戶的微服務將部署在獨立的 Namespace 中。",
        "en": "You are designing a multi-tenant SaaS platform that will run on Google Kubernetes Engine (GKE). Each tenant's microservices will be deployed in a separate Namespace.",
        "wg": [
          { "t": "多租戶", "en": "Multi-tenant", "ps": "adjective" },
          { "t": "命名空間", "en": "Namespace", "ps": "noun" }
        ]
      },
      {
        "t": "安全團隊要求必須嚴格隔離租戶之間的網路流量，確保租戶 A 的 Pod 無法與租戶 B 的 Pod 通訊。同時，維運團隊希望盡可能減少對底層節點 (Nodes) 的管理負擔。請選擇兩項配置來滿足這些需求。",
        "en": "The security team requires strict isolation of network traffic between tenants, ensuring Tenant A's Pods cannot communicate with Tenant B's Pods. Meanwhile, the operations team wants to minimize the management burden of underlying nodes. Please select two configurations to meet these requirements.",
        "wg": [
          { "t": "隔離", "en": "isolation", "ps": "noun" },
          { "t": "管理負擔", "en": "management burden", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 建立 GKE Autopilot 叢集，讓 Google 全權管理節點的配置、擴展與安全修補。",
        "en": "(A) Create a GKE Autopilot cluster, allowing Google to fully manage node provisioning, scaling, and security patching.",
        "wg": [
          { "t": "全權管理", "en": "fully manage", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(B) 建立 GKE Standard 叢集，並啟用 Node Auto-provisioning 與 Shielded GKE Nodes。",
        "en": "(B) Create a GKE Standard cluster and enable Node Auto-provisioning and Shielded GKE Nodes.",
        "wg": [
          { "t": "節點自動配置", "en": "Node Auto-provisioning", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 定義並套用 Kubernetes Network Policies，配置 `ingress` 和 `egress` 規則以拒絕跨 Namespace 的通訊。",
        "en": "(C) Define and apply Kubernetes Network Policies, configuring `ingress` and `egress` rules to deny cross-Namespace communication.",
        "wg": [
          { "t": "跨 Namespace 通訊", "en": "cross-Namespace communication", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 為每個租戶建立獨立的 VPC 網路，並使用 VPC Peering 連接所有網路到一個共用的 GKE 控制平面。",
        "en": "(D) Create separate VPC networks for each tenant and use VPC Peering to connect all networks to a shared GKE control plane.",
        "wg": [
          { "t": "控制平面", "en": "control plane", "ps": "noun" }
        ]
      },
      {
        "t": "(E) 使用 Binary Authorization 確保只有經過簽署的映像檔才能部署到租戶的 Namespace。",
        "en": "(E) Use Binary Authorization to ensure only signed images can be deployed to tenant Namespaces.",
        "wg": [
          { "t": "經過簽署的映像檔", "en": "signed images", "ps": "noun phrase" }
        ]
      }
    ],
    "answer": "(A), (C)",
    "why": {
      "t": "需求有兩點：最小化節點管理 (Low Ops) 與網路隔離 (Isolation)。(A) GKE Autopilot 是完全託管的解決方案，消除了節點管理負擔。(C) Network Policies 是在 K8s 叢集內實現 Pod 層級網路隔離的標準方法。兩者結合可滿足需求。(D) 架構不可行，單一 GKE 叢集不能跨越多個 VPC。(E) 是供應鏈安全，與網路隔離無關。",
      "en": "The requirements are twofold: minimize node management (Low Ops) and network isolation. (A) GKE Autopilot is a fully managed solution that removes the node management burden. (C) Network Policies are the standard method for enforcing Pod-level network isolation within a K8s cluster. Combining them meets the needs. (D) is architecturally invalid; a single GKE cluster cannot span multiple VPCs. (E) is supply chain security, unrelated to network isolation.",
      "wg": [
        { "t": "架構不可行", "en": "architecturally invalid", "ps": "adjective phrase" }
      ]
    }
  },
  {
    "no": "5",
    "level": "hard",
    "keywords": "Data Analytics, Security, Cloud DLP, BigQuery",
    "question": [
      {
        "t": "您的行銷部門希望分析儲存在 BigQuery 中的歷史客戶支援日誌，以改善服務品質。然而，這些日誌包含敏感的個人識別資訊 (PII)，如電子郵件地址和電話號碼。",
        "en": "Your marketing department wants to analyze historical customer support logs stored in BigQuery to improve service quality. However, these logs contain sensitive Personally Identifiable Information (PII), such as email addresses and phone numbers.",
        "wg": [
          { "t": "個人識別資訊", "en": "Personally Identifiable Information (PII)", "ps": "noun" }
        ]
      },
      {
        "t": "根據公司的隱私政策，行銷團隊不得接觸原始 PII 數據。您需要建立一個自動化的處理解決方案，在資料可供分析之前對其進行去識別化 (De-identification)，同時保留資料的分析價值（例如，統計來自同一電子郵件的請求次數）。",
        "en": "According to the company's privacy policy, the marketing team must not access raw PII data. You need to create an automated processing solution to de-identify the data before it is available for analysis, while preserving its analytical value (e.g., counting requests from the same email).",
        "wg": [
          { "t": "去識別化", "en": "De-identification", "ps": "noun" },
          { "t": "分析價值", "en": "analytical value", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud DLP API 建立一個檢查範本 (Inspection Template)，掃描 BigQuery 資料表並標記含有 PII 的列。使用 IAM 條件限制行銷團隊只能存取未被標記的列。",
        "en": "(A) Use the Cloud DLP API to create an Inspection Template that scans the BigQuery table and tags rows containing PII. Use IAM Conditions to restrict the marketing team's access to only untagged rows.",
        "wg": [
          { "t": "檢查範本", "en": "Inspection Template", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 建立一個 Cloud DLP 去識別化作業 (De-identification Job)，配置確定性加密 (Deterministic Encryption) 或雜湊轉換 (Hashing)，將處理後的資料寫入一個新的 BigQuery 資料集，並僅授予行銷團隊對新資料集的存取權。",
        "en": "(B) Create a Cloud DLP De-identification Job configured with Deterministic Encryption or Hashing, write the processed data to a new BigQuery dataset, and grant the marketing team access only to the new dataset.",
        "wg": [
          { "t": "確定性加密", "en": "Deterministic Encryption", "ps": "noun" },
          { "t": "雜湊轉換", "en": "Hashing", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 在 BigQuery 中建立授權視圖 (Authorized View)，在 SQL 查詢中使用 `REGEXP_REPLACE` 函式遮蔽電子郵件和電話號碼。授予行銷團隊存取此視圖的權限。",
        "en": "(C) Create an Authorized View in BigQuery, using the `REGEXP_REPLACE` function in the SQL query to mask emails and phone numbers. Grant the marketing team access to this view.",
        "wg": [
          { "t": "授權視圖", "en": "Authorized View", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Data Catalog 自動標記敏感欄位。配置 BigQuery 的 Column-level Security，根據 Data Catalog 標籤動態遮蔽查詢結果中的 PII。",
        "en": "(D) Use Data Catalog to automatically tag sensitive columns. Configure BigQuery Column-level Security to dynamically mask PII in query results based on Data Catalog tags.",
        "wg": [
          { "t": "欄位級安全性", "en": "Column-level Security", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "題目要求「保留分析價值（統計次數）」，這意味著相同的 PII 必須轉換為相同的代碼（如雜湊值）。(B) 的確定性加密或雜湊能滿足此需求，並將資料物理隔離在新資料集中，最為安全。(C) 使用 SQL 遮蔽可能無法保留統計關聯性，且維護 Regex 較為困難。(D) Column-level Security 通常會完全隱藏或將值設為 Null，不利於統計分析。",
      "en": "The requirement to 'preserve analytical value (count requests)' implies that the same PII must be transformed into the same token (e.g., hash). (B) Deterministic Encryption or Hashing meets this need and physically isolates data in a new dataset, offering the highest security. (C) SQL masking might not preserve statistical correlation and maintaining Regex is hard. (D) Column-level Security usually hides data completely or nullifies it, which hinders statistical analysis.",
      "wg": [
        { "t": "統計關聯性", "en": "statistical correlation", "ps": "noun" },
        { "t": "物理隔離", "en": "physically isolates", "ps": "verb phrase" }
      ]
    }
  },
  {
    "no": "6",
    "level": "hard",
    "keywords": "Databases, Spanner, Global Consistency, Scalability",
    "question": [
      {
        "t": "您正在為一家全球零售商設計庫存管理系統。該系統必須支援高頻率的讀寫操作，並且在北美、歐洲和亞洲的使用者之間保持強一致性 (Strong Consistency)，以防止在不同地區重複銷售同一件商品。",
        "en": "You are designing an inventory management system for a global retailer. The system must support high-frequency read/write operations and maintain Strong Consistency among users in North America, Europe, and Asia to prevent double-selling the same item in different regions.",
        "wg": [
          { "t": "強一致性", "en": "Strong Consistency", "ps": "noun" },
          { "t": "重複銷售", "en": "double-selling", "ps": "verb (gerund)" }
        ]
      },
      {
        "t": "您預期資料量將達到數百 TB，且需要能夠隨著業務增長水平擴展寫入吞吐量。下列哪種資料庫解決方案最適合此需求？",
        "en": "You expect the data volume to reach hundreds of TBs and require the ability to horizontally scale write throughput as the business grows. Which database solution is best suited for this requirement?",
        "wg": [
          { "t": "水平擴展", "en": "horizontally scale", "ps": "verb" },
          { "t": "寫入吞吐量", "en": "write throughput", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud SQL for PostgreSQL，配置跨區域的讀取複本 (Read Replicas) 以支援全球讀取，並依賴應用程式邏輯來處理寫入一致性。",
        "en": "(A) Use Cloud SQL for PostgreSQL, configuring cross-region Read Replicas to support global reads, and rely on application logic to handle write consistency.",
        "wg": [
          { "t": "讀取複本", "en": "Read Replicas", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 使用 Cloud Bigtable，因其具有極高的寫入吞吐量和亞毫秒級延遲，適合處理大規模庫存數據。",
        "en": "(B) Use Cloud Bigtable, as it has extremely high write throughput and sub-millisecond latency, suitable for handling large-scale inventory data.",
        "wg": [
          { "t": "亞毫秒級", "en": "sub-millisecond", "ps": "adjective" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Spanner，配置多區域 (Multi-region) 執行個體配置。它提供全球 ACID 交易支援和水平寫入擴展能力。",
        "en": "(C) Use Cloud Spanner, configuring a Multi-region instance configuration. It provides global ACID transaction support and horizontal write scaling capabilities.",
        "wg": [
          { "t": "ACID 交易", "en": "ACID transactions", "ps": "noun" },
          { "t": "水平寫入擴展", "en": "horizontal write scaling", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Firestore 在 Datastore 模式下運行，利用其多區域複製功能來確保資料在全球範圍內的可用性和一致性。",
        "en": "(D) Use Firestore running in Datastore mode, leveraging its multi-region replication capabilities to ensure data availability and consistency on a global scale.",
        "wg": [
          { "t": "多區域複製", "en": "multi-region replication", "ps": "noun" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "關鍵需求是「全球強一致性」與「水平寫入擴展」。Cloud Spanner 是唯一能同時滿足這兩點的 GCP 服務，利用 TrueTime 實現全球 ACID 交易。(A) Cloud SQL 無法水平擴展寫入。(B) Bigtable 僅提供單一列原子性，不支援跨列 ACID 交易，且通常是最終一致性。(D) Firestore 的寫入吞吐量有硬性限制，不適合大規模高頻寫入。",
      "en": "Key requirements are 'Global Strong Consistency' and 'Horizontal Write Scaling'. Cloud Spanner is the only GCP service meeting both, using TrueTime for global ACID transactions. (A) Cloud SQL cannot scale writes horizontally. (B) Bigtable only provides single-row atomicity, not cross-row ACID transactions, and is typically eventually consistent. (D) Firestore has hard limits on write throughput, unsuitable for large-scale high-frequency writes.",
      "wg": [
        { "t": "硬性限制", "en": "hard limits", "ps": "noun" }
      ]
    }
  },
  {
    "no": "7",
    "level": "hard",
    "keywords": "Security, Zero Trust, IAP, BeyondCorp",
    "question": [
      {
        "t": "您的公司開發了一個內部的 Web 管理工具，運行在 Compute Engine 的私有 IP 虛擬機上。您需要允許外部承包商存取此工具，但公司安全政策禁止為承包商發放 VPN 客戶端憑證，且禁止將虛擬機的端口直接暴露在公網上。",
        "en": "Your company has developed an internal Web administration tool running on Compute Engine VMs with private IPs. You need to allow external contractors to access this tool, but corporate security policy forbids issuing VPN client credentials to contractors and prohibits exposing VM ports directly to the public internet.",
        "wg": [
          { "t": "承包商", "en": "contractors", "ps": "noun" },
          { "t": "公網", "en": "public internet", "ps": "noun" }
        ]
      },
      {
        "t": "您需要實作一個基於身分的存取解決方案，並能根據使用者的情境（如地理位置）進行存取控制。應該採取什麼行動？",
        "en": "You need to implement an identity-based access solution that allows access control based on user context (e.g., geographic location). What action should you take?",
        "wg": [
          { "t": "基於身分的", "en": "identity-based", "ps": "adjective" },
          { "t": "情境", "en": "context", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 設定 HTTPS 負載平衡器，啟用 Identity-Aware Proxy (IAP)。將承包商新增至具有 `IAP-Secured Web App User` 角色的群組，並配置 Access Levels 以限制地理位置。",
        "en": "(A) Configure an HTTPS Load Balancer and enable Identity-Aware Proxy (IAP). Add contractors to a group with the `IAP-Secured Web App User` role, and configure Access Levels to restrict geographic location.",
        "wg": [
          { "t": "存取層級", "en": "Access Levels", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 在虛擬機上安裝 Cloud VPN 閘道，並配置 Client VPN。使用 IAM 條件限制承包商只能在特定時間段內連線。",
        "en": "(B) Install a Cloud VPN gateway on the VM and configure Client VPN. Use IAM Conditions to restrict contractors to connect only during specific time periods.",
        "wg": [
          { "t": "閘道", "en": "gateway", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Armor 建立安全政策，將承包商的來源 IP 地址列入白名單，並阻擋其他所有 IP。將此政策綁定到負載平衡器的後端服務。",
        "en": "(C) Use Cloud Armor to create a security policy, whitelisting the contractors' source IP addresses and blocking all other IPs. Bind this policy to the Load Balancer's backend service.",
        "wg": [
          { "t": "白名單", "en": "whitelisting", "ps": "verb (gerund)" }
        ]
      },
      {
        "t": "(D) 部署一台 Bastion Host (跳板機) 在公有子網中，允許承包商透過 SSH 隧道轉發流量到內部 Web 工具。使用 OS Login 管理 SSH 金鑰。",
        "en": "(D) Deploy a Bastion Host in a public subnet, allowing contractors to forward traffic to the internal Web tool via SSH tunneling. Use OS Login to manage SSH keys.",
        "wg": [
          { "t": "跳板機", "en": "Bastion Host", "ps": "noun" },
          { "t": "隧道轉發", "en": "tunneling", "ps": "verb (gerund)" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "IAP 是 BeyondCorp 模型的實作，允許在不使用 VPN 的情況下，透過負載平衡器安全地公開內部應用程式。它驗證身分與 Context (透過 Access Context Manager)。(B) 違反了「禁止 VPN」的政策。(C) 基於 IP 的白名單難以維護且不具備身分驗證功能。(D) 涉及 SSH 隧道，對 Web 應用來說使用者體驗差且管理複雜。",
      "en": "IAP is an implementation of the BeyondCorp model, allowing secure exposure of internal apps via Load Balancer without VPN. It verifies identity and Context (via Access Context Manager). (B) violates the 'no VPN' policy. (C) IP-based whitelisting is hard to maintain and lacks authentication. (D) involves SSH tunneling, offering poor UX for Web apps and complex management.",
      "wg": [
        { "t": "使用者體驗", "en": "UX (User Experience)", "ps": "noun" }
      ]
    }
  },
  {
    "no": "8",
    "level": "hard",
    "keywords": "Cost Optimization, Compute Engine, Batch Processing, Spot VMs",
    "question": [
      {
        "t": "您正在為一個基因體定序專案設計運算架構。該工作負載包含大量的批次處理作業，具有高度的容錯能力 (Fault-tolerant)，即如果某個節點中斷，作業可以重新排程而不會遺失整體進度。",
        "en": "You are designing a computing architecture for a genomic sequencing project. The workload consists of massive batch processing jobs that are highly fault-tolerant, meaning if a node is interrupted, the job can be rescheduled without losing overall progress.",
        "wg": [
          { "t": "容錯能力", "en": "Fault-tolerant", "ps": "adjective" },
          { "t": "重新排程", "en": "rescheduled", "ps": "verb" }
        ]
      },
      {
        "t": "專案預算非常有限，成本優化是首要考量。您需要選擇最具成本效益的 Compute Engine 配置來運行這些作業。",
        "en": "The project budget is very limited, making cost optimization the primary consideration. You need to choose the most cost-effective Compute Engine configuration to run these jobs.",
        "wg": [
          { "t": "最具成本效益", "en": "most cost-effective", "ps": "adjective phrase" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 E2 標準執行個體並購買 3 年期的承諾使用折扣 (CUDs)，以獲得相比按需價格約 50% 的折扣。",
        "en": "(A) Use E2 standard instances and purchase 3-year Committed Use Discounts (CUDs) to get approximately 50% discount compared to on-demand pricing.",
        "wg": [
          { "t": "承諾使用折扣", "en": "Committed Use Discounts (CUDs)", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 建立一個 Managed Instance Group (MIG)，將所有實例配置為 Spot VMs。Spot VMs 比標準實例便宜高達 91%，非常適合容錯工作負載。",
        "en": "(B) Create a Managed Instance Group (MIG) and configure all instances as Spot VMs. Spot VMs are up to 91% cheaper than standard instances and are ideal for fault-tolerant workloads.",
        "wg": [
          { "t": "適合", "en": "ideal for", "ps": "adjective phrase" }
        ]
      },
      {
        "t": "(C) 使用自定義機器類型 (Custom Machine Types) 來精確匹配工作負載的 CPU 和 RAM 需求，避免資源浪費。",
        "en": "(C) Use Custom Machine Types to precisely match the workload's CPU and RAM requirements, avoiding resource waste.",
        "wg": [
          { "t": "資源浪費", "en": "resource waste", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用具有本地 SSD 的 N2 執行個體來加速 I/O 效能，縮短作業運行時間，從而減少總體計費時數。",
        "en": "(D) Use N2 instances with Local SSD to accelerate I/O performance, shortening job runtime and thus reducing total billed hours.",
        "wg": [
          { "t": "總體計費時數", "en": "total billed hours", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "對於「容錯」且「預算有限」的批次處理，Spot VMs (前身為 Preemptible VMs) 是最佳選擇，因為它們提供最大的折扣 (60-91%)。雖然它們可能隨時被 Google 收回，但容錯應用可以處理這種情況。(A) CUD 適合穩定負載，且折扣幅度不如 Spot。(C) 和 (D) 雖然能優化效能，但在單價上無法與 Spot VM 競爭。",
      "en": "For 'fault-tolerant' and 'budget-constrained' batch processing, Spot VMs (formerly Preemptible VMs) are the best choice as they offer the steepest discount (60-91%). Although they can be reclaimed by Google at any time, fault-tolerant apps can handle this. (A) CUD is for stable loads and discounts are less than Spot. (C) and (D) optimize performance but cannot compete with Spot VM on unit price.",
      "wg": [
        { "t": "收回", "en": "reclaimed", "ps": "verb" },
        { "t": "單價", "en": "unit price", "ps": "noun" }
      ]
    }
  },
  {
    "no": "9",
    "level": "hard",
    "keywords": "SRE, Reliability, Error Budget, SLO",
    "question": [
      {
        "t": "您的團隊採用了網站可靠性工程 (SRE) 實務，並為其核心服務定義了服務水準目標 (SLO)。目前的可用性 SLO 設定為 99.9%。",
        "en": "Your team has adopted Site Reliability Engineering (SRE) practices and defined Service Level Objectives (SLOs) for its core services. The current availability SLO is set at 99.9%.",
        "wg": [
          { "t": "服務水準目標", "en": "Service Level Objectives (SLOs)", "ps": "noun" }
        ]
      },
      {
        "t": "在過去的 28 天內，由於一系列的發布失敗，該服務的錯誤預算 (Error Budget) 已經完全耗盡。同時，開發團隊正準備推出一個備受期待的新功能。作為負責維護可靠性的架構師，您應該建議什麼行動？",
        "en": "Over the past 28 days, due to a series of release failures, the service's Error Budget has been completely exhausted. Meanwhile, the development team is preparing to launch a highly anticipated new feature. As the architect responsible for reliability, what action should you recommend?",
        "wg": [
          { "t": "錯誤預算", "en": "Error Budget", "ps": "noun" },
          { "t": "耗盡", "en": "exhausted", "ps": "verb" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 暫時降低 SLO 目標至 99.5% 以恢復錯誤預算，允許新功能發布，並在下個季度重新評估 SLO。",
        "en": "(A) Temporarily lower the SLO target to 99.5% to replenish the error budget, allowing the new feature launch, and re-evaluate the SLO next quarter.",
        "wg": [
          { "t": "恢復", "en": "replenish", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 凍結所有非關鍵的功能發布，將工程資源轉向提高系統穩定性，直到服務累積足夠的正常運行時間使錯誤預算轉正。",
        "en": "(B) Freeze all non-critical feature releases and redirect engineering resources towards improving system stability until the service accumulates enough uptime to turn the error budget positive.",
        "wg": [
          { "t": "凍結", "en": "Freeze", "ps": "verb" },
          { "t": "轉正", "en": "turn positive", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(C) 允許新功能發布，但配置更嚴格的自動擴展策略 (Auto-scaling policy) 以確保有額外的容量來處理潛在的不穩定。",
        "en": "(C) Allow the new feature launch but configure a stricter Auto-scaling policy to ensure extra capacity to handle potential instability.",
        "wg": [
          { "t": "潛在的不穩定", "en": "potential instability", "ps": "noun phrase" }
        ]
      },
      {
        "t": "(D) 僅針對新功能進行金絲雀部署 (Canary Deployment) 至 5% 的使用者，如果錯誤率沒有顯著增加，則繼續全面推廣。",
        "en": "(D) Perform a Canary Deployment of the new feature to only 5% of users, and if the error rate does not significantly increase, proceed with a full rollout.",
        "wg": [
          { "t": "全面推廣", "en": "full rollout", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "根據 SRE 原則，錯誤預算耗盡的後果應該是停止功能發布 (Freeze)，並專注於可靠性工作。這是平衡速度與穩定性的核心機制。(A) 改變目標是作弊。(C) 和 (D) 忽略了預算耗盡的事實，這會破壞 SRE 協議的信任基礎。",
      "en": "According to SRE principles, the consequence of exhausting the error budget should be to halt feature releases (Freeze) and focus on reliability work. This is the core mechanism for balancing velocity and stability. (A) Changing the target is cheating. (C) and (D) ignore the fact that the budget is exhausted, undermining the trust basis of the SRE agreement.",
      "wg": [
        { "t": "信任基礎", "en": "trust basis", "ps": "noun" }
      ]
    }
  },
  {
    "no": "10",
    "level": "hard",
    "keywords": "Migration, Database, Oracle, Bare Metal Solution",
    "question": [
      {
        "t": "您的企業正在進行大規模上雲計畫。您有一個關鍵任務的 Oracle 資料庫，大小約為 50 TB，且依賴 Oracle Real Application Clusters (RAC) 提供的共用儲存架構。",
        "en": "Your enterprise is undergoing a massive cloud migration program. You have a mission-critical Oracle database, approximately 50 TB in size, relying on the shared storage architecture provided by Oracle Real Application Clusters (RAC).",
        "wg": [
          { "t": "共用儲存架構", "en": "shared storage architecture", "ps": "noun" }
        ]
      },
      {
        "t": "由於嚴格的軟體授權條款，您不能在一般的虛擬化環境 (Cloud vCPUs) 中運行此資料庫。此外，應用程式層將遷移至 Google Kubernetes Engine (GKE)，並要求與資料庫之間的延遲極低 (< 2ms)。您應選擇哪種架構？",
        "en": "Due to strict software licensing terms, you cannot run this database in a generic virtualized environment (Cloud vCPUs). Additionally, the application layer will migrate to Google Kubernetes Engine (GKE) and requires extremely low latency (< 2ms) to the database. Which architecture should you choose?",
        "wg": [
          { "t": "軟體授權條款", "en": "software licensing terms", "ps": "noun" },
          { "t": "極低", "en": "extremely low", "ps": "adjective phrase" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Compute Engine 的 Sole-tenant Nodes，這提供了專用的物理硬體，滿足隔離需求，並在上面自行安裝 Oracle RAC。",
        "en": "(A) Use Compute Engine Sole-tenant Nodes, which provide dedicated physical hardware meeting isolation needs, and self-install Oracle RAC on top.",
        "wg": [
          { "t": "專用的物理硬體", "en": "dedicated physical hardware", "ps": "noun phrase" }
        ]
      },
      {
        "t": "(B) 採用 Google Cloud Bare Metal Solution (BMS)。這是在 Google 區域擴展中運行的託管專用硬體，支援 Oracle RAC，並透過專用互連與 GCP 服務低延遲連接。",
        "en": "(B) Adopt Google Cloud Bare Metal Solution (BMS). This is managed dedicated hardware running in Google regional extensions, supports Oracle RAC, and connects to GCP services with low latency via dedicated interconnect.",
        "wg": [
          { "t": "區域擴展", "en": "regional extensions", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Database Migration Service 將 Oracle 資料庫轉換為 Cloud SQL for PostgreSQL，這是一個完全託管且授權友好的替代方案。",
        "en": "(C) Use Database Migration Service to convert the Oracle database to Cloud SQL for PostgreSQL, which is a fully managed and license-friendly alternative.",
        "wg": [
          { "t": "完全託管", "en": "fully managed", "ps": "adjective" }
        ]
      },
      {
        "t": "(D) 在 GKE 叢集中部署 Oracle 資料庫容器，使用 Local SSD 作為儲存，並利用 Anti-affinity 規則確保 Pod 分布在不同節點上。",
        "en": "(D) Deploy Oracle database containers in the GKE cluster, use Local SSD for storage, and leverage Anti-affinity rules to ensure Pods are distributed across different nodes.",
        "wg": [
          { "t": "反親和性規則", "en": "Anti-affinity rules", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Bare Metal Solution (BMS) 是專為解決 Oracle 授權限制 (需要實體核心) 與 RAC 需求 (共用儲存 Layer 2 需求) 而設計的產品，且它位於 Google 資料中心旁，能滿足低延遲需求。(A) Sole-tenant nodes 雖然是獨占硬體，但本質仍是 Hypervisor 虛擬化，通常不被 Oracle 認可為「實體核心計費」，且在 GCP 上自行架設 RAC 相當困難（缺乏多重掛載的共用區塊儲存支援）。(C) 重構風險高。(D) 不符合授權且無法支援 RAC。",
      "en": "Bare Metal Solution (BMS) is specifically designed to address Oracle licensing constraints (requiring physical cores) and RAC requirements (shared storage Layer 2 needs), situated next to Google data centers to meet low latency needs. (A) Sole-tenant nodes, while dedicated hardware, are still hypervisor-virtualized and often not recognized by Oracle for 'physical core billing', plus setting up RAC on GCP is difficult (lack of multi-writer shared block storage). (C) High refactoring risk. (D) Non-compliant licensing and no RAC support.",
      "wg": [
        { "t": "實體核心計費", "en": "physical core billing", "ps": "noun phrase" }
      ]
    }
  },
  {
    "no": "11",
    "level": "hard",
    "keywords": "Networking, VPC, Shared VPC, Security",
    "question": [
      {
        "t": "您正在為一家大型企業設計網路架構，該企業擁有多個獨立的開發團隊，每個團隊負責不同的微服務。安全團隊要求必須集中管理網路安全政策（如防火牆規則與子網配置），但開發團隊應能夠自主建立與管理其虛擬機和負載平衡器。",
        "en": "You are designing a network architecture for a large enterprise with multiple independent development teams, each responsible for different microservices. The security team requires centralized management of network security policies (like firewall rules and subnet configuration), but development teams should be able to autonomously create and manage their VMs and load balancers.",
        "wg": [
          { "t": "集中管理", "en": "centralized management", "ps": "noun" },
          { "t": "自主", "en": "autonomously", "ps": "adverb" }
        ]
      },
      {
        "t": "目前的專案結構是每個團隊擁有自己的 GCP 專案。您需要選擇最適合的 VPC 架構來滿足這些權限分離的需求。",
        "en": "The current project structure is that each team has its own GCP project. You need to select the most suitable VPC architecture to meet these separation of duties requirements.",
        "wg": [
          { "t": "權限分離", "en": "separation of duties", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 VPC Network Peering 將每個服務專案的 VPC 連接到一個中央的管理 VPC。安全團隊在中央 VPC 管理防火牆。",
        "en": "(A) Use VPC Network Peering to connect each service project's VPC to a central management VPC. The security team manages firewalls in the central VPC.",
        "wg": [
          { "t": "管理 VPC", "en": "management VPC", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 實作 Shared VPC 架構。指定一個 Host Project 由安全團隊管理網路資源，並將開發團隊的專案作為 Service Projects 連接。授予開發者 `Compute Network User` 角色。",
        "en": "(B) Implement a Shared VPC architecture. Designate a Host Project where the security team manages network resources, and attach development team projects as Service Projects. Grant developers the `Compute Network User` role.",
        "wg": [
          { "t": "主機專案", "en": "Host Project", "ps": "noun" },
          { "t": "服務專案", "en": "Service Projects", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 為每個團隊建立獨立的 VPC，並使用 VPN Gateway 建立 Hub-and-Spoke 拓撲。透過 Cloud Router 交換路由以實現互連。",
        "en": "(C) Create independent VPCs for each team and build a Hub-and-Spoke topology using VPN Gateways. Exchange routes via Cloud Router for interconnectivity.",
        "wg": [
          { "t": "Hub-and-Spoke 拓撲", "en": "Hub-and-Spoke topology", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用單一龐大的 GCP 專案容納所有資源，利用 IAM Conditions 限制每個團隊只能操作特定標籤 (Tags) 的虛擬機。",
        "en": "(D) Use a single massive GCP project to house all resources, leveraging IAM Conditions to restrict each team to operate only on VMs with specific Tags.",
        "wg": [
          { "t": "容納", "en": "house", "ps": "verb" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Shared VPC 是解決「集中網路管理」與「分散資源建立」的標準模式。Host Project 持有網路（子網、防火牆），Service Projects 使用網路。(A) Peering 的防火牆規則是在各自的 VPC 中管理，無法達成集中安全控制。(C) 管理複雜且成本高。(D) 單一專案違反了資源隔離原則且難以管理配額。",
      "en": "Shared VPC is the standard pattern for solving 'centralized network management' and 'decentralized resource creation'. The Host Project holds the network (subnets, firewalls), and Service Projects use it. (A) With Peering, firewall rules are managed in respective VPCs, failing centralized security control. (C) Complex management and high cost. (D) Single project violates resource isolation principles and makes quota management difficult.",
      "wg": [
        { "t": "分散資源建立", "en": "decentralized resource creation", "ps": "noun phrase" },
        { "t": "資源隔離原則", "en": "resource isolation principles", "ps": "noun phrase" }
      ]
    }
  },
  {
    "no": "12",
    "level": "hard",
    "keywords": "Security, Cloud Armor, DDoS, Load Balancing",
    "question": [
      {
        "t": "您負責維運一個面向全球的電子商務網站，該網站使用 Global External HTTP(S) Load Balancer 作為前端。在黑色星期五促銷期間，網站遭受了大規模的 DDoS 攻擊。",
        "en": "You are responsible for operating a global-facing e-commerce website fronted by a Global External HTTP(S) Load Balancer. During a Black Friday sale, the site suffered a massive DDoS attack.",
        "wg": [
          { "t": "面向全球的", "en": "global-facing", "ps": "adjective" },
          { "t": "促銷期間", "en": "sale period", "ps": "noun" }
        ]
      },
      {
        "t": "攻擊流量特徵是來自特定幾個國家的 IP 地址發送大量無效的 HTTP POST 請求，導致後端服務過載。您需要立即採取行動緩解攻擊，並防止未來發生類似事件，同時盡量不影響正常用戶。",
        "en": "The attack traffic is characterized by IPs from a few specific countries sending a large volume of invalid HTTP POST requests, overloading backend services. You need to take immediate action to mitigate the attack and prevent future occurrences, while minimizing impact on legitimate users.",
        "wg": [
          { "t": "緩解", "en": "mitigate", "ps": "verb" },
          { "t": "正常用戶", "en": "legitimate users", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用 Google Cloud Armor，並配置一條安全政策來拒絕來自攻擊來源國家的流量 (Geo-blocking)。同時啟用 Adaptive Protection 以自動偵測未來的異常流量模式。",
        "en": "(A) Enable Google Cloud Armor and configure a security policy to deny traffic from the attacking source countries (Geo-blocking). Also enable Adaptive Protection to automatically detect future anomalous traffic patterns.",
        "wg": [
          { "t": "異常流量模式", "en": "anomalous traffic patterns", "ps": "noun phrase" }
        ]
      },
      {
        "t": "(B) 在 VPC 防火牆規則中新增一條拒絕規則，阻擋來自這些國家 IP 範圍的所有流量，並將此規則套用到所有後端實例。",
        "en": "(B) Add a deny rule in VPC firewall rules to block all traffic from the IP ranges of these countries, and apply this rule to all backend instances.",
        "wg": [
          { "t": "阻擋", "en": "block", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 將負載平衡器切換為 TCP Proxy Load Balancer，因為它在本質上比 HTTP(S) Load Balancer 更能抵抗 Layer 7 的應用層攻擊。",
        "en": "(C) Switch the load balancer to a TCP Proxy Load Balancer, as it is inherently more resistant to Layer 7 application-layer attacks than an HTTP(S) Load Balancer.",
        "wg": [
          { "t": "本質上", "en": "inherently", "ps": "adverb" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Functions 編寫一個腳本，分析 Cloud Logging 中的存取日誌，識別攻擊 IP 並動態更新 VPC 防火牆規則。",
        "en": "(D) Write a script using Cloud Functions to analyze access logs in Cloud Logging, identify attacking IPs, and dynamically update VPC firewall rules.",
        "wg": [
          { "t": "動態更新", "en": "dynamically update", "ps": "verb phrase" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Cloud Armor 是專門設計用於 HTTP(S) LB 的邊緣防禦服務，可以基於地理位置 (Geo-blocking) 過濾流量，且 Adaptive Protection 能利用 ML 自動學習正常流量模型。(B) 和 (D) 無效，因為流量是透過 Global LB 進入的，後端實例看到的是 LB 的 IP (除非使用 Network LB，但題目已指定 HTTP LB)，且 VPC 防火牆無法有效處理 DDoS 規模的流量。(C) 降級為 TCP LB 會失去 WAF 功能，反而更難防禦 Layer 7 攻擊。",
      "en": "Cloud Armor is an edge defense service specifically designed for HTTP(S) LB, capable of filtering traffic based on geo-location, and Adaptive Protection uses ML to learn normal traffic models automatically. (B) and (D) are ineffective because traffic enters via Global LB, so backends see the LB's IP (unless using Network LB, but the question specifies HTTP LB), and VPC firewalls cannot effectively handle DDoS-scale traffic. (C) Downgrading to TCP LB loses WAF capabilities, making Layer 7 defense harder.",
      "wg": [
        { "t": "降級", "en": "downgrading", "ps": "verb (gerund)" },
        { "t": "邊緣防禦", "en": "edge defense", "ps": "noun" }
      ]
    }
  },
  {
    "no": "13",
    "level": "hard",
    "keywords": "Compute, Instance Groups, Reliability, Rolling Update",
    "question": [
      {
        "t": "您正在管理一個由 Managed Instance Group (MIG) 支援的無狀態 Web 應用程式。您需要發布一個新的應用程式版本 (v2.0)，但必須確保部署過程零停機 (Zero Downtime)，且在任何時間點可用的實例數量不能低於目前的 80%。",
        "en": "You are managing a stateless Web application backed by a Managed Instance Group (MIG). You need to release a new application version (v2.0) but must ensure zero downtime during deployment, and the number of available instances must not drop below 80% of the current count at any time.",
        "wg": [
          { "t": "零停機", "en": "Zero Downtime", "ps": "noun" },
          { "t": "可用的實例", "en": "available instances", "ps": "noun" }
        ]
      },
      {
        "t": "此外，如果在部署過程中發現新版本有嚴重錯誤，必須能夠迅速且自動地停止部署。您應該如何配置更新策略？",
        "en": "Additionally, if a critical bug is discovered in the new version during deployment, the deployment must stop quickly and automatically. How should you configure the update strategy?",
        "wg": [
          { "t": "更新策略", "en": "update strategy", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 `gcloud compute instance-groups managed rolling-action start-update`，設定 `max-unavailable=20%` 和 `max-surge=20%`。配置 Health Check，若失敗率超過閾值則 MIG 會自動暫停更新。",
        "en": "(A) Use `gcloud compute instance-groups managed rolling-action start-update`, setting `max-unavailable=20%` and `max-surge=20%`. Configure a Health Check so the MIG automatically pauses the update if failure rate exceeds a threshold.",
        "wg": [
          { "t": "失敗率", "en": "failure rate", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 建立一個新的 MIG 運行 v2.0，並將其加入到 Load Balancer 後端。手動將流量從舊 MIG 切換到新 MIG (Blue/Green Deployment)，如果發現錯誤則立即切回。",
        "en": "(B) Create a new MIG running v2.0 and add it to the Load Balancer backend. Manually switch traffic from the old MIG to the new MIG (Blue/Green Deployment), and switch back immediately if errors are found.",
        "wg": [
          { "t": "手動切換", "en": "manually switch", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(C) 使用 `gcloud compute instance-groups managed rolling-action replace` 命令一次替換所有實例，依賴 Load Balancer 的健康檢查將流量引導至健康的實例。",
        "en": "(C) Use the `gcloud compute instance-groups managed rolling-action replace` command to replace all instances at once, relying on the Load Balancer's health check to direct traffic to healthy instances.",
        "wg": [
          { "t": "一次替換", "en": "replace ... at once", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(D) 寫一個腳本逐一刪除舊實例並建立新實例，並在每次建立後呼叫應用程式的 `/health` 端點進行驗證，如果驗證失敗則終止腳本。",
        "en": "(D) Write a script to delete old instances and create new ones one by one, calling the application's `/health` endpoint after each creation for validation, and terminating the script if validation fails.",
        "wg": [
          { "t": "終止腳本", "en": "terminating the script", "ps": "verb phrase" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "MIG 的 Rolling Update 功能原生支援 `max-unavailable` 參數來保證容量（題目要求不低於 80%，即最多不可用 20%），並且能與 Health Check 整合實現自動化停止。(B) Blue/Green 雖然可行但需要雙倍資源，且題目暗示要「配置更新策略」通常指 MIG 內建功能。(D) 手動腳本維護困難且容易出錯。(C) `replace` 通常用於重新建立實例而非版本更新，且一次性替換會導致停機。",
      "en": "MIG's Rolling Update feature natively supports the `max-unavailable` parameter to guarantee capacity (question requires no less than 80%, i.e., max unavailable 20%) and integrates with Health Checks for automated stopping. (B) Blue/Green is viable but requires double resources, and 'configure update strategy' usually implies native MIG features. (D) Manual scripts are hard to maintain and error-prone. (C) `replace` is typically for recreating instances, not version updates, and replacing all at once causes downtime.",
      "wg": [
        { "t": "原生支援", "en": "natively supports", "ps": "verb phrase" },
        { "t": "雙倍資源", "en": "double resources", "ps": "noun phrase" }
      ]
    }
  },
  {
    "no": "14",
    "level": "hard",
    "keywords": "Data Analytics, BigQuery, Performance, Partitioning",
    "question": [
      {
        "t": "您正在管理一個 BigQuery 資料倉儲，其中包含一個名為 `transaction_logs` 的巨型資料表，儲存了過去 5 年的銷售記錄（數 PB）。分析師經常查詢該表，通常是篩選「特定日期範圍」以及「特定商店 ID」。",
        "en": "You are managing a BigQuery data warehouse containing a massive table named `transaction_logs`, storing sales records for the past 5 years (several PBs). Analysts frequently query this table, typically filtering by 'specific date range' and 'specific store ID'.",
        "wg": [
          { "t": "巨型資料表", "en": "massive table", "ps": "noun" },
          { "t": "篩選", "en": "filtering", "ps": "verb (gerund)" }
        ]
      },
      {
        "t": "目前的查詢成本非常高且速度緩慢。您需要優化資料表結構以減少掃描的數據量 (Bytes Scanned) 並提升查詢效能。請選擇最佳的優化策略。",
        "en": "Current query costs are very high and speeds are slow. You need to optimize the table structure to reduce the amount of data scanned (Bytes Scanned) and improve query performance. Please select the best optimization strategy.",
        "wg": [
          { "t": "掃描的數據量", "en": "amount of data scanned", "ps": "noun phrase" },
          { "t": "優化策略", "en": "optimization strategy", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 僅根據 `store_id` 進行分區 (Partitioning)，因為商店 ID 是高基數 (High Cardinality) 欄位，這樣可以最大程度地切分資料。",
        "en": "(A) Partition only by `store_id`, because store ID is a High Cardinality field, which maximizes data splitting.",
        "wg": [
          { "t": "高基數", "en": "High Cardinality", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 根據 `transaction_date` 進行分區 (Partitioning)，並根據 `store_id` 進行叢集 (Clustering)。",
        "en": "(B) Partition by `transaction_date` and Cluster by `store_id`.",
        "wg": [
          { "t": "叢集", "en": "Clustering", "ps": "verb (gerund)" }
        ]
      },
      {
        "t": "(C) 根據 `store_id` 進行分區，並根據 `transaction_date` 進行叢集。",
        "en": "(C) Partition by `store_id` and Cluster by `transaction_date`.",
        "wg": [
          { "t": "分區", "en": "Partition", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 建立多個授權視圖 (Authorized Views)，每個視圖預先篩選不同的年份，強迫分析師查詢特定的視圖。",
        "en": "(D) Create multiple Authorized Views, each pre-filtering a different year, forcing analysts to query specific views.",
        "wg": [
          { "t": "強迫", "en": "forcing", "ps": "verb" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "BigQuery 最佳實務建議對日期/時間欄位進行分區 (Partitioning)，這能最有效地修剪 (Prune) 不需要的時間範圍分區。對於高基數欄位如 `store_id`，應使用叢集 (Clustering)，這能將相同 ID 的資料物理上存放在一起，進一步減少掃描。選項 (A) 和 (C) 錯誤，因為 BigQuery 限制分區數量 (4000)，高基數欄位不適合做分區鍵。(D) 治標不治本，無法優化底層掃描。",
      "en": "BigQuery best practices recommend Partitioning on date/time fields, which most effectively prunes unnecessary time range partitions. For high cardinality fields like `store_id`, Clustering should be used to physically co-locate data with the same ID, further reducing scanning. Options (A) and (C) are incorrect because BigQuery limits partition count (4000), making high cardinality fields unsuitable for partition keys. (D) addresses symptoms not root causes, failing to optimize underlying scanning.",
      "wg": [
        { "t": "修剪", "en": "Prune", "ps": "verb" },
        { "t": "治標不治本", "en": "addresses symptoms not root causes", "ps": "verb phrase" }
      ]
    }
  },
  {
    "no": "15",
    "level": "hard",
    "keywords": "Security, IAM, Organization Policy, Compliance",
    "question": [
      {
        "t": "您的公司剛剛收購了一家初創公司，並將其 GCP 專案遷移到了您公司的 GCP Organization 下。為了確保合規性，您必須防止該初創公司的開發人員在特定區域 (如 asia-east1) 以外的地方建立新的 Compute Engine 資源。",
        "en": "Your company has just acquired a startup and migrated its GCP projects under your company's GCP Organization. To ensure compliance, you must prevent the startup's developers from creating new Compute Engine resources outside of specific regions (e.g., asia-east1).",
        "wg": [
          { "t": "收購", "en": "acquired", "ps": "verb" },
          { "t": "防止", "en": "prevent", "ps": "verb" }
        ]
      },
      {
        "t": "初創公司的開發人員目前在他們的專案中擁有 `Owner` 角色。您需要一種強制性的方法來實施此限制，且該方法不能被專案擁有者繞過。請選擇兩項正確的行動。",
        "en": "The startup's developers currently hold the `Owner` role in their projects. You need a mandatory method to enforce this restriction, and the method cannot be bypassed by project owners. Please select two correct actions.",
        "wg": [
          { "t": "強制性的", "en": "mandatory", "ps": "adjective" },
          { "t": "繞過", "en": "bypassed", "ps": "verb" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 將初創公司的專案放入一個新的 Folder 中。",
        "en": "(A) Place the startup's projects into a new Folder.",
        "wg": [
          { "t": "放入", "en": "Place", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 在該 Folder 層級定義 Organization Policy，設定 `constraints/gcp.resourceLocations` 限制，僅允許 `asia-east1`。",
        "en": "(B) Define an Organization Policy at that Folder level, setting the `constraints/gcp.resourceLocations` constraint to allow only `asia-east1`.",
        "wg": [
          { "t": "定義", "en": "Define", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 IAM 條件修改所有開發人員的權限，僅在資源名稱包含 `asia-east1` 時授予 `compute.instances.create` 權限。",
        "en": "(C) Use IAM Conditions to modify permissions for all developers, granting `compute.instances.create` only when the resource name contains `asia-east1`.",
        "wg": [
          { "t": "修改", "en": "modify", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 建立一個 Cloud Function 監聽 Cloud Audit Logs，如果發現非 `asia-east1` 的資源被建立，則自動刪除該資源。",
        "en": "(D) Create a Cloud Function listening to Cloud Audit Logs that automatically deletes any resource created outside `asia-east1`.",
        "wg": [
          { "t": "監聽", "en": "listening to", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(E) 撤銷開發人員的 `Owner` 角色，改為授予 `Compute Admin`，這會自動限制他們只能在預設區域建立資源。",
        "en": "(E) Revoke the developers' `Owner` role and grant `Compute Admin` instead, which automatically restricts them to creating resources in the default region.",
        "wg": [
          { "t": "撤銷", "en": "Revoke", "ps": "verb" }
        ]
      }
    ],
    "answer": "(A), (B)",
    "why": {
      "t": "Organization Policy 是唯一能覆蓋 IAM 權限 (包括 Owner) 的強制性護欄 (Guardrails)。(A) 和 (B) 的組合是標準做法：透過 Folder 分組並在 Folder 層級套用政策。(C) IAM 條件無法輕易限制「區域」，通常是針對資源名稱或標籤，且維護困難。(D) 是事後補救 (Detective) 而非預防 (Preventative)，且會有短暫的合規漏洞。(E) Compute Admin 仍然可以在任何區域建立資源。",
      "en": "Organization Policy is the only mandatory guardrail that overrides IAM permissions (including Owner). The combination of (A) and (B) is standard practice: grouping via Folder and applying policy at the Folder level. (C) IAM Conditions cannot easily restrict 'region', usually targeting resource names or tags, and are hard to maintain. (D) is Detective rather than Preventative, leaving a brief compliance gap. (E) Compute Admin can still create resources in any region.",
      "wg": [
        { "t": "強制性護欄", "en": "mandatory guardrail", "ps": "noun phrase" },
        { "t": "事後補救", "en": "Detective", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "16",
    "level": "hard",
    "keywords": "Storage, Filestore, GKE, Migration",
    "question": [
      {
        "t": "您的團隊正在將一個傳統的內容管理系統 (CMS) 從地端遷移到 GKE。該應用程式由多個 Web 伺服器組成，它們需要同時讀寫同一個共用檔案目錄來存取媒體資產 (圖片、影片)。",
        "en": "Your team is migrating a legacy Content Management System (CMS) from on-premises to GKE. The application consists of multiple web servers that need to simultaneously read and write to the same shared file directory to access media assets (images, videos).",
        "wg": [
          { "t": "內容管理系統", "en": "Content Management System (CMS)", "ps": "noun" },
          { "t": "共用檔案目錄", "en": "shared file directory", "ps": "noun" }
        ]
      },
      {
        "t": "應用程式代碼依賴於標準的 POSIX 文件系統介面，無法立即重構以使用物件儲存 (Object Storage)。您需要選擇一個 GCP 原生儲存服務來支援此需求，並在 Kubernetes 中正確掛載。",
        "en": "The application code relies on a standard POSIX file system interface and cannot be immediately refactored to use Object Storage. You need to choose a GCP native storage service to support this requirement and mount it correctly in Kubernetes.",
        "wg": [
          { "t": "POSIX 文件系統介面", "en": "POSIX file system interface", "ps": "noun" },
          { "t": "重構", "en": "refactored", "ps": "verb" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Compute Engine Persistent Disk (PD)，並將存取模式設定為 `ReadWriteMany`。",
        "en": "(A) Use Compute Engine Persistent Disk (PD) and set the access mode to `ReadWriteMany`.",
        "wg": [
          { "t": "存取模式", "en": "access mode", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 佈建 Cloud Filestore 實例，並在 GKE 中使用 NFS Client Provisioner 或 CSI Driver 將其掛載為 `ReadWriteMany` 的 Persistent Volume。",
        "en": "(B) Provision a Cloud Filestore instance and mount it as a `ReadWriteMany` Persistent Volume in GKE using the NFS Client Provisioner or CSI Driver.",
        "wg": [
          { "t": "掛載", "en": "mount", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Storage FUSE 將 GCS Bucket 掛載到每個 Pod 的本地文件系統中。",
        "en": "(C) Use Cloud Storage FUSE to mount a GCS Bucket into the local file system of each Pod.",
        "wg": [
          { "t": "本地文件系統", "en": "local file system", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 在 GKE 節點上設定 Local SSD，並使用 HostPath 將其暴露給 Pod，以獲得最高的 I/O 效能。",
        "en": "(D) Configure Local SSD on GKE nodes and expose it to Pods using HostPath for maximum I/O performance.",
        "wg": [
          { "t": "最高 I/O 效能", "en": "maximum I/O performance", "ps": "noun phrase" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "需求是「多個 Pod 同時讀寫 (ReadWriteMany)」且需要「POSIX 介面」。(B) Cloud Filestore 是託管的 NFS 服務，專為此設計，且 GKE 原生支援透過 CSI 驅動掛載。(A) Persistent Disk 預設不支援多重寫入 (ReadWriteMany)，除非是唯讀。(C) GCS FUSE 雖然模擬文件系統，但效能較差且不完全符合 POSIX 標準（例如追加寫入限制），不適合作為高負載 CMS 的後端。(D) HostPath 和 Local SSD 是單節點儲存，無法跨節點共享數據。",
      "en": "The requirement is 'simultaneous read/write by multiple Pods (ReadWriteMany)' and 'POSIX interface'. (B) Cloud Filestore is a managed NFS service designed for this, and GKE natively supports mounting via CSI drivers. (A) Persistent Disk does not support ReadWriteMany by default unless read-only. (C) GCS FUSE simulates a file system but has poor performance and isn't fully POSIX compliant (e.g., append limits), unsuitable for high-load CMS. (D) HostPath and Local SSD are single-node storage, unable to share data across nodes.",
      "wg": [
        { "t": "模擬", "en": "simulates", "ps": "verb" },
        { "t": "跨節點共享", "en": "share data across nodes", "ps": "verb phrase" }
      ]
    }
  },
  {
    "no": "17",
    "level": "hard",
    "keywords": "AI/ML, Vertex AI, Pipelines, MLOps",
    "question": [
      {
        "t": "您的資料科學團隊已經開發了一個 TensorFlow 模型來預測客戶流失。目前，他們手動在筆記本電腦上運行訓練腳本，這導致了模型版本混亂且難以復現。",
        "en": "Your data science team has developed a TensorFlow model to predict customer churn. Currently, they manually run training scripts on laptops, leading to model version chaos and reproducibility issues.",
        "wg": [
          { "t": "客戶流失", "en": "customer churn", "ps": "noun" },
          { "t": "難以復現", "en": "reproducibility issues", "ps": "noun phrase" }
        ]
      },
      {
        "t": "您需要設計一個自動化且可擴展的 MLOps 解決方案。該方案必須能夠在 Cloud Storage 有新資料上傳時自動觸發重新訓練，並支援模型評估與自動部署到端點。您應該使用哪組 GCP 服務？",
        "en": "You need to design an automated and scalable MLOps solution. The solution must automatically trigger retraining when new data is uploaded to Cloud Storage, and support model evaluation and automatic deployment to endpoints. Which set of GCP services should you use?",
        "wg": [
          { "t": "重新訓練", "en": "retraining", "ps": "noun" },
          { "t": "自動部署", "en": "automatic deployment", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud Composer 編排 Airflow DAG 來執行訓練。使用 Cloud Functions 監聽 GCS 事件來觸發 DAG。",
        "en": "(A) Use Cloud Composer to orchestrate Airflow DAGs for training. Use Cloud Functions to listen for GCS events to trigger the DAG.",
        "wg": [
          { "t": "編排", "en": "orchestrate", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 構建 Vertex AI Pipelines 來定義端到端工作流。使用 Cloud Functions 監聽 GCS 事件並呼叫 Vertex AI Pipeline API。將模型註冊到 Vertex AI Model Registry。",
        "en": "(B) Build Vertex AI Pipelines to define the end-to-end workflow. Use Cloud Functions to listen for GCS events and call the Vertex AI Pipeline API. Register the model to Vertex AI Model Registry.",
        "wg": [
          { "t": "端到端工作流", "en": "end-to-end workflow", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Compute Engine 上的 Cron 作業定期檢查 GCS，然後啟動一個包含 GPU 的 VM 進行訓練腳本。",
        "en": "(C) Use Cron jobs on Compute Engine to periodically check GCS, then spin up a VM with GPUs to run the training script.",
        "wg": [
          { "t": "定期檢查", "en": "periodically check", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Build 觸發器連接到源代碼庫，當代碼更新時自動構建 Docker 映像檔並推送到 Artifact Registry。",
        "en": "(D) Use Cloud Build triggers connected to the source code repository to automatically build Docker images and push to Artifact Registry when code updates.",
        "wg": [
          { "t": "源代碼庫", "en": "source code repository", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "Vertex AI Pipelines (基於 Kubeflow) 是 GCP 上標準化 MLOps 工作流的最佳實踐。它專為 ML 步驟（資料準備、訓練、評估）設計，並與 Model Registry 整合。(A) Cloud Composer 雖然也能編排，但它是通用的，缺乏 Vertex AI 特有的 ML Metadata 追蹤與模型管理功能。(C) 是手動維運的反模式。(D) 僅解決了 CI (代碼構建)，未解決 CT (持續訓練) 與 CD (模型部署)。",
      "en": "Vertex AI Pipelines (based on Kubeflow) is the best practice for standardized MLOps workflows on GCP. It is designed for ML steps (data prep, training, evaluation) and integrates with Model Registry. (A) Cloud Composer can orchestrate but is generic, lacking Vertex AI's specific ML Metadata tracking and model management. (C) is a manual ops anti-pattern. (D) only addresses CI (code build), not CT (Continuous Training) or CD (Model Deployment).",
      "wg": [
        { "t": "反模式", "en": "anti-pattern", "ps": "noun" }
      ]
    }
  },
  {
    "no": "18",
    "level": "hard",
    "keywords": "Networking, Cloud DNS, Private Zone, Hybrid",
    "question": [
      {
        "t": "您的公司擁有混合雲架構，地端網路透過 Cloud VPN 與 GCP VPC 連接。地端伺服器需要能夠解析 GCP 中內部負載平衡器的 DNS 名稱 (例如 `app.internal.gcp`)，反之亦然，GCP 內的 VM 也需要解析地端伺服器的名稱。",
        "en": "Your company has a hybrid cloud architecture, with the on-premises network connected to the GCP VPC via Cloud VPN. On-premises servers need to resolve DNS names of internal load balancers in GCP (e.g., `app.internal.gcp`), and vice versa, VMs inside GCP need to resolve on-premises server names.",
        "wg": [
          { "t": "混合雲架構", "en": "hybrid cloud architecture", "ps": "noun" },
          { "t": "解析", "en": "resolve", "ps": "verb" }
        ]
      },
      {
        "t": "您已經在 Cloud DNS 中設定了 Private Zones。為了實現雙向 DNS 解析，您需要採取什麼額外配置？",
        "en": "You have already configured Private Zones in Cloud DNS. What additional configuration do you need to implement bidirectional DNS resolution?",
        "wg": [
          { "t": "雙向 DNS 解析", "en": "bidirectional DNS resolution", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在 Cloud DNS 中建立一個 Inbound Server Policy 以允許地端查詢 GCP，並設定一個 Forwarding Zone 將地端網域的查詢轉發到地端 DNS 伺服器 IP。",
        "en": "(A) Create an Inbound Server Policy in Cloud DNS to allow on-prem queries to GCP, and set up a Forwarding Zone to forward queries for the on-prem domain to the on-prem DNS server IPs.",
        "wg": [
          { "t": "轉發", "en": "forward", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 在地端 DNS 伺服器中新增 GCP 的公共 DNS IP (8.8.8.8) 作為轉發器，並在 GCP VPC 網路設定中啟用 Global DNS。",
        "en": "(B) Add GCP's public DNS IP (8.8.8.8) as a forwarder in the on-premises DNS server, and enable Global DNS in the GCP VPC network settings.",
        "wg": [
          { "t": "轉發器", "en": "forwarder", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 在每一台 GCP VM 上安裝 Bind9 DNS 伺服器，並配置其為地端 DNS 的從屬區域 (Slave Zone)。",
        "en": "(C) Install Bind9 DNS servers on every GCP VM and configure them as Slave Zones of the on-premises DNS.",
        "wg": [
          { "t": "從屬區域", "en": "Slave Zone", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Router 的 BGP 屬性來廣播 DNS 記錄到地端網路。",
        "en": "(D) Use Cloud Router's BGP attributes to advertise DNS records to the on-premises network.",
        "wg": [
          { "t": "廣播", "en": "advertise", "ps": "verb" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Cloud DNS 的標準混合雲模式包含兩部分：1. **Inbound Server Policy**：提供一個內部 IP (在 VPC 子網中) 供地端 DNS 轉發請求，解決「地端 -> GCP」。2. **Forwarding Zone**：告訴 Cloud DNS 將特定後綴 (如 `.corp`) 的請求轉發到地端 DNS IP，解決「GCP -> 地端」。(B) 公共 DNS 8.8.8.8 無法解析您的私有區域。(D) BGP 廣播 IP 路由，不傳輸 DNS 記錄。",
      "en": "The standard hybrid cloud pattern for Cloud DNS involves two parts: 1. **Inbound Server Policy**: Provides an internal IP (in VPC subnet) for on-prem DNS to forward requests, solving 'On-prem -> GCP'. 2. **Forwarding Zone**: Tells Cloud DNS to forward requests for specific suffixes (e.g., `.corp`) to on-prem DNS IPs, solving 'GCP -> On-prem'. (B) Public DNS 8.8.8.8 cannot resolve your private zones. (D) BGP advertises IP routes, not DNS records.",
      "wg": [
        { "t": "標準混合雲模式", "en": "standard hybrid cloud pattern", "ps": "noun phrase" }
      ]
    }
  },
  {
    "no": "19",
    "level": "hard",
    "keywords": "Security, KMS, CMEK, Separation of Duties",
    "question": [
      {
        "t": "您的客戶是一家金融銀行，計畫將高度機密的交易資料儲存在 Cloud Storage 中。根據法規要求，客戶必須擁有並控制加密金鑰 (Customer-Managed Encryption Keys, CMEK)，且必須實施職責分離 (Separation of Duties)。",
        "en": "Your client is a financial bank planning to store highly confidential transaction data in Cloud Storage. Per regulatory requirements, the client must own and control the encryption keys (Customer-Managed Encryption Keys, CMEK) and must implement Separation of Duties (SoD).",
        "wg": [
          { "t": "職責分離", "en": "Separation of Duties", "ps": "noun" },
          { "t": "高度機密", "en": "highly confidential", "ps": "adjective phrase" }
        ]
      },
      {
        "t": "這意味著負責管理金鑰 (建立、輪替、銷毀) 的人員，不得擁有使用該金鑰解密數據的權限。您應該如何設計 IAM 角色分配？",
        "en": "This means that the personnel responsible for managing keys (creation, rotation, destruction) must not have permission to use the key to decrypt data. How should you design the IAM role assignment?",
        "wg": [
          { "t": "角色分配", "en": "role assignment", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 為金鑰管理員分配 `Cloud KMS Admin` 角色。為儲存服務帳戶和資料使用者分配 `Cloud KMS CryptoKey Encrypter/Decrypter` 角色。",
        "en": "(A) Assign the `Cloud KMS Admin` role to Key Administrators. Assign the `Cloud KMS CryptoKey Encrypter/Decrypter` role to the Storage Service Account and data users.",
        "wg": [
          { "t": "金鑰管理員", "en": "Key Administrators", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 為金鑰管理員分配 `Owner` 角色以確保完全控制。為資料使用者分配 `Storage Object Admin` 角色。",
        "en": "(B) Assign the `Owner` role to Key Administrators to ensure full control. Assign the `Storage Object Admin` role to data users.",
        "wg": [
          { "t": "完全控制", "en": "full control", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 為金鑰管理員分配 `Cloud KMS CryptoKey Encrypter/Decrypter` 角色。為資料使用者分配 `Cloud KMS Admin` 角色。",
        "en": "(C) Assign the `Cloud KMS CryptoKey Encrypter/Decrypter` role to Key Administrators. Assign the `Cloud KMS Admin` role to data users.",
        "wg": [
          { "t": "分配", "en": "Assign", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 建立一個自定義角色，包含 `cloudkms.keys.create` 和 `cloudkms.cryptoKeyVersions.useToDecrypt`，並將其分配給所有相關人員。",
        "en": "(D) Create a custom role containing `cloudkms.keys.create` and `cloudkms.cryptoKeyVersions.useToDecrypt`, and assign it to all relevant personnel.",
        "wg": [
          { "t": "相關人員", "en": "relevant personnel", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "這是 Cloud KMS 中職責分離的標準模式。`Cloud KMS Admin` 允許管理金鑰 (metadata operations) 但**不允許**執行加密/解密操作 (data operations)。`Cloud KMS CryptoKey Encrypter/Decrypter` 則相反，允許使用金鑰但不允許管理。這樣確保了管理員無法偷看數據。(B) Owner 權限過大，違反最小權限。(D) 違反職責分離。",
      "en": "This is the standard pattern for Separation of Duties in Cloud KMS. `Cloud KMS Admin` allows managing keys (metadata operations) but does **not** allow cryptographic operations (data operations). `Cloud KMS CryptoKey Encrypter/Decrypter` is the opposite, allowing key usage but not management. This ensures admins cannot peek at the data. (B) Owner permission is too broad, violating least privilege. (D) violates Separation of Duties.",
      "wg": [
        { "t": "標準模式", "en": "standard pattern", "ps": "noun" },
        { "t": "最小權限", "en": "least privilege", "ps": "noun" }
      ]
    }
  },
  {
    "no": "20",
    "level": "hard",
    "keywords": "Compute, Cloud Run, Serverless, WebSocket",
    "question": [
      {
        "t": "您正在開發一個即時協作白板應用程式，該應用程式依賴 WebSocket 協議來實現客戶端之間的低延遲雙向通訊。",
        "en": "You are developing a real-time collaborative whiteboard application that relies on the WebSocket protocol for low-latency bidirectional communication between clients.",
        "wg": [
          { "t": "雙向通訊", "en": "bidirectional communication", "ps": "noun" },
          { "t": "協作白板", "en": "collaborative whiteboard", "ps": "noun" }
        ]
      },
      {
        "t": "您希望採用無伺服器架構以減少維運負擔，並希望應用程式能夠在沒有流量時自動縮減到零 (Scale to Zero)。同時，應用程式需要能夠存取 VPC 內的 Redis 緩存。您應該選擇哪個運算服務？",
        "en": "You want to adopt a serverless architecture to reduce operational overhead, and want the application to automatically scale to zero when there is no traffic. Additionally, the application needs to access a Redis cache within the VPC. Which compute service should you choose?",
        "wg": [
          { "t": "無伺服器架構", "en": "serverless architecture", "ps": "noun" },
          { "t": "維運負擔", "en": "operational overhead", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) App Engine Standard Environment (Python 3 runtime)，因為它支援 WebSocket 並具有內建的 Memcache。",
        "en": "(A) App Engine Standard Environment (Python 3 runtime), because it supports WebSockets and has built-in Memcache.",
        "wg": [
          { "t": "內建", "en": "built-in", "ps": "adjective" }
        ]
      },
      {
        "t": "(B) Cloud Functions (2nd Gen)，因為它基於 Cloud Run 構建，支援更長的超時時間，適合短暫的 HTTP 請求。",
        "en": "(B) Cloud Functions (2nd Gen), because it is built on Cloud Run and supports longer timeouts, suitable for short-lived HTTP requests.",
        "wg": [
          { "t": "超時時間", "en": "timeouts", "ps": "noun" }
        ]
      },
      {
        "t": "(C) Cloud Run，啟用 Session Affinity。配置 Serverless VPC Access Connector 以連接到 Redis。",
        "en": "(C) Cloud Run, with Session Affinity enabled. Configure a Serverless VPC Access Connector to connect to Redis.",
        "wg": [
          { "t": "連接", "en": "connect", "ps": "verb" }
        ]
      },
      {
        "t": "(D) Google Kubernetes Engine (GKE) Standard，因為只有 Kubernetes 能夠處理有狀態的 WebSocket 連線。",
        "en": "(D) Google Kubernetes Engine (GKE) Standard, because only Kubernetes can handle stateful WebSocket connections.",
        "wg": [
          { "t": "有狀態的", "en": "stateful", "ps": "adjective" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Run 支援 WebSocket、HTTP/2 和 gRPC，並且具備 Scale to Zero 的無伺服器特性，是現代化應用的首選。透過 VPC Connector (或 Direct VPC Egress) 可以存取內部 Redis。(A) App Engine Standard 歷史上對 WebSocket 支援有限 (通常需要 Flex)，且正在逐漸被 Cloud Run 取代。(B) Cloud Functions 不適合長時間保持的 WebSocket 連線。(D) GKE 可以做，但違背了「無伺服器」與「減少維運」的需求。",
      "en": "Cloud Run supports WebSockets, HTTP/2, and gRPC, and features Serverless Scale to Zero capabilities, making it the top choice for modern apps. Access to internal Redis is possible via VPC Connector (or Direct VPC Egress). (A) App Engine Standard historically had limited WebSocket support (often requiring Flex) and is being superseded by Cloud Run. (B) Cloud Functions is unsuitable for long-lived WebSocket connections. (D) GKE can do it but violates the 'serverless' and 'reduce ops' requirements.",
      "wg": [
        { "t": "首選", "en": "top choice", "ps": "noun" },
        { "t": "取代", "en": "superseded", "ps": "verb" }
      ]
    }
  },
  {
    "no": "21",
    "level": "hard",
    "keywords": "Data Analytics, Dataflow, Streaming, Windowing",
    "question": [
      {
        "t": "您的物聯網 (IoT) 平台每秒從全球數百萬個傳感器接收數千個事件。資料透過 Pub/Sub 進入 GCP。業務需求要求您計算每分鐘的平均溫度，並且必須準確處理「遲到數據」 (Late Data)，即事件發生時間與到達雲端時間有顯著延遲的情況。",
        "en": "Your IoT platform receives thousands of events per second from millions of global sensors. Data enters GCP via Pub/Sub. Business requirements dictate that you calculate the average temperature per minute and must accurately handle 'Late Data', where there is a significant delay between the event occurrence and its arrival in the cloud.",
        "wg": [
          { "t": "遲到數據", "en": "Late Data", "ps": "noun" },
          { "t": "顯著延遲", "en": "significant delay", "ps": "noun phrase" }
        ]
      },
      {
        "t": "處理後的結果需要寫入 Bigtable 以供即時儀表板使用。您需要一個能夠保證「精確一次」 (Exactly-once) 處理且能原生支援事件時間視窗 (Event-time Windowing) 的全託管解決方案。",
        "en": "The processed results need to be written to Bigtable for real-time dashboards. You need a fully managed solution that guarantees 'Exactly-once' processing and natively supports Event-time Windowing.",
        "wg": [
          { "t": "精確一次", "en": "Exactly-once", "ps": "adjective" },
          { "t": "事件時間視窗", "en": "Event-time Windowing", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud Functions 觸發器處理每個 Pub/Sub 訊息，將數據寫入 Firestore。利用 Firestore 的即時更新功能來計算平均值。",
        "en": "(A) Use Cloud Functions triggers to process each Pub/Sub message and write data to Firestore. Leverage Firestore's real-time update capabilities to calculate averages.",
        "wg": [
          { "t": "即時更新", "en": "real-time update", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 部署一個 Cloud Dataproc 叢集，運行 Spark Streaming 作業。配置 Spark 的 Watermarking 功能來處理遲到數據，並使用 Checkpointing 確保容錯。",
        "en": "(B) Deploy a Cloud Dataproc cluster running Spark Streaming jobs. Configure Spark's Watermarking feature to handle late data and use Checkpointing for fault tolerance.",
        "wg": [
          { "t": "容錯", "en": "fault tolerance", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Dataflow 編寫 Apache Beam 管道。啟用 Streaming Engine，並定義 Windowing 策略與 Watermarks 以正確聚合遲到數據，最後 Sink 到 Bigtable。",
        "en": "(C) Use Cloud Dataflow to write an Apache Beam pipeline. Enable Streaming Engine, and define Windowing strategies and Watermarks to correctly aggregate late data, finally sinking to Bigtable.",
        "wg": [
          { "t": "聚合", "en": "aggregate", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用 BigQuery 的串流插入 API (Streaming Insert) 將原始數據直接載入資料表，然後建立一個排程查詢 (Scheduled Query) 每分鐘運行一次 SQL 來計算平均值。",
        "en": "(D) Use BigQuery's Streaming Insert API to load raw data directly into tables, then create a Scheduled Query to run SQL every minute to calculate averages.",
        "wg": [
          { "t": "排程查詢", "en": "Scheduled Query", "ps": "noun" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Cloud Dataflow (Apache Beam) 是處理複雜串流分析、事件時間視窗 (Windowing) 和浮水印 (Watermarks) 以解決遲到數據問題的最佳工具，且提供 Exactly-once 語意。(A) Cloud Functions 不適合高吞吐量串流聚合，且難以處理視窗邏輯。(B) Dataproc (Spark) 雖然技術上可行，但需要管理叢集，不符合「全託管」的最佳偏好。(D) BigQuery 排程查詢是批次處理，無法滿足即時儀表板對低延遲的需求，且難以處理事件時間的重新聚合。",
      "en": "Cloud Dataflow (Apache Beam) is the best tool for complex stream analytics, handling Event-time Windowing and Watermarks for late data, and provides Exactly-once semantics. (A) Cloud Functions is ill-suited for high-throughput stream aggregation and windowing logic. (B) Dataproc (Spark) requires cluster management, missing the 'fully managed' preference. (D) BigQuery Scheduled Queries are batch processes, failing low-latency real-time dashboard needs and event-time re-aggregation.",
      "wg": [
        { "t": "最佳工具", "en": "best tool", "ps": "noun" },
        { "t": "重新聚合", "en": "re-aggregation", "ps": "noun" }
      ]
    }
  },
  {
    "no": "22",
    "level": "hard",
    "keywords": "Security, VPC Service Controls, Data Exfiltration, Context-aware",
    "question": [
      {
        "t": "您的組織處理高度敏感的金融數據，儲存在 BigQuery 和 Cloud Storage 中。您必須防止「資料外洩」(Data Exfiltration) 風險，例如防止擁有合法權限的內部員工將數據複製到他們個人的 Gmail 帳戶所擁有的 GCP 專案中。",
        "en": "Your organization processes highly sensitive financial data stored in BigQuery and Cloud Storage. You must prevent the risk of 'Data Exfiltration', such as authorized insiders copying data to GCP projects owned by their personal Gmail accounts.",
        "wg": [
          { "t": "資料外洩", "en": "Data Exfiltration", "ps": "noun" },
          { "t": "內部員工", "en": "insiders", "ps": "noun" }
        ]
      },
      {
        "t": "同時，您需要允許來自地端企業網路 (透過 Interconnect 連接) 的數據分析師存取這些資源。請選擇兩項配置來構建此安全邊界。",
        "en": "At the same time, you need to allow data analysts from the on-premises corporate network (connected via Interconnect) to access these resources. Please select two configurations to build this security perimeter.",
        "wg": [
          { "t": "安全邊界", "en": "security perimeter", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 實施 VPC Service Controls，建立一個服務邊界 (Service Perimeter)，將包含敏感數據的專案納入其中，並設定 `restricted-googleapis.com` DNS 解析以強制流量走私有路徑。",
        "en": "(A) Implement VPC Service Controls, creating a Service Perimeter to include projects containing sensitive data, and configure `restricted-googleapis.com` DNS resolution to force traffic over private paths.",
        "wg": [
          { "t": "納入", "en": "include", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 在 IAM 政策中移除所有 `Basic Roles` (如 Owner, Editor)，並強制實施多因素驗證 (MFA)，以確保只有受信任的身分可以登入。",
        "en": "(B) Remove all `Basic Roles` (e.g., Owner, Editor) from IAM policies and enforce Multi-Factor Authentication (MFA) to ensure only trusted identities can log in.",
        "wg": [
          { "t": "受信任的身分", "en": "trusted identities", "ps": "noun phrase" }
        ]
      },
      {
        "t": "(C) 配置 Ingress 和 Egress 規則 (Access Levels)，允許來自地端 IP 範圍的流量進入服務邊界，但明確拒絕數據流向邊界外的任何位置。",
        "en": "(C) Configure Ingress and Egress rules (Access Levels) to allow traffic from on-premises IP ranges into the Service Perimeter, but explicitly deny data flow to any location outside the perimeter.",
        "wg": [
          { "t": "明確拒絕", "en": "explicitly deny", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(D) 使用 Cloud DLP 掃描所有外發流量，如果偵測到敏感數據模式，則自動阻斷傳輸。",
        "en": "(D) Use Cloud DLP to scan all outbound traffic and automatically block transmission if sensitive data patterns are detected.",
        "wg": [
          { "t": "外發流量", "en": "outbound traffic", "ps": "noun" }
        ]
      },
      {
        "t": "(E) 啟用 Cloud Storage 的 Bucket Lock 功能，防止資料被移動或刪除。",
        "en": "(E) Enable Cloud Storage Bucket Lock features to prevent data from being moved or deleted.",
        "wg": [
          { "t": "移動", "en": "moved", "ps": "verb" }
        ]
      }
    ],
    "answer": "(A), (C)",
    "why": {
      "t": "VPC Service Controls (VPC SC) 是防止 API 層級資料外洩 (如 `bq cp` 到外部專案) 的核心工具。(A) 建立邊界並使用 `restricted-googleapis.com` 是標準實作步驟。(C) Access Levels (Ingress/Egress 規則) 是允許合法外部存取 (如地端 IP) 穿越邊界的機制。(B) 雖然是好習慣，但無法防止合法使用者將資料複製到外部。(D) DLP 通常用於靜態掃描或去識別化，不具備即時攔截 API 流量作為防火牆的功能。(E) Bucket Lock 防止刪除/修改，不防止複製 (讀取)。",
      "en": "VPC Service Controls (VPC SC) is the core tool for preventing API-level data exfiltration (e.g., `bq cp` to external projects). (A) Creating a perimeter and using `restricted-googleapis.com` are standard implementation steps. (C) Access Levels (Ingress/Egress rules) are the mechanism to allow legitimate external access (like on-prem IPs) across the perimeter. (B) is good practice but doesn't prevent authorized users from copying data out. (D) DLP is for static scanning/de-identification, not a real-time API traffic firewall. (E) Bucket Lock prevents deletion/modification, not copying (reading).",
      "wg": [
        { "t": "標準實作步驟", "en": "standard implementation steps", "ps": "noun phrase" },
        { "t": "即時攔截", "en": "real-time interception", "ps": "noun phrase" }
      ]
    }
  },
  {
    "no": "23",
    "level": "hard",
    "keywords": "Databases, Bigtable, Schema Design, Performance",
    "question": [
      {
        "t": "您正在設計一個用於儲存時序金融市場數據 (Time-series Data) 的 Cloud Bigtable 架構。該應用程式將每秒寫入數萬筆股票報價，並經常查詢「特定股票代碼 (Ticker) 在最近一小時內的報價」。",
        "en": "You are designing a Cloud Bigtable architecture for storing time-series financial market data. The application will write tens of thousands of stock quotes per second and frequently query 'quotes for a specific stock ticker within the last hour'.",
        "wg": [
          { "t": "時序數據", "en": "Time-series Data", "ps": "noun" },
          { "t": "股票報價", "en": "stock quotes", "ps": "noun" }
        ]
      },
      {
        "t": "您需要設計 Row Key 以優化寫入效能（避免熱點 Hotspotting）並確保讀取查詢的高效性。下列哪個 Row Key 設計最合適？",
        "en": "You need to design a Row Key to optimize write performance (avoid Hotspotting) while ensuring efficient read queries. Which Row Key design is most appropriate?",
        "wg": [
          { "t": "熱點", "en": "Hotspotting", "ps": "noun" },
          { "t": "高效性", "en": "efficiency", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) `[Timestamp]#[Ticker]`。這種設計讓最新的數據總是寫入到資料表的末端，便於範圍掃描。",
        "en": "(A) `[Timestamp]#[Ticker]`. This design ensures the latest data is always written to the end of the table, facilitating range scans.",
        "wg": [
          { "t": "範圍掃描", "en": "range scans", "ps": "noun" }
        ]
      },
      {
        "t": "(B) `[Ticker]#[Timestamp]`。這允許您針對特定股票進行高效的掃描，但如果某支股票交易量過大，可能會導致單一節點過載。",
        "en": "(B) `[Ticker]#[Timestamp]`. This allows efficient scanning for a specific stock, but if a stock has excessive trading volume, it might overload a single node.",
        "wg": [
          { "t": "單一節點過載", "en": "overload a single node", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(C) `[Ticker]#[Reverse_Timestamp]`。這確保了特定股票的最新數據位於該股票區塊的頂部，便於查詢「最近一小時」的數據，且避免了單調遞增的時間戳記造成的寫入熱點。",
        "en": "(C) `[Ticker]#[Reverse_Timestamp]`. This ensures the latest data for a specific stock is at the top of that stock's block, facilitating 'last hour' queries, and avoids write hotspots caused by monotonically increasing timestamps.",
        "wg": [
          { "t": "單調遞增", "en": "monotonically increasing", "ps": "adjective phrase" }
        ]
      },
      {
        "t": "(D) `[Hash(Ticker)]#[Timestamp]`。透過對股票代碼進行雜湊，可以將數據均勻分散在所有節點上，實現最佳的寫入負載平衡。",
        "en": "(D) `[Hash(Ticker)]#[Timestamp]`. Hashing the ticker distributes data evenly across all nodes, achieving optimal write load balancing.",
        "wg": [
          { "t": "均勻分散", "en": "distributes ... evenly", "ps": "verb phrase" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "對於時序資料，Bigtable 的最佳實踐是將查詢條件 (Ticker) 放在前面，並反轉時間戳記 (Reverse Timestamp)。這樣可以將最新資料放在一起，讓讀取查詢 (`start_key`, `end_key`) 非常高效。選項 (A) 以時間戳開頭會導致嚴重的寫入熱點 (所有寫入都集中在表尾)。選項 (B) 時間戳順序排列，查詢最新資料需要掃描到最後。選項 (D) 雖然寫入分佈好，但因雜湊破壞了排序，導致無法針對「特定股票」進行高效的範圍查詢 (需要 Scatter-gather)。",
      "en": "For time-series data, Bigtable best practice is to place the query entity (Ticker) first and use a Reverse Timestamp. This keeps the latest data adjacent, making read queries (`start_key`, `end_key`) highly efficient. Option (A) starting with timestamp causes severe write hotspots (all writes at table end). Option (B) with sequential timestamps requires scanning to the end for latest data. Option (D) distributes writes well but hashing breaks ordering, preventing efficient range queries for a 'specific stock' (requires Scatter-gather).",
      "wg": [
        { "t": "最佳實踐", "en": "best practice", "ps": "noun" },
        { "t": "寫入熱點", "en": "write hotspots", "ps": "noun" }
      ]
    }
  },
  {
    "no": "24",
    "level": "hard",
    "keywords": "Observability, Cloud Trace, Cloud Profiler, Performance",
    "question": [
      {
        "t": "您負責維運一個由數十個微服務組成的電子商務後端，這些服務運行在 GKE 上。最近用戶報告「結帳」功能的延遲偶爾會飆升至 5 秒以上（正常為 200 毫秒）。",
        "en": "You operate an e-commerce backend consisting of dozens of microservices running on GKE. Users recently reported that latency for the 'Checkout' function occasionally spikes to over 5 seconds (normally 200ms).",
        "wg": [
          { "t": "飆升", "en": "spikes", "ps": "verb" },
          { "t": "延遲", "en": "latency", "ps": "noun" }
        ]
      },
      {
        "t": "這些延遲尖峰難以復現。您懷疑是某個下游微服務的特定程式碼路徑效率低落，或者是資源競爭導致的 CPU 節流。您應該使用哪兩種工具來確切診斷問題的根本原因？",
        "en": "These latency spikes are hard to reproduce. You suspect inefficient code paths in a downstream microservice or CPU throttling caused by resource contention. Which two tools should you use to pinpoint the root cause?",
        "wg": [
          { "t": "資源競爭", "en": "resource contention", "ps": "noun" },
          { "t": "根本原因", "en": "root cause", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 啟用 Cloud Trace。這將提供分散式追蹤的瀑布視圖，幫助您識別哪個微服務或哪個 RPC 呼叫佔用了最多的時間。",
        "en": "(A) Enable Cloud Trace. This provides a waterfall view of distributed traces, helping you identify which microservice or RPC call is consuming the most time.",
        "wg": [
          { "t": "分散式追蹤", "en": "distributed traces", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 配置 Cloud Profiler。這將持續收集 CPU 和記憶體使用情況的樣本，並產生火焰圖 (Flame Graphs)，顯示特定函式或方法的資源消耗。",
        "en": "(B) Configure Cloud Profiler. This continuously collects samples of CPU and memory usage and generates Flame Graphs showing resource consumption of specific functions or methods.",
        "wg": [
          { "t": "火焰圖", "en": "Flame Graphs", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Logging 並將所有應用程式日誌的級別設為 `DEBUG`。將日誌匯出到 BigQuery 並執行 SQL 分析以尋找延遲模式。",
        "en": "(C) Use Cloud Logging and set all application log levels to `DEBUG`. Export logs to BigQuery and run SQL analysis to find latency patterns.",
        "wg": [
          { "t": "日誌級別", "en": "log levels", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 在所有微服務上安裝 Cloud Debugger (Snapshot Debugger)。設定條件斷點以捕捉延遲超過 5 秒時的變數狀態。",
        "en": "(D) Install Cloud Debugger (Snapshot Debugger) on all microservices. Set conditional breakpoints to capture variable states when latency exceeds 5 seconds.",
        "wg": [
          { "t": "條件斷點", "en": "conditional breakpoints", "ps": "noun" }
        ]
      },
      {
        "t": "(E) 使用 Cloud Monitoring 的 Uptime Checks 從多個區域持續 ping 結帳 API，以確認延遲是否與網路地理位置有關。",
        "en": "(E) Use Cloud Monitoring Uptime Checks to continuously ping the Checkout API from multiple regions to verify if latency is related to network geography.",
        "wg": [
          { "t": "地理位置", "en": "geography", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A), (B)",
    "why": {
      "t": "診斷「微服務延遲」與「效率低落代碼」的標準組合是 Trace + Profiler。(A) Cloud Trace 透過分散式追蹤 (Span) 找出是「哪個服務」變慢。(B) Cloud Profiler 透過火焰圖找出是服務內的「哪行程式碼」佔用了 CPU/RAM。 (C) `DEBUG` 日誌會產生巨量數據且增加延遲，不適合生產環境效能診斷。(D) Debugger 是用於邏輯錯誤 (變數值)，而非效能分析。(E) Uptime Checks 只能測量整體外部延遲，無法深入內部架構。",
      "en": "The standard combo for diagnosing 'microservice latency' and 'inefficient code' is Trace + Profiler. (A) Cloud Trace identifies 'which service' is slow via distributed traces (Spans). (B) Cloud Profiler identifies 'which line of code' is consuming CPU/RAM via Flame Graphs. (C) `DEBUG` logs generate massive data and add latency, unsuitable for prod performance diagnostics. (D) Debugger is for logic errors (variable values), not profiling. (E) Uptime Checks only measure overall external latency, unable to inspect internal architecture.",
      "wg": [
        { "t": "標準組合", "en": "standard combo", "ps": "noun" },
        { "t": "深入", "en": "inspect ... internal", "ps": "verb" }
      ]
    }
  },
  {
    "no": "25",
    "level": "hard",
    "keywords": "Identity, GCDS, SSO, Hybrid",
    "question": [
      {
        "t": "您的公司使用地端的 Microsoft Active Directory (AD) 作為其主要身分來源。您希望員工能夠使用其現有的 AD 憑證登入 Google Cloud Console，並自動配置其 Google 帳戶。",
        "en": "Your company uses on-premises Microsoft Active Directory (AD) as its primary identity source. You want employees to be able to log in to the Google Cloud Console using their existing AD credentials and have their Google accounts automatically provisioned.",
        "wg": [
          { "t": "身分來源", "en": "identity source", "ps": "noun" },
          { "t": "自動配置", "en": "automatically provisioned", "ps": "verb phrase" }
        ]
      },
      {
        "t": "當員工從 AD 中被刪除或停用時，他們對 Google Cloud 的存取權也必須立即或在下一次同步時被撤銷。您應該結合使用哪兩種工具來實現此混合身分架構？",
        "en": "When an employee is deleted or disabled in AD, their access to Google Cloud must also be revoked immediately or at the next sync. Which two tools should you use in combination to achieve this hybrid identity architecture?",
        "wg": [
          { "t": "混合身分架構", "en": "hybrid identity architecture", "ps": "noun" },
          { "t": "撤銷", "en": "revoked", "ps": "verb" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Google Cloud Directory Sync (GCDS) 將使用者和群組從 AD 單向同步到 Cloud Identity。配置 AD FS (Active Directory Federation Services) 作為身分提供者 (IdP) 來處理 SAML SSO。",
        "en": "(A) Use Google Cloud Directory Sync (GCDS) to one-way sync users and groups from AD to Cloud Identity. Configure AD FS (Active Directory Federation Services) as the Identity Provider (IdP) to handle SAML SSO.",
        "wg": [
          { "t": "單向同步", "en": "one-way sync", "ps": "verb phrase" },
          { "t": "身分提供者", "en": "Identity Provider (IdP)", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 使用 Managed Service for Microsoft Active Directory 在 GCP 上託管一個 AD 複本，並設定與地端 AD 的雙向信任。使用者直接使用 AD 帳戶登入。",
        "en": "(B) Use Managed Service for Microsoft Active Directory to host an AD replica on GCP and set up a two-way trust with on-premises AD. Users log in directly with AD accounts.",
        "wg": [
          { "t": "雙向信任", "en": "two-way trust", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 編寫一個腳本使用 Admin SDK Directory API，定期從 AD 匯出 CSV 並匯入到 Cloud Identity。使用 Firebase Authentication 處理登入。",
        "en": "(C) Write a script using the Admin SDK Directory API to periodically export CSVs from AD and import them into Cloud Identity. Use Firebase Authentication to handle logins.",
        "wg": [
          { "t": "匯出", "en": "export", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 在 Cloud Identity 中啟用 LDAP 同步功能，讓 Google 直接充當 LDAP 客戶端查詢地端 AD 進行驗證。",
        "en": "(D) Enable LDAP sync features in Cloud Identity, allowing Google to act directly as an LDAP client querying on-premises AD for authentication.",
        "wg": [
          { "t": "查詢", "en": "querying", "ps": "verb (gerund)" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "這是混合身分的標準模式：**GCDS** 負責「帳戶生命週期同步」(Provisioning/Deprovisioning)，確保 Cloud Identity 中有帳戶；**SAML SSO (透過 AD FS)** 負責「身分驗證」(Authentication)，確保密碼保留在地端 AD，不傳送給 Google。(B) Managed AD 是用於讓 Windows VM 加入網域，而非讓使用者登入 Google Cloud Console。(D) Cloud Identity 不直接透過 LDAP 驗證使用者 (Secure LDAP 是反向的，讓應用程式透過 LDAP 驗證 Google 帳戶)。",
      "en": "This is the standard hybrid identity pattern: **GCDS** handles 'Account Lifecycle Sync' (Provisioning/Deprovisioning), ensuring accounts exist in Cloud Identity; **SAML SSO (via AD FS)** handles 'Authentication', ensuring passwords stay in on-prem AD and aren't sent to Google. (B) Managed AD is for domain-joining Windows VMs, not for logging users into Google Cloud Console. (D) Cloud Identity doesn't auth users via LDAP directly (Secure LDAP is the reverse, letting apps auth Google accounts via LDAP).",
      "wg": [
        { "t": "標準模式", "en": "standard pattern", "ps": "noun" },
        { "t": "身分驗證", "en": "Authentication", "ps": "noun" }
      ]
    }
  },
  {
    "no": "26",
    "level": "hard",
    "keywords": "Compute, Cloud Functions, Eventarc, Event-driven",
    "question": [
      {
        "t": "您的應用程式允許使用者上傳高解析度圖片到 Cloud Storage。每次上傳後，系統需要自動產生縮圖、提取 Metadata (Exif) 並使用 Vision API 進行內容審核。這些步驟是獨立且非同步的。",
        "en": "Your application allows users to upload high-resolution images to Cloud Storage. After each upload, the system needs to automatically generate thumbnails, extract Metadata (Exif), and use the Vision API for content moderation. These steps are independent and asynchronous.",
        "wg": [
          { "t": "非同步的", "en": "asynchronous", "ps": "adjective" },
          { "t": "內容審核", "en": "content moderation", "ps": "noun" }
        ]
      },
      {
        "t": "您希望採用鬆散耦合 (Loosely Coupled) 的無伺服器架構，以便將來可以輕鬆新增其他處理步驟 (如發送通知)，而無需修改現有程式碼。您應該如何設計？",
        "en": "You want to adopt a Loosely Coupled serverless architecture so that you can easily add other processing steps (like sending notifications) in the future without modifying existing code. How should you design this?",
        "wg": [
          { "t": "鬆散耦合", "en": "Loosely Coupled", "ps": "adjective" },
          { "t": "修改", "en": "modifying", "ps": "verb (gerund)" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用 GCS 的 Pub/Sub 通知功能 (Object Change Notification)。建立多個 Cloud Functions (縮圖、Metadata、審核)，每個都訂閱同一個 Pub/Sub 主題。",
        "en": "(A) Enable GCS Pub/Sub notifications (Object Change Notification). Create multiple Cloud Functions (Thumbnail, Metadata, Moderation), each subscribing to the same Pub/Sub topic.",
        "wg": [
          { "t": "訂閱", "en": "subscribing", "ps": "verb (gerund)" }
        ]
      },
      {
        "t": "(B) 編寫單一個 Cloud Function，由 `google.storage.object.finalize` 事件觸發。在函式內部依序執行縮圖產生、Metadata 提取和 Vision API 呼叫。",
        "en": "(B) Write a single Cloud Function triggered by the `google.storage.object.finalize` event. Inside the function, sequentially execute thumbnail generation, Metadata extraction, and Vision API calls.",
        "wg": [
          { "t": "依序執行", "en": "sequentially execute", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(C) 使用 Cloud Tasks。當圖片上傳時，前端應用程式建立三個任務並分別發送到三個不同的 Cloud Tasks 佇列，由 Cloud Run Worker 處理。",
        "en": "(C) Use Cloud Tasks. When an image is uploaded, the frontend application creates three tasks and sends them to three different Cloud Tasks queues, processed by Cloud Run Workers.",
        "wg": [
          { "t": "佇列", "en": "queues", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Composer 編排一個 DAG。每 5 分鐘掃描一次 Bucket 中的新文件，並平行執行處理步驟。",
        "en": "(D) Use Cloud Composer to orchestrate a DAG. Scan the Bucket for new files every 5 minutes and execute processing steps in parallel.",
        "wg": [
          { "t": "掃描", "en": "Scan", "ps": "verb" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Pub/Sub 模式是實現「鬆散耦合」與「一對多」事件分發的標準架構。(A) 透過 Pub/Sub，新增一個處理步驟 (如通知) 只需新增一個訂閱者 (Subscriber)，完全不影響現有流程。(B) 單一函式是緊密耦合 (Tightly Coupled)，新增功能需要修改代碼且增加了執行時間風險。(C) Cloud Tasks 增加了前端的複雜度。(D) 是批次處理，不是事件驅動。",
      "en": "The Pub/Sub pattern is the standard architecture for 'Loosely Coupled' and 'One-to-Many' event distribution. (A) With Pub/Sub, adding a processing step (like notification) only requires adding a Subscriber, without affecting existing flows. (B) A single function is Tightly Coupled; adding features requires code changes and increases runtime risk. (C) Cloud Tasks adds complexity to the frontend. (D) is batch processing, not event-driven.",
      "wg": [
        { "t": "緊密耦合", "en": "Tightly Coupled", "ps": "adjective" },
        { "t": "標準架構", "en": "standard architecture", "ps": "noun" }
      ]
    }
  },
  {
    "no": "27",
    "level": "hard",
    "keywords": "Networking, Private Google Access, Cloud NAT, Security",
    "question": [
      {
        "t": "您有一個私有 GKE 叢集 (Private Cluster)，節點沒有公共 IP 地址。叢集內的應用程式需要存取 Cloud Storage 下載數據，同時也需要存取外部第三方的 API (互聯網) 來獲取匯率資訊。",
        "en": "You have a Private GKE Cluster where nodes do not have public IP addresses. Applications within the cluster need to access Cloud Storage to download data and also need to access external third-party APIs (Internet) to fetch exchange rate information.",
        "wg": [
          { "t": "私有 GKE 叢集", "en": "Private GKE Cluster", "ps": "noun" },
          { "t": "匯率資訊", "en": "exchange rate information", "ps": "noun" }
        ]
      },
      {
        "t": "為了安全起見，您不能為節點分配外部 IP。您應該如何配置網路以同時滿足這兩個需求，並確保對 Cloud Storage 的存取保持在 Google 骨幹網絡內？",
        "en": "For security reasons, you cannot assign external IPs to the nodes. How should you configure the network to meet both requirements simultaneously, ensuring access to Cloud Storage remains within Google's backbone network?",
        "wg": [
          { "t": "骨幹網絡", "en": "backbone network", "ps": "noun" },
          { "t": "同時滿足", "en": "meet ... simultaneously", "ps": "verb phrase" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在子網上啟用 Private Google Access 以存取 GCS。配置 Cloud NAT 以允許對互聯網的出站存取 (Outbound Access)。",
        "en": "(A) Enable Private Google Access on the subnet to access GCS. Configure Cloud NAT to allow Outbound Access to the Internet.",
        "wg": [
          { "t": "出站存取", "en": "Outbound Access", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 配置 VPC Service Controls 將 GCS 和 GKE 納入邊界。使用 Cloud VPN 連接到互聯網閘道。",
        "en": "(B) Configure VPC Service Controls to include GCS and GKE in a perimeter. Use Cloud VPN to connect to an internet gateway.",
        "wg": [
          { "t": "邊界", "en": "perimeter", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 為 GKE 節點分配 Ephemeral External IPs，但使用防火牆規則阻擋所有入站 (Ingress) 流量，僅允許出站流量。",
        "en": "(C) Assign Ephemeral External IPs to GKE nodes, but use firewall rules to block all Ingress traffic, allowing only outbound traffic.",
        "wg": [
          { "t": "入站", "en": "Ingress", "ps": "adjective" }
        ]
      },
      {
        "t": "(D) 使用 Private Service Connect 建立一個端點來存取 GCS。對於互聯網存取，部署一個 Proxy VM 並配置路由。",
        "en": "(D) Use Private Service Connect to create an endpoint for accessing GCS. For internet access, deploy a Proxy VM and configure routing.",
        "wg": [
          { "t": "端點", "en": "endpoint", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "這是標準的私有網路配置模式。**Private Google Access (PGA)** 允許無公網 IP 的 VM 透過 Google 內部網路存取 Google API (如 GCS)。**Cloud NAT** 為這些 VM 提供出站互聯網存取 (如第三方 API) 而不暴露入站 IP。(C) 違反了「不分配外部 IP」的要求，且防火牆管理複雜。(D) Proxy VM 是非託管解決方案，存在單點故障與維護負擔，Cloud NAT 是更好的選擇。",
      "en": "This is the standard private networking pattern. **Private Google Access (PGA)** allows VMs without public IPs to access Google APIs (like GCS) via Google's internal network. **Cloud NAT** provides outbound internet access (like third-party APIs) for these VMs without exposing ingress IPs. (C) violates the 'no external IP' requirement and firewall management is complex. (D) Proxy VM is an unmanaged solution with SPOF and maintenance burden; Cloud NAT is superior.",
      "wg": [
        { "t": "出站互聯網存取", "en": "outbound internet access", "ps": "noun phrase" },
        { "t": "單點故障", "en": "SPOF (Single Point of Failure)", "ps": "noun" }
      ]
    }
  },
  {
    "no": "28",
    "level": "hard",
    "keywords": "Architecture, Disaster Recovery, Cloud SQL, RTO/RPO",
    "question": [
      {
        "t": "您的關鍵任務應用程式使用 Cloud SQL for PostgreSQL 作為資料庫。業務連續性計畫 (BCP) 要求在發生區域性災難 (Region Failure) 時，必須能在 1 小時內 (RTO < 1h) 在另一個區域恢復服務，且資料遺失不得超過 5 分鐘 (RPO < 5m)。",
        "en": "Your mission-critical application uses Cloud SQL for PostgreSQL. The Business Continuity Plan (BCP) requires that in the event of a Region Failure, service must be restored in another region within 1 hour (RTO < 1h), with no more than 5 minutes of data loss (RPO < 5m).",
        "wg": [
          { "t": "區域性災難", "en": "Region Failure", "ps": "noun" },
          { "t": "業務連續性計畫", "en": "Business Continuity Plan (BCP)", "ps": "noun" }
        ]
      },
      {
        "t": "您應該如何配置 Cloud SQL 以滿足這些嚴格的災難復原需求？",
        "en": "How should you configure Cloud SQL to meet these strict disaster recovery requirements?",
        "wg": [
          { "t": "災難復原", "en": "disaster recovery", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 啟用高可用性 (HA) 配置。這會自動在同一區域的不同可用區 (Zone) 建立待命實例，確保在區域故障時自動切換。",
        "en": "(A) Enable High Availability (HA) configuration. This automatically creates a standby instance in a different Zone within the same region, ensuring automatic failover during regional failures.",
        "wg": [
          { "t": "待命實例", "en": "standby instance", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 在災難復原區域建立一個跨區域讀取複本 (Cross-Region Read Replica)。當主區域故障時，手動將該複本提升 (Promote) 為主實例。",
        "en": "(B) Create a Cross-Region Read Replica in the disaster recovery region. When the primary region fails, manually Promote this replica to be the primary instance.",
        "wg": [
          { "t": "提升", "en": "Promote", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 配置每日自動備份，並使用 `gcloud sql backups copy` 將備份複製到另一個區域的 GCS Bucket。災難發生時，從備份還原新實例。",
        "en": "(C) Configure daily automated backups and use `gcloud sql backups copy` to copy backups to a GCS Bucket in another region. In a disaster, restore a new instance from the backup.",
        "wg": [
          { "t": "還原", "en": "restore", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Spanner 替換 Cloud SQL，因為只有 Spanner 提供真正的全球同步複製和 99.999% 的可用性，Cloud SQL 無法滿足 RPO < 5m。",
        "en": "(D) Replace Cloud SQL with Cloud Spanner, as only Spanner provides true global synchronous replication and 99.999% availability; Cloud SQL cannot meet RPO < 5m.",
        "wg": [
          { "t": "同步複製", "en": "synchronous replication", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "針對「區域性故障 (Region Failure)」，標準 HA (選項 A) 無效，因為它僅是區域內的跨 Zone 備援。正確的 DR 策略是使用跨區域讀取複本 (Cross-Region Read Replica)。PostgreSQL 複本通常延遲在秒級或分鐘級，滿足 RPO < 5m；提升複本並更新應用程式連線可在 1 小時內完成，滿足 RTO < 1h。(C) 每日備份的 RPO 是 24 小時，不符合要求。(D) 雖然 Spanner 更強，但 Cloud SQL 的跨區複本已足夠滿足此題 RPO/RTO，無需昂貴的遷移。",
      "en": "For 'Region Failure', standard HA (Option A) is ineffective as it's only cross-Zone within a region. The correct DR strategy is using a Cross-Region Read Replica. PostgreSQL replica lag is typically seconds or minutes, meeting RPO < 5m; promoting the replica and updating app connections fits within 1 hour, meeting RTO < 1h. (C) Daily backups have an RPO of 24 hours, failing requirements. (D) While Spanner is stronger, Cloud SQL's cross-region replica suffices for this RPO/RTO without expensive migration.",
      "wg": [
        { "t": "無效", "en": "ineffective", "ps": "adjective" },
        { "t": "昂貴的遷移", "en": "expensive migration", "ps": "noun phrase" }
      ]
    }
  },
  {
    "no": "29",
    "level": "hard",
    "keywords": "Storage, Cloud Storage, Lifecycle Management, Cost Optimization",
    "question": [
      {
        "t": "一家媒體公司每天生成 10 TB 的原始影片素材。這些素材在生成後的前 30 天內會被頻繁存取（編輯、轉碼）。30 天後，存取頻率急劇下降，僅偶爾讀取。一年後，這些數據僅需為了合規性保留，幾乎不會被讀取。",
        "en": "A media company generates 10 TB of raw video footage daily. This footage is accessed frequently (editing, transcoding) during the first 30 days. After 30 days, access frequency drops sharply to occasional reads. After one year, the data is retained solely for compliance and is almost never read.",
        "wg": [
          { "t": "原始影片素材", "en": "raw video footage", "ps": "noun" },
          { "t": "急劇下降", "en": "drops sharply", "ps": "verb phrase" }
        ]
      },
      {
        "t": "您需要設計一個最具成本效益的儲存策略，自動化管理這些數據的生命週期，且無需任何應用程式代碼變更。",
        "en": "You need to design the most cost-effective storage strategy to automate the lifecycle management of this data without any application code changes.",
        "wg": [
          { "t": "最具成本效益", "en": "most cost-effective", "ps": "adjective phrase" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 建立一個 Bucket，設定預設儲存類別為 Standard。配置 Object Lifecycle Management 規則：30 天後轉為 Nearline，365 天後轉為 Archive。",
        "en": "(A) Create a Bucket with default storage class set to Standard. Configure Object Lifecycle Management rules: transition to Nearline after 30 days, and to Archive after 365 days.",
        "wg": [
          { "t": "預設儲存類別", "en": "default storage class", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 建立一個 Bucket，啟用 Autoclass 功能。Autoclass 會根據每個物件的實際存取模式，自動將其在 Standard 和 Nearline/Archive 之間移動。",
        "en": "(B) Create a Bucket and enable Autoclass. Autoclass automatically moves objects between Standard and Nearline/Archive based on each object's actual access pattern.",
        "wg": [
          { "t": "實際存取模式", "en": "actual access pattern", "ps": "noun phrase" }
        ]
      },
      {
        "t": "(C) 將資料直接寫入 Coldline Bucket。雖然前 30 天的檢索費用較高，但考慮到長期的儲存節省，總體成本最低。",
        "en": "(C) Write data directly to a Coldline Bucket. Although retrieval costs are higher for the first 30 days, the overall cost is lowest considering long-term storage savings.",
        "wg": [
          { "t": "檢索費用", "en": "retrieval costs", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 使用三個不同的 Bucket (Standard, Nearline, Archive)。編寫一個 Cloud Function，在第 30 天和第 365 天將物件移動到相應的 Bucket 並刪除原始物件。",
        "en": "(D) Use three different Buckets (Standard, Nearline, Archive). Write a Cloud Function to move objects to the corresponding Bucket and delete the original on day 30 and day 365.",
        "wg": [
          { "t": "相應的", "en": "corresponding", "ps": "adjective" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "題目描述的存取模式非常有規律 (30天, 1年)，因此使用基於規則的 Lifecycle Management 是最簡單且最具成本效益的 (無管理費)。(B) Autoclass 適用於存取模式「不可預測」的情況，且會收取管理費 ($0.0025/1k objects)，對於已知模式可能較貴。(C) Coldline 在頻繁存取期 (前30天) 會產生巨額的 Data Retrieval 費用，不划算。(D) 需要維護代碼，且移動物件會產生額外費用 (Class A Request)。",
      "en": "The described access pattern is highly regular (30 days, 1 year), so rule-based Lifecycle Management is simplest and most cost-effective (no management fee). (B) Autoclass is for 'unpredictable' patterns and charges a management fee ($0.0025/1k objects), likely more expensive for known patterns. (C) Coldline incurs huge Data Retrieval fees during the frequent access period (first 30 days), making it uneconomical. (D) Requires code maintenance and moving objects incurs extra fees (Class A Request).",
      "wg": [
        { "t": "有規律", "en": "highly regular", "ps": "adjective phrase" },
        { "t": "不划算", "en": "uneconomical", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "30",
    "level": "hard",
    "keywords": "Hybrid, Anthos, Config Management, Governance",
    "question": [
      {
        "t": "您的企業在 Google Cloud (GKE) 和地端資料中心 (Anthos on VMware) 同時運行 Kubernetes 叢集。為了確保合規性，安全團隊要求所有叢集中的 Namespace 都必須套用一致的 Resource Quotas 和 Network Policies。",
        "en": "Your enterprise runs Kubernetes clusters on both Google Cloud (GKE) and on-premises data centers (Anthos on VMware). To ensure compliance, the security team requires that consistent Resource Quotas and Network Policies be applied to Namespaces across all clusters.",
        "wg": [
          { "t": "一致的", "en": "consistent", "ps": "adjective" },
          { "t": "配額", "en": "Quotas", "ps": "noun" }
        ]
      },
      {
        "t": "此外，您希望防止任何「配置漂移」(Configuration Drift)，即當有人手動修改叢集設定時，系統能自動將其還原為標準狀態。您應該使用什麼工具來實現這一目標？",
        "en": "Additionally, you want to prevent 'Configuration Drift', meaning if someone manually modifies cluster settings, the system automatically reverts them to the standard state. Which tool should you use to achieve this?",
        "wg": [
          { "t": "配置漂移", "en": "Configuration Drift", "ps": "noun" },
          { "t": "還原", "en": "reverts", "ps": "verb" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Anthos Config Management (ACM) 的 Config Sync 功能。將配置 YAML 檔儲存在 Git 儲存庫中，Config Sync 會持續監控並強制同步所有叢集。",
        "en": "(A) Use the Config Sync feature of Anthos Config Management (ACM). Store configuration YAML files in a Git repository, and Config Sync will continuously monitor and enforce synchronization across all clusters.",
        "wg": [
          { "t": "強制同步", "en": "enforce synchronization", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(B) 使用 Terraform 建立所有叢集資源。設定一個定期的 CI/CD 管道運行 `terraform apply`，以覆蓋任何手動更改。",
        "en": "(B) Use Terraform to create all cluster resources. Set up a periodic CI/CD pipeline to run `terraform apply` to overwrite any manual changes.",
        "wg": [
          { "t": "覆蓋", "en": "overwrite", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 在每個叢集中安裝 Open Policy Agent (OPA) Gatekeeper。編寫 Rego 策略來驗證每個 API 請求，並拒絕不符合規範的變更。",
        "en": "(C) Install Open Policy Agent (OPA) Gatekeeper on each cluster. Write Rego policies to validate every API request and reject non-compliant changes.",
        "wg": [
          { "t": "拒絕", "en": "reject", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 使用 Cloud Deployment Manager 管理 GKE 資源。它具有內建的漂移檢測功能，可以自動修復資源。",
        "en": "(D) Use Cloud Deployment Manager to manage GKE resources. It has built-in drift detection capabilities that can automatically repair resources.",
        "wg": [
          { "t": "漂移檢測", "en": "drift detection", "ps": "noun" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Anthos Config Management (ACM) 是專為多叢集、混合雲環境設計的 GitOps 工具。Config Sync 能夠自動修復漂移 (Self-healing)，確保叢集狀態始終與 Git repo 一致。(B) Terraform 是「觸發式」的，無法即時檢測漂移，且對 K8s 內部資源 (如 NetworkPolicy) 的管理不如 ACM 原生。(C) OPA Gatekeeper (ACM 的 Policy Controller) 僅能「攔截/驗證」請求，無法「分發」配置或「自動還原」已存在的漂移。(D) Deployment Manager 不支援 K8s 內部資源管理。",
      "en": "Anthos Config Management (ACM) is a GitOps tool designed for multi-cluster, hybrid environments. Config Sync offers self-healing to automatically fix drift, ensuring cluster state matches the Git repo. (B) Terraform is 'trigger-based', cannot detect drift in real-time, and manages K8s internal resources (like NetworkPolicy) less natively than ACM. (C) OPA Gatekeeper (ACM's Policy Controller) only 'intercepts/validates' requests, unable to 'distribute' configs or 'automatically revert' existing drift. (D) Deployment Manager does not support K8s internal resource management.",
      "wg": [
        { "t": "自動修復", "en": "Self-healing", "ps": "noun" },
        { "t": "觸發式", "en": "trigger-based", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "31",
    "level": "hard",
    "keywords": "Networking, Private Service Connect, Shared VPC, Security",
    "question": [
      {
        "t": "您的組織使用 Shared VPC 架構，其中有一個 Host Project 和多個 Service Projects。您希望在其中一個 Service Project 中部署一個內部微服務，並允許其他所有 Service Projects (甚至不同 VPC 的專案) 安全地存取它，而不使用 VPC Peering（因為 IP 地址重疊問題）。",
        "en": "Your organization uses a Shared VPC architecture with a Host Project and multiple Service Projects. You want to deploy an internal microservice in one of the Service Projects and allow all other Service Projects (even those in different VPCs) to securely access it without using VPC Peering (due to IP overlap issues).",
        "wg": [
          { "t": "內部微服務", "en": "internal microservice", "ps": "noun" },
          { "t": "IP 地址重疊", "en": "IP overlap", "ps": "noun" }
        ]
      },
      {
        "t": "消費者專案 (Consumer Projects) 應該能夠使用其 VPC 內的一個私有 IP 來存取該服務。您應該如何架構此連線？",
        "en": "Consumer Projects should be able to access the service using a private IP within their own VPC. How should you architect this connection?",
        "wg": [
          { "t": "消費者專案", "en": "Consumer Projects", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 在生產者專案中，建立一個 Internal HTTP(S) Load Balancer，並發布一個 Service Attachment。在消費者專案中，建立一個 Private Service Connect (PSC) Endpoint 指向該 Attachment。",
        "en": "(A) In the producer project, create an Internal HTTP(S) Load Balancer and publish a Service Attachment. In consumer projects, create a Private Service Connect (PSC) Endpoint pointing to that Attachment.",
        "wg": [
          { "t": "服務附件", "en": "Service Attachment", "ps": "noun" },
          { "t": "端點", "en": "Endpoint", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 在生產者專案中，建立一個 Internal TCP/UDP Load Balancer。配置 VPC Firewall 規則以允許來自所有消費者 VPC IP 範圍的流量，並使用 Cloud DNS 私有區域解析服務名稱。",
        "en": "(B) In the producer project, create an Internal TCP/UDP Load Balancer. Configure VPC Firewall rules to allow traffic from all consumer VPC IP ranges, and use Cloud DNS private zones to resolve the service name.",
        "wg": [
          { "t": "解析", "en": "resolve", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 Cloud VPN 將所有消費者 VPC 連接到生產者 VPC。使用 Cloud Router 和 BGP 交換路由，並啟用 NAT 以解決 IP 重疊問題。",
        "en": "(C) Use Cloud VPN to connect all consumer VPCs to the producer VPC. Use Cloud Router and BGP to exchange routes, and enable NAT to resolve IP overlap issues.",
        "wg": [
          { "t": "交換路由", "en": "exchange routes", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(D) 將微服務部署在 App Engine Standard 上，並啟用 Identity-Aware Proxy (IAP)。消費者應用程式使用服務帳戶憑證進行驗證。",
        "en": "(D) Deploy the microservice on App Engine Standard and enable Identity-Aware Proxy (IAP). Consumer applications authenticate using service account credentials.",
        "wg": [
          { "t": "驗證", "en": "authenticate", "ps": "verb" }
        ]
      }
    ],
    "answer": "(A)",
    "why": {
      "t": "Private Service Connect (PSC) 是解決「IP 重疊」和「跨 VPC/Org 私有存取」的標準方案。它使用生產者-消費者模型：生產者發布 Service Attachment，消費者建立 Endpoint (Forwarding Rule)。(B) 和 (C) 依賴路由互通，無法解決 IP 重疊問題（除非做極其複雜的雙向 NAT）。(D) App Engine Standard 預設是公網存取，雖然有 IAP，但題目要求是「內部微服務」且消費者需使用「私有 IP」。",
      "en": "Private Service Connect (PSC) is the standard solution for 'IP overlap' and 'cross-VPC/Org private access'. It uses a producer-consumer model: Producer publishes a Service Attachment, Consumer creates an Endpoint (Forwarding Rule). (B) and (C) rely on routing connectivity and cannot solve IP overlap (unless complex bi-directional NAT is used). (D) App Engine Standard is public by default; while IAP adds security, the requirement is 'internal microservice' accessed via 'private IP'.",
      "wg": [
        { "t": "路由互通", "en": "routing connectivity", "ps": "noun phrase" },
        { "t": "標準方案", "en": "standard solution", "ps": "noun phrase" }
      ]
    }
  },
  {
    "no": "32",
    "level": "hard",
    "keywords": "Compute, Bare Metal Solution, Oracle, Architecture",
    "question": [
      {
        "t": "您正在規劃將一個關鍵的 Oracle Exadata 資料庫遷移到 Google Cloud。該資料庫支援核心的銀行交易系統，對延遲極度敏感，且需要 Oracle RAC 來實現高可用性。",
        "en": "You are planning to migrate a critical Oracle Exadata database to Google Cloud. This database supports core banking transaction systems, is extremely latency-sensitive, and requires Oracle RAC for high availability.",
        "wg": [
          { "t": "極度敏感", "en": "extremely sensitive", "ps": "adjective phrase" },
          { "t": "核心的", "en": "core", "ps": "adjective" }
        ]
      },
      {
        "t": "您決定使用 Google Cloud Bare Metal Solution (BMS)。應用程式伺服器將運行在 Compute Engine 上。您需要如何設計網路連接以確保 BMS 環境與 GCP 原生環境之間的延遲最低？",
        "en": "You decided to use Google Cloud Bare Metal Solution (BMS). Application servers will run on Compute Engine. How should you design the network connectivity to ensure minimum latency between the BMS environment and the GCP native environment?",
        "wg": [
          { "t": "網路連接", "en": "network connectivity", "ps": "noun" },
          { "t": "原生環境", "en": "native environment", "ps": "noun" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud VPN (HA VPN) 通過公共互聯網連接 Compute Engine VPC 和 BMS 區域擴展網路。",
        "en": "(A) Use Cloud VPN (HA VPN) to connect the Compute Engine VPC and the BMS regional extension network over the public internet.",
        "wg": [
          { "t": "區域擴展", "en": "regional extension", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 配置 Partner Interconnect 連接 BMS 和 GCP VPC。BMS 被視為一個「地端」位置，數據通過合作夥伴網路傳輸。",
        "en": "(B) Configure Partner Interconnect to connect BMS and the GCP VPC. BMS is treated as an 'on-premises' location, and data travels through a partner network.",
        "wg": [
          { "t": "被視為", "en": "treated as", "ps": "verb phrase" }
        ]
      },
      {
        "t": "(C) 在 GCP 專案中配置 Partner Interconnect 的 VLAN Attachment，直接連接到 BMS 環境預先配置好的 Dedicated Interconnect 電路 (Region Extension)。",
        "en": "(C) Configure a Partner Interconnect VLAN Attachment in the GCP project, connecting directly to the pre-provisioned Dedicated Interconnect circuits (Region Extension) of the BMS environment.",
        "wg": [
          { "t": "預先配置好的", "en": "pre-provisioned", "ps": "adjective" }
        ]
      },
      {
        "t": "(D) 使用 VPC Network Peering 直接將 BMS 網路與 Compute Engine VPC 對等互連。",
        "en": "(D) Use VPC Network Peering to directly peer the BMS network with the Compute Engine VPC.",
        "wg": [
          { "t": "對等互連", "en": "peer", "ps": "verb" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "Bare Metal Solution (BMS) 位於 Google 區域擴展中，與 GCP 主區域物理相鄰。連接方式是透過 **Partner Interconnect** (使用 VLAN Attachments)，但底層實際上是 Google 預先鋪設的專用線路，不經過第三方 ISP。這提供了極低延遲和高頻寬。(A) VPN 延遲太高。(B) 雖然名義上是 Partner Interconnect，但不需要外部合作夥伴網路介入。(D) BMS 網路不是標準 VPC，不能直接使用 VPC Peering。",
      "en": "Bare Metal Solution (BMS) resides in Google regional extensions, physically adjacent to GCP main regions. Connectivity is via **Partner Interconnect** (using VLAN Attachments), but the underlying infrastructure is dedicated lines pre-laid by Google, bypassing third-party ISPs. This offers extremely low latency and high bandwidth. (A) VPN latency is too high. (B) While nominally Partner Interconnect, it doesn't involve external partner networks. (D) BMS network is not a standard VPC and cannot use VPC Peering directly.",
      "wg": [
        { "t": "物理相鄰", "en": "physically adjacent", "ps": "adjective phrase" },
        { "t": "預先鋪設", "en": "pre-laid", "ps": "adjective" }
      ]
    }
  },
  {
    "no": "33",
    "level": "hard",
    "keywords": "Security, Compliance, CMEK, Cloud EKM, Trust",
    "question": [
      {
        "t": "您的公司是一家歐洲政府承包商，必須遵守極其嚴格的資料主權法規。法規要求所有儲存在雲端的資料必須使用加密金鑰保護，且這些金鑰的「金鑰材料」(Key Material) 絕不能存儲在雲端供應商的基礎設施中（即使是加密形式也不行）。",
        "en": "Your company is a European government contractor and must comply with extremely strict data sovereignty regulations. Regulations require that all data stored in the cloud must be protected using encryption keys, and the 'Key Material' for these keys must never be stored on the cloud provider's infrastructure (even in encrypted form).",
        "wg": [
          { "t": "金鑰材料", "en": "Key Material", "ps": "noun" },
          { "t": "資料主權", "en": "data sovereignty", "ps": "noun" }
        ]
      },
      {
        "t": "您希望使用 BigQuery 進行資料分析。您應該採用哪種金鑰管理策略？",
        "en": "You want to use BigQuery for data analysis. Which key management strategy should you adopt?",
        "wg": [
          { "t": "採用", "en": "adopt", "ps": "verb" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 使用 Cloud KMS 的 Customer-Managed Encryption Keys (CMEK)，並選擇 `Software` 保護級別。金鑰由 Google 管理但由客戶控制生命週期。",
        "en": "(A) Use Cloud KMS Customer-Managed Encryption Keys (CMEK) with `Software` protection level. Keys are managed by Google but the lifecycle is controlled by the customer.",
        "wg": [
          { "t": "生命週期", "en": "lifecycle", "ps": "noun" }
        ]
      },
      {
        "t": "(B) 使用 Cloud KMS 搭配 Cloud HSM。金鑰存儲在 FIPS 140-2 Level 3 認證的硬體中，Google 無法匯出金鑰。",
        "en": "(B) Use Cloud KMS with Cloud HSM. Keys are stored in FIPS 140-2 Level 3 certified hardware, and Google cannot export the keys.",
        "wg": [
          { "t": "匯出", "en": "export", "ps": "verb" }
        ]
      },
      {
        "t": "(C) 使用 Cloud External Key Manager (Cloud EKM)。將金鑰存儲在位於歐洲本地資料中心的第三方 HSM 中 (如 Thales 或 Fortanix)。BigQuery 在需要解密時會透過互聯網呼叫外部 HSM。",
        "en": "(C) Use Cloud External Key Manager (Cloud EKM). Store keys in a third-party HSM (like Thales or Fortanix) located in a local European data center. BigQuery calls the external HSM over the internet when decryption is needed.",
        "wg": [
          { "t": "呼叫", "en": "calls", "ps": "verb" }
        ]
      },
      {
        "t": "(D) 在客戶端進行加密 (Client-side Encryption)，然後將加密後的 Blob 上傳到 BigQuery。BigQuery 使用其預設金鑰進行第二次加密 (Envelope Encryption)。",
        "en": "(D) Perform Client-side Encryption, then upload the encrypted blobs to BigQuery. BigQuery uses its default keys for a second layer of encryption (Envelope Encryption).",
        "wg": [
          { "t": "客戶端", "en": "Client-side", "ps": "adjective" }
        ]
      }
    ],
    "answer": "(C)",
    "why": {
      "t": "題目強調「金鑰材料絕不能存儲在雲端供應商的基礎設施中」。只有 **Cloud EKM** 符合此要求，它允許金鑰保留在外部系統中，Google 僅在需要時透過 API 請求使用金鑰進行操作（金鑰材料不離開外部 HSM）。(A) 和 (B) 的金鑰材料最終仍位於 Google 的資料中心內（無論是軟體還是 HSM）。(D) 雖然符合要求，但導致 BigQuery 喪失分析能力（無法查詢加密的 Blob）。",
      "en": "The question emphasizes 'Key Material must never be stored on the cloud provider's infrastructure'. Only **Cloud EKM** meets this requirement, allowing keys to remain in external systems; Google only requests key usage via API when needed (key material never leaves external HSM). (A) and (B) store key material within Google's data centers (software or HSM). (D) meets the requirement but renders BigQuery unable to analyze (cannot query encrypted blobs).",
      "wg": [
        { "t": "喪失", "en": "renders ... unable", "ps": "verb phrase" }
      ]
    }
  },
  {
    "no": "34",
    "level": "hard",
    "keywords": "Compute, GKE, Cost Optimization, Spot VMs, Node Pools",
    "question": [
      {
        "t": "您正在 GKE 上運行一個混合型工作負載。其中包括：1. 關鍵的 API 伺服器 (Stateful)，不能容忍中斷。2. 大量的背景影像處理工作 (Batch jobs)，這是無狀態的且可容錯。",
        "en": "You are running a hybrid workload on GKE. This includes: 1. Critical API servers (Stateful) that cannot tolerate interruptions. 2. A large volume of background image processing work (Batch jobs) that is stateless and fault-tolerant.",
        "wg": [
          { "t": "混合型工作負載", "en": "hybrid workload", "ps": "noun" },
          { "t": "不能容忍中斷", "en": "cannot tolerate interruptions", "ps": "verb phrase" }
        ]
      },
      {
        "t": "您希望最大程度地降低成本，同時保證 API 伺服器的穩定性。您應該如何配置 GKE 節點池 (Node Pools)？",
        "en": "You want to maximize cost reduction while guaranteeing API server stability. How should you configure GKE Node Pools?",
        "wg": [
          { "t": "最大程度地降低", "en": "maximize ... reduction", "ps": "verb phrase" }
        ]
      }
    ],
    "type": "單選題",
    "options": [
      {
        "t": "(A) 建立一個單一的節點池，混合使用標準實例和 Spot VMs。使用 Pod Disruption Budgets (PDB) 來防止 API 伺服器被驅逐。",
        "en": "(A) Create a single node pool using a mix of standard instances and Spot VMs. Use Pod Disruption Budgets (PDB) to prevent API servers from being evicted.",
        "wg": [
          { "t": "驅逐", "en": "evicted", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 建立兩個節點池。池 A 使用標準實例，並設定 Taint `tier=critical`。池 B 使用 Spot VMs，不設定 Taint。在 API 伺服器 Pod 上設定 Toleration 和 Node Affinity 指向池 A；在批次作業 Pod 上設定 Node Affinity 指向池 B。",
        "en": "(B) Create two node pools. Pool A uses standard instances with Taint `tier=critical`. Pool B uses Spot VMs with no Taint. Configure Tolerations and Node Affinity on API server Pods to point to Pool A; configure Node Affinity on batch job Pods to point to Pool B.",
        "wg": [
          { "t": "容忍度", "en": "Toleration", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 建立兩個節點池。池 A 使用標準實例。池 B 使用 Spot VMs。在 API 伺服器 Pod 上設定 `requiredDuringSchedulingIgnoredDuringExecution` Node Affinity 指向池 A。批次作業 Pod 不需要特殊配置。",
        "en": "(C) Create two node pools. Pool A uses standard instances. Pool B uses Spot VMs. Configure `requiredDuringSchedulingIgnoredDuringExecution` Node Affinity on API server Pods to point to Pool A. Batch job Pods need no special configuration.",
        "wg": [
          { "t": "特殊配置", "en": "special configuration", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 啟用 GKE Autopilot。Autopilot 會自動識別 Pod 的優先級 (Priority Class)，並將關鍵 Pod 安排在標準節點上，將非關鍵 Pod 安排在 Spot 節點上。",
        "en": "(D) Enable GKE Autopilot. Autopilot automatically identifies Pod Priority Class and schedules critical Pods on standard nodes and non-critical Pods on Spot nodes.",
        "wg": [
          { "t": "優先級", "en": "Priority Class", "ps": "noun" }
        ]
      }
    ],
    "answer": "(B)",
    "why": {
      "t": "最佳實踐是隔離工作負載。(B) 使用 Taint 可以**主動阻止**非關鍵的批次作業 (Batch jobs) 意外調度到昂貴的關鍵節點池 (Pool A)，確保池 A 專供 API 伺服器使用。同時 Node Affinity 確保 API 伺服器只去池 A。(C) 雖然 API 伺服器去了池 A，但批次作業可能會填滿池 A，導致資源競爭。(A) PDB 無法阻止 Spot VM 被 Google 硬體收回。(D) Autopilot 支援 Spot，但在使用上仍需在 Pod spec 中明確聲明 `cloud.google.com/gke-spot=true` (Node Selector)，並非完全自動依賴 Priority Class。",
      "en": "Best practice is workload isolation. (B) Using Taints **actively prevents** non-critical batch jobs from being accidentally scheduled on the expensive critical pool (Pool A), ensuring Pool A is dedicated to API servers. Node Affinity ensures API servers only go to Pool A. (C) While API servers go to Pool A, batch jobs might fill up Pool A, causing resource contention. (A) PDB cannot prevent Spot VM reclamation by Google. (D) Autopilot supports Spot but requires explicit `cloud.google.com/gke-spot=true` (Node Selector) declaration in Pod spec, not purely automatic based on Priority Class.",
      "wg": [
        { "t": "主動阻止", "en": "actively prevents", "ps": "verb phrase" },
        { "t": "資源競爭", "en": "resource contention", "ps": "noun" }
      ]
    }
  },
  {
    "no": "35",
    "level": "hard",
    "keywords": "Data Analytics, Pub/Sub, Dataflow, Scalability",
    "question": [
      {
        "t": "您的遊戲公司即將舉行一場大型線上活動。您預計會有數百萬玩家同時在線，每秒產生 100,000 條遙測事件 (Telemetry Events)。這些事件透過 Pub/Sub 傳送，並由 Dataflow 處理後寫入 BigQuery。",
        "en": "Your gaming company is about to host a massive online event. You expect millions of concurrent players generating 100,000 telemetry events per second. These events are sent via Pub/Sub, processed by Dataflow, and written to BigQuery.",
        "wg": [
          { "t": "遙測事件", "en": "Telemetry Events", "ps": "noun" },
          { "t": "同時在線", "en": "concurrent", "ps": "adjective" }
        ]
      },
      {
        "t": "在壓力測試中，您發現 Pub/Sub 的積壓 (Backlog) 隨時間增加，Dataflow 的處理延遲也隨之上升。您檢查了配額，發現並未達到上限。您應該採取哪兩項行動來優化 Dataflow 管道的吞吐量？",
        "en": "During stress testing, you noticed Pub/Sub backlog increasing over time, and Dataflow processing latency rising accordingly. You checked quotas and haven't hit limits. Which two actions should you take to optimize Dataflow pipeline throughput?",
        "wg": [
          { "t": "積壓", "en": "Backlog", "ps": "noun" },
          { "t": "吞吐量", "en": "throughput", "ps": "noun" }
        ]
      }
    ],
    "type": "複選題",
    "options": [
      {
        "t": "(A) 啟用 Dataflow Streaming Engine。這將 Shuffle 和 State 管理從 Worker VM 卸載到專用的服務後端，顯著提升自動擴展的響應速度和處理能力。",
        "en": "(A) Enable Dataflow Streaming Engine. This offloads Shuffle and State management from Worker VMs to a dedicated service backend, significantly improving autoscaling responsiveness and processing power.",
        "wg": [
          { "t": "卸載", "en": "offloads", "ps": "verb" }
        ]
      },
      {
        "t": "(B) 增加 Pub/Sub 主題的分區 (Partitions) 數量，以增加並行寫入的能力。",
        "en": "(B) Increase the number of Pub/Sub topic partitions to increase parallel write capacity.",
        "wg": [
          { "t": "分區", "en": "partitions", "ps": "noun" }
        ]
      },
      {
        "t": "(C) 在 Dataflow 管道中使用 `GroupByKey` 操作前，先應用一個隨機密鑰進行 `Reshuffle`，以防止特定的熱點鍵 (Hot Keys) 導致單一 Worker 過載。",
        "en": "(C) Apply a random key `Reshuffle` before `GroupByKey` operations in the Dataflow pipeline to prevent specific Hot Keys from overloading a single Worker.",
        "wg": [
          { "t": "熱點鍵", "en": "Hot Keys", "ps": "noun" }
        ]
      },
      {
        "t": "(D) 將 Dataflow Worker 的機器類型更改為 N2D (高效能)，並啟用 `enable_fast_cloning`。",
        "en": "(D) Change the Dataflow Worker machine type to N2D (high performance) and enable `enable_fast_cloning`.",
        "wg": [
          { "t": "高效能", "en": "high performance", "ps": "adjective" }
        ]
      },
      {
        "t": "(E) 在 Pub/Sub 訂閱中啟用 `Enable Message Ordering`，以確保 Dataflow 按順序處理訊息，減少亂序重組的開銷。",
        "en": "(E) Enable `Enable Message Ordering` in the Pub/Sub subscription to ensure Dataflow processes messages in order, reducing out-of-order reassembly overhead.",
        "wg": [
          { "t": "按順序", "en": "in order", "ps": "adverb phrase" }
        ]
      }
    ],
    "answer": "(A), (C)",
    "why": {
      "t": "Dataflow 效能瓶頸通常來自兩方面：1. Shuffle/State 管理負擔過重，2. 數據傾斜 (Data Skew/Hot Keys)。(A) **Streaming Engine** 是解決第一個問題的關鍵，它將複雜的 Shuffle 移出 VM。(C) **Reshuffle (防止 Hot Keys)** 是解決數據傾斜的標準模式，特別是在遊戲遙測中，某些玩家或房間的事件可能遠多於其他。(B) Pub/Sub 自動擴展，沒有「分區」概念需用戶管理 (那是 Kafka)。(E) 啟用 Message Ordering 會限制並行處理能力，反而降低吞吐量。",
      "en": "Dataflow performance bottlenecks usually stem from: 1. Heavy Shuffle/State management, 2. Data Skew/Hot Keys. (A) **Streaming Engine** is key to solving the first, moving complex Shuffle out of VMs. (C) **Reshuffle (preventing Hot Keys)** is standard for data skew, especially in gaming where some players/rooms generate far more events. (B) Pub/Sub autoscales; there are no user-managed 'partitions' (that's Kafka). (E) Enabling Message Ordering limits parallelism, actually reducing throughput.",
      "wg": [
        { "t": "數據傾斜", "en": "Data Skew", "ps": "noun" },
        { "t": "限制", "en": "limits", "ps": "verb" }
      ]
    }
  }
]
